{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from trainer import Trainer, TrainerArgs\n",
    "\n",
    "from TTS.tts.configs.glow_tts_config import GlowTTSConfig\n",
    "\n",
    "from TTS.tts.configs.shared_configs import BaseDatasetConfig\n",
    "from TTS.tts.datasets import load_tts_samples\n",
    "from TTS.tts.models.glow_tts import GlowTTS\n",
    "from TTS.tts.utils.text.tokenizer import TTSTokenizer\n",
    "from TTS.utils.audio import AudioProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"train\"\n",
    "dataset_path = \"LJSpeech-1.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset_config = BaseDatasetConfig(\n",
    "    formatter=\"ljspeech\", meta_file_train=\"metadata.csv\", path=dataset_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = GlowTTSConfig(\n",
    "    batch_size=32,\n",
    "    eval_batch_size=8,\n",
    "    num_loader_workers=8,\n",
    "    num_eval_loader_workers=8,\n",
    "    run_eval=True,\n",
    "    test_delay_epochs=-1,\n",
    "    epochs=40,\n",
    "    text_cleaner=\"phoneme_cleaners\",\n",
    "    use_phonemes=True,\n",
    "    phoneme_language=\"en-us\",\n",
    "    phoneme_cache_path=os.path.join(output_path, \"phoneme_cache\"),\n",
    "    print_step=25,\n",
    "    print_eval=True,\n",
    "    mixed_precision=True,\n",
    "    output_path=output_path,\n",
    "    datasets=[dataset_config],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ap = AudioProcessor.init_from_config(config)\n",
    "\n",
    "tokenizer, config = TTSTokenizer.init_from_config(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples, eval_samples = load_tts_samples(\n",
    "    dataset_config,\n",
    "    eval_split=True,\n",
    "    eval_split_max_size=config.eval_split_max_size,\n",
    "    eval_split_size=config.eval_split_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GlowTTS(config, ap, tokenizer, speaker_manager=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " > Training Environment:\n",
      " | > Backend: Torch\n",
      " | > Mixed precision: True\n",
      " | > Precision: fp16\n",
      " | > Current device: 0\n",
      " | > Num. of GPUs: 1\n",
      " | > Num. of CPUs: 16\n",
      " | > Num. of Torch Threads: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " | > Torch seed: 54321\n",
      " | > Torch CUDNN: True\n",
      " | > Torch CUDNN deterministic: False\n",
      " | > Torch CUDNN benchmark: False\n",
      " | > Torch TF32 MatMul: False\n",
      " > Start Tensorboard: tensorboard --logdir=train/run-February-22-2025_01+01AM-9b6e3e6\n",
      "\n",
      " > Model has 28610449 parameters\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    TrainerArgs(), config, output_path, model=model, train_samples=train_samples, eval_samples=eval_samples\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 0/10\u001b[0m\n",
      " --> train/run-February-22-2025_01+01AM-9b6e3e6\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-22 01:01:20) \u001b[0m\n",
      "d͡ʒoʊsɪf di. nɪkɔl,\n",
      "Character '͡' not found in the vocabulary. Discarding it.\n",
      "ðə ɪŋkaʊntɚ ɪn ðə lʌnt͡ʃɹum.\n",
      "Character '͡' not found in the vocabulary. Discarding it.\n",
      "noʊ soʊld͡ʒɚz iðɚ.\n",
      "Character '͡' not found in the vocabulary. Discarding it.\n",
      "æftɚ fɚðɚ kwɛst͡ʃənɪŋ\n",
      "Character '͡' not found in the vocabulary. Discarding it.\n",
      "ðə soʊld͡ʒɚz ðɛn?\n",
      "Character '͡' not found in the vocabulary. Discarding it.\n",
      "ɪn kwɪɡliz d͡ʒʌd͡ʒmənt,\n",
      "Character '͡' not found in the vocabulary. Discarding it.\n",
      "ðə dʌt͡ʃəs əv kɛnt.\n",
      "Character '͡' not found in the vocabulary. Discarding it.\n",
      "hɚ kæptən wəz d͡ʒɑn smɪθ,\n",
      "Character '͡' not found in the vocabulary. Discarding it.\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:01:28 -- STEP: 0/811 -- GLOBAL_STEP: 0\u001b[0m\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 4.5945  (4.594481706619263)\n",
      "     | > loader_time: 3.4383  (3.438286781311035)\n",
      "\n",
      " [!] `train_step()` retuned `None` outputs. Skipping training step.\n",
      " [!] `train_step()` retuned `None` outputs. Skipping training step.\n",
      " [!] `train_step()` retuned `None` outputs. Skipping training step.\n",
      " [!] `train_step()` retuned `None` outputs. Skipping training step.\n",
      " [!] `train_step()` retuned `None` outputs. Skipping training step.\n",
      " [!] `train_step()` retuned `None` outputs. Skipping training step.\n",
      " [!] `train_step()` retuned `None` outputs. Skipping training step.\n",
      " [!] `train_step()` retuned `None` outputs. Skipping training step.\n",
      " [!] `train_step()` retuned `None` outputs. Skipping training step.\n",
      " [!] `train_step()` retuned `None` outputs. Skipping training step.\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:01:41 -- STEP: 25/811 -- GLOBAL_STEP: 25\u001b[0m\n",
      "     | > loss: 3.9555912017822266  (4.052179463704427)\n",
      "     | > log_mle: 0.8365178108215332  (0.8260264197985331)\n",
      "     | > loss_dur: 3.1190733909606934  (3.226153008143107)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(10.6877, device='cuda:0')  (tensor(10.1719, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.5192  (0.5051443481445312)\n",
      "     | > loader_time: 0.0046  (3.7345070838928227)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:01:58 -- STEP: 50/811 -- GLOBAL_STEP: 50\u001b[0m\n",
      "     | > loss: 4.125707149505615  (4.042190110683442)\n",
      "     | > log_mle: 0.8257442116737366  (0.8278882563114166)\n",
      "     | > loss_dur: 3.2999627590179443  (3.214301860332489)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(11.0949, device='cuda:0')  (tensor(10.6673, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.7999  (0.5933951807022094)\n",
      "     | > loader_time: 0.0058  (1.8701472473144536)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:02:17 -- STEP: 75/811 -- GLOBAL_STEP: 75\u001b[0m\n",
      "     | > loss: 4.013096332550049  (4.031085678247307)\n",
      "     | > log_mle: 0.8271570801734924  (0.8288087872358468)\n",
      "     | > loss_dur: 3.185939073562622  (3.202276879090529)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(10.7993, device='cuda:0')  (tensor(10.7664, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.5543  (0.6449004618326822)\n",
      "     | > loader_time: 0.0034  (1.24901268641154)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:02:37 -- STEP: 100/811 -- GLOBAL_STEP: 100\u001b[0m\n",
      "     | > loss: 4.053307056427002  (4.0222837050755835)\n",
      "     | > log_mle: 0.820000171661377  (0.8294922716087765)\n",
      "     | > loss_dur: 3.233306884765625  (3.1927914301554363)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(10.9502, device='cuda:0')  (tensor(10.8056, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 1.1664  (0.6803517603874208)\n",
      "     | > loader_time: 0.0176  (0.9383572316169745)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:02:59 -- STEP: 125/811 -- GLOBAL_STEP: 125\u001b[0m\n",
      "     | > loss: 3.907080888748169  (4.019252764660378)\n",
      "     | > log_mle: 0.8318209648132324  (0.8297700182251309)\n",
      "     | > loss_dur: 3.0752599239349365  (3.1894827407339346)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(10.7684, device='cuda:0')  (tensor(10.8389, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.4436  (0.7156081771850588)\n",
      "     | > loader_time: 0.0038  (0.7530546894073491)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:03:18 -- STEP: 150/811 -- GLOBAL_STEP: 150\u001b[0m\n",
      "     | > loss: 4.101287841796875  (4.015740624495914)\n",
      "     | > log_mle: 0.8339043259620667  (0.8300950178078241)\n",
      "     | > loss_dur: 3.267383337020874  (3.185645602430616)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(11.1057, device='cuda:0')  (tensor(10.8582, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.4914  (0.718474143346151)\n",
      "     | > loader_time: 0.0077  (0.6292549324035648)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:03:39 -- STEP: 175/811 -- GLOBAL_STEP: 175\u001b[0m\n",
      "     | > loss: 3.9633162021636963  (4.012083926345361)\n",
      "     | > log_mle: 0.8337584137916565  (0.8300689993482647)\n",
      "     | > loss_dur: 3.1295578479766846  (3.182014917604852)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(11.0064, device='cuda:0')  (tensor(10.8714, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 1.0995  (0.733154433114188)\n",
      "     | > loader_time: 0.0068  (0.540730314254761)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:04:00 -- STEP: 200/811 -- GLOBAL_STEP: 200\u001b[0m\n",
      "     | > loss: 3.896812677383423  (4.006369464020977)\n",
      "     | > log_mle: 0.8324115872383118  (0.830267996537058)\n",
      "     | > loss_dur: 3.064401149749756  (3.1761014612097496)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(10.6908, device='cuda:0')  (tensor(10.8752, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.5617  (0.7430115258693695)\n",
      "     | > loader_time: 0.0111  (0.4746846997737886)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:04:20 -- STEP: 225/811 -- GLOBAL_STEP: 225\u001b[0m\n",
      "     | > loss: 3.952315330505371  (4.000636084135185)\n",
      "     | > log_mle: 0.8304363489151001  (0.8302802302116572)\n",
      "     | > loss_dur: 3.1218791007995605  (3.1703558500422995)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(10.7780, device='cuda:0')  (tensor(10.8740, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.6059  (0.7478994072808159)\n",
      "     | > loader_time: 0.0045  (0.42349112086825913)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:04:39 -- STEP: 250/811 -- GLOBAL_STEP: 250\u001b[0m\n",
      "     | > loss: 4.050116062164307  (3.9975414901971784)\n",
      "     | > log_mle: 0.8344279527664185  (0.830237249781688)\n",
      "     | > loss_dur: 3.2156879901885986  (3.1673042406638467)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(11.0077, device='cuda:0')  (tensor(10.8763, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.7687  (0.7481365642547607)\n",
      "     | > loader_time: 0.0047  (0.3823601293563844)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:04:58 -- STEP: 275/811 -- GLOBAL_STEP: 275\u001b[0m\n",
      "     | > loss: 3.9446630477905273  (3.994902810510596)\n",
      "     | > log_mle: 0.8275009393692017  (0.8301484197940466)\n",
      "     | > loss_dur: 3.1171622276306152  (3.1647543925159387)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(10.8506, device='cuda:0')  (tensor(10.8767, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.8721  (0.7485688148845325)\n",
      "     | > loader_time: 0.005  (0.3483307014812123)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:05:17 -- STEP: 300/811 -- GLOBAL_STEP: 300\u001b[0m\n",
      "     | > loss: 3.965703010559082  (3.993788091067607)\n",
      "     | > log_mle: 0.8350074291229248  (0.8301562981358888)\n",
      "     | > loss_dur: 3.1306955814361572  (3.163631792726188)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(10.8272, device='cuda:0')  (tensor(10.8777, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.4439  (0.7467893195152283)\n",
      "     | > loader_time: 0.0049  (0.32026932001113906)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:05:36 -- STEP: 325/811 -- GLOBAL_STEP: 325\u001b[0m\n",
      "     | > loss: 3.905095100402832  (3.9904213806939475)\n",
      "     | > log_mle: 0.8265878558158875  (0.8301304813415283)\n",
      "     | > loss_dur: 3.0785071849823  (3.1602908982170947)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(10.8416, device='cuda:0')  (tensor(10.8734, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.5052  (0.748287818615253)\n",
      "     | > loader_time: 0.007  (0.29638983799861046)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:05:56 -- STEP: 350/811 -- GLOBAL_STEP: 350\u001b[0m\n",
      "     | > loss: 4.052164077758789  (3.9870640102554744)\n",
      "     | > log_mle: 0.8253610134124756  (0.8300542761297786)\n",
      "     | > loss_dur: 3.2268030643463135  (3.157009732723235)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(11.0654, device='cuda:0')  (tensor(10.8674, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.6245  (0.7498236649377004)\n",
      "     | > loader_time: 0.0138  (0.2761061007635935)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:06:14 -- STEP: 375/811 -- GLOBAL_STEP: 375\u001b[0m\n",
      "     | > loss: 3.9458484649658203  (3.983925097609217)\n",
      "     | > log_mle: 0.8301047682762146  (0.8299301077241765)\n",
      "     | > loss_dur: 3.115743637084961  (3.153994988088737)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(10.7030, device='cuda:0')  (tensor(10.8609, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.4715  (0.7488325684865315)\n",
      "     | > loader_time: 0.0058  (0.25816002146403)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:06:35 -- STEP: 400/811 -- GLOBAL_STEP: 400\u001b[0m\n",
      "     | > loss: 3.8830254077911377  (3.980586441969258)\n",
      "     | > log_mle: 0.8310415148735046  (0.8298543636615459)\n",
      "     | > loss_dur: 3.0519838333129883  (3.1507320752510646)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(10.6055, device='cuda:0')  (tensor(10.8522, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.8019  (0.7534034603834151)\n",
      "     | > loader_time: 0.0047  (0.2427332186698914)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:06:55 -- STEP: 425/811 -- GLOBAL_STEP: 425\u001b[0m\n",
      "     | > loss: 3.940486192703247  (3.9762353196201534)\n",
      "     | > log_mle: 0.82253497838974  (0.8297541546534342)\n",
      "     | > loss_dur: 3.1179511547088623  (3.146481162381458)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(10.7450, device='cuda:0')  (tensor(10.8407, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 1.5009  (0.7552029177721807)\n",
      "     | > loader_time: 0.0052  (0.2289486391404096)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:07:15 -- STEP: 450/811 -- GLOBAL_STEP: 450\u001b[0m\n",
      "     | > loss: 3.8866994380950928  (3.9711870458993026)\n",
      "     | > log_mle: 0.8129057288169861  (0.8296877461400898)\n",
      "     | > loss_dur: 3.073793649673462  (3.1414992982690975)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(10.6869, device='cuda:0')  (tensor(10.8272, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.6158  (0.7570833677715724)\n",
      "     | > loader_time: 0.006  (0.21673614713880754)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:07:36 -- STEP: 475/811 -- GLOBAL_STEP: 475\u001b[0m\n",
      "     | > loss: 3.908291816711426  (3.967812633514402)\n",
      "     | > log_mle: 0.8250256776809692  (0.8296489746339858)\n",
      "     | > loss_dur: 3.083266019821167  (3.138163656829505)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(10.6610, device='cuda:0')  (tensor(10.8148, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.8549  (0.7602981928775184)\n",
      "     | > loader_time: 0.0077  (0.2058639034472014)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:07:58 -- STEP: 500/811 -- GLOBAL_STEP: 500\u001b[0m\n",
      "     | > loss: 3.96956729888916  (3.9639398117454667)\n",
      "     | > log_mle: 0.8292227387428284  (0.8294674711568014)\n",
      "     | > loss_dur: 3.1403446197509766  (3.1344723409535926)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(10.6265, device='cuda:0')  (tensor(10.8017, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.907  (0.7648301973342895)\n",
      "     | > loader_time: 0.0066  (0.19620894050598148)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:08:17 -- STEP: 525/811 -- GLOBAL_STEP: 525\u001b[0m\n",
      "     | > loss: 3.8031563758850098  (3.9596619624535996)\n",
      "     | > log_mle: 0.8212277293205261  (0.8292009619833195)\n",
      "     | > loss_dur: 2.981928586959839  (3.130460999775858)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(10.4142, device='cuda:0')  (tensor(10.7874, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.4751  (0.7648658075786771)\n",
      "     | > loader_time: 0.0063  (0.18729629970732192)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:08:38 -- STEP: 550/811 -- GLOBAL_STEP: 550\u001b[0m\n",
      "     | > loss: 3.8797483444213867  (3.9553974186932583)\n",
      "     | > log_mle: 0.8258774280548096  (0.828978360582281)\n",
      "     | > loss_dur: 3.053870916366577  (3.1264190563449143)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(10.4033, device='cuda:0')  (tensor(10.7719, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.9014  (0.7669858936829999)\n",
      "     | > loader_time: 0.0058  (0.17922015883705836)\n",
      "\n",
      "ðə fɑsfeɪts wɪt͡ʃ ðə pɹɑsɛs əv “boʊltɪŋ” ɹimuvz tə ə lɑɹd͡ʒ ɪkstɛnt fɹʌm waɪt flaʊɚ, ɡoʊ dɪɹɛktli tə ðə mænjəfækt͡ʃɚ əv boʊn,\n",
      "Character '“' not found in the vocabulary. Discarding it.\n",
      "ðə fɑsfeɪts wɪt͡ʃ ðə pɹɑsɛs əv “boʊltɪŋ” ɹimuvz tə ə lɑɹd͡ʒ ɪkstɛnt fɹʌm waɪt flaʊɚ, ɡoʊ dɪɹɛktli tə ðə mænjəfækt͡ʃɚ əv boʊn,\n",
      "Character '”' not found in the vocabulary. Discarding it.\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:08:59 -- STEP: 575/811 -- GLOBAL_STEP: 575\u001b[0m\n",
      "     | > loss: 3.823526620864868  (3.9508384392324785)\n",
      "     | > log_mle: 0.8238480091094971  (0.8287756773222867)\n",
      "     | > loss_dur: 2.999678611755371  (3.1220627607497486)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(10.2766, device='cuda:0')  (tensor(10.7554, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.975  (0.7694902374433431)\n",
      "     | > loader_time: 0.0072  (0.17188126107920765)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:09:22 -- STEP: 600/811 -- GLOBAL_STEP: 600\u001b[0m\n",
      "     | > loss: 3.7834296226501465  (3.945821181798384)\n",
      "     | > log_mle: 0.8185145854949951  (0.8285280869168752)\n",
      "     | > loss_dur: 2.9649150371551514  (3.1172930931640876)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(10.1402, device='cuda:0')  (tensor(10.7369, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 1.4721  (0.7743994128704066)\n",
      "     | > loader_time: 0.0064  (0.16531778494517002)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:09:44 -- STEP: 625/811 -- GLOBAL_STEP: 625\u001b[0m\n",
      "     | > loss: 4.010653018951416  (3.941230276929652)\n",
      "     | > log_mle: 0.8223215341567993  (0.8282963003569501)\n",
      "     | > loss_dur: 3.1883316040039062  (3.1129339753127683)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(10.6028, device='cuda:0')  (tensor(10.7189, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.9373  (0.7783945621490473)\n",
      "     | > loader_time: 0.0221  (0.15916852836608877)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:10:05 -- STEP: 650/811 -- GLOBAL_STEP: 650\u001b[0m\n",
      "     | > loss: 3.831927537918091  (3.9355652604252085)\n",
      "     | > log_mle: 0.8260261416435242  (0.8280136958695948)\n",
      "     | > loss_dur: 3.005901336669922  (3.1075515631586312)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(10.2743, device='cuda:0')  (tensor(10.6986, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.7034  (0.7800310263266925)\n",
      "     | > loader_time: 0.0075  (0.15352805944589462)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:10:25 -- STEP: 675/811 -- GLOBAL_STEP: 675\u001b[0m\n",
      "     | > loss: 3.8612358570098877  (3.9314556792266373)\n",
      "     | > log_mle: 0.8250312209129333  (0.8277965937341962)\n",
      "     | > loss_dur: 3.0362045764923096  (3.1036590837894518)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(10.2863, device='cuda:0')  (tensor(10.6794, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.825  (0.7804246199572521)\n",
      "     | > loader_time: 0.0058  (0.14816338185910827)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:10:46 -- STEP: 700/811 -- GLOBAL_STEP: 700\u001b[0m\n",
      "     | > loss: 3.705026626586914  (3.9264812300170666)\n",
      "     | > log_mle: 0.8243380188941956  (0.8275554488534512)\n",
      "     | > loss_dur: 2.8806886672973633  (3.098925780558931)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(9.8779, device='cuda:0')  (tensor(10.6574, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.4083  (0.7815533798081528)\n",
      "     | > loader_time: 0.0051  (0.14322634424482078)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:11:05 -- STEP: 725/811 -- GLOBAL_STEP: 725\u001b[0m\n",
      "     | > loss: 3.6955642700195312  (3.920680088096564)\n",
      "     | > log_mle: 0.8244917392730713  (0.8272656837543407)\n",
      "     | > loss_dur: 2.87107253074646  (3.0934144040087714)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(9.8306, device='cuda:0')  (tensor(10.6343, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.5815  (0.7796009076874826)\n",
      "     | > loader_time: 0.0066  (0.13863649598483385)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:11:24 -- STEP: 750/811 -- GLOBAL_STEP: 750\u001b[0m\n",
      "     | > loss: 3.6260368824005127  (3.9139965659863227)\n",
      "     | > log_mle: 0.8149606585502625  (0.8269757749261083)\n",
      "     | > loss_dur: 2.8110761642456055  (3.087020791221309)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(9.6363, device='cuda:0')  (tensor(10.6086, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.486  (0.7793238255182896)\n",
      "     | > loader_time: 0.0044  (0.13438874244689952)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:11:47 -- STEP: 775/811 -- GLOBAL_STEP: 775\u001b[0m\n",
      "     | > loss: 3.694925308227539  (3.907689000110999)\n",
      "     | > log_mle: 0.8210809826850891  (0.8267191445126253)\n",
      "     | > loss_dur: 2.8738443851470947  (3.0809698562996055)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(9.7657, device='cuda:0')  (tensor(10.5833, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 1.2422  (0.7830525302886957)\n",
      "     | > loader_time: 0.0078  (0.13044555971699384)\n",
      "\n",
      "bɹɛd ɹeɪzd wɪθ wʌt ɪz noʊn tə beɪkɚz æz ə “spʌnd͡ʒ,” ɹikwaɪɚz mɔɹ taɪm ænd ə tɹaɪfəl mɔɹ wɚk ðən ðə sɪmplɚ fɔɹm fɚ wɪt͡ʃ aɪ hæv d͡ʒʌst ɔlɹɛdi ɡɪvən dɪɹɛkʃənz.\n",
      "Character '“' not found in the vocabulary. Discarding it.\n",
      "bɹɛd ɹeɪzd wɪθ wʌt ɪz noʊn tə beɪkɚz æz ə “spʌnd͡ʒ,” ɹikwaɪɚz mɔɹ taɪm ænd ə tɹaɪfəl mɔɹ wɚk ðən ðə sɪmplɚ fɔɹm fɚ wɪt͡ʃ aɪ hæv d͡ʒʌst ɔlɹɛdi ɡɪvən dɪɹɛkʃənz.\n",
      "Character '”' not found in the vocabulary. Discarding it.\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:12:08 -- STEP: 800/811 -- GLOBAL_STEP: 800\u001b[0m\n",
      "     | > loss: 3.7254319190979004  (3.9017020065573185)\n",
      "     | > log_mle: 0.8201586008071899  (0.8264663034602057)\n",
      "     | > loss_dur: 2.9052734375  (3.075235704530643)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(9.7588, device='cuda:0')  (tensor(10.5580, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.4785  (0.7844527456164354)\n",
      "     | > loader_time: 0.0079  (0.12675419449806216)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "kɚvwisiɚ maɪt hæv lɪvd ə sɛnt͡ʃɚi ɚliɚ.\n",
      "Character '͡' not found in the vocabulary. Discarding it.\n",
      "bʌt əkɔɹdɪŋ tə ðə ɑpəzɪt vju noʊ ɹizən kən bi əsaɪnd waɪ sʌt͡ʃ ʃʊd bi ðə keɪs.\n",
      "ðɪs d͡ʒeɪl wəz nɑmənəli tə ɹipleɪs ðə ɡɪltspɚ stɹit kəmptɚ,\n",
      "Character '͡' not found in the vocabulary. Discarding it.\n",
      "Character '͡' not found in the vocabulary. Discarding it.\n",
      "ʌndɚ ðə eɪbəl ænd ɛnɚd͡ʒɛtɪk lidɚʃɪp əv d͡ʒɛnɚəl d͡ʒɑnsən.\n",
      "Character '͡' not found in the vocabulary. Discarding it.\n",
      "kəntɪnjud dænsɪŋ ænd ɹɛvəlɪŋ ʌntɪl ðeɪ lɚnd ðə kæpt͡ʃɚ bʌt tu sɚtənli.\n",
      "Character '͡' not found in the vocabulary. Discarding it.\n",
      "dɪskʌst ɪn t͡ʃæptɚ sɪks əv ðɪs ɹɪpɔɹt.\n",
      "Character '͡' not found in the vocabulary. Discarding it.\n",
      "ðə pɛnʌltəmɪt əv sʌt͡ʃ ɪnæktmənts, mɛni əv ðə pɹəvɪʒənz əv wɪt͡ʃ stɪl ɹɪmeɪn ɪn fɔɹs.\n",
      "Character '͡' not found in the vocabulary. Discarding it.\n",
      "t͡ʃæptɚ sɛvən. li hɑɹvi ɔzwɔld, bækɡɹaʊnd ænd pɑsəbəl moʊtɪvz, pɑɹt tu.\n",
      "Character '͡' not found in the vocabulary. Discarding it.\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: 3.559353828430176  (3.559353828430176)\n",
      "     | > log_mle: 0.8156291246414185  (0.8156291246414185)\n",
      "     | > loss_dur: 2.743724822998047  (2.743724822998047)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: 3.6279280185699463  (3.6279280185699463)\n",
      "     | > log_mle: 0.7998151779174805  (0.7998151779174805)\n",
      "     | > loss_dur: 2.828112840652466  (2.828112840652466)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: 3.5893280506134033  (3.608628034591675)\n",
      "     | > log_mle: 0.8256784081459045  (0.8127467930316925)\n",
      "     | > loss_dur: 2.7636497020721436  (2.7958812713623047)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: 3.74767804145813  (3.654978036880493)\n",
      "     | > log_mle: 0.8232160210609436  (0.8162365357081095)\n",
      "     | > loss_dur: 2.924462080001831  (2.8387415409088135)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: 3.760734796524048  (3.681417226791382)\n",
      "     | > log_mle: 0.8096796870231628  (0.8145973235368729)\n",
      "     | > loss_dur: 2.9510550498962402  (2.86681991815567)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: 3.636920928955078  (3.6725179672241213)\n",
      "     | > log_mle: 0.8166065216064453  (0.8149991631507874)\n",
      "     | > loss_dur: 2.820314407348633  (2.8575188159942626)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: 3.862544298171997  (3.7041890223821006)\n",
      "     | > log_mle: 0.8118694424629211  (0.814477543036143)\n",
      "     | > loss_dur: 3.0506749153137207  (2.8897114992141724)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: 3.569467306137085  (3.684943062918527)\n",
      "     | > log_mle: 0.8143282532691956  (0.814456215926579)\n",
      "     | > loss_dur: 2.755139112472534  (2.8704868725367954)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: 3.6181774139404297  (3.6765973567962646)\n",
      "     | > log_mle: 0.8063405752182007  (0.8134417608380318)\n",
      "     | > loss_dur: 2.8118367195129395  (2.8631556034088135)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: 3.6641287803649902  (3.675211959415012)\n",
      "     | > log_mle: 0.8231649398803711  (0.8145221140649583)\n",
      "     | > loss_dur: 2.840963840484619  (2.8606898519727917)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: 3.741518974304199  (3.6818426609039308)\n",
      "     | > log_mle: 0.8276913166046143  (0.8158390343189239)\n",
      "     | > loss_dur: 2.913827657699585  (2.866003632545471)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: 3.6682395935058594  (3.680606018413197)\n",
      "     | > log_mle: 0.8238099217414856  (0.8165636604482477)\n",
      "     | > loss_dur: 2.8444297313690186  (2.8640423688021572)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: 3.5892529487609863  (3.672993262608846)\n",
      "     | > log_mle: 0.8122919797897339  (0.8162076870600382)\n",
      "     | > loss_dur: 2.776960849761963  (2.8567855755488076)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: 3.813556671142578  (3.683805832496056)\n",
      "     | > log_mle: 0.8218838572502136  (0.8166443155362055)\n",
      "     | > loss_dur: 2.9916727542877197  (2.867161512374878)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: 3.617410659790039  (3.679063320159912)\n",
      "     | > log_mle: 0.8019490838050842  (0.8155946561268398)\n",
      "     | > loss_dur: 2.8154616355895996  (2.863468664033072)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: 3.6063733100891113  (3.6742173194885255)\n",
      "     | > log_mle: 0.8180018663406372  (0.8157551368077596)\n",
      "     | > loss_dur: 2.7883713245391846  (2.85846217473348)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: 3.812605142593384  (3.682866558432579)\n",
      "     | > log_mle: 0.8096745014190674  (0.8153750970959663)\n",
      "     | > loss_dur: 3.0029306411743164  (2.867491453886032)\n",
      "\n",
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time: 0.21255211532115936 \u001b[0m(+0.0)\n",
      "     | > avg_loss: 3.682866558432579 \u001b[0m(+0.0)\n",
      "     | > avg_log_mle: 0.8153750970959663 \u001b[0m(+0.0)\n",
      "     | > avg_loss_dur: 2.867491453886032 \u001b[0m(+0.0)\n",
      "\n",
      " > BEST MODEL : train/run-February-22-2025_01+01AM-9b6e3e6/best_model_811.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 1/10\u001b[0m\n",
      " --> train/run-February-22-2025_01+01AM-9b6e3e6\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-22 01:12:41) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:12:50 -- STEP: 14/811 -- GLOBAL_STEP: 825\u001b[0m\n",
      "     | > loss: 3.7178211212158203  (3.797896010535104)\n",
      "     | > log_mle: 0.8050602674484253  (0.8076506938253131)\n",
      "     | > loss_dur: 2.9127609729766846  (2.9902453252247403)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(9.7169, device='cuda:0')  (tensor(9.5589, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.4846  (0.47057758058820454)\n",
      "     | > loader_time: 0.0093  (0.0046117305755615234)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:13:01 -- STEP: 39/811 -- GLOBAL_STEP: 850\u001b[0m\n",
      "     | > loss: 3.7333667278289795  (3.7585417796403933)\n",
      "     | > log_mle: 0.8201798796653748  (0.8114267175014203)\n",
      "     | > loss_dur: 2.91318678855896  (2.947115054497352)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(9.5846, device='cuda:0')  (tensor(9.5757, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.5409  (0.4531885477212759)\n",
      "     | > loader_time: 0.0054  (0.005021975590632513)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:13:20 -- STEP: 64/811 -- GLOBAL_STEP: 875\u001b[0m\n",
      "     | > loss: 3.6660072803497314  (3.702665839344263)\n",
      "     | > log_mle: 0.8174457550048828  (0.8123985882848501)\n",
      "     | > loss_dur: 2.8485615253448486  (2.890267252922058)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(9.5469, device='cuda:0')  (tensor(9.4872, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.8325  (0.5603388510644438)\n",
      "     | > loader_time: 0.0211  (0.008497610688209537)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:13:37 -- STEP: 89/811 -- GLOBAL_STEP: 900\u001b[0m\n",
      "     | > loss: 3.538466453552246  (3.6776554450560153)\n",
      "     | > log_mle: 0.8181048631668091  (0.8127076666006882)\n",
      "     | > loss_dur: 2.7203614711761475  (2.8649477824736183)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(9.1800, device='cuda:0')  (tensor(9.4444, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.6519  (0.5901884014686842)\n",
      "     | > loader_time: 0.0512  (0.009440357765454925)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:13:54 -- STEP: 114/811 -- GLOBAL_STEP: 925\u001b[0m\n",
      "     | > loss: 3.6239962577819824  (3.663299332585251)\n",
      "     | > log_mle: 0.8230563402175903  (0.8127843528463129)\n",
      "     | > loss_dur: 2.8009400367736816  (2.8505149828760254)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(9.3446, device='cuda:0')  (tensor(9.4104, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.556  (0.6123883285020525)\n",
      "     | > loader_time: 0.0098  (0.009374603890536124)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:14:11 -- STEP: 139/811 -- GLOBAL_STEP: 950\u001b[0m\n",
      "     | > loss: 3.7119011878967285  (3.650915819963963)\n",
      "     | > log_mle: 0.8226979970932007  (0.8127584538871436)\n",
      "     | > loss_dur: 2.8892033100128174  (2.838157369078493)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(9.3637, device='cuda:0')  (tensor(9.3781, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.5504  (0.6161054038315367)\n",
      "     | > loader_time: 0.0637  (0.009524925149601998)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:14:28 -- STEP: 164/811 -- GLOBAL_STEP: 975\u001b[0m\n",
      "     | > loss: 3.4850776195526123  (3.63951788588268)\n",
      "     | > log_mle: 0.814526379108429  (0.812658048984481)\n",
      "     | > loss_dur: 2.670551300048828  (2.826859839078859)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(9.0827, device='cuda:0')  (tensor(9.3449, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.9469  (0.629266237340322)\n",
      "     | > loader_time: 0.0172  (0.009640447977112563)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:14:45 -- STEP: 189/811 -- GLOBAL_STEP: 1000\u001b[0m\n",
      "     | > loss: 3.4696452617645264  (3.6265424243987554)\n",
      "     | > log_mle: 0.801760733127594  (0.8122080315357794)\n",
      "     | > loss_dur: 2.667884588241577  (2.814334397593506)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(8.9492, device='cuda:0')  (tensor(9.3070, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 1.0533  (0.6295703517066107)\n",
      "     | > loader_time: 0.0047  (0.00928456821138897)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:15:00 -- STEP: 214/811 -- GLOBAL_STEP: 1025\u001b[0m\n",
      "     | > loss: 3.551232099533081  (3.6154535440641027)\n",
      "     | > log_mle: 0.8046988844871521  (0.8121086537280929)\n",
      "     | > loss_dur: 2.746533155441284  (2.803344894792434)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(8.9877, device='cuda:0')  (tensor(9.2656, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.6893  (0.6283663533558357)\n",
      "     | > loader_time: 0.0048  (0.008945297972064154)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:15:16 -- STEP: 239/811 -- GLOBAL_STEP: 1050\u001b[0m\n",
      "     | > loss: 3.476961851119995  (3.60436113209904)\n",
      "     | > log_mle: 0.7994897365570068  (0.8117015326871034)\n",
      "     | > loss_dur: 2.6774721145629883  (2.7926596048985584)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(8.6910, device='cuda:0')  (tensor(9.2223, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.7142  (0.6266831872852279)\n",
      "     | > loader_time: 0.0058  (0.00861186063439277)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:15:31 -- STEP: 264/811 -- GLOBAL_STEP: 1075\u001b[0m\n",
      "     | > loss: 3.4285495281219482  (3.5958831825039606)\n",
      "     | > log_mle: 0.7988383173942566  (0.811299612124761)\n",
      "     | > loss_dur: 2.629711151123047  (2.784583575797805)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(8.6132, device='cuda:0')  (tensor(9.1832, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.4822  (0.6250077133828943)\n",
      "     | > loader_time: 0.0046  (0.008462431755932892)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:15:49 -- STEP: 289/811 -- GLOBAL_STEP: 1100\u001b[0m\n",
      "     | > loss: 3.466526508331299  (3.588426048780395)\n",
      "     | > log_mle: 0.80558180809021  (0.8108865214466636)\n",
      "     | > loss_dur: 2.660944700241089  (2.777539532077356)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(8.5430, device='cuda:0')  (tensor(9.1426, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.5475  (0.6317335536323204)\n",
      "     | > loader_time: 0.0095  (0.00863316232357883)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:16:05 -- STEP: 314/811 -- GLOBAL_STEP: 1125\u001b[0m\n",
      "     | > loss: 3.520014524459839  (3.580415592831411)\n",
      "     | > log_mle: 0.8004279136657715  (0.810624921018151)\n",
      "     | > loss_dur: 2.7195866107940674  (2.7697906759893844)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(8.6693, device='cuda:0')  (tensor(9.1002, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.6792  (0.6292290771083465)\n",
      "     | > loader_time: 0.0068  (0.008537757928204383)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:16:22 -- STEP: 339/811 -- GLOBAL_STEP: 1150\u001b[0m\n",
      "     | > loss: 3.454435110092163  (3.573048158381189)\n",
      "     | > log_mle: 0.8143308758735657  (0.8102412981621284)\n",
      "     | > loss_dur: 2.640104293823242  (2.7628068635597365)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(8.2883, device='cuda:0')  (tensor(9.0566, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.5728  (0.6343437985333016)\n",
      "     | > loader_time: 0.0046  (0.008341066956871725)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:16:38 -- STEP: 364/811 -- GLOBAL_STEP: 1175\u001b[0m\n",
      "     | > loss: 3.5254905223846436  (3.564727615524124)\n",
      "     | > log_mle: 0.79988032579422  (0.8097536349362069)\n",
      "     | > loss_dur: 2.7256102561950684  (2.7549739846816443)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(8.5056, device='cuda:0')  (tensor(9.0107, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.8506  (0.6329042996679036)\n",
      "     | > loader_time: 0.0048  (0.008235998206086207)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:16:59 -- STEP: 389/811 -- GLOBAL_STEP: 1200\u001b[0m\n",
      "     | > loss: 3.415111541748047  (3.557909445774892)\n",
      "     | > log_mle: 0.8047589063644409  (0.8093132133042598)\n",
      "     | > loss_dur: 2.6103525161743164  (2.74859623553514)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(8.1002, device='cuda:0')  (tensor(8.9667, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.5871  (0.6455987075913537)\n",
      "     | > loader_time: 0.0064  (0.00860990779258904)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:17:18 -- STEP: 414/811 -- GLOBAL_STEP: 1225\u001b[0m\n",
      "     | > loss: 3.4883830547332764  (3.550270540702746)\n",
      "     | > log_mle: 0.7993581295013428  (0.8089050519581579)\n",
      "     | > loss_dur: 2.6890249252319336  (2.7413654914800683)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(8.2626, device='cuda:0')  (tensor(8.9208, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.7708  (0.6502630480245695)\n",
      "     | > loader_time: 0.0237  (0.008725246945441053)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:17:35 -- STEP: 439/811 -- GLOBAL_STEP: 1250\u001b[0m\n",
      "     | > loss: 3.390019416809082  (3.542216627907373)\n",
      "     | > log_mle: 0.8066321611404419  (0.8084657898253351)\n",
      "     | > loss_dur: 2.5833871364593506  (2.733750839711323)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(8.0527, device='cuda:0')  (tensor(8.8727, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.8864  (0.6518390026613903)\n",
      "     | > loader_time: 0.0118  (0.008695517694216925)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:17:54 -- STEP: 464/811 -- GLOBAL_STEP: 1275\u001b[0m\n",
      "     | > loss: 3.388632297515869  (3.5355646240300147)\n",
      "     | > log_mle: 0.8011202812194824  (0.8080740175370512)\n",
      "     | > loss_dur: 2.5875120162963867  (2.72749060906213)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(7.9378, device='cuda:0')  (tensor(8.8267, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.5823  (0.6572924626284634)\n",
      "     | > loader_time: 0.0041  (0.008704045209391368)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:18:11 -- STEP: 489/811 -- GLOBAL_STEP: 1300\u001b[0m\n",
      "     | > loss: 3.4265003204345703  (3.5295594235870738)\n",
      "     | > log_mle: 0.7912436723709106  (0.8076073270146344)\n",
      "     | > loss_dur: 2.635256767272949  (2.7219520985226944)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(8.0007, device='cuda:0')  (tensor(8.7803, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.6194  (0.6582568705935178)\n",
      "     | > loader_time: 0.0051  (0.00870703090675526)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:18:30 -- STEP: 514/811 -- GLOBAL_STEP: 1325\u001b[0m\n",
      "     | > loss: 3.345252275466919  (3.5233794353351517)\n",
      "     | > log_mle: 0.7969561219215393  (0.807114919451888)\n",
      "     | > loss_dur: 2.5482962131500244  (2.716264518318474)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(7.7528, device='cuda:0')  (tensor(8.7345, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.7282  (0.6621986511616393)\n",
      "     | > loader_time: 0.0334  (0.008938414577380233)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:18:46 -- STEP: 539/811 -- GLOBAL_STEP: 1350\u001b[0m\n",
      "     | > loss: 3.3504390716552734  (3.516991761265969)\n",
      "     | > log_mle: 0.7983445525169373  (0.8065243175388047)\n",
      "     | > loss_dur: 2.5520944595336914  (2.7104674456070894)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(7.5212, device='cuda:0')  (tensor(8.6876, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.3848  (0.6594951334158876)\n",
      "     | > loader_time: 0.0231  (0.00892419850450279)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:19:02 -- STEP: 564/811 -- GLOBAL_STEP: 1375\u001b[0m\n",
      "     | > loss: 3.28944730758667  (3.510916120617102)\n",
      "     | > log_mle: 0.7866514325141907  (0.8060320461472723)\n",
      "     | > loss_dur: 2.502795934677124  (2.704884075949379)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(7.4019, device='cuda:0')  (tensor(8.6409, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.3331  (0.6592728516734241)\n",
      "     | > loader_time: 0.0047  (0.00893622214067067)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:19:20 -- STEP: 589/811 -- GLOBAL_STEP: 1400\u001b[0m\n",
      "     | > loss: 3.4097442626953125  (3.50562927111705)\n",
      "     | > log_mle: 0.7945187091827393  (0.805469008779283)\n",
      "     | > loss_dur: 2.6152255535125732  (2.700160263754517)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(7.5721, device='cuda:0')  (tensor(8.5958, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.4849  (0.6606376859247184)\n",
      "     | > loader_time: 0.0047  (0.00911688845105001)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:19:37 -- STEP: 614/811 -- GLOBAL_STEP: 1425\u001b[0m\n",
      "     | > loss: 3.3474645614624023  (3.500602167281732)\n",
      "     | > log_mle: 0.7948507070541382  (0.8049481364531316)\n",
      "     | > loss_dur: 2.5526139736175537  (2.695654030731525)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(7.3909, device='cuda:0')  (tensor(8.5511, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.6397  (0.6615000485597301)\n",
      "     | > loader_time: 0.007  (0.009090797908919639)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:19:56 -- STEP: 639/811 -- GLOBAL_STEP: 1450\u001b[0m\n",
      "     | > loss: 3.353905200958252  (3.495020181733491)\n",
      "     | > log_mle: 0.7914708852767944  (0.8043496445497627)\n",
      "     | > loss_dur: 2.562434196472168  (2.6906705376501203)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(7.3622, device='cuda:0')  (tensor(8.5061, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.6353  (0.6637524047368019)\n",
      "     | > loader_time: 0.0187  (0.009167507034325634)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:20:14 -- STEP: 664/811 -- GLOBAL_STEP: 1475\u001b[0m\n",
      "     | > loss: 3.3702757358551025  (3.4897189172635596)\n",
      "     | > log_mle: 0.7912595868110657  (0.8038080300552303)\n",
      "     | > loss_dur: 2.5790162086486816  (2.685910887028798)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(7.2965, device='cuda:0')  (tensor(8.4611, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 1.0575  (0.6661185902285296)\n",
      "     | > loader_time: 0.0067  (0.009241264986704635)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:20:32 -- STEP: 689/811 -- GLOBAL_STEP: 1500\u001b[0m\n",
      "     | > loss: 3.3731958866119385  (3.4855579222580864)\n",
      "     | > log_mle: 0.7871766090393066  (0.8032278529272373)\n",
      "     | > loss_dur: 2.586019277572632  (2.6823300695903773)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(7.2116, device='cuda:0')  (tensor(8.4177, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.7839  (0.6678064651516944)\n",
      "     | > loader_time: 0.0067  (0.009242128391570388)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:20:50 -- STEP: 714/811 -- GLOBAL_STEP: 1525\u001b[0m\n",
      "     | > loss: 3.3514819145202637  (3.4807781852593944)\n",
      "     | > log_mle: 0.7867164611816406  (0.8025965714821965)\n",
      "     | > loss_dur: 2.564765453338623  (2.678181613860679)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(7.1612, device='cuda:0')  (tensor(8.3737, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.6449  (0.6683089395865008)\n",
      "     | > loader_time: 0.0202  (0.00939624917273428)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:21:07 -- STEP: 739/811 -- GLOBAL_STEP: 1550\u001b[0m\n",
      "     | > loss: 3.2998037338256836  (3.4753265058236127)\n",
      "     | > log_mle: 0.781501293182373  (0.8020195824690216)\n",
      "     | > loss_dur: 2.5183024406433105  (2.6733069239191822)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(6.9433, device='cuda:0')  (tensor(8.3293, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.4218  (0.6683238049482626)\n",
      "     | > loader_time: 0.0059  (0.009469448471585531)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:21:24 -- STEP: 764/811 -- GLOBAL_STEP: 1575\u001b[0m\n",
      "     | > loss: 3.344886302947998  (3.470158595377238)\n",
      "     | > log_mle: 0.7929320931434631  (0.8013985615750261)\n",
      "     | > loss_dur: 2.5519542694091797  (2.668760034426345)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(7.0139, device='cuda:0')  (tensor(8.2858, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.4872  (0.6676328032428686)\n",
      "     | > loader_time: 0.0051  (0.009475710816408323)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:21:42 -- STEP: 789/811 -- GLOBAL_STEP: 1600\u001b[0m\n",
      "     | > loss: 3.3377647399902344  (3.465159424055363)\n",
      "     | > log_mle: 0.7821153402328491  (0.8008343504106744)\n",
      "     | > loss_dur: 2.555649518966675  (2.6643250744001343)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(6.9501, device='cuda:0')  (tensor(8.2429, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.6339  (0.6690383734056405)\n",
      "     | > loader_time: 0.0114  (0.009636327794296204)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: 3.261584758758545  (3.261584758758545)\n",
      "     | > log_mle: 0.7819939851760864  (0.7819939851760864)\n",
      "     | > loss_dur: 2.479590892791748  (2.479590892791748)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: 3.0760374069213867  (3.0760374069213867)\n",
      "     | > log_mle: 0.7649089694023132  (0.7649089694023132)\n",
      "     | > loss_dur: 2.3111283779144287  (2.3111283779144287)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: 3.268214225769043  (3.172125816345215)\n",
      "     | > log_mle: 0.7909544110298157  (0.7779316902160645)\n",
      "     | > loss_dur: 2.477259874343872  (2.3941941261291504)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: 3.24385666847229  (3.1960361003875732)\n",
      "     | > log_mle: 0.7845390439033508  (0.7801341414451599)\n",
      "     | > loss_dur: 2.459317684173584  (2.4159019788106284)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: 3.2963619232177734  (3.2211175560951233)\n",
      "     | > log_mle: 0.7721195220947266  (0.7781304866075516)\n",
      "     | > loss_dur: 2.524242401123047  (2.442987084388733)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: 3.1748604774475098  (3.2118661403656006)\n",
      "     | > log_mle: 0.7783346176147461  (0.7781713128089904)\n",
      "     | > loss_dur: 2.3965258598327637  (2.433694839477539)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: 3.324272871017456  (3.230600595474243)\n",
      "     | > log_mle: 0.7730469703674316  (0.7773172557353973)\n",
      "     | > loss_dur: 2.5512259006500244  (2.453283349672953)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: 3.2429070472717285  (3.232358660016741)\n",
      "     | > log_mle: 0.7774847745895386  (0.7773411870002747)\n",
      "     | > loss_dur: 2.4654221534729004  (2.455017464501517)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: 3.2142276763916016  (3.2300922870635986)\n",
      "     | > log_mle: 0.7699720859527588  (0.7764200493693352)\n",
      "     | > loss_dur: 2.4442555904388428  (2.453672230243683)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: 3.3068089485168457  (3.238616360558404)\n",
      "     | > log_mle: 0.7849819660186768  (0.7773713734414842)\n",
      "     | > loss_dur: 2.521826982498169  (2.461244980494181)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: 3.293063163757324  (3.2440610408782957)\n",
      "     | > log_mle: 0.7892519235610962  (0.7785594284534454)\n",
      "     | > loss_dur: 2.5038113594055176  (2.465501618385315)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: 3.306595802307129  (3.249746019190008)\n",
      "     | > log_mle: 0.7849779725074768  (0.7791429324583574)\n",
      "     | > loss_dur: 2.521617889404297  (2.470603097568859)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: 3.2181293964385986  (3.2471113006273904)\n",
      "     | > log_mle: 0.7763081192970276  (0.7789066980282465)\n",
      "     | > loss_dur: 2.441821336746216  (2.468204617500305)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: 3.3235650062561035  (3.2529923549065223)\n",
      "     | > log_mle: 0.7831684350967407  (0.7792345239565923)\n",
      "     | > loss_dur: 2.5403966903686523  (2.4737578538747935)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: 3.1669795513153076  (3.2468485832214355)\n",
      "     | > log_mle: 0.7662808895111084  (0.7783092643533435)\n",
      "     | > loss_dur: 2.400698661804199  (2.4685393401554654)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: 3.232445478439331  (3.245888376235962)\n",
      "     | > log_mle: 0.7810271382331848  (0.7784904559453328)\n",
      "     | > loss_dur: 2.451418399810791  (2.467397944132487)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: 3.384394407272339  (3.2545450031757355)\n",
      "     | > log_mle: 0.7724676728248596  (0.7781140320003033)\n",
      "     | > loss_dur: 2.611926794052124  (2.4764309972524643)\n",
      "\n",
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.004525527358055115 \u001b[0m(-0.20802658796310425)\n",
      "     | > avg_loss:\u001b[92m 3.2545450031757355 \u001b[0m(-0.42832155525684357)\n",
      "     | > avg_log_mle:\u001b[92m 0.7781140320003033 \u001b[0m(-0.03726106509566307)\n",
      "     | > avg_loss_dur:\u001b[92m 2.4764309972524643 \u001b[0m(-0.3910604566335678)\n",
      "\n",
      " > BEST MODEL : train/run-February-22-2025_01+01AM-9b6e3e6/best_model_1622.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 2/10\u001b[0m\n",
      " --> train/run-February-22-2025_01+01AM-9b6e3e6\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-22 01:22:06) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:22:09 -- STEP: 3/811 -- GLOBAL_STEP: 1625\u001b[0m\n",
      "     | > loss: 3.4649429321289062  (3.4907153447469077)\n",
      "     | > log_mle: 0.768803596496582  (0.7820117076237997)\n",
      "     | > loss_dur: 2.696139335632324  (2.7087036768595376)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(7.1169, device='cuda:0')  (tensor(7.0702, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.4296  (0.4148007233937581)\n",
      "     | > loader_time: 0.0021  (0.0031714439392089844)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:22:20 -- STEP: 28/811 -- GLOBAL_STEP: 1650\u001b[0m\n",
      "     | > loss: 3.441835403442383  (3.366990336350032)\n",
      "     | > log_mle: 0.7806257605552673  (0.7779004935707364)\n",
      "     | > loss_dur: 2.6612095832824707  (2.5890898278781345)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(6.9960, device='cuda:0')  (tensor(6.8626, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.3907  (0.4230292865208217)\n",
      "     | > loader_time: 0.0038  (0.004406613962990897)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:22:33 -- STEP: 53/811 -- GLOBAL_STEP: 1675\u001b[0m\n",
      "     | > loss: 3.213675022125244  (3.3222964079874866)\n",
      "     | > log_mle: 0.7833823561668396  (0.7779381376392437)\n",
      "     | > loss_dur: 2.4302926063537598  (2.5443582579774677)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(6.7176, device='cuda:0')  (tensor(6.7873, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.9034  (0.4663839160271411)\n",
      "     | > loader_time: 0.0031  (0.004933321251059478)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:22:48 -- STEP: 78/811 -- GLOBAL_STEP: 1700\u001b[0m\n",
      "     | > loss: 3.357527732849121  (3.2983883069111752)\n",
      "     | > log_mle: 0.7766716480255127  (0.7771226366360983)\n",
      "     | > loss_dur: 2.5808560848236084  (2.5212656565201588)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(6.8100, device='cuda:0')  (tensor(6.7338, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.606  (0.5052911929595165)\n",
      "     | > loader_time: 0.0045  (0.005429451282207782)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:23:04 -- STEP: 103/811 -- GLOBAL_STEP: 1725\u001b[0m\n",
      "     | > loss: 3.3400561809539795  (3.2818471737278316)\n",
      "     | > log_mle: 0.76178377866745  (0.776133674441032)\n",
      "     | > loss_dur: 2.5782723426818848  (2.5057134929212563)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(6.6224, device='cuda:0')  (tensor(6.6751, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.6255  (0.5301904307985768)\n",
      "     | > loader_time: 0.0054  (0.005627953890457893)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:23:20 -- STEP: 128/811 -- GLOBAL_STEP: 1750\u001b[0m\n",
      "     | > loss: 3.144169569015503  (3.26915205642581)\n",
      "     | > log_mle: 0.7658244967460632  (0.7750188829377294)\n",
      "     | > loss_dur: 2.378345012664795  (2.494133165106178)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(6.3575, device='cuda:0')  (tensor(6.6215, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.6592  (0.5484695397317407)\n",
      "     | > loader_time: 0.004  (0.005939284339547156)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:23:36 -- STEP: 153/811 -- GLOBAL_STEP: 1775\u001b[0m\n",
      "     | > loss: 3.2891151905059814  (3.2626124067244184)\n",
      "     | > log_mle: 0.7683854103088379  (0.7740675148621103)\n",
      "     | > loss_dur: 2.5207297801971436  (2.488544884849997)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(6.4714, device='cuda:0')  (tensor(6.5770, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.6326  (0.5604593753814695)\n",
      "     | > loader_time: 0.0058  (0.0062581495521894445)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:23:51 -- STEP: 178/811 -- GLOBAL_STEP: 1800\u001b[0m\n",
      "     | > loss: 3.2715389728546143  (3.2531814334097873)\n",
      "     | > log_mle: 0.7657226920127869  (0.7725907557466057)\n",
      "     | > loss_dur: 2.5058162212371826  (2.480590668956885)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(6.3719, device='cuda:0')  (tensor(6.5341, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.732  (0.5646664413173547)\n",
      "     | > loader_time: 0.0043  (0.006535824764980357)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:24:06 -- STEP: 203/811 -- GLOBAL_STEP: 1825\u001b[0m\n",
      "     | > loss: 3.2111988067626953  (3.2445025526244065)\n",
      "     | > log_mle: 0.7555081844329834  (0.7712808280742814)\n",
      "     | > loss_dur: 2.455690622329712  (2.473221716622412)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(6.1589, device='cuda:0')  (tensor(6.4903, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.6597  (0.5694183469405901)\n",
      "     | > loader_time: 0.0041  (0.006650841294838288)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:24:22 -- STEP: 228/811 -- GLOBAL_STEP: 1850\u001b[0m\n",
      "     | > loss: 3.1515636444091797  (3.235659525059817)\n",
      "     | > log_mle: 0.7541820406913757  (0.7698932491373598)\n",
      "     | > loss_dur: 2.397381544113159  (2.4657662699097065)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(6.0516, device='cuda:0')  (tensor(6.4494, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.8003  (0.5757249185913488)\n",
      "     | > loader_time: 0.0048  (0.0067892555604901214)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:24:38 -- STEP: 253/811 -- GLOBAL_STEP: 1875\u001b[0m\n",
      "     | > loss: 3.0488381385803223  (3.228130113465984)\n",
      "     | > log_mle: 0.7552531957626343  (0.7684692811117813)\n",
      "     | > loss_dur: 2.2935848236083984  (2.459660825993231)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(5.8929, device='cuda:0')  (tensor(6.4111, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.52  (0.580904824931631)\n",
      "     | > loader_time: 0.0043  (0.006662202918011208)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:24:54 -- STEP: 278/811 -- GLOBAL_STEP: 1900\u001b[0m\n",
      "     | > loss: 3.1403653621673584  (3.2229691769579336)\n",
      "     | > log_mle: 0.7555834650993347  (0.7669522826620145)\n",
      "     | > loss_dur: 2.384781837463379  (2.4560168878637616)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(6.0009, device='cuda:0')  (tensor(6.3769, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.8215  (0.5847165987645979)\n",
      "     | > loader_time: 0.0059  (0.006669118250016684)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:25:11 -- STEP: 303/811 -- GLOBAL_STEP: 1925\u001b[0m\n",
      "     | > loss: 3.1568539142608643  (3.2184484233163766)\n",
      "     | > log_mle: 0.746340811252594  (0.7655670160901038)\n",
      "     | > loss_dur: 2.410513162612915  (2.452881400734678)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(6.0143, device='cuda:0')  (tensor(6.3469, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.8884  (0.5928760157166533)\n",
      "     | > loader_time: 0.0076  (0.006763217472794032)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:25:28 -- STEP: 328/811 -- GLOBAL_STEP: 1950\u001b[0m\n",
      "     | > loss: 3.109062433242798  (3.212962534369492)\n",
      "     | > log_mle: 0.7428710460662842  (0.7641058293421097)\n",
      "     | > loss_dur: 2.3661913871765137  (2.4488566975768022)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(5.8374, device='cuda:0')  (tensor(6.3167, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.6992  (0.5986177041763209)\n",
      "     | > loader_time: 0.0053  (0.006900217474960699)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:25:45 -- STEP: 353/811 -- GLOBAL_STEP: 1975\u001b[0m\n",
      "     | > loss: 3.1120052337646484  (3.2066007342622234)\n",
      "     | > log_mle: 0.7406935691833496  (0.762694575800099)\n",
      "     | > loss_dur: 2.371311664581299  (2.443906151876908)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(5.7935, device='cuda:0')  (tensor(6.2847, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.8415  (0.602375414148606)\n",
      "     | > loader_time: 0.0048  (0.006936617005648086)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:26:04 -- STEP: 378/811 -- GLOBAL_STEP: 2000\u001b[0m\n",
      "     | > loss: 3.2069106101989746  (3.202031235215525)\n",
      "     | > log_mle: 0.7412325143814087  (0.7612189033990187)\n",
      "     | > loss_dur: 2.4656782150268555  (2.440812325982189)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(5.9721, device='cuda:0')  (tensor(6.2575, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.728  (0.6114948584289148)\n",
      "     | > loader_time: 0.0072  (0.007161693598227526)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:26:19 -- STEP: 403/811 -- GLOBAL_STEP: 2025\u001b[0m\n",
      "     | > loss: 3.0247883796691895  (3.194992368925298)\n",
      "     | > log_mle: 0.7451590299606323  (0.7598142586925783)\n",
      "     | > loss_dur: 2.2796294689178467  (2.435178105943551)\n",
      "     | > amp_scaler: 16384.0  (16424.655086848627)\n",
      "     | > grad_norm: tensor(5.6888, device='cuda:0')  (tensor(6.2138, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.5338  (0.6110219482156832)\n",
      "     | > loader_time: 0.0058  (0.007269384251634773)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:26:35 -- STEP: 428/811 -- GLOBAL_STEP: 2050\u001b[0m\n",
      "     | > loss: 3.0997612476348877  (3.1891905392441795)\n",
      "     | > log_mle: 0.7362549901008606  (0.7583530992269518)\n",
      "     | > loss_dur: 2.363506317138672  (2.430837436257121)\n",
      "     | > amp_scaler: 16384.0  (16422.28037383177)\n",
      "     | > grad_norm: tensor(5.7566, device='cuda:0')  (tensor(6.1881, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.6773  (0.6121286493595518)\n",
      "     | > loader_time: 0.0076  (0.007344369576356122)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:26:52 -- STEP: 453/811 -- GLOBAL_STEP: 2075\u001b[0m\n",
      "     | > loss: 3.051913261413574  (3.18298662840399)\n",
      "     | > log_mle: 0.7373062372207642  (0.7569469834531909)\n",
      "     | > loss_dur: 2.3146071434020996  (2.4260396415297816)\n",
      "     | > amp_scaler: 16384.0  (16420.167770419426)\n",
      "     | > grad_norm: tensor(5.7532, device='cuda:0')  (tensor(6.1630, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.3262  (0.6147354791232821)\n",
      "     | > loader_time: 0.0051  (0.007558505793017794)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:27:08 -- STEP: 478/811 -- GLOBAL_STEP: 2100\u001b[0m\n",
      "     | > loss: 3.117617607116699  (3.1778883450200865)\n",
      "     | > log_mle: 0.7253459692001343  (0.7555109079163446)\n",
      "     | > loss_dur: 2.3922715187072754  (2.4223774332381685)\n",
      "     | > amp_scaler: 16384.0  (16418.276150627607)\n",
      "     | > grad_norm: tensor(5.6650, device='cuda:0')  (tensor(6.1395, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.4543  (0.6160219064816274)\n",
      "     | > loader_time: 0.0044  (0.0076661474036372355)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:27:24 -- STEP: 503/811 -- GLOBAL_STEP: 2125\u001b[0m\n",
      "     | > loss: 3.0707907676696777  (3.1726523915057627)\n",
      "     | > log_mle: 0.7225219011306763  (0.7540388315856814)\n",
      "     | > loss_dur: 2.348268747329712  (2.4186135561281357)\n",
      "     | > amp_scaler: 16384.0  (16416.57256461231)\n",
      "     | > grad_norm: tensor(5.6386, device='cuda:0')  (tensor(6.1176, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.4628  (0.6161379273795705)\n",
      "     | > loader_time: 0.0066  (0.007866425258264862)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:27:40 -- STEP: 528/811 -- GLOBAL_STEP: 2150\u001b[0m\n",
      "     | > loss: 3.096560001373291  (3.166973826560107)\n",
      "     | > log_mle: 0.7168155908584595  (0.7524923807518051)\n",
      "     | > loss_dur: 2.379744529724121  (2.4144814425345618)\n",
      "     | > amp_scaler: 16384.0  (16415.030303030286)\n",
      "     | > grad_norm: tensor(5.7035, device='cuda:0')  (tensor(6.0959, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.7076  (0.6165892233451211)\n",
      "     | > loader_time: 0.0056  (0.007969973213744885)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:27:56 -- STEP: 553/811 -- GLOBAL_STEP: 2175\u001b[0m\n",
      "     | > loss: 3.015721082687378  (3.161165773760777)\n",
      "     | > log_mle: 0.7241144180297852  (0.7510143104556672)\n",
      "     | > loss_dur: 2.2916066646575928  (2.4101514605027203)\n",
      "     | > amp_scaler: 16384.0  (16413.627486437596)\n",
      "     | > grad_norm: tensor(5.6020, device='cuda:0')  (tensor(6.0737, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.6293  (0.6157556800255943)\n",
      "     | > loader_time: 0.0144  (0.008098578582404963)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:28:11 -- STEP: 578/811 -- GLOBAL_STEP: 2200\u001b[0m\n",
      "     | > loss: 3.043613910675049  (3.155751119847941)\n",
      "     | > log_mle: 0.7210056781768799  (0.7495156604938441)\n",
      "     | > loss_dur: 2.322608232498169  (2.4062354556416965)\n",
      "     | > amp_scaler: 16384.0  (16412.346020761226)\n",
      "     | > grad_norm: tensor(5.6251, device='cuda:0')  (tensor(6.0533, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 1.1201  (0.6147415419350863)\n",
      "     | > loader_time: 0.0059  (0.00805891178883483)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:28:26 -- STEP: 603/811 -- GLOBAL_STEP: 2225\u001b[0m\n",
      "     | > loss: 3.178483486175537  (3.150356354800425)\n",
      "     | > log_mle: 0.7072592377662659  (0.7480342204297952)\n",
      "     | > loss_dur: 2.471224308013916  (2.4023221310098375)\n",
      "     | > amp_scaler: 16384.0  (16411.17081260363)\n",
      "     | > grad_norm: tensor(5.7309, device='cuda:0')  (tensor(6.0333, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.496  (0.6142317928485023)\n",
      "     | > loader_time: 0.0054  (0.008115449750403661)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:28:42 -- STEP: 628/811 -- GLOBAL_STEP: 2250\u001b[0m\n",
      "     | > loss: 3.0607311725616455  (3.1448963219952426)\n",
      "     | > log_mle: 0.702937126159668  (0.7465603642972415)\n",
      "     | > loss_dur: 2.3577940464019775  (2.3983359541862628)\n",
      "     | > amp_scaler: 16384.0  (16410.089171974505)\n",
      "     | > grad_norm: tensor(5.6299, device='cuda:0')  (tensor(6.0141, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.6251  (0.6143443531291509)\n",
      "     | > loader_time: 0.0038  (0.008093650553636488)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:28:59 -- STEP: 653/811 -- GLOBAL_STEP: 2275\u001b[0m\n",
      "     | > loss: 2.8841872215270996  (3.138403385740691)\n",
      "     | > log_mle: 0.7133700847625732  (0.7450545986980246)\n",
      "     | > loss_dur: 2.1708171367645264  (2.393348783300262)\n",
      "     | > amp_scaler: 16384.0  (16409.0903522205)\n",
      "     | > grad_norm: tensor(5.3089, device='cuda:0')  (tensor(5.9939, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.4399  (0.6168367366148184)\n",
      "     | > loader_time: 0.0234  (0.00820142131121929)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:29:17 -- STEP: 678/811 -- GLOBAL_STEP: 2300\u001b[0m\n",
      "     | > loss: 2.949320077896118  (3.133326734413439)\n",
      "     | > log_mle: 0.7032771110534668  (0.7435623168242015)\n",
      "     | > loss_dur: 2.2460429668426514  (2.3897644147760397)\n",
      "     | > amp_scaler: 16384.0  (16408.165191740405)\n",
      "     | > grad_norm: tensor(5.4385, device='cuda:0')  (tensor(5.9756, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.6742  (0.6195948412284747)\n",
      "     | > loader_time: 0.0055  (0.00820899255859465)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:29:32 -- STEP: 703/811 -- GLOBAL_STEP: 2325\u001b[0m\n",
      "     | > loss: 3.000491142272949  (3.127965046704917)\n",
      "     | > log_mle: 0.7061767578125  (0.7420700026270673)\n",
      "     | > loss_dur: 2.294314384460449  (2.3858950406016195)\n",
      "     | > amp_scaler: 16384.0  (16407.30583214793)\n",
      "     | > grad_norm: tensor(5.4699, device='cuda:0')  (tensor(5.9572, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.4323  (0.6188295447131147)\n",
      "     | > loader_time: 0.0042  (0.0082341305392226)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:29:48 -- STEP: 728/811 -- GLOBAL_STEP: 2350\u001b[0m\n",
      "     | > loss: 2.979313850402832  (3.1219366815063974)\n",
      "     | > log_mle: 0.6998936533927917  (0.7405780903421914)\n",
      "     | > loss_dur: 2.2794201374053955  (2.3813585864973588)\n",
      "     | > amp_scaler: 16384.0  (16406.505494505494)\n",
      "     | > grad_norm: tensor(5.5040, device='cuda:0')  (tensor(5.9388, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.7251  (0.6189560710073833)\n",
      "     | > loader_time: 0.032  (0.008303564000915701)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:30:03 -- STEP: 753/811 -- GLOBAL_STEP: 2375\u001b[0m\n",
      "     | > loss: 2.9203734397888184  (3.115215034282223)\n",
      "     | > log_mle: 0.6976073980331421  (0.7390732537227797)\n",
      "     | > loss_dur: 2.2227659225463867  (2.376141775493446)\n",
      "     | > amp_scaler: 16384.0  (16405.758300132806)\n",
      "     | > grad_norm: tensor(5.3278, device='cuda:0')  (tensor(5.9192, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.6366  (0.6184166943726155)\n",
      "     | > loader_time: 0.0071  (0.00834838675946038)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:30:19 -- STEP: 778/811 -- GLOBAL_STEP: 2400\u001b[0m\n",
      "     | > loss: 2.898115634918213  (3.1088099951609234)\n",
      "     | > log_mle: 0.6940953731536865  (0.7376465137023238)\n",
      "     | > loss_dur: 2.2040202617645264  (2.3711634764021667)\n",
      "     | > amp_scaler: 16384.0  (16405.059125964002)\n",
      "     | > grad_norm: tensor(5.3056, device='cuda:0')  (tensor(5.9007, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.6888  (0.6174512384483319)\n",
      "     | > loader_time: 0.0044  (0.008454458879014836)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:30:32 -- STEP: 803/811 -- GLOBAL_STEP: 2425\u001b[0m\n",
      "     | > loss: 2.976294994354248  (3.1025966956636224)\n",
      "     | > log_mle: 0.6859859824180603  (0.7361774567797649)\n",
      "     | > loss_dur: 2.290308952331543  (2.3664192339848467)\n",
      "     | > amp_scaler: 16384.0  (16404.403486924028)\n",
      "     | > grad_norm: tensor(5.4287, device='cuda:0')  (tensor(5.8825, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.2803  (0.6146526597950557)\n",
      "     | > loader_time: 0.0053  (0.008467660597519744)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: 2.787235975265503  (2.787235975265503)\n",
      "     | > log_mle: 0.6971705555915833  (0.6971705555915833)\n",
      "     | > loss_dur: 2.0900654792785645  (2.0900654792785645)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: 2.719888210296631  (2.719888210296631)\n",
      "     | > log_mle: 0.6793206930160522  (0.6793206930160522)\n",
      "     | > loss_dur: 2.040567636489868  (2.040567636489868)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: 2.8049700260162354  (2.762429118156433)\n",
      "     | > log_mle: 0.7057256698608398  (0.692523181438446)\n",
      "     | > loss_dur: 2.0992443561553955  (2.069905996322632)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: 2.874983787536621  (2.7999473412831626)\n",
      "     | > log_mle: 0.6906598806381226  (0.6919020811716715)\n",
      "     | > loss_dur: 2.184323787689209  (2.1080452601114907)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: 2.855419635772705  (2.813815414905548)\n",
      "     | > log_mle: 0.6800602674484253  (0.68894162774086)\n",
      "     | > loss_dur: 2.1753594875335693  (2.1248738169670105)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: 2.813347339630127  (2.813721799850464)\n",
      "     | > log_mle: 0.685164749622345  (0.688186252117157)\n",
      "     | > loss_dur: 2.1281826496124268  (2.125535583496094)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: 2.8610410690307617  (2.8216083447138467)\n",
      "     | > log_mle: 0.6775373816490173  (0.686411440372467)\n",
      "     | > loss_dur: 2.1835036277770996  (2.1351969242095947)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: 2.8192837238311768  (2.8212762560163225)\n",
      "     | > log_mle: 0.6878724098205566  (0.6866201502936227)\n",
      "     | > loss_dur: 2.13141131401062  (2.1346561227525984)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: 2.7594783306121826  (2.813551515340805)\n",
      "     | > log_mle: 0.6814675331115723  (0.6859760731458664)\n",
      "     | > loss_dur: 2.0780107975006104  (2.1275754570961)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: 2.881086826324463  (2.821055438783434)\n",
      "     | > log_mle: 0.6916035413742065  (0.6866013473934598)\n",
      "     | > loss_dur: 2.189483404159546  (2.134454117880927)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: 2.815952777862549  (2.8205451726913453)\n",
      "     | > log_mle: 0.6948033571243286  (0.6874215483665467)\n",
      "     | > loss_dur: 2.1211495399475098  (2.1331236600875854)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: 2.8530309200286865  (2.823498422449285)\n",
      "     | > log_mle: 0.6907477378845215  (0.687723929231817)\n",
      "     | > loss_dur: 2.162283182144165  (2.1357745257290928)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: 2.7970311641693115  (2.821292817592621)\n",
      "     | > log_mle: 0.688241720199585  (0.6877670784791311)\n",
      "     | > loss_dur: 2.1087894439697266  (2.133525768915812)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: 2.9066200256347656  (2.8278564489804783)\n",
      "     | > log_mle: 0.6894830465316772  (0.6878990760216346)\n",
      "     | > loss_dur: 2.217137098312378  (2.139957409638625)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: 2.7682642936706543  (2.823599866458348)\n",
      "     | > log_mle: 0.6792751550674438  (0.6872830816677639)\n",
      "     | > loss_dur: 2.088989019393921  (2.136316810335432)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: 2.8054068088531494  (2.8223869959513346)\n",
      "     | > log_mle: 0.6909603476524353  (0.6875282327334086)\n",
      "     | > loss_dur: 2.1144464015960693  (2.1348587830861407)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: 2.8721492290496826  (2.8254971355199814)\n",
      "     | > log_mle: 0.6811611652374268  (0.6871302910149097)\n",
      "     | > loss_dur: 2.190988063812256  (2.138366863131523)\n",
      "\n",
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.003769233822822571 \u001b[0m(-0.0007562935352325439)\n",
      "     | > avg_loss:\u001b[92m 2.8254971355199814 \u001b[0m(-0.4290478676557541)\n",
      "     | > avg_log_mle:\u001b[92m 0.6871302910149097 \u001b[0m(-0.09098374098539352)\n",
      "     | > avg_loss_dur:\u001b[92m 2.138366863131523 \u001b[0m(-0.33806413412094116)\n",
      "\n",
      " > BEST MODEL : train/run-February-22-2025_01+01AM-9b6e3e6/best_model_2433.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 3/10\u001b[0m\n",
      " --> train/run-February-22-2025_01+01AM-9b6e3e6\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-22 01:30:46) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:30:54 -- STEP: 17/811 -- GLOBAL_STEP: 2450\u001b[0m\n",
      "     | > loss: 2.9323158264160156  (2.9423874266007366)\n",
      "     | > log_mle: 0.698108971118927  (0.695973301635069)\n",
      "     | > loss_dur: 2.2342069149017334  (2.246414086397956)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(5.3523, device='cuda:0')  (tensor(5.3591, device='cuda:0'))\n",
      "     | > current_lr: 7.5e-07 \n",
      "     | > step_time: 0.3661  (0.34740732697879567)\n",
      "     | > loader_time: 0.0039  (0.004255449070649988)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:31:02 -- STEP: 42/811 -- GLOBAL_STEP: 2475\u001b[0m\n",
      "     | > loss: 2.74354887008667  (2.9020052012943083)\n",
      "     | > log_mle: 0.6876963376998901  (0.6937503190267653)\n",
      "     | > loss_dur: 2.0558526515960693  (2.2082548538843794)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(5.1378, device='cuda:0')  (tensor(5.2995, device='cuda:0'))\n",
      "     | > current_lr: 7.5e-07 \n",
      "     | > step_time: 0.4749  (0.3425997211819603)\n",
      "     | > loader_time: 0.0045  (0.004239939507983979)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:31:15 -- STEP: 67/811 -- GLOBAL_STEP: 2500\u001b[0m\n",
      "     | > loss: 2.868861675262451  (2.8743243680071475)\n",
      "     | > log_mle: 0.6855260133743286  (0.6919019044335208)\n",
      "     | > loss_dur: 2.183335781097412  (2.1824224493396818)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(5.2502, device='cuda:0')  (tensor(5.2532, device='cuda:0'))\n",
      "     | > current_lr: 7.5e-07 \n",
      "     | > step_time: 0.3634  (0.39776636949226035)\n",
      "     | > loader_time: 0.021  (0.004766531844637288)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:31:29 -- STEP: 92/811 -- GLOBAL_STEP: 2525\u001b[0m\n",
      "     | > loss: 2.7949132919311523  (2.8525214920873228)\n",
      "     | > log_mle: 0.6834226846694946  (0.6902945236019464)\n",
      "     | > loss_dur: 2.1114907264709473  (2.1622269542320915)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(5.0023, device='cuda:0')  (tensor(5.2164, device='cuda:0'))\n",
      "     | > current_lr: 7.5e-07 \n",
      "     | > step_time: 0.3878  (0.43791756681773975)\n",
      "     | > loader_time: 0.0039  (0.005066223766492762)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:31:43 -- STEP: 117/811 -- GLOBAL_STEP: 2550\u001b[0m\n",
      "     | > loss: 2.8077120780944824  (2.84363811240237)\n",
      "     | > log_mle: 0.6758391857147217  (0.6879970069624418)\n",
      "     | > loss_dur: 2.1318728923797607  (2.1556410993266306)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(5.0389, device='cuda:0')  (tensor(5.1958, device='cuda:0'))\n",
      "     | > current_lr: 7.5e-07 \n",
      "     | > step_time: 0.5676  (0.4628227653666439)\n",
      "     | > loader_time: 0.0049  (0.004936134713327785)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:31:57 -- STEP: 142/811 -- GLOBAL_STEP: 2575\u001b[0m\n",
      "     | > loss: 2.8274989128112793  (2.8314204182423337)\n",
      "     | > log_mle: 0.6713112592697144  (0.685925435012495)\n",
      "     | > loss_dur: 2.1561877727508545  (2.145494978192826)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(5.0410, device='cuda:0')  (tensor(5.1717, device='cuda:0'))\n",
      "     | > current_lr: 7.5e-07 \n",
      "     | > step_time: 0.4968  (0.48084065276132504)\n",
      "     | > loader_time: 0.0198  (0.005547024834323938)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:32:11 -- STEP: 167/811 -- GLOBAL_STEP: 2600\u001b[0m\n",
      "     | > loss: 2.780198574066162  (2.8218792655510816)\n",
      "     | > log_mle: 0.6662867069244385  (0.6836525619386912)\n",
      "     | > loss_dur: 2.1139118671417236  (2.138226696117194)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(5.0907, device='cuda:0')  (tensor(5.1515, device='cuda:0'))\n",
      "     | > current_lr: 7.5e-07 \n",
      "     | > step_time: 0.4124  (0.4866317631955632)\n",
      "     | > loader_time: 0.0105  (0.005758332635114295)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:32:25 -- STEP: 192/811 -- GLOBAL_STEP: 2625\u001b[0m\n",
      "     | > loss: 2.827695369720459  (2.8088791631162167)\n",
      "     | > log_mle: 0.6611131429672241  (0.681330737968286)\n",
      "     | > loss_dur: 2.1665823459625244  (2.1275484189391127)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(5.1200, device='cuda:0')  (tensor(5.1280, device='cuda:0'))\n",
      "     | > current_lr: 7.5e-07 \n",
      "     | > step_time: 0.3969  (0.4976913308103879)\n",
      "     | > loader_time: 0.004  (0.005694781740506492)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:32:39 -- STEP: 217/811 -- GLOBAL_STEP: 2650\u001b[0m\n",
      "     | > loss: 2.6757471561431885  (2.796914790632538)\n",
      "     | > log_mle: 0.660391092300415  (0.6793028910039208)\n",
      "     | > loss_dur: 2.0153560638427734  (2.1176118927617233)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.9515, device='cuda:0')  (tensor(5.1038, device='cuda:0'))\n",
      "     | > current_lr: 7.5e-07 \n",
      "     | > step_time: 0.4062  (0.5014644537103892)\n",
      "     | > loader_time: 0.016  (0.005709514090542421)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:32:52 -- STEP: 242/811 -- GLOBAL_STEP: 2675\u001b[0m\n",
      "     | > loss: 2.7845511436462402  (2.7864477437389783)\n",
      "     | > log_mle: 0.6621036529541016  (0.6769798095068656)\n",
      "     | > loss_dur: 2.1224474906921387  (2.109467930537612)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(5.0444, device='cuda:0')  (tensor(5.0810, device='cuda:0'))\n",
      "     | > current_lr: 7.5e-07 \n",
      "     | > step_time: 0.5903  (0.5047074704130822)\n",
      "     | > loader_time: 0.0055  (0.005803841204682659)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:33:07 -- STEP: 267/811 -- GLOBAL_STEP: 2700\u001b[0m\n",
      "     | > loss: 2.702927589416504  (2.7765942262799554)\n",
      "     | > log_mle: 0.6496663689613342  (0.6745942132303332)\n",
      "     | > loss_dur: 2.0532612800598145  (2.1020000097010483)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.9195, device='cuda:0')  (tensor(5.0607, device='cuda:0'))\n",
      "     | > current_lr: 7.5e-07 \n",
      "     | > step_time: 0.4957  (0.5127980217951518)\n",
      "     | > loader_time: 0.0044  (0.00580748547328992)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:33:22 -- STEP: 292/811 -- GLOBAL_STEP: 2725\u001b[0m\n",
      "     | > loss: 2.6316945552825928  (2.769016968877349)\n",
      "     | > log_mle: 0.644832968711853  (0.6723342101051384)\n",
      "     | > loss_dur: 1.9868615865707397  (2.0966827559144545)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.7773, device='cuda:0')  (tensor(5.0436, device='cuda:0'))\n",
      "     | > current_lr: 7.5e-07 \n",
      "     | > step_time: 0.6063  (0.5181048496128766)\n",
      "     | > loader_time: 0.0059  (0.006069040461762312)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:33:37 -- STEP: 317/811 -- GLOBAL_STEP: 2750\u001b[0m\n",
      "     | > loss: 2.6559157371520996  (2.7608017462661225)\n",
      "     | > log_mle: 0.6391785144805908  (0.6702771942698242)\n",
      "     | > loss_dur: 2.016737222671509  (2.0905245482357526)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.7683, device='cuda:0')  (tensor(5.0266, device='cuda:0'))\n",
      "     | > current_lr: 7.5e-07 \n",
      "     | > step_time: 0.7387  (0.5241826287579465)\n",
      "     | > loader_time: 0.008  (0.0062664540408161554)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:33:51 -- STEP: 342/811 -- GLOBAL_STEP: 2775\u001b[0m\n",
      "     | > loss: 2.599088668823242  (2.7522506783580236)\n",
      "     | > log_mle: 0.6418133974075317  (0.6681170259651384)\n",
      "     | > loss_dur: 1.9572752714157104  (2.084133648384385)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.7244, device='cuda:0')  (tensor(5.0073, device='cuda:0'))\n",
      "     | > current_lr: 7.5e-07 \n",
      "     | > step_time: 0.5498  (0.5261277113741605)\n",
      "     | > loader_time: 0.0124  (0.00652587832066051)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:34:06 -- STEP: 367/811 -- GLOBAL_STEP: 2800\u001b[0m\n",
      "     | > loss: 2.6076912879943848  (2.7431629145827547)\n",
      "     | > log_mle: 0.6297531127929688  (0.6659173996312092)\n",
      "     | > loss_dur: 1.9779382944107056  (2.077245510891283)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.7357, device='cuda:0')  (tensor(4.9884, device='cuda:0'))\n",
      "     | > current_lr: 7.5e-07 \n",
      "     | > step_time: 0.4979  (0.5304149983689314)\n",
      "     | > loader_time: 0.0049  (0.006655599505764914)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:34:21 -- STEP: 392/811 -- GLOBAL_STEP: 2825\u001b[0m\n",
      "     | > loss: 2.604869842529297  (2.734832420032852)\n",
      "     | > log_mle: 0.6275557279586792  (0.6637107658447049)\n",
      "     | > loss_dur: 1.9773141145706177  (2.071121649778619)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.6685, device='cuda:0')  (tensor(4.9695, device='cuda:0'))\n",
      "     | > current_lr: 7.5e-07 \n",
      "     | > step_time: 0.6047  (0.5347944826495894)\n",
      "     | > loader_time: 0.0058  (0.0067053564957210016)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:34:36 -- STEP: 417/811 -- GLOBAL_STEP: 2850\u001b[0m\n",
      "     | > loss: 2.596318006515503  (2.7254997185951804)\n",
      "     | > log_mle: 0.6221301555633545  (0.6616391658211209)\n",
      "     | > loss_dur: 1.9741878509521484  (2.0638605476283347)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.6672, device='cuda:0')  (tensor(4.9502, device='cuda:0'))\n",
      "     | > current_lr: 7.5e-07 \n",
      "     | > step_time: 0.4947  (0.5363440313499326)\n",
      "     | > loader_time: 0.0141  (0.0070452861648669365)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:34:51 -- STEP: 442/811 -- GLOBAL_STEP: 2875\u001b[0m\n",
      "     | > loss: 2.64937424659729  (2.716563255538768)\n",
      "     | > log_mle: 0.6267234683036804  (0.6594628056519709)\n",
      "     | > loss_dur: 2.022650718688965  (2.057100444897268)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.7178, device='cuda:0')  (tensor(4.9319, device='cuda:0'))\n",
      "     | > current_lr: 7.5e-07 \n",
      "     | > step_time: 0.7382  (0.5397296744773834)\n",
      "     | > loader_time: 0.0316  (0.007240140060493851)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:35:06 -- STEP: 467/811 -- GLOBAL_STEP: 2900\u001b[0m\n",
      "     | > loss: 2.614802837371826  (2.7080411523006207)\n",
      "     | > log_mle: 0.6135638952255249  (0.6573280239003115)\n",
      "     | > loss_dur: 2.001239061355591  (2.0507131240607825)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.6705, device='cuda:0')  (tensor(4.9141, device='cuda:0'))\n",
      "     | > current_lr: 7.5e-07 \n",
      "     | > step_time: 0.6284  (0.5417084448853198)\n",
      "     | > loader_time: 0.006  (0.007342199697229032)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:35:21 -- STEP: 492/811 -- GLOBAL_STEP: 2925\u001b[0m\n",
      "     | > loss: 2.509922504425049  (2.7003052971227386)\n",
      "     | > log_mle: 0.6149188280105591  (0.6551667216832073)\n",
      "     | > loss_dur: 1.8950036764144897  (2.0451385705936236)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.4848, device='cuda:0')  (tensor(4.8972, device='cuda:0'))\n",
      "     | > current_lr: 7.5e-07 \n",
      "     | > step_time: 0.4364  (0.5444537536884716)\n",
      "     | > loader_time: 0.0048  (0.007503430533215285)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:35:35 -- STEP: 517/811 -- GLOBAL_STEP: 2950\u001b[0m\n",
      "     | > loss: 2.541226387023926  (2.6924556205535537)\n",
      "     | > log_mle: 0.6128706932067871  (0.653055685862351)\n",
      "     | > loss_dur: 1.9283555746078491  (2.039399930310202)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.5470, device='cuda:0')  (tensor(4.8810, device='cuda:0'))\n",
      "     | > current_lr: 7.5e-07 \n",
      "     | > step_time: 0.5793  (0.5447447129328896)\n",
      "     | > loader_time: 0.0112  (0.007623839424472714)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:35:51 -- STEP: 542/811 -- GLOBAL_STEP: 2975\u001b[0m\n",
      "     | > loss: 2.5490634441375732  (2.684374231254042)\n",
      "     | > log_mle: 0.6026864051818848  (0.6508962895817423)\n",
      "     | > loss_dur: 1.9463770389556885  (2.033477936723575)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.6143, device='cuda:0')  (tensor(4.8645, device='cuda:0'))\n",
      "     | > current_lr: 7.5e-07 \n",
      "     | > step_time: 0.4486  (0.5473868019906362)\n",
      "     | > loader_time: 0.0047  (0.007656305038621067)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:36:06 -- STEP: 567/811 -- GLOBAL_STEP: 3000\u001b[0m\n",
      "     | > loss: 2.50618314743042  (2.676257210854289)\n",
      "     | > log_mle: 0.6013872623443604  (0.6487992395379135)\n",
      "     | > loss_dur: 1.9047960042953491  (2.0274579663756023)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.4977, device='cuda:0')  (tensor(4.8476, device='cuda:0'))\n",
      "     | > current_lr: 7.5e-07 \n",
      "     | > step_time: 0.6552  (0.5497788508312628)\n",
      "     | > loader_time: 0.0065  (0.007709493082036419)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:36:22 -- STEP: 592/811 -- GLOBAL_STEP: 3025\u001b[0m\n",
      "     | > loss: 2.539355993270874  (2.6687501568246526)\n",
      "     | > log_mle: 0.6008912324905396  (0.6467238970704984)\n",
      "     | > loss_dur: 1.9384647607803345  (2.0220262543172454)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.5218, device='cuda:0')  (tensor(4.8319, device='cuda:0'))\n",
      "     | > current_lr: 7.5e-07 \n",
      "     | > step_time: 0.7314  (0.5527328651499108)\n",
      "     | > loader_time: 0.0048  (0.007818114113163304)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:36:38 -- STEP: 617/811 -- GLOBAL_STEP: 3050\u001b[0m\n",
      "     | > loss: 2.5131490230560303  (2.6614644639495895)\n",
      "     | > log_mle: 0.5913885831832886  (0.6446381266345086)\n",
      "     | > loss_dur: 1.9217604398727417  (2.0168263328712994)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.5032, device='cuda:0')  (tensor(4.8169, device='cuda:0'))\n",
      "     | > current_lr: 7.5e-07 \n",
      "     | > step_time: 0.9086  (0.5564265096593333)\n",
      "     | > loader_time: 0.0137  (0.00792187114202416)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:36:53 -- STEP: 642/811 -- GLOBAL_STEP: 3075\u001b[0m\n",
      "     | > loss: 2.43332839012146  (2.653467568653024)\n",
      "     | > log_mle: 0.5876227617263794  (0.6425607847833195)\n",
      "     | > loss_dur: 1.8457056283950806  (2.010906778206334)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.3888, device='cuda:0')  (tensor(4.8014, device='cuda:0'))\n",
      "     | > current_lr: 7.5e-07 \n",
      "     | > step_time: 0.5891  (0.5570761039620996)\n",
      "     | > loader_time: 0.0116  (0.007925250819910355)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:37:09 -- STEP: 667/811 -- GLOBAL_STEP: 3100\u001b[0m\n",
      "     | > loss: 2.475705146789551  (2.646354577709354)\n",
      "     | > log_mle: 0.5775116682052612  (0.6404718669100685)\n",
      "     | > loss_dur: 1.898193597793579  (2.0058827049907353)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.4787, device='cuda:0')  (tensor(4.7872, device='cuda:0'))\n",
      "     | > current_lr: 7.5e-07 \n",
      "     | > step_time: 0.581  (0.5590545712918541)\n",
      "     | > loader_time: 0.0134  (0.008143007844641824)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:37:24 -- STEP: 692/811 -- GLOBAL_STEP: 3125\u001b[0m\n",
      "     | > loss: 2.4131581783294678  (2.639591228755225)\n",
      "     | > log_mle: 0.57722407579422  (0.6383275019295643)\n",
      "     | > loss_dur: 1.835934042930603  (2.00126372062402)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.3594, device='cuda:0')  (tensor(4.7733, device='cuda:0'))\n",
      "     | > current_lr: 7.5e-07 \n",
      "     | > step_time: 0.6687  (0.5611247709720817)\n",
      "     | > loader_time: 0.0049  (0.008160446420570329)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:37:40 -- STEP: 717/811 -- GLOBAL_STEP: 3150\u001b[0m\n",
      "     | > loss: 2.3583407402038574  (2.632329754583343)\n",
      "     | > log_mle: 0.5669997930526733  (0.6361938015021374)\n",
      "     | > loss_dur: 1.791340947151184  (1.9961359460982322)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.2927, device='cuda:0')  (tensor(4.7586, device='cuda:0'))\n",
      "     | > current_lr: 7.5e-07 \n",
      "     | > step_time: 0.8791  (0.5633027510330443)\n",
      "     | > loader_time: 0.0164  (0.008251794378794053)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:37:56 -- STEP: 742/811 -- GLOBAL_STEP: 3175\u001b[0m\n",
      "     | > loss: 2.3068764209747314  (2.624507557028391)\n",
      "     | > log_mle: 0.5712224841117859  (0.6341102804456441)\n",
      "     | > loss_dur: 1.7356538772583008  (1.9903972698350483)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.1743, device='cuda:0')  (tensor(4.7435, device='cuda:0'))\n",
      "     | > current_lr: 7.5e-07 \n",
      "     | > step_time: 0.58  (0.5645715367761914)\n",
      "     | > loader_time: 0.0235  (0.008289313059290145)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:38:11 -- STEP: 767/811 -- GLOBAL_STEP: 3200\u001b[0m\n",
      "     | > loss: 2.384817600250244  (2.6171468174597465)\n",
      "     | > log_mle: 0.5795263648033142  (0.6320649694743654)\n",
      "     | > loss_dur: 1.8052912950515747  (1.9850818419238894)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.3017, device='cuda:0')  (tensor(4.7292, device='cuda:0'))\n",
      "     | > current_lr: 7.5e-07 \n",
      "     | > step_time: 0.4515  (0.5660515216991528)\n",
      "     | > loader_time: 0.0064  (0.008301881332596397)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:38:27 -- STEP: 792/811 -- GLOBAL_STEP: 3225\u001b[0m\n",
      "     | > loss: 2.351069450378418  (2.6095244333599585)\n",
      "     | > log_mle: 0.5655852556228638  (0.6299947887809595)\n",
      "     | > loss_dur: 1.7854840755462646  (1.9795296389346173)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.2205, device='cuda:0')  (tensor(4.7144, device='cuda:0'))\n",
      "     | > current_lr: 7.5e-07 \n",
      "     | > step_time: 0.41  (0.5672404148963973)\n",
      "     | > loader_time: 0.0052  (0.008402718137008967)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: 2.250122308731079  (2.250122308731079)\n",
      "     | > log_mle: 0.5795291066169739  (0.5795291066169739)\n",
      "     | > loss_dur: 1.6705931425094604  (1.6705931425094604)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: 2.192974090576172  (2.192974090576172)\n",
      "     | > log_mle: 0.5646558403968811  (0.5646558403968811)\n",
      "     | > loss_dur: 1.628318190574646  (1.628318190574646)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: 2.3145103454589844  (2.253742218017578)\n",
      "     | > log_mle: 0.5949971675872803  (0.5798265039920807)\n",
      "     | > loss_dur: 1.7195132970809937  (1.6739157438278198)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: 2.302919626235962  (2.270134687423706)\n",
      "     | > log_mle: 0.5698914527893066  (0.5765148202578226)\n",
      "     | > loss_dur: 1.7330281734466553  (1.6936198870340984)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: 2.3161983489990234  (2.2816506028175354)\n",
      "     | > log_mle: 0.5544054508209229  (0.5709874778985977)\n",
      "     | > loss_dur: 1.7617930173873901  (1.7106631696224213)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: 2.262223958969116  (2.2777652740478516)\n",
      "     | > log_mle: 0.5555603504180908  (0.5679020524024964)\n",
      "     | > loss_dur: 1.7066636085510254  (1.709863257408142)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: 2.317718029022217  (2.284424066543579)\n",
      "     | > log_mle: 0.5439703464508057  (0.5639134347438812)\n",
      "     | > loss_dur: 1.7737476825714111  (1.7205106616020203)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: 2.2863669395446777  (2.2847016198294505)\n",
      "     | > log_mle: 0.5659183263778687  (0.5641998478344509)\n",
      "     | > loss_dur: 1.7204484939575195  (1.7205017805099487)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: 2.239379405975342  (2.2790363430976868)\n",
      "     | > log_mle: 0.561822772026062  (0.5639027133584023)\n",
      "     | > loss_dur: 1.6775566339492798  (1.7151336371898651)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: 2.311814785003662  (2.282678392198351)\n",
      "     | > log_mle: 0.5668981075286865  (0.5642355349328783)\n",
      "     | > loss_dur: 1.744916558265686  (1.718442850642734)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: 2.2611515522003174  (2.2805257081985473)\n",
      "     | > log_mle: 0.5696181654930115  (0.5647737979888916)\n",
      "     | > loss_dur: 1.6915333271026611  (1.7157518982887268)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: 2.3280482292175293  (2.2848459373820913)\n",
      "     | > log_mle: 0.5639969110488892  (0.5647031719034369)\n",
      "     | > loss_dur: 1.7640513181686401  (1.7201427546414463)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: 2.2476158142089844  (2.2817434271176658)\n",
      "     | > log_mle: 0.5670017004013062  (0.564894715944926)\n",
      "     | > loss_dur: 1.6806142330169678  (1.7168487111727397)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: 2.351733446121216  (2.287127274733323)\n",
      "     | > log_mle: 0.562313437461853  (0.5646961560616127)\n",
      "     | > loss_dur: 1.7894200086593628  (1.7224311186717107)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: 2.2231571674346924  (2.2825579813548496)\n",
      "     | > log_mle: 0.5591473579406738  (0.5642998133386885)\n",
      "     | > loss_dur: 1.6640098094940186  (1.7182581680161613)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: 2.288203001022339  (2.282934315999349)\n",
      "     | > log_mle: 0.567253828048706  (0.5644967476526896)\n",
      "     | > loss_dur: 1.7209491729736328  (1.7184375683466593)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: 2.3386034965515137  (2.2864136397838593)\n",
      "     | > log_mle: 0.5560240745544434  (0.5639672055840492)\n",
      "     | > loss_dur: 1.7825793027877808  (1.7224464267492294)\n",
      "\n",
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.0034173130989074707 \u001b[0m(-0.0003519207239151001)\n",
      "     | > avg_loss:\u001b[92m 2.2864136397838593 \u001b[0m(-0.5390834957361221)\n",
      "     | > avg_log_mle:\u001b[92m 0.5639672055840492 \u001b[0m(-0.12316308543086052)\n",
      "     | > avg_loss_dur:\u001b[92m 1.7224464267492294 \u001b[0m(-0.4159204363822937)\n",
      "\n",
      " > BEST MODEL : train/run-February-22-2025_01+01AM-9b6e3e6/best_model_3244.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 4/10\u001b[0m\n",
      " --> train/run-February-22-2025_01+01AM-9b6e3e6\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-22 01:38:46) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:38:50 -- STEP: 6/811 -- GLOBAL_STEP: 3250\u001b[0m\n",
      "     | > loss: 2.39892578125  (2.4858224391937256)\n",
      "     | > log_mle: 0.5850676894187927  (0.5838255981604258)\n",
      "     | > loss_dur: 1.8138580322265625  (1.9019968112309773)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.1634, device='cuda:0')  (tensor(4.4077, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 0.3124  (0.355976939201355)\n",
      "     | > loader_time: 0.0024  (0.0036859909693400064)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:39:00 -- STEP: 31/811 -- GLOBAL_STEP: 3275\u001b[0m\n",
      "     | > loss: 2.347076177597046  (2.4266611299207135)\n",
      "     | > log_mle: 0.5722472071647644  (0.5792085316873365)\n",
      "     | > loss_dur: 1.7748289108276367  (1.8474525905424548)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.2474, device='cuda:0')  (tensor(4.3543, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 0.2901  (0.35599034832369897)\n",
      "     | > loader_time: 0.0032  (0.004831375614289315)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:39:13 -- STEP: 56/811 -- GLOBAL_STEP: 3300\u001b[0m\n",
      "     | > loss: 2.2718353271484375  (2.3936776135649)\n",
      "     | > log_mle: 0.5735306143760681  (0.5775723425405366)\n",
      "     | > loss_dur: 1.6983047723770142  (1.8161052763462067)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.1580, device='cuda:0')  (tensor(4.3163, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 0.8685  (0.4326421959059579)\n",
      "     | > loader_time: 0.0042  (0.007561930588313512)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:39:27 -- STEP: 81/811 -- GLOBAL_STEP: 3325\u001b[0m\n",
      "     | > loss: 2.226219892501831  (2.378818762155227)\n",
      "     | > log_mle: 0.578980028629303  (0.5752572902926693)\n",
      "     | > loss_dur: 1.6472398042678833  (1.8035614725984173)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.1116, device='cuda:0')  (tensor(4.2981, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 0.6057  (0.4631949324666718)\n",
      "     | > loader_time: 0.0043  (0.007488130051412701)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:39:40 -- STEP: 106/811 -- GLOBAL_STEP: 3350\u001b[0m\n",
      "     | > loss: 2.3241395950317383  (2.366658905767044)\n",
      "     | > log_mle: 0.5665294528007507  (0.5721319374048485)\n",
      "     | > loss_dur: 1.7576102018356323  (1.7945269672375805)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.1876, device='cuda:0')  (tensor(4.2772, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 0.6193  (0.4782834367932014)\n",
      "     | > loader_time: 0.0067  (0.006980846512992428)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:39:54 -- STEP: 131/811 -- GLOBAL_STEP: 3375\u001b[0m\n",
      "     | > loss: 2.305527925491333  (2.3554415702819815)\n",
      "     | > log_mle: 0.5585541725158691  (0.5692288561631708)\n",
      "     | > loss_dur: 1.7469737529754639  (1.7862127072938525)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.2153, device='cuda:0')  (tensor(4.2629, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 0.5386  (0.48721075239982314)\n",
      "     | > loader_time: 0.0048  (0.007152349894283383)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:40:08 -- STEP: 156/811 -- GLOBAL_STEP: 3400\u001b[0m\n",
      "     | > loss: 2.1594886779785156  (2.347905513567801)\n",
      "     | > log_mle: 0.5508763194084167  (0.5661873507958195)\n",
      "     | > loss_dur: 1.608612298965454  (1.781718155512443)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.9111, device='cuda:0')  (tensor(4.2528, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 0.4405  (0.4977520704269409)\n",
      "     | > loader_time: 0.0043  (0.006821779104379507)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:40:22 -- STEP: 181/811 -- GLOBAL_STEP: 3425\u001b[0m\n",
      "     | > loss: 2.2541418075561523  (2.338258686645253)\n",
      "     | > log_mle: 0.5375542640686035  (0.5632121250115711)\n",
      "     | > loss_dur: 1.7165875434875488  (1.775046556035458)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.1369, device='cuda:0')  (tensor(4.2412, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 0.6157  (0.5057141938920835)\n",
      "     | > loader_time: 0.0045  (0.006611207572136136)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:40:36 -- STEP: 206/811 -- GLOBAL_STEP: 3450\u001b[0m\n",
      "     | > loss: 2.2484934329986572  (2.3285300465463408)\n",
      "     | > log_mle: 0.5278393626213074  (0.5601613235126425)\n",
      "     | > loss_dur: 1.7206541299819946  (1.7683687186935573)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.1329, device='cuda:0')  (tensor(4.2274, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 0.567  (0.5127604459095925)\n",
      "     | > loader_time: 0.0044  (0.006623190583534611)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:40:51 -- STEP: 231/811 -- GLOBAL_STEP: 3475\u001b[0m\n",
      "     | > loss: 2.2246286869049072  (2.3184543791271355)\n",
      "     | > log_mle: 0.5414459705352783  (0.5574465484330151)\n",
      "     | > loss_dur: 1.683182716369629  (1.7610078260496065)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.0825, device='cuda:0')  (tensor(4.2138, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 0.4966  (0.5211849945448175)\n",
      "     | > loader_time: 0.0045  (0.006506969402362774)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:41:05 -- STEP: 256/811 -- GLOBAL_STEP: 3500\u001b[0m\n",
      "     | > loss: 2.2364587783813477  (2.310016181319949)\n",
      "     | > log_mle: 0.5384799838066101  (0.5545667465776207)\n",
      "     | > loss_dur: 1.6979787349700928  (1.7554494300857186)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.0514, device='cuda:0')  (tensor(4.2019, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 0.5005  (0.5244752885773774)\n",
      "     | > loader_time: 0.0049  (0.006546705029904842)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:41:19 -- STEP: 281/811 -- GLOBAL_STEP: 3525\u001b[0m\n",
      "     | > loss: 2.225175619125366  (2.3036567121213825)\n",
      "     | > log_mle: 0.523225724697113  (0.5516085013800245)\n",
      "     | > loss_dur: 1.7019498348236084  (1.7520482052263415)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.0898, device='cuda:0')  (tensor(4.1936, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 0.326  (0.5274184403470399)\n",
      "     | > loader_time: 0.0039  (0.006563984202320465)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:41:34 -- STEP: 306/811 -- GLOBAL_STEP: 3550\u001b[0m\n",
      "     | > loss: 2.1906204223632812  (2.2972256467233256)\n",
      "     | > log_mle: 0.514946699142456  (0.5489825826454785)\n",
      "     | > loss_dur: 1.6756737232208252  (1.7482430599873362)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.0399, device='cuda:0')  (tensor(4.1868, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 0.4081  (0.5302875447117421)\n",
      "     | > loader_time: 0.0055  (0.00660899262023128)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:41:48 -- STEP: 331/811 -- GLOBAL_STEP: 3575\u001b[0m\n",
      "     | > loss: 2.169917583465576  (2.2904402993596893)\n",
      "     | > log_mle: 0.502347469329834  (0.5463407199008229)\n",
      "     | > loss_dur: 1.6675701141357422  (1.7440995759474187)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.0153, device='cuda:0')  (tensor(4.1776, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 0.7267  (0.5327047927141908)\n",
      "     | > loader_time: 0.0064  (0.006747297650017407)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:42:03 -- STEP: 356/811 -- GLOBAL_STEP: 3600\u001b[0m\n",
      "     | > loss: 2.184553384780884  (2.283359490083842)\n",
      "     | > log_mle: 0.5089845061302185  (0.5439112538869464)\n",
      "     | > loss_dur: 1.6755688190460205  (1.7394482332668948)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.0381, device='cuda:0')  (tensor(4.1678, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 0.4348  (0.5363061053029604)\n",
      "     | > loader_time: 0.0038  (0.006762368625469422)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:42:17 -- STEP: 381/811 -- GLOBAL_STEP: 3625\u001b[0m\n",
      "     | > loss: 2.1914453506469727  (2.2770882009521225)\n",
      "     | > log_mle: 0.4939873218536377  (0.5412773162986978)\n",
      "     | > loss_dur: 1.6974579095840454  (1.735810881524574)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.0827, device='cuda:0')  (tensor(4.1591, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 0.3429  (0.5367085145214409)\n",
      "     | > loader_time: 0.0083  (0.007027706761998455)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:42:31 -- STEP: 406/811 -- GLOBAL_STEP: 3650\u001b[0m\n",
      "     | > loss: 2.192012310028076  (2.2695707987094735)\n",
      "     | > log_mle: 0.5027774572372437  (0.539017323422902)\n",
      "     | > loss_dur: 1.6892348527908325  (1.73055347198336)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.0985, device='cuda:0')  (tensor(4.1482, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 0.4209  (0.5368640663588575)\n",
      "     | > loader_time: 0.0037  (0.007377259249757663)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:42:46 -- STEP: 431/811 -- GLOBAL_STEP: 3675\u001b[0m\n",
      "     | > loss: 2.1756303310394287  (2.2624699776244537)\n",
      "     | > log_mle: 0.4881878197193146  (0.536537957025515)\n",
      "     | > loss_dur: 1.6874425411224365  (1.7259320178330637)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.0798, device='cuda:0')  (tensor(4.1391, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 0.6712  (0.5392742439101853)\n",
      "     | > loader_time: 0.0087  (0.007506699130595975)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:43:01 -- STEP: 456/811 -- GLOBAL_STEP: 3700\u001b[0m\n",
      "     | > loss: 2.20863676071167  (2.2558501216403215)\n",
      "     | > log_mle: 0.49011164903640747  (0.5341994946724494)\n",
      "     | > loss_dur: 1.7185250520706177  (1.7216506247457706)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.0548, device='cuda:0')  (tensor(4.1308, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 0.3336  (0.5419083718667944)\n",
      "     | > loader_time: 0.0041  (0.00744035003478067)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:43:16 -- STEP: 481/811 -- GLOBAL_STEP: 3725\u001b[0m\n",
      "     | > loss: 2.1252903938293457  (2.2497184147705895)\n",
      "     | > log_mle: 0.4843693673610687  (0.5318460072276503)\n",
      "     | > loss_dur: 1.6409211158752441  (1.7178724062417996)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.0369, device='cuda:0')  (tensor(4.1231, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 0.5878  (0.5437905158917268)\n",
      "     | > loader_time: 0.0099  (0.007602509738501789)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:43:31 -- STEP: 506/811 -- GLOBAL_STEP: 3750\u001b[0m\n",
      "     | > loss: 2.157653331756592  (2.2438011546379957)\n",
      "     | > log_mle: 0.4778827428817749  (0.5296165232248462)\n",
      "     | > loss_dur: 1.6797704696655273  (1.7141846305296826)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.9793, device='cuda:0')  (tensor(4.1155, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 0.4884  (0.5467009407729493)\n",
      "     | > loader_time: 0.0053  (0.007648437390685553)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:43:47 -- STEP: 531/811 -- GLOBAL_STEP: 3775\u001b[0m\n",
      "     | > loss: 2.086258888244629  (2.2373929733161417)\n",
      "     | > log_mle: 0.4858655035495758  (0.5273541097587116)\n",
      "     | > loss_dur: 1.600393295288086  (1.7100388633329315)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.9255, device='cuda:0')  (tensor(4.1077, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 0.4495  (0.551068163636489)\n",
      "     | > loader_time: 0.0067  (0.007686198767969164)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:44:07 -- STEP: 556/811 -- GLOBAL_STEP: 3800\u001b[0m\n",
      "     | > loss: 2.1276352405548096  (2.231292479115424)\n",
      "     | > log_mle: 0.48006123304367065  (0.5251531983129417)\n",
      "     | > loss_dur: 1.6475740671157837  (1.7061392802128692)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.9720, device='cuda:0')  (tensor(4.1002, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 0.4253  (0.5605234216443065)\n",
      "     | > loader_time: 0.0068  (0.007822458692591825)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:44:27 -- STEP: 581/811 -- GLOBAL_STEP: 3825\u001b[0m\n",
      "     | > loss: 2.123704195022583  (2.225422717823219)\n",
      "     | > log_mle: 0.46821436285972595  (0.5229742263352407)\n",
      "     | > loss_dur: 1.6554899215698242  (1.7024484905646717)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.9800, device='cuda:0')  (tensor(4.0933, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 0.8685  (0.5701855825269896)\n",
      "     | > loader_time: 0.0101  (0.008219750530748483)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:44:47 -- STEP: 606/811 -- GLOBAL_STEP: 3850\u001b[0m\n",
      "     | > loss: 2.100853204727173  (2.2199164867007704)\n",
      "     | > log_mle: 0.4773758351802826  (0.5209256487809403)\n",
      "     | > loss_dur: 1.6234773397445679  (1.6989908373788638)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.9821, device='cuda:0')  (tensor(4.0869, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 0.6012  (0.578883219473432)\n",
      "     | > loader_time: 0.0317  (0.00845592958305535)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:45:07 -- STEP: 631/811 -- GLOBAL_STEP: 3875\u001b[0m\n",
      "     | > loss: 2.044466257095337  (2.2139102073176735)\n",
      "     | > log_mle: 0.4705082178115845  (0.5188813293603644)\n",
      "     | > loss_dur: 1.5739580392837524  (1.6950288776739275)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.8797, device='cuda:0')  (tensor(4.0800, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 0.4293  (0.5866546506171364)\n",
      "     | > loader_time: 0.0053  (0.008494664674326658)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:45:28 -- STEP: 656/811 -- GLOBAL_STEP: 3900\u001b[0m\n",
      "     | > loss: 2.07706618309021  (2.207779460382172)\n",
      "     | > log_mle: 0.45772358775138855  (0.5168659487602922)\n",
      "     | > loss_dur: 1.6193426847457886  (1.6909135107587023)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.8795, device='cuda:0')  (tensor(4.0729, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 0.8161  (0.5954158204357791)\n",
      "     | > loader_time: 0.0172  (0.008808848697964736)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:45:45 -- STEP: 681/811 -- GLOBAL_STEP: 3925\u001b[0m\n",
      "     | > loss: 2.047760486602783  (2.2028845856718386)\n",
      "     | > log_mle: 0.45947855710983276  (0.5148499781777336)\n",
      "     | > loss_dur: 1.5882819890975952  (1.6880346065750906)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.8467, device='cuda:0')  (tensor(4.0674, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 0.9676  (0.599076551487792)\n",
      "     | > loader_time: 0.0127  (0.008831924628931346)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:46:04 -- STEP: 706/811 -- GLOBAL_STEP: 3950\u001b[0m\n",
      "     | > loss: 2.0958995819091797  (2.197773181682944)\n",
      "     | > log_mle: 0.44876009225845337  (0.5128163107309398)\n",
      "     | > loss_dur: 1.6471394300460815  (1.684956870234384)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.9577, device='cuda:0')  (tensor(4.0615, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 0.9931  (0.603961404254686)\n",
      "     | > loader_time: 0.0431  (0.008993224449265782)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:46:20 -- STEP: 731/811 -- GLOBAL_STEP: 3975\u001b[0m\n",
      "     | > loss: 1.9311765432357788  (2.191889451401342)\n",
      "     | > log_mle: 0.4626554548740387  (0.5108813066570611)\n",
      "     | > loss_dur: 1.4685211181640625  (1.6810081438881266)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.7089, device='cuda:0')  (tensor(4.0547, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 0.554  (0.6046503646918422)\n",
      "     | > loader_time: 0.0079  (0.009051976549641709)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:46:36 -- STEP: 756/811 -- GLOBAL_STEP: 4000\u001b[0m\n",
      "     | > loss: 1.980452299118042  (2.1860097881662783)\n",
      "     | > log_mle: 0.45741984248161316  (0.5089401501038724)\n",
      "     | > loss_dur: 1.5230324268341064  (1.6770696375105116)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.7527, device='cuda:0')  (tensor(4.0477, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 0.812  (0.6053709624305599)\n",
      "     | > loader_time: 0.0054  (0.009010096075673586)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:46:53 -- STEP: 781/811 -- GLOBAL_STEP: 4025\u001b[0m\n",
      "     | > loss: 2.0200414657592773  (2.1800818325768048)\n",
      "     | > log_mle: 0.43554627895355225  (0.507128336937877)\n",
      "     | > loss_dur: 1.5844953060150146  (1.6729534957534067)\n",
      "     | > amp_scaler: 32768.0  (16677.695262483994)\n",
      "     | > grad_norm: tensor(3.8541, device='cuda:0')  (tensor(4.0403, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 1.0191  (0.6065203810776081)\n",
      "     | > loader_time: 0.0096  (0.008971332435266006)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:47:06 -- STEP: 806/811 -- GLOBAL_STEP: 4050\u001b[0m\n",
      "     | > loss: 1.9213370084762573  (2.1743182063694313)\n",
      "     | > log_mle: 0.4524807035923004  (0.5052463317257602)\n",
      "     | > loss_dur: 1.4688563346862793  (1.6690718751983074)\n",
      "     | > amp_scaler: 32768.0  (17176.774193548386)\n",
      "     | > grad_norm: tensor(3.6778, device='cuda:0')  (tensor(4.0334, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 0.3662  (0.603838755830049)\n",
      "     | > loader_time: 0.0052  (0.00903123188255442)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: 1.9125487804412842  (1.9125487804412842)\n",
      "     | > log_mle: 0.466235876083374  (0.466235876083374)\n",
      "     | > loss_dur: 1.4463129043579102  (1.4463129043579102)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: 1.841171383857727  (1.841171383857727)\n",
      "     | > log_mle: 0.4533684253692627  (0.4533684253692627)\n",
      "     | > loss_dur: 1.3878029584884644  (1.3878029584884644)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: 1.9325276613235474  (1.8868495225906372)\n",
      "     | > log_mle: 0.49186787009239197  (0.47261814773082733)\n",
      "     | > loss_dur: 1.440659761428833  (1.4142313599586487)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: 1.931903600692749  (1.9018675486246746)\n",
      "     | > log_mle: 0.45652610063552856  (0.4672541320323944)\n",
      "     | > loss_dur: 1.4753774404525757  (1.4346133867899578)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: 1.9440500736236572  (1.9124131798744202)\n",
      "     | > log_mle: 0.43855929374694824  (0.46008042246103287)\n",
      "     | > loss_dur: 1.505490779876709  (1.4523327350616455)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: 1.8839441537857056  (1.9067193746566773)\n",
      "     | > log_mle: 0.43732750415802  (0.4555298388004303)\n",
      "     | > loss_dur: 1.4466166496276855  (1.4511895179748535)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: 1.9851785898208618  (1.9197959105173747)\n",
      "     | > log_mle: 0.42166176438331604  (0.44988515973091125)\n",
      "     | > loss_dur: 1.5635168552398682  (1.469910740852356)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: 1.9215657711029053  (1.920048747743879)\n",
      "     | > log_mle: 0.4575099050998688  (0.4509744090693338)\n",
      "     | > loss_dur: 1.4640558958053589  (1.4690743344170707)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: 1.9023747444152832  (1.9178394973278046)\n",
      "     | > log_mle: 0.4516885578632355  (0.45106367766857147)\n",
      "     | > loss_dur: 1.4506862163543701  (1.466775819659233)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: 1.9608914852142334  (1.9226230515374079)\n",
      "     | > log_mle: 0.45253831148147583  (0.4512275258700053)\n",
      "     | > loss_dur: 1.5083531141281128  (1.4713955190446641)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: 1.8981337547302246  (1.9201741218566895)\n",
      "     | > log_mle: 0.4552762508392334  (0.4516323983669281)\n",
      "     | > loss_dur: 1.4428575038909912  (1.468541717529297)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: 1.9288363456726074  (1.9209615967490457)\n",
      "     | > log_mle: 0.4487573206424713  (0.45137102766470477)\n",
      "     | > loss_dur: 1.4800790548324585  (1.4695905663750388)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: 1.890425443649292  (1.9184169173240662)\n",
      "     | > log_mle: 0.4576112926006317  (0.45189104974269867)\n",
      "     | > loss_dur: 1.432814121246338  (1.4665258626143138)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: 1.9661389589309692  (1.9220878436015203)\n",
      "     | > log_mle: 0.44497618079185486  (0.4513591367464799)\n",
      "     | > loss_dur: 1.521162748336792  (1.4707286999775813)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: 1.8696540594100952  (1.9183425733021326)\n",
      "     | > log_mle: 0.4471795856952667  (0.451060597385679)\n",
      "     | > loss_dur: 1.4224745035171509  (1.4672819716589791)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: 1.9155226945877075  (1.9181545813878378)\n",
      "     | > log_mle: 0.4529244899749756  (0.45118485689163207)\n",
      "     | > loss_dur: 1.462598204612732  (1.4669697205225627)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: 1.9199784994125366  (1.9182685762643814)\n",
      "     | > log_mle: 0.44425976276397705  (0.45075203850865364)\n",
      "     | > loss_dur: 1.4757187366485596  (1.4675165340304375)\n",
      "\n",
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[91m 0.05183854699134827 \u001b[0m(+0.048421233892440796)\n",
      "     | > avg_loss:\u001b[92m 1.9182685762643814 \u001b[0m(-0.36814506351947784)\n",
      "     | > avg_log_mle:\u001b[92m 0.45075203850865364 \u001b[0m(-0.11321516707539558)\n",
      "     | > avg_loss_dur:\u001b[92m 1.4675165340304375 \u001b[0m(-0.25492989271879196)\n",
      "\n",
      " > BEST MODEL : train/run-February-22-2025_01+01AM-9b6e3e6/best_model_4055.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 5/10\u001b[0m\n",
      " --> train/run-February-22-2025_01+01AM-9b6e3e6\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-22 01:47:21) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:47:30 -- STEP: 20/811 -- GLOBAL_STEP: 4075\u001b[0m\n",
      "     | > loss: 2.011863946914673  (2.0675160944461823)\n",
      "     | > log_mle: 0.4824083149433136  (0.4767155185341835)\n",
      "     | > loss_dur: 1.5294556617736816  (1.5908005654811859)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.8581, device='cuda:0')  (tensor(3.7404, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-06 \n",
      "     | > step_time: 0.3083  (0.349839973449707)\n",
      "     | > loader_time: 0.0034  (0.004535055160522461)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:47:40 -- STEP: 45/811 -- GLOBAL_STEP: 4100\u001b[0m\n",
      "     | > loss: 1.89646577835083  (2.0216362688276504)\n",
      "     | > log_mle: 0.471087783575058  (0.4729662756125132)\n",
      "     | > loss_dur: 1.4253779649734497  (1.5486700005001495)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.6663, device='cuda:0')  (tensor(3.7888, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-06 \n",
      "     | > step_time: 0.4039  (0.37459187507629393)\n",
      "     | > loader_time: 0.0043  (0.005562252468532986)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:47:55 -- STEP: 70/811 -- GLOBAL_STEP: 4125\u001b[0m\n",
      "     | > loss: 1.9722223281860352  (2.0041476096425734)\n",
      "     | > log_mle: 0.45214545726776123  (0.47089935966900415)\n",
      "     | > loss_dur: 1.520076870918274  (1.5332482542310446)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.8116, device='cuda:0')  (tensor(3.7948, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-06 \n",
      "     | > step_time: 0.4522  (0.4393754618508475)\n",
      "     | > loader_time: 0.0041  (0.00582188538142613)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:48:09 -- STEP: 95/811 -- GLOBAL_STEP: 4150\u001b[0m\n",
      "     | > loss: 1.9481730461120605  (1.989721071092706)\n",
      "     | > log_mle: 0.4362911283969879  (0.469426627535569)\n",
      "     | > loss_dur: 1.511881947517395  (1.520294446694224)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.7549, device='cuda:0')  (tensor(3.7860, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-06 \n",
      "     | > step_time: 0.5035  (0.47372807452553195)\n",
      "     | > loader_time: 0.0041  (0.006691478428087736)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:48:24 -- STEP: 120/811 -- GLOBAL_STEP: 4175\u001b[0m\n",
      "     | > loss: 1.929549217224121  (1.9805133849382401)\n",
      "     | > log_mle: 0.4418320059776306  (0.466352200259765)\n",
      "     | > loss_dur: 1.4877172708511353  (1.5141611893971765)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.8204, device='cuda:0')  (tensor(3.7810, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-06 \n",
      "     | > step_time: 0.7829  (0.4975194255510966)\n",
      "     | > loader_time: 0.0048  (0.007270063956578573)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:48:39 -- STEP: 145/811 -- GLOBAL_STEP: 4200\u001b[0m\n",
      "     | > loss: 1.91970956325531  (1.9707712559864439)\n",
      "     | > log_mle: 0.46718427538871765  (0.4643912728490501)\n",
      "     | > loss_dur: 1.45252525806427  (1.5063799866314596)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.7080, device='cuda:0')  (tensor(3.7725, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-06 \n",
      "     | > step_time: 0.5992  (0.5087537403764396)\n",
      "     | > loader_time: 0.0056  (0.00747043017683358)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:48:53 -- STEP: 170/811 -- GLOBAL_STEP: 4225\u001b[0m\n",
      "     | > loss: 1.9194204807281494  (1.963708252766553)\n",
      "     | > log_mle: 0.4397451877593994  (0.461748865071465)\n",
      "     | > loss_dur: 1.47967529296875  (1.5019593912012443)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.7981, device='cuda:0')  (tensor(3.7672, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-06 \n",
      "     | > step_time: 0.4813  (0.5177004154990702)\n",
      "     | > loader_time: 0.0041  (0.00746609463411219)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:49:08 -- STEP: 195/811 -- GLOBAL_STEP: 4250\u001b[0m\n",
      "     | > loss: 1.8965321779251099  (1.952814316138243)\n",
      "     | > log_mle: 0.43570879101753235  (0.4590830697463109)\n",
      "     | > loss_dur: 1.4608234167099  (1.4937312492957489)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.6867, device='cuda:0')  (tensor(3.7568, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-06 \n",
      "     | > step_time: 0.5409  (0.5249574490082572)\n",
      "     | > loader_time: 0.0047  (0.007397703024057242)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:49:22 -- STEP: 220/811 -- GLOBAL_STEP: 4275\u001b[0m\n",
      "     | > loss: 1.8624120950698853  (1.944367271119898)\n",
      "     | > log_mle: 0.44282177090644836  (0.4569787244905125)\n",
      "     | > loss_dur: 1.4195903539657593  (1.4873885474421766)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.6858, device='cuda:0')  (tensor(3.7486, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-06 \n",
      "     | > step_time: 0.5597  (0.5285341273654595)\n",
      "     | > loader_time: 0.0127  (0.007421844655817206)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:49:36 -- STEP: 245/811 -- GLOBAL_STEP: 4300\u001b[0m\n",
      "     | > loss: 1.8684991598129272  (1.9369855661781468)\n",
      "     | > log_mle: 0.45731380581855774  (0.45467713268435733)\n",
      "     | > loss_dur: 1.411185383796692  (1.4823084339803583)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.7392, device='cuda:0')  (tensor(3.7416, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-06 \n",
      "     | > step_time: 0.6664  (0.5312305722917833)\n",
      "     | > loader_time: 0.0044  (0.007364886147635323)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:49:50 -- STEP: 270/811 -- GLOBAL_STEP: 4325\u001b[0m\n",
      "     | > loss: 1.8977162837982178  (1.9307800421008356)\n",
      "     | > log_mle: 0.44109365344047546  (0.4523924888284118)\n",
      "     | > loss_dur: 1.45662260055542  (1.4783875536035613)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.7065, device='cuda:0')  (tensor(3.7357, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-06 \n",
      "     | > step_time: 0.7354  (0.5323962494179058)\n",
      "     | > loader_time: 0.0044  (0.007403978595027217)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:50:06 -- STEP: 295/811 -- GLOBAL_STEP: 4350\u001b[0m\n",
      "     | > loss: 1.9220389127731323  (1.9258040601924313)\n",
      "     | > log_mle: 0.43419793248176575  (0.45030012918730916)\n",
      "     | > loss_dur: 1.487841010093689  (1.4755039316112715)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.7997, device='cuda:0')  (tensor(3.7325, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-06 \n",
      "     | > step_time: 0.5472  (0.5389830670114294)\n",
      "     | > loader_time: 0.0054  (0.007569102109488794)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:50:21 -- STEP: 320/811 -- GLOBAL_STEP: 4375\u001b[0m\n",
      "     | > loss: 1.8264724016189575  (1.919999185949564)\n",
      "     | > log_mle: 0.42214539647102356  (0.44850813299417497)\n",
      "     | > loss_dur: 1.4043270349502563  (1.471491053327918)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.6137, device='cuda:0')  (tensor(3.7275, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-06 \n",
      "     | > step_time: 0.4558  (0.5423319019377237)\n",
      "     | > loader_time: 0.0038  (0.007654401659965515)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:50:36 -- STEP: 345/811 -- GLOBAL_STEP: 4400\u001b[0m\n",
      "     | > loss: 1.8526653051376343  (1.914207625043565)\n",
      "     | > log_mle: 0.434479683637619  (0.4466745415459508)\n",
      "     | > loss_dur: 1.4181855916976929  (1.4675330832384632)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.6469, device='cuda:0')  (tensor(3.7206, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-06 \n",
      "     | > step_time: 0.8652  (0.5459958636242416)\n",
      "     | > loader_time: 0.0055  (0.007701400397480398)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:50:50 -- STEP: 370/811 -- GLOBAL_STEP: 4425\u001b[0m\n",
      "     | > loss: 1.8135812282562256  (1.9090513000617155)\n",
      "     | > log_mle: 0.4119179844856262  (0.4448908795376082)\n",
      "     | > loss_dur: 1.4016631841659546  (1.4641604204435603)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.6792, device='cuda:0')  (tensor(3.7152, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-06 \n",
      "     | > step_time: 0.633  (0.5477017241555295)\n",
      "     | > loader_time: 0.0048  (0.007854452648678338)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:51:06 -- STEP: 395/811 -- GLOBAL_STEP: 4450\u001b[0m\n",
      "     | > loss: 1.7964963912963867  (1.9037687971622128)\n",
      "     | > log_mle: 0.4274592697620392  (0.4431318458122543)\n",
      "     | > loss_dur: 1.36903715133667  (1.4606369513499582)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.5752, device='cuda:0')  (tensor(3.7093, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-06 \n",
      "     | > step_time: 0.6501  (0.5516663720336146)\n",
      "     | > loader_time: 0.0194  (0.008029893681972844)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:51:20 -- STEP: 420/811 -- GLOBAL_STEP: 4475\u001b[0m\n",
      "     | > loss: 1.8280563354492188  (1.898324024393445)\n",
      "     | > log_mle: 0.4136602282524109  (0.4415291754972367)\n",
      "     | > loss_dur: 1.414396047592163  (1.456794848896208)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.6297, device='cuda:0')  (tensor(3.7031, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-06 \n",
      "     | > step_time: 0.553  (0.5519908609844392)\n",
      "     | > loader_time: 0.0063  (0.008065649441310335)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:51:35 -- STEP: 445/811 -- GLOBAL_STEP: 4500\u001b[0m\n",
      "     | > loss: 1.8120907545089722  (1.8924996255488877)\n",
      "     | > log_mle: 0.4098321199417114  (0.4398584146847886)\n",
      "     | > loss_dur: 1.4022586345672607  (1.4526412109310705)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.6146, device='cuda:0')  (tensor(3.6958, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-06 \n",
      "     | > step_time: 0.5626  (0.554000082444609)\n",
      "     | > loader_time: 0.0062  (0.008025543341475925)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:51:51 -- STEP: 470/811 -- GLOBAL_STEP: 4525\u001b[0m\n",
      "     | > loss: 1.773496150970459  (1.8875595128282587)\n",
      "     | > log_mle: 0.3980023264884949  (0.43824691823188294)\n",
      "     | > loss_dur: 1.3754937648773193  (1.4493125938354652)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.5762, device='cuda:0')  (tensor(3.6904, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-06 \n",
      "     | > step_time: 0.5855  (0.5570670609778546)\n",
      "     | > loader_time: 0.0144  (0.008157015861348907)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:52:06 -- STEP: 495/811 -- GLOBAL_STEP: 4550\u001b[0m\n",
      "     | > loss: 1.7120281457901  (1.882609290546841)\n",
      "     | > log_mle: 0.41486692428588867  (0.4367873109350301)\n",
      "     | > loss_dur: 1.2971612215042114  (1.4458219790699505)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.4009, device='cuda:0')  (tensor(3.6846, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-06 \n",
      "     | > step_time: 0.6659  (0.5587814321421614)\n",
      "     | > loader_time: 0.0231  (0.008213949203491215)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:52:20 -- STEP: 520/811 -- GLOBAL_STEP: 4575\u001b[0m\n",
      "     | > loss: 1.7762612104415894  (1.8782217264175416)\n",
      "     | > log_mle: 0.38997364044189453  (0.43518835409329487)\n",
      "     | > loss_dur: 1.3862875699996948  (1.443033371521876)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.5467, device='cuda:0')  (tensor(3.6794, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-06 \n",
      "     | > step_time: 0.613  (0.5592525280438937)\n",
      "     | > loader_time: 0.0057  (0.008231453712169944)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:52:36 -- STEP: 545/811 -- GLOBAL_STEP: 4600\u001b[0m\n",
      "     | > loss: 1.81034255027771  (1.8733640237685738)\n",
      "     | > log_mle: 0.3932264447212219  (0.4337026115404356)\n",
      "     | > loss_dur: 1.4171160459518433  (1.4396614109704249)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.6070, device='cuda:0')  (tensor(3.6729, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-06 \n",
      "     | > step_time: 0.8212  (0.561815337084849)\n",
      "     | > loader_time: 0.0043  (0.008345481015126641)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:52:52 -- STEP: 570/811 -- GLOBAL_STEP: 4625\u001b[0m\n",
      "     | > loss: 1.7549982070922852  (1.8688387145075882)\n",
      "     | > log_mle: 0.4101940989494324  (0.4323043370978874)\n",
      "     | > loss_dur: 1.344804048538208  (1.4365343758934424)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.4971, device='cuda:0')  (tensor(3.6674, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-06 \n",
      "     | > step_time: 0.3628  (0.5634714800014831)\n",
      "     | > loader_time: 0.0047  (0.008414718561005174)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:53:07 -- STEP: 595/811 -- GLOBAL_STEP: 4650\u001b[0m\n",
      "     | > loss: 1.7385505437850952  (1.8644726452707243)\n",
      "     | > log_mle: 0.39544105529785156  (0.430950320017438)\n",
      "     | > loss_dur: 1.3431094884872437  (1.4335223238007364)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.4991, device='cuda:0')  (tensor(3.6618, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-06 \n",
      "     | > step_time: 0.8673  (0.564672274148765)\n",
      "     | > loader_time: 0.0103  (0.008418998798402418)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:53:23 -- STEP: 620/811 -- GLOBAL_STEP: 4675\u001b[0m\n",
      "     | > loss: 1.7676024436950684  (1.860126684173461)\n",
      "     | > log_mle: 0.40271222591400146  (0.4296574727662148)\n",
      "     | > loss_dur: 1.364890217781067  (1.4304692099171308)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.5370, device='cuda:0')  (tensor(3.6562, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-06 \n",
      "     | > step_time: 0.8144  (0.5675019637230905)\n",
      "     | > loader_time: 0.0183  (0.008512421961753601)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:53:39 -- STEP: 645/811 -- GLOBAL_STEP: 4700\u001b[0m\n",
      "     | > loss: 1.7845144271850586  (1.8553024243938832)\n",
      "     | > log_mle: 0.394145667552948  (0.42831847219504127)\n",
      "     | > loss_dur: 1.3903687000274658  (1.4269839508588928)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.5949, device='cuda:0')  (tensor(3.6498, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-06 \n",
      "     | > step_time: 0.5503  (0.5689898801404379)\n",
      "     | > loader_time: 0.0121  (0.008610119930533474)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:53:54 -- STEP: 670/811 -- GLOBAL_STEP: 4725\u001b[0m\n",
      "     | > loss: 1.7497425079345703  (1.8512928601521164)\n",
      "     | > log_mle: 0.3763628602027893  (0.4269396016402031)\n",
      "     | > loss_dur: 1.3733795881271362  (1.424353257399887)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.5390, device='cuda:0')  (tensor(3.6448, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-06 \n",
      "     | > step_time: 0.5301  (0.5707592469542779)\n",
      "     | > loader_time: 0.0053  (0.00871487589024786)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:54:10 -- STEP: 695/811 -- GLOBAL_STEP: 4750\u001b[0m\n",
      "     | > loss: 1.7876653671264648  (1.8475141103319126)\n",
      "     | > log_mle: 0.40944987535476685  (0.42557147839944137)\n",
      "     | > loss_dur: 1.3782154321670532  (1.421942630946208)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.5555, device='cuda:0')  (tensor(3.6398, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-06 \n",
      "     | > step_time: 0.7065  (0.5719090911124254)\n",
      "     | > loader_time: 0.0408  (0.008768168456262826)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:54:25 -- STEP: 720/811 -- GLOBAL_STEP: 4775\u001b[0m\n",
      "     | > loss: 1.7683911323547363  (1.8434192288253042)\n",
      "     | > log_mle: 0.37365400791168213  (0.42420236505568026)\n",
      "     | > loss_dur: 1.3947371244430542  (1.4192168626520376)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.5275, device='cuda:0')  (tensor(3.6343, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-06 \n",
      "     | > step_time: 0.4625  (0.5720656239324148)\n",
      "     | > loader_time: 0.0047  (0.008797470066282488)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:54:41 -- STEP: 745/811 -- GLOBAL_STEP: 4800\u001b[0m\n",
      "     | > loss: 1.701174259185791  (1.838637547044946)\n",
      "     | > log_mle: 0.40020233392715454  (0.42292590689339093)\n",
      "     | > loss_dur: 1.3009718656539917  (1.4157116390714715)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.4502, device='cuda:0')  (tensor(3.6275, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-06 \n",
      "     | > step_time: 0.5459  (0.5738785727712132)\n",
      "     | > loader_time: 0.0055  (0.008830604617227646)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:54:56 -- STEP: 770/811 -- GLOBAL_STEP: 4825\u001b[0m\n",
      "     | > loss: 1.7144606113433838  (1.8343490670253704)\n",
      "     | > log_mle: 0.3942590355873108  (0.4217250626969647)\n",
      "     | > loss_dur: 1.3202016353607178  (1.4126240032059811)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.4480, device='cuda:0')  (tensor(3.6209, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-06 \n",
      "     | > step_time: 0.421  (0.5745489634476698)\n",
      "     | > loader_time: 0.0061  (0.008896960530962263)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:55:12 -- STEP: 795/811 -- GLOBAL_STEP: 4850\u001b[0m\n",
      "     | > loss: 1.709869146347046  (1.829867604543578)\n",
      "     | > log_mle: 0.37868040800094604  (0.42042732092569457)\n",
      "     | > loss_dur: 1.331188678741455  (1.4094402829056272)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.4439, device='cuda:0')  (tensor(3.6142, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-06 \n",
      "     | > step_time: 0.7007  (0.5769778929416493)\n",
      "     | > loader_time: 0.0062  (0.008889103235688598)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: 1.6133522987365723  (1.6133522987365723)\n",
      "     | > log_mle: 0.40486830472946167  (0.40486830472946167)\n",
      "     | > loss_dur: 1.2084840536117554  (1.2084840536117554)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: 1.5351111888885498  (1.5351111888885498)\n",
      "     | > log_mle: 0.3895326256752014  (0.3895326256752014)\n",
      "     | > loss_dur: 1.1455785036087036  (1.1455785036087036)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: 1.6333420276641846  (1.5842266082763672)\n",
      "     | > log_mle: 0.4323590397834778  (0.4109458327293396)\n",
      "     | > loss_dur: 1.200982928276062  (1.1732807159423828)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: 1.6351068019866943  (1.6011866728464763)\n",
      "     | > log_mle: 0.393507719039917  (0.40513312816619873)\n",
      "     | > loss_dur: 1.2415990829467773  (1.1960535049438477)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: 1.650067687034607  (1.613406926393509)\n",
      "     | > log_mle: 0.37438786029815674  (0.39744681119918823)\n",
      "     | > loss_dur: 1.2756798267364502  (1.2159600853919983)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: 1.592085361480713  (1.6091426134109497)\n",
      "     | > log_mle: 0.3698144555091858  (0.39192034006118776)\n",
      "     | > loss_dur: 1.2222708463668823  (1.217222237586975)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: 1.6838046312332153  (1.621586283047994)\n",
      "     | > log_mle: 0.35215747356414795  (0.38529319564501446)\n",
      "     | > loss_dur: 1.3316471576690674  (1.2362930576006572)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: 1.6119616031646729  (1.6202113287789481)\n",
      "     | > log_mle: 0.39748650789260864  (0.38703509739467074)\n",
      "     | > loss_dur: 1.2144750356674194  (1.2331761973244804)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: 1.601330041885376  (1.6178511679172516)\n",
      "     | > log_mle: 0.38852882385253906  (0.3872218132019043)\n",
      "     | > loss_dur: 1.212801218032837  (1.230629324913025)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: 1.6676702499389648  (1.6233866214752197)\n",
      "     | > log_mle: 0.3874630928039551  (0.3872486220465766)\n",
      "     | > loss_dur: 1.2802071571350098  (1.2361379729376898)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: 1.5954599380493164  (1.6205939531326294)\n",
      "     | > log_mle: 0.3906872868537903  (0.387592488527298)\n",
      "     | > loss_dur: 1.204772710800171  (1.233001446723938)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: 1.6244795322418213  (1.6209471875971013)\n",
      "     | > log_mle: 0.3836868405342102  (0.38723742961883545)\n",
      "     | > loss_dur: 1.2407927513122559  (1.2337097471410579)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: 1.5976366996765137  (1.6190046469370525)\n",
      "     | > log_mle: 0.39555609226226807  (0.38793065150578815)\n",
      "     | > loss_dur: 1.2020806074142456  (1.2310739854971569)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: 1.6696515083312988  (1.6229005593519945)\n",
      "     | > log_mle: 0.3778098225593567  (0.3871521262022165)\n",
      "     | > loss_dur: 1.2918416261672974  (1.2357484193948598)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: 1.583622932434082  (1.6200950145721436)\n",
      "     | > log_mle: 0.38352757692337036  (0.38689322982515606)\n",
      "     | > loss_dur: 1.2000954151153564  (1.2332017762320382)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: 1.6204493045806885  (1.6201186339060465)\n",
      "     | > log_mle: 0.388296902179718  (0.38698680798212687)\n",
      "     | > loss_dur: 1.2321523427963257  (1.2331318140029908)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: 1.630444884300232  (1.6207640245556831)\n",
      "     | > log_mle: 0.3831446170806885  (0.38674667105078697)\n",
      "     | > loss_dur: 1.2473002672195435  (1.2340173423290253)\n",
      "\n",
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.011228621006011963 \u001b[0m(-0.040609925985336304)\n",
      "     | > avg_loss:\u001b[92m 1.6207640245556831 \u001b[0m(-0.2975045517086983)\n",
      "     | > avg_log_mle:\u001b[92m 0.38674667105078697 \u001b[0m(-0.06400536745786667)\n",
      "     | > avg_loss_dur:\u001b[92m 1.2340173423290253 \u001b[0m(-0.2334991917014122)\n",
      "\n",
      " > BEST MODEL : train/run-February-22-2025_01+01AM-9b6e3e6/best_model_4866.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 6/10\u001b[0m\n",
      " --> train/run-February-22-2025_01+01AM-9b6e3e6\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-22 01:55:31) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:55:36 -- STEP: 9/811 -- GLOBAL_STEP: 4875\u001b[0m\n",
      "     | > loss: 1.914139986038208  (1.8107544978459675)\n",
      "     | > log_mle: 0.423015296459198  (0.41746894187397426)\n",
      "     | > loss_dur: 1.4911246299743652  (1.3932855526606243)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.7733, device='cuda:0')  (tensor(3.5613, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 0.3596  (0.3770880964067247)\n",
      "     | > loader_time: 0.0041  (0.0040842956966824)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:55:45 -- STEP: 34/811 -- GLOBAL_STEP: 4900\u001b[0m\n",
      "     | > loss: 1.6616191864013672  (1.73620422447429)\n",
      "     | > log_mle: 0.42442864179611206  (0.41178471814183626)\n",
      "     | > loss_dur: 1.2371906042099  (1.324419494937448)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.3888, device='cuda:0')  (tensor(3.4895, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 0.3675  (0.36574384044198427)\n",
      "     | > loader_time: 0.0048  (0.004734901820912081)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:55:59 -- STEP: 59/811 -- GLOBAL_STEP: 4925\u001b[0m\n",
      "     | > loss: 1.6402380466461182  (1.7064228845854936)\n",
      "     | > log_mle: 0.40761226415634155  (0.411205287707054)\n",
      "     | > loss_dur: 1.2326257228851318  (1.2952175867759574)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.3281, device='cuda:0')  (tensor(3.4317, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 0.3961  (0.4374877032587084)\n",
      "     | > loader_time: 0.0034  (0.0058828935784808675)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:56:13 -- STEP: 84/811 -- GLOBAL_STEP: 4950\u001b[0m\n",
      "     | > loss: 1.6442967653274536  (1.692871237084979)\n",
      "     | > log_mle: 0.39917993545532227  (0.4104042489613806)\n",
      "     | > loss_dur: 1.2451168298721313  (1.2824669835113347)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.2959, device='cuda:0')  (tensor(3.3901, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 0.3296  (0.4705523791767302)\n",
      "     | > loader_time: 0.0052  (0.006383458773295085)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:56:28 -- STEP: 109/811 -- GLOBAL_STEP: 4975\u001b[0m\n",
      "     | > loss: 1.6500310897827148  (1.6849423231334861)\n",
      "     | > log_mle: 0.4009096026420593  (0.4078520719611317)\n",
      "     | > loss_dur: 1.2491214275360107  (1.2770902465242862)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.3206, device='cuda:0')  (tensor(3.3768, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 0.5412  (0.49270146702407697)\n",
      "     | > loader_time: 0.0044  (0.00641643672908118)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:56:42 -- STEP: 134/811 -- GLOBAL_STEP: 5000\u001b[0m\n",
      "     | > loss: 1.6551620960235596  (1.6770799355720407)\n",
      "     | > log_mle: 0.3820316195487976  (0.4054987708579249)\n",
      "     | > loss_dur: 1.2731305360794067  (1.2715811604884137)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.3214, device='cuda:0')  (tensor(3.3674, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 0.6702  (0.5032804261392623)\n",
      "     | > loader_time: 0.0153  (0.006822838712094435)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:56:57 -- STEP: 159/811 -- GLOBAL_STEP: 5025\u001b[0m\n",
      "     | > loss: 1.6351282596588135  (1.671566718029526)\n",
      "     | > log_mle: 0.3850973844528198  (0.4030851487468625)\n",
      "     | > loss_dur: 1.2500308752059937  (1.268481564971636)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.3689, device='cuda:0')  (tensor(3.3599, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 0.4935  (0.5171995642800002)\n",
      "     | > loader_time: 0.0055  (0.006775085281276103)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:57:12 -- STEP: 184/811 -- GLOBAL_STEP: 5050\u001b[0m\n",
      "     | > loss: 1.6098415851593018  (1.6643779582303504)\n",
      "     | > log_mle: 0.3696872591972351  (0.4005909171765267)\n",
      "     | > loss_dur: 1.2401543855667114  (1.2637870350609663)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.2969, device='cuda:0')  (tensor(3.3477, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 0.8465  (0.527424533729968)\n",
      "     | > loader_time: 0.0042  (0.006847182045812192)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:57:26 -- STEP: 209/811 -- GLOBAL_STEP: 5075\u001b[0m\n",
      "     | > loss: 1.6045995950698853  (1.6574917101974123)\n",
      "     | > log_mle: 0.38780462741851807  (0.3982833576829811)\n",
      "     | > loss_dur: 1.2167949676513672  (1.2592083478088023)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.2021, device='cuda:0')  (tensor(3.3365, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 0.5935  (0.5314744340175647)\n",
      "     | > loader_time: 0.0053  (0.007007895474228563)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:57:41 -- STEP: 234/811 -- GLOBAL_STEP: 5100\u001b[0m\n",
      "     | > loss: 1.6669559478759766  (1.6513805312988086)\n",
      "     | > log_mle: 0.36557304859161377  (0.3962344508140516)\n",
      "     | > loss_dur: 1.3013828992843628  (1.2551460760271456)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.3860, device='cuda:0')  (tensor(3.3232, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 0.7006  (0.5350600307823247)\n",
      "     | > loader_time: 0.0052  (0.006965990759368636)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:57:55 -- STEP: 259/811 -- GLOBAL_STEP: 5125\u001b[0m\n",
      "     | > loss: 1.5933905839920044  (1.6457636747581157)\n",
      "     | > log_mle: 0.3657238483428955  (0.3940546288223341)\n",
      "     | > loss_dur: 1.2276667356491089  (1.2517090423687092)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.3046, device='cuda:0')  (tensor(3.3132, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 0.8306  (0.5370937516790559)\n",
      "     | > loader_time: 0.0249  (0.007156959371677237)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:58:10 -- STEP: 284/811 -- GLOBAL_STEP: 5150\u001b[0m\n",
      "     | > loss: 1.5936453342437744  (1.6422632441554272)\n",
      "     | > log_mle: 0.3707907795906067  (0.39206034207428014)\n",
      "     | > loss_dur: 1.2228546142578125  (1.250202897568824)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.2940, device='cuda:0')  (tensor(3.3062, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 0.5765  (0.5419403633601229)\n",
      "     | > loader_time: 0.0065  (0.007377212316217557)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:58:25 -- STEP: 309/811 -- GLOBAL_STEP: 5175\u001b[0m\n",
      "     | > loss: 1.5301053524017334  (1.6379173662284425)\n",
      "     | > log_mle: 0.38038569688796997  (0.39044855414470814)\n",
      "     | > loss_dur: 1.1497195959091187  (1.2474688079364866)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.0788, device='cuda:0')  (tensor(3.2976, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 0.6451  (0.5445134963804074)\n",
      "     | > loader_time: 0.0207  (0.007485862688725049)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:58:39 -- STEP: 334/811 -- GLOBAL_STEP: 5200\u001b[0m\n",
      "     | > loss: 1.5459892749786377  (1.6338218700386087)\n",
      "     | > log_mle: 0.3671000003814697  (0.38856069511639135)\n",
      "     | > loss_dur: 1.178889274597168  (1.2452611712638497)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.0268, device='cuda:0')  (tensor(3.2889, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 0.5599  (0.5454162330684542)\n",
      "     | > loader_time: 0.0044  (0.007462896272807778)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:58:54 -- STEP: 359/811 -- GLOBAL_STEP: 5225\u001b[0m\n",
      "     | > loss: 1.5238734483718872  (1.6299569188386278)\n",
      "     | > log_mle: 0.35104429721832275  (0.38712021675282526)\n",
      "     | > loss_dur: 1.1728291511535645  (1.242836698516166)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.0350, device='cuda:0')  (tensor(3.2793, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 0.9229  (0.5482433745455937)\n",
      "     | > loader_time: 0.0048  (0.0075638725897063785)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:59:08 -- STEP: 384/811 -- GLOBAL_STEP: 5250\u001b[0m\n",
      "     | > loss: 1.5290486812591553  (1.6264630227039252)\n",
      "     | > log_mle: 0.3545263409614563  (0.3852858477427313)\n",
      "     | > loss_dur: 1.1745223999023438  (1.241177171779176)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.0676, device='cuda:0')  (tensor(3.2717, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 0.4023  (0.5488747165848806)\n",
      "     | > loader_time: 0.0094  (0.007699669649203618)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:59:23 -- STEP: 409/811 -- GLOBAL_STEP: 5275\u001b[0m\n",
      "     | > loss: 1.5554527044296265  (1.6224758595883986)\n",
      "     | > log_mle: 0.35291433334350586  (0.38394780212917645)\n",
      "     | > loss_dur: 1.2025383710861206  (1.2385280540345065)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.1269, device='cuda:0')  (tensor(3.2623, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 0.3289  (0.5492836583797384)\n",
      "     | > loader_time: 0.0047  (0.007974599567777076)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:59:39 -- STEP: 434/811 -- GLOBAL_STEP: 5300\u001b[0m\n",
      "     | > loss: 1.55411958694458  (1.6185247428406213)\n",
      "     | > log_mle: 0.3525407910346985  (0.3822870870477043)\n",
      "     | > loss_dur: 1.2015788555145264  (1.236237652840153)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.2025, device='cuda:0')  (tensor(3.2539, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 0.654  (0.5537259941276863)\n",
      "     | > loader_time: 0.0046  (0.00804831300462995)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:59:54 -- STEP: 459/811 -- GLOBAL_STEP: 5325\u001b[0m\n",
      "     | > loss: 1.5395662784576416  (1.6148183112050967)\n",
      "     | > log_mle: 0.3559383749961853  (0.38089815067829386)\n",
      "     | > loss_dur: 1.183627963066101  (1.2339201576050074)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.0432, device='cuda:0')  (tensor(3.2446, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 0.9712  (0.5555593453201594)\n",
      "     | > loader_time: 0.0051  (0.008119426781315678)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:00:08 -- STEP: 484/811 -- GLOBAL_STEP: 5350\u001b[0m\n",
      "     | > loss: 1.5831141471862793  (1.6115476902851384)\n",
      "     | > log_mle: 0.33791667222976685  (0.3793666035798955)\n",
      "     | > loss_dur: 1.2451975345611572  (1.2321810845501169)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.1733, device='cuda:0')  (tensor(3.2369, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 0.385  (0.5557937469364199)\n",
      "     | > loader_time: 0.0047  (0.00820098484843229)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:00:23 -- STEP: 509/811 -- GLOBAL_STEP: 5375\u001b[0m\n",
      "     | > loss: 1.574652075767517  (1.6085523659681755)\n",
      "     | > log_mle: 0.3401740789413452  (0.37796721248823434)\n",
      "     | > loss_dur: 1.2344779968261719  (1.2305851511964632)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.1599, device='cuda:0')  (tensor(3.2305, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 0.4373  (0.5566381040397)\n",
      "     | > loader_time: 0.0057  (0.00845121306848431)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:00:38 -- STEP: 534/811 -- GLOBAL_STEP: 5400\u001b[0m\n",
      "     | > loss: 1.5503469705581665  (1.6049672106232085)\n",
      "     | > log_mle: 0.36003684997558594  (0.3766505114929506)\n",
      "     | > loss_dur: 1.1903101205825806  (1.2283166970653037)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.0180, device='cuda:0')  (tensor(3.2218, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 0.7019  (0.5580870533703867)\n",
      "     | > loader_time: 0.0059  (0.008528086576568934)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:00:53 -- STEP: 559/811 -- GLOBAL_STEP: 5425\u001b[0m\n",
      "     | > loss: 1.5528085231781006  (1.601656001241134)\n",
      "     | > log_mle: 0.349537193775177  (0.3752803701727462)\n",
      "     | > loss_dur: 1.2032712697982788  (1.2263756286692749)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.0470, device='cuda:0')  (tensor(3.2143, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 0.5791  (0.5587795514326832)\n",
      "     | > loader_time: 0.0048  (0.008730412382559173)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:01:08 -- STEP: 584/811 -- GLOBAL_STEP: 5450\u001b[0m\n",
      "     | > loss: 1.5649333000183105  (1.5985850010016185)\n",
      "     | > log_mle: 0.3659301996231079  (0.3739466739129529)\n",
      "     | > loss_dur: 1.1990031003952026  (1.2246383248943176)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(2.9944, device='cuda:0')  (tensor(3.2071, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 0.4143  (0.561581523451087)\n",
      "     | > loader_time: 0.0068  (0.0087215190064417)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:01:24 -- STEP: 609/811 -- GLOBAL_STEP: 5475\u001b[0m\n",
      "     | > loss: 1.5045666694641113  (1.595662198826205)\n",
      "     | > log_mle: 0.342123806476593  (0.3726680871398969)\n",
      "     | > loss_dur: 1.162442922592163  (1.2229941094841672)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.0163, device='cuda:0')  (tensor(3.2002, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 0.9097  (0.5633188272736149)\n",
      "     | > loader_time: 0.0099  (0.008644520159816883)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:01:40 -- STEP: 634/811 -- GLOBAL_STEP: 5500\u001b[0m\n",
      "     | > loss: 1.5273497104644775  (1.5923693067267857)\n",
      "     | > log_mle: 0.3551729917526245  (0.3714364209103659)\n",
      "     | > loss_dur: 1.172176718711853  (1.220932884359209)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.0876, device='cuda:0')  (tensor(3.1924, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 0.4684  (0.5652156590663298)\n",
      "     | > loader_time: 0.0058  (0.008693004256167229)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:01:55 -- STEP: 659/811 -- GLOBAL_STEP: 5525\u001b[0m\n",
      "     | > loss: 1.5284312963485718  (1.5892524357449835)\n",
      "     | > log_mle: 0.34763312339782715  (0.3702301201672039)\n",
      "     | > loss_dur: 1.1807981729507446  (1.2190223143567438)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.0491, device='cuda:0')  (tensor(3.1846, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 0.399  (0.567183006153483)\n",
      "     | > loader_time: 0.0057  (0.008785612485477505)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:02:10 -- STEP: 684/811 -- GLOBAL_STEP: 5550\u001b[0m\n",
      "     | > loss: 1.5303434133529663  (1.5868291643976458)\n",
      "     | > log_mle: 0.31014299392700195  (0.36890137931931083)\n",
      "     | > loss_dur: 1.2202004194259644  (1.2179277833790805)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.0757, device='cuda:0')  (tensor(3.1786, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 0.5621  (0.5679424164587991)\n",
      "     | > loader_time: 0.015  (0.008916329570681005)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:02:26 -- STEP: 709/811 -- GLOBAL_STEP: 5575\u001b[0m\n",
      "     | > loss: 1.4659383296966553  (1.5843949928270231)\n",
      "     | > log_mle: 0.3247324228286743  (0.3676476630320501)\n",
      "     | > loss_dur: 1.141205906867981  (1.216747328323773)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(2.9010, device='cuda:0')  (tensor(3.1726, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 0.7883  (0.5692939062212687)\n",
      "     | > loader_time: 0.0055  (0.009026895961573135)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:02:43 -- STEP: 734/811 -- GLOBAL_STEP: 5600\u001b[0m\n",
      "     | > loss: 1.495898723602295  (1.5810954604876455)\n",
      "     | > log_mle: 0.3281649947166443  (0.36641980122967693)\n",
      "     | > loss_dur: 1.1677337884902954  (1.214675658080493)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(2.9409, device='cuda:0')  (tensor(3.1647, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 0.5832  (0.5722051683498661)\n",
      "     | > loader_time: 0.0095  (0.008989622547451068)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:02:58 -- STEP: 759/811 -- GLOBAL_STEP: 5625\u001b[0m\n",
      "     | > loss: 1.4913244247436523  (1.577985433250547)\n",
      "     | > log_mle: 0.3186628818511963  (0.36520042025995814)\n",
      "     | > loss_dur: 1.172661542892456  (1.212785011851897)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(2.9065, device='cuda:0')  (tensor(3.1565, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 0.5824  (0.5733983010956737)\n",
      "     | > loader_time: 0.0176  (0.008993013731261624)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:03:14 -- STEP: 784/811 -- GLOBAL_STEP: 5650\u001b[0m\n",
      "     | > loss: 1.4803144931793213  (1.5748042131260942)\n",
      "     | > log_mle: 0.32560795545578003  (0.36406612209975714)\n",
      "     | > loss_dur: 1.1547064781188965  (1.2107380899239557)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(2.9918, device='cuda:0')  (tensor(3.1487, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 0.6409  (0.5746705556402403)\n",
      "     | > loader_time: 0.0324  (0.009060654409077685)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:03:26 -- STEP: 809/811 -- GLOBAL_STEP: 5675\u001b[0m\n",
      "     | > loss: 1.4570119380950928  (1.5718001458789266)\n",
      "     | > log_mle: 0.3390875458717346  (0.3628532259882748)\n",
      "     | > loss_dur: 1.1179243326187134  (1.2089469188223365)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(2.8782, device='cuda:0')  (tensor(3.1417, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 0.3526  (0.5708444908316557)\n",
      "     | > loader_time: 0.0062  (0.009049425608442789)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: 1.4171357154846191  (1.4171357154846191)\n",
      "     | > log_mle: 0.35313040018081665  (0.35313040018081665)\n",
      "     | > loss_dur: 1.0640053749084473  (1.0640053749084473)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: 1.34634530544281  (1.34634530544281)\n",
      "     | > log_mle: 0.3371070623397827  (0.3371070623397827)\n",
      "     | > loss_dur: 1.0092382431030273  (1.0092382431030273)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: 1.4221820831298828  (1.3842636942863464)\n",
      "     | > log_mle: 0.379868745803833  (0.35848790407180786)\n",
      "     | > loss_dur: 1.0423133373260498  (1.0257757902145386)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: 1.4331510066986084  (1.4005594650904338)\n",
      "     | > log_mle: 0.340808629989624  (0.3525948127110799)\n",
      "     | > loss_dur: 1.0923423767089844  (1.0479646523793538)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: 1.443054437637329  (1.4111832082271576)\n",
      "     | > log_mle: 0.31934964656829834  (0.3442835211753845)\n",
      "     | > loss_dur: 1.1237047910690308  (1.066899687051773)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: 1.391319990158081  (1.4072105646133424)\n",
      "     | > log_mle: 0.3140386939048767  (0.33823455572128297)\n",
      "     | > loss_dur: 1.0772812366485596  (1.0689759969711303)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: 1.464684009552002  (1.416789472103119)\n",
      "     | > log_mle: 0.2959578037261963  (0.3311884303887685)\n",
      "     | > loss_dur: 1.1687262058258057  (1.085601031780243)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: 1.4231202602386475  (1.4176938704081945)\n",
      "     | > log_mle: 0.34515756368637085  (0.33318402085985455)\n",
      "     | > loss_dur: 1.0779627561569214  (1.0845098495483398)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: 1.3941243886947632  (1.4147476851940155)\n",
      "     | > log_mle: 0.335094690322876  (0.33342285454273224)\n",
      "     | > loss_dur: 1.0590296983718872  (1.0813248306512833)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: 1.455209732055664  (1.4192434681786432)\n",
      "     | > log_mle: 0.3338891863822937  (0.3334746691915724)\n",
      "     | > loss_dur: 1.1213204860687256  (1.0857687923643324)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: 1.3976491689682007  (1.4170840382575989)\n",
      "     | > log_mle: 0.3373984098434448  (0.33386704325675964)\n",
      "     | > loss_dur: 1.0602507591247559  (1.0832169890403747)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: 1.4140409231185913  (1.41680739142678)\n",
      "     | > log_mle: 0.3277808427810669  (0.33331375230442395)\n",
      "     | > loss_dur: 1.0862600803375244  (1.083493633703752)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: 1.3992154598236084  (1.4153413971265156)\n",
      "     | > log_mle: 0.34082621335983276  (0.333939790725708)\n",
      "     | > loss_dur: 1.0583893060684204  (1.0814016064008076)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: 1.4690442085266113  (1.4194723826188307)\n",
      "     | > log_mle: 0.3233482241630554  (0.3331250548362732)\n",
      "     | > loss_dur: 1.1456960439682007  (1.0863473323675303)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: 1.3947138786315918  (1.4177039180483137)\n",
      "     | > log_mle: 0.3301622271537781  (0.3329134242875235)\n",
      "     | > loss_dur: 1.0645517110824585  (1.0847905022757396)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: 1.4135053157806396  (1.4174240112304688)\n",
      "     | > log_mle: 0.3344123959541321  (0.3330133557319641)\n",
      "     | > loss_dur: 1.0790928602218628  (1.0844106594721479)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: 1.4369810819625854  (1.418646328151226)\n",
      "     | > log_mle: 0.32925450801849365  (0.3327784277498722)\n",
      "     | > loss_dur: 1.1077265739440918  (1.0858679041266444)\n",
      "\n",
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.0033444613218307495 \u001b[0m(-0.007884159684181213)\n",
      "     | > avg_loss:\u001b[92m 1.418646328151226 \u001b[0m(-0.2021176964044571)\n",
      "     | > avg_log_mle:\u001b[92m 0.3327784277498722 \u001b[0m(-0.053968243300914764)\n",
      "     | > avg_loss_dur:\u001b[92m 1.0858679041266444 \u001b[0m(-0.1481494382023809)\n",
      "\n",
      " > BEST MODEL : train/run-February-22-2025_01+01AM-9b6e3e6/best_model_5677.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 7/10\u001b[0m\n",
      " --> train/run-February-22-2025_01+01AM-9b6e3e6\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-22 02:03:38) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:03:50 -- STEP: 23/811 -- GLOBAL_STEP: 5700\u001b[0m\n",
      "     | > loss: 1.5111110210418701  (1.534935624703117)\n",
      "     | > log_mle: 0.34658724069595337  (0.3645387991614964)\n",
      "     | > loss_dur: 1.1645238399505615  (1.1703968410906584)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(2.9531, device='cuda:0')  (tensor(3.0296, device='cuda:0'))\n",
      "     | > current_lr: 1.75e-06 \n",
      "     | > step_time: 0.368  (0.3709601941316024)\n",
      "     | > loader_time: 0.0045  (0.005152070004007091)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:04:01 -- STEP: 48/811 -- GLOBAL_STEP: 5725\u001b[0m\n",
      "     | > loss: 1.5204192399978638  (1.4972307508190472)\n",
      "     | > log_mle: 0.383736252784729  (0.36119862024982763)\n",
      "     | > loss_dur: 1.1366829872131348  (1.1360321417450907)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(2.7726, device='cuda:0')  (tensor(2.9452, device='cuda:0'))\n",
      "     | > current_lr: 1.75e-06 \n",
      "     | > step_time: 0.5953  (0.39107459286848706)\n",
      "     | > loader_time: 0.0054  (0.00509886940320333)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:04:15 -- STEP: 73/811 -- GLOBAL_STEP: 5750\u001b[0m\n",
      "     | > loss: 1.4367666244506836  (1.4846313114035619)\n",
      "     | > log_mle: 0.37125998735427856  (0.35921165061323607)\n",
      "     | > loss_dur: 1.0655065774917603  (1.1254196656893378)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(2.7735, device='cuda:0')  (tensor(2.9059, device='cuda:0'))\n",
      "     | > current_lr: 1.75e-06 \n",
      "     | > step_time: 0.5819  (0.4478175019564694)\n",
      "     | > loader_time: 0.0191  (0.005724995103600907)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:04:30 -- STEP: 98/811 -- GLOBAL_STEP: 5775\u001b[0m\n",
      "     | > loss: 1.4948581457138062  (1.4762827486408001)\n",
      "     | > log_mle: 0.35572385787963867  (0.3577469538669197)\n",
      "     | > loss_dur: 1.1391342878341675  (1.1185358008559867)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(2.9338, device='cuda:0')  (tensor(2.8808, device='cuda:0'))\n",
      "     | > current_lr: 1.75e-06 \n",
      "     | > step_time: 0.6474  (0.4816722431961371)\n",
      "     | > loader_time: 0.0047  (0.006205850717972736)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:04:44 -- STEP: 123/811 -- GLOBAL_STEP: 5800\u001b[0m\n",
      "     | > loss: 1.4765965938568115  (1.4707235679393862)\n",
      "     | > log_mle: 0.33928197622299194  (0.35449345615821154)\n",
      "     | > loss_dur: 1.1373145580291748  (1.1162301166270807)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(2.8469, device='cuda:0')  (tensor(2.8739, device='cuda:0'))\n",
      "     | > current_lr: 1.75e-06 \n",
      "     | > step_time: 0.7827  (0.49980006179189296)\n",
      "     | > loader_time: 0.0452  (0.00650262251132872)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:04:58 -- STEP: 148/811 -- GLOBAL_STEP: 5825\u001b[0m\n",
      "     | > loss: 1.5001072883605957  (1.4655388690329891)\n",
      "     | > log_mle: 0.304080069065094  (0.3521794193499797)\n",
      "     | > loss_dur: 1.1960272789001465  (1.1133594529048814)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.0255, device='cuda:0')  (tensor(2.8683, device='cuda:0'))\n",
      "     | > current_lr: 1.75e-06 \n",
      "     | > step_time: 0.5201  (0.5076513080983549)\n",
      "     | > loader_time: 0.0047  (0.0067723699518152155)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:05:13 -- STEP: 173/811 -- GLOBAL_STEP: 5850\u001b[0m\n",
      "     | > loss: 1.3549251556396484  (1.4609264996699522)\n",
      "     | > log_mle: 0.3369879126548767  (0.34991693910146715)\n",
      "     | > loss_dur: 1.0179373025894165  (1.1110095633247676)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(2.6489, device='cuda:0')  (tensor(2.8628, device='cuda:0'))\n",
      "     | > current_lr: 1.75e-06 \n",
      "     | > step_time: 0.6099  (0.5190965261073471)\n",
      "     | > loader_time: 0.0041  (0.0069537686474750475)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:05:29 -- STEP: 198/811 -- GLOBAL_STEP: 5875\u001b[0m\n",
      "     | > loss: 1.4629255533218384  (1.4546065264277994)\n",
      "     | > log_mle: 0.33174586296081543  (0.3474952437058843)\n",
      "     | > loss_dur: 1.131179690361023  (1.10711128663535)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(2.8939, device='cuda:0')  (tensor(2.8559, device='cuda:0'))\n",
      "     | > current_lr: 1.75e-06 \n",
      "     | > step_time: 0.5678  (0.5325094449399698)\n",
      "     | > loader_time: 0.0037  (0.0069311086577598475)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:05:45 -- STEP: 223/811 -- GLOBAL_STEP: 5900\u001b[0m\n",
      "     | > loss: 1.397045612335205  (1.4491394806335864)\n",
      "     | > log_mle: 0.32241129875183105  (0.34517809467999916)\n",
      "     | > loss_dur: 1.074634313583374  (1.1039613894282967)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(2.7500, device='cuda:0')  (tensor(2.8464, device='cuda:0'))\n",
      "     | > current_lr: 1.75e-06 \n",
      "     | > step_time: 0.6202  (0.5408588492816871)\n",
      "     | > loader_time: 0.006  (0.006947676697119467)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:06:02 -- STEP: 248/811 -- GLOBAL_STEP: 5925\u001b[0m\n",
      "     | > loss: 1.4213488101959229  (1.445488943207649)\n",
      "     | > log_mle: 0.32148754596710205  (0.3430624825339163)\n",
      "     | > loss_dur: 1.0998612642288208  (1.1024264642788513)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(2.7618, device='cuda:0')  (tensor(2.8379, device='cuda:0'))\n",
      "     | > current_lr: 1.75e-06 \n",
      "     | > step_time: 0.712  (0.5562808696300753)\n",
      "     | > loader_time: 0.0163  (0.007171366483934462)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:06:19 -- STEP: 273/811 -- GLOBAL_STEP: 5950\u001b[0m\n",
      "     | > loss: 1.4284647703170776  (1.4420224624675713)\n",
      "     | > log_mle: 0.324548602104187  (0.34098759872136086)\n",
      "     | > loss_dur: 1.1039161682128906  (1.101034866366194)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(2.6910, device='cuda:0')  (tensor(2.8321, device='cuda:0'))\n",
      "     | > current_lr: 1.75e-06 \n",
      "     | > step_time: 0.5698  (0.5646089634179196)\n",
      "     | > loader_time: 0.0056  (0.007215469311445186)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:06:35 -- STEP: 298/811 -- GLOBAL_STEP: 5975\u001b[0m\n",
      "     | > loss: 1.405432939529419  (1.439318330095919)\n",
      "     | > log_mle: 0.3208006024360657  (0.3391268675359302)\n",
      "     | > loss_dur: 1.0846322774887085  (1.1001914641601125)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(2.8475, device='cuda:0')  (tensor(2.8300, device='cuda:0'))\n",
      "     | > current_lr: 1.75e-06 \n",
      "     | > step_time: 0.6271  (0.5692364745492104)\n",
      "     | > loader_time: 0.0047  (0.007175459157700504)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:06:49 -- STEP: 323/811 -- GLOBAL_STEP: 6000\u001b[0m\n",
      "     | > loss: 1.437875747680664  (1.4361537790888985)\n",
      "     | > log_mle: 0.30010467767715454  (0.3375073730391982)\n",
      "     | > loss_dur: 1.1377711296081543  (1.09864640734144)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(2.9461, device='cuda:0')  (tensor(2.8254, device='cuda:0'))\n",
      "     | > current_lr: 1.75e-06 \n",
      "     | > step_time: 0.6555  (0.5690210072248715)\n",
      "     | > loader_time: 0.0173  (0.007313690687480723)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:07:04 -- STEP: 348/811 -- GLOBAL_STEP: 6025\u001b[0m\n",
      "     | > loss: 1.36981201171875  (1.4330764320389988)\n",
      "     | > log_mle: 0.3090651035308838  (0.335861830533236)\n",
      "     | > loss_dur: 1.0607469081878662  (1.0972146016770399)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(2.6574, device='cuda:0')  (tensor(2.8187, device='cuda:0'))\n",
      "     | > current_lr: 1.75e-06 \n",
      "     | > step_time: 0.5996  (0.5710502602588174)\n",
      "     | > loader_time: 0.0048  (0.007318877625739435)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:07:19 -- STEP: 373/811 -- GLOBAL_STEP: 6050\u001b[0m\n",
      "     | > loss: 1.3721907138824463  (1.4298862794129528)\n",
      "     | > log_mle: 0.3101957440376282  (0.33424631711944514)\n",
      "     | > loss_dur: 1.061995029449463  (1.0956399624533057)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(2.6904, device='cuda:0')  (tensor(2.8117, device='cuda:0'))\n",
      "     | > current_lr: 1.75e-06 \n",
      "     | > step_time: 0.5647  (0.5727719762050437)\n",
      "     | > loader_time: 0.0043  (0.0074236744530399084)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:07:36 -- STEP: 398/811 -- GLOBAL_STEP: 6075\u001b[0m\n",
      "     | > loss: 1.402794599533081  (1.4272396627383022)\n",
      "     | > log_mle: 0.3089790344238281  (0.33263118722331)\n",
      "     | > loss_dur: 1.093815565109253  (1.0946084750657108)\n",
      "     | > amp_scaler: 32768.0  (17207.316582914573)\n",
      "     | > grad_norm: tensor(2.7428, device='cuda:0')  (tensor(2.8083, device='cuda:0'))\n",
      "     | > current_lr: 1.75e-06 \n",
      "     | > step_time: 1.0044  (0.5782830331792785)\n",
      "     | > loader_time: 0.0049  (0.00772713836114011)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:07:51 -- STEP: 423/811 -- GLOBAL_STEP: 6100\u001b[0m\n",
      "     | > loss: 1.3519808053970337  (1.4239328877018422)\n",
      "     | > log_mle: 0.31918418407440186  (0.3312425599312389)\n",
      "     | > loss_dur: 1.0327966213226318  (1.092690326502419)\n",
      "     | > amp_scaler: 32768.0  (18126.978723404245)\n",
      "     | > grad_norm: tensor(2.6648, device='cuda:0')  (tensor(2.8022, device='cuda:0'))\n",
      "     | > current_lr: 1.75e-06 \n",
      "     | > step_time: 0.3458  (0.5779487647063345)\n",
      "     | > loader_time: 0.0059  (0.0077353594714586315)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:08:07 -- STEP: 448/811 -- GLOBAL_STEP: 6125\u001b[0m\n",
      "     | > loss: 1.3624541759490967  (1.4207915453506372)\n",
      "     | > log_mle: 0.32246726751327515  (0.3297358768592989)\n",
      "     | > loss_dur: 1.0399868488311768  (1.0910556671608769)\n",
      "     | > amp_scaler: 32768.0  (18943.99999999998)\n",
      "     | > grad_norm: tensor(2.6303, device='cuda:0')  (tensor(2.7963, device='cuda:0'))\n",
      "     | > current_lr: 1.75e-06 \n",
      "     | > step_time: 0.4732  (0.5798715017735959)\n",
      "     | > loader_time: 0.0046  (0.00784558536750929)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:08:21 -- STEP: 473/811 -- GLOBAL_STEP: 6150\u001b[0m\n",
      "     | > loss: 1.3618052005767822  (1.4181552001336164)\n",
      "     | > log_mle: 0.3192352056503296  (0.3284011295431513)\n",
      "     | > loss_dur: 1.0425699949264526  (1.0897540692043097)\n",
      "     | > amp_scaler: 32768.0  (19674.65539112049)\n",
      "     | > grad_norm: tensor(2.7721, device='cuda:0')  (tensor(2.7915, device='cuda:0'))\n",
      "     | > current_lr: 1.75e-06 \n",
      "     | > step_time: 0.6578  (0.5792329548277262)\n",
      "     | > loader_time: 0.0061  (0.007930044896002799)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:08:37 -- STEP: 498/811 -- GLOBAL_STEP: 6175\u001b[0m\n",
      "     | > loss: 1.3590443134307861  (1.4154705165859212)\n",
      "     | > log_mle: 0.2997403144836426  (0.3270309478882327)\n",
      "     | > loss_dur: 1.0593039989471436  (1.088439567022055)\n",
      "     | > amp_scaler: 32768.0  (20331.9518072289)\n",
      "     | > grad_norm: tensor(2.6224, device='cuda:0')  (tensor(2.7865, device='cuda:0'))\n",
      "     | > current_lr: 1.75e-06 \n",
      "     | > step_time: 0.4853  (0.5802043805639429)\n",
      "     | > loader_time: 0.0229  (0.00810236911697081)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:08:52 -- STEP: 523/811 -- GLOBAL_STEP: 6200\u001b[0m\n",
      "     | > loss: 1.3503012657165527  (1.4128666099581166)\n",
      "     | > log_mle: 0.29736053943634033  (0.32558725247191667)\n",
      "     | > loss_dur: 1.0529407262802124  (1.0872793560046305)\n",
      "     | > amp_scaler: 32768.0  (20926.409177820253)\n",
      "     | > grad_norm: tensor(2.7122, device='cuda:0')  (tensor(2.7828, device='cuda:0'))\n",
      "     | > current_lr: 1.75e-06 \n",
      "     | > step_time: 0.3639  (0.5816649738734814)\n",
      "     | > loader_time: 0.0149  (0.00816761284895654)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:09:07 -- STEP: 548/811 -- GLOBAL_STEP: 6225\u001b[0m\n",
      "     | > loss: 1.3541975021362305  (1.4102971442859544)\n",
      "     | > log_mle: 0.2910616993904114  (0.324275547788091)\n",
      "     | > loss_dur: 1.0631358623504639  (1.0860215950838836)\n",
      "     | > amp_scaler: 32768.0  (21466.627737226263)\n",
      "     | > grad_norm: tensor(2.7475, device='cuda:0')  (tensor(2.7775, device='cuda:0'))\n",
      "     | > current_lr: 1.75e-06 \n",
      "     | > step_time: 0.426  (0.5814445262407735)\n",
      "     | > loader_time: 0.0048  (0.008255202404774016)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:09:24 -- STEP: 573/811 -- GLOBAL_STEP: 6250\u001b[0m\n",
      "     | > loss: 1.3795262575149536  (1.4078136819819513)\n",
      "     | > log_mle: 0.29689109325408936  (0.3230911552593971)\n",
      "     | > loss_dur: 1.0826351642608643  (1.0847225256823325)\n",
      "     | > amp_scaler: 32768.0  (21959.706806282702)\n",
      "     | > grad_norm: tensor(2.6999, device='cuda:0')  (tensor(2.7729, device='cuda:0'))\n",
      "     | > current_lr: 1.75e-06 \n",
      "     | > step_time: 0.4285  (0.5843632346048404)\n",
      "     | > loader_time: 0.0056  (0.008448021990258446)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:09:41 -- STEP: 598/811 -- GLOBAL_STEP: 6275\u001b[0m\n",
      "     | > loss: 1.321685552597046  (1.4054575709993635)\n",
      "     | > log_mle: 0.2929365038871765  (0.32196069949845396)\n",
      "     | > loss_dur: 1.0287489891052246  (1.083496870504175)\n",
      "     | > amp_scaler: 32768.0  (22411.558528428064)\n",
      "     | > grad_norm: tensor(2.5597, device='cuda:0')  (tensor(2.7668, device='cuda:0'))\n",
      "     | > current_lr: 1.75e-06 \n",
      "     | > step_time: 0.3925  (0.5886785362077795)\n",
      "     | > loader_time: 0.008  (0.008588330004127528)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:09:58 -- STEP: 623/811 -- GLOBAL_STEP: 6300\u001b[0m\n",
      "     | > loss: 1.3567240238189697  (1.4029726520970018)\n",
      "     | > log_mle: 0.3013381361961365  (0.3208426411232251)\n",
      "     | > loss_dur: 1.055385947227478  (1.0821300099213655)\n",
      "     | > amp_scaler: 32768.0  (22827.146067415702)\n",
      "     | > grad_norm: tensor(2.6400, device='cuda:0')  (tensor(2.7614, device='cuda:0'))\n",
      "     | > current_lr: 1.75e-06 \n",
      "     | > step_time: 0.4127  (0.5913531083739205)\n",
      "     | > loader_time: 0.0066  (0.008583621075601103)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:10:15 -- STEP: 648/811 -- GLOBAL_STEP: 6325\u001b[0m\n",
      "     | > loss: 1.3059300184249878  (1.4002463379759857)\n",
      "     | > log_mle: 0.2913355827331543  (0.3196857371999894)\n",
      "     | > loss_dur: 1.0145944356918335  (1.0805605998561707)\n",
      "     | > amp_scaler: 32768.0  (23210.66666666664)\n",
      "     | > grad_norm: tensor(2.5917, device='cuda:0')  (tensor(2.7550, device='cuda:0'))\n",
      "     | > current_lr: 1.75e-06 \n",
      "     | > step_time: 0.3587  (0.5948596953609843)\n",
      "     | > loader_time: 0.0053  (0.008667491836312375)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:10:32 -- STEP: 673/811 -- GLOBAL_STEP: 6350\u001b[0m\n",
      "     | > loss: 1.2982159852981567  (1.3983098656426225)\n",
      "     | > log_mle: 0.28138232231140137  (0.3185104067045724)\n",
      "     | > loss_dur: 1.0168336629867554  (1.079799457786697)\n",
      "     | > amp_scaler: 32768.0  (23565.693907875157)\n",
      "     | > grad_norm: tensor(2.6143, device='cuda:0')  (tensor(2.7506, device='cuda:0'))\n",
      "     | > current_lr: 1.75e-06 \n",
      "     | > step_time: 0.4949  (0.5961818843858558)\n",
      "     | > loader_time: 0.0136  (0.00865576490427729)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:10:45 -- STEP: 698/811 -- GLOBAL_STEP: 6375\u001b[0m\n",
      "     | > loss: 1.3830320835113525  (1.396350975364533)\n",
      "     | > log_mle: 0.274938702583313  (0.31734276603491035)\n",
      "     | > loss_dur: 1.1080933809280396  (1.0790082084756878)\n",
      "     | > amp_scaler: 32768.0  (23895.28939828078)\n",
      "     | > grad_norm: tensor(2.7294, device='cuda:0')  (tensor(2.7460, device='cuda:0'))\n",
      "     | > current_lr: 1.75e-06 \n",
      "     | > step_time: 0.4433  (0.5941438811556314)\n",
      "     | > loader_time: 0.005  (0.0086309117369119)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:11:00 -- STEP: 723/811 -- GLOBAL_STEP: 6400\u001b[0m\n",
      "     | > loss: 1.2949179410934448  (1.3938866645963368)\n",
      "     | > log_mle: 0.2902628183364868  (0.3162170975864507)\n",
      "     | > loss_dur: 1.004655122756958  (1.077669566267919)\n",
      "     | > amp_scaler: 32768.0  (24202.091286307033)\n",
      "     | > grad_norm: tensor(2.4908, device='cuda:0')  (tensor(2.7399, device='cuda:0'))\n",
      "     | > current_lr: 1.75e-06 \n",
      "     | > step_time: 0.7554  (0.592810388092843)\n",
      "     | > loader_time: 0.0052  (0.0087257836369558)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:11:14 -- STEP: 748/811 -- GLOBAL_STEP: 6425\u001b[0m\n",
      "     | > loss: 1.3086293935775757  (1.3910864942214078)\n",
      "     | > log_mle: 0.28870487213134766  (0.31508387338350136)\n",
      "     | > loss_dur: 1.019924521446228  (1.0760026202004225)\n",
      "     | > amp_scaler: 32768.0  (24488.38502673795)\n",
      "     | > grad_norm: tensor(2.4603, device='cuda:0')  (tensor(2.7331, device='cuda:0'))\n",
      "     | > current_lr: 1.75e-06 \n",
      "     | > step_time: 0.9123  (0.5914970145506016)\n",
      "     | > loader_time: 0.005  (0.008730699353039587)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:11:29 -- STEP: 773/811 -- GLOBAL_STEP: 6450\u001b[0m\n",
      "     | > loss: 1.3528509140014648  (1.388654180362648)\n",
      "     | > log_mle: 0.2836679220199585  (0.31412885391079864)\n",
      "     | > loss_dur: 1.0691829919815063  (1.0745253253723333)\n",
      "     | > amp_scaler: 32768.0  (24756.16041397152)\n",
      "     | > grad_norm: tensor(2.6131, device='cuda:0')  (tensor(2.7274, device='cuda:0'))\n",
      "     | > current_lr: 1.75e-06 \n",
      "     | > step_time: 0.5903  (0.5915975246824234)\n",
      "     | > loader_time: 0.0366  (0.008827203303999616)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:11:44 -- STEP: 798/811 -- GLOBAL_STEP: 6475\u001b[0m\n",
      "     | > loss: 1.3037859201431274  (1.386098365287734)\n",
      "     | > log_mle: 0.2800772190093994  (0.3129752350779699)\n",
      "     | > loss_dur: 1.023708701133728  (1.073123129014682)\n",
      "     | > amp_scaler: 32768.0  (25007.15789473682)\n",
      "     | > grad_norm: tensor(2.5314, device='cuda:0')  (tensor(2.7227, device='cuda:0'))\n",
      "     | > current_lr: 1.75e-06 \n",
      "     | > step_time: 0.3137  (0.591993258710493)\n",
      "     | > loader_time: 0.0049  (0.00884206372693667)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: 1.2725098133087158  (1.2725098133087158)\n",
      "     | > log_mle: 0.3065081238746643  (0.3065081238746643)\n",
      "     | > loss_dur: 0.9660016298294067  (0.9660016298294067)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: 1.1951379776000977  (1.1951379776000977)\n",
      "     | > log_mle: 0.2894410490989685  (0.2894410490989685)\n",
      "     | > loss_dur: 0.9056969881057739  (0.9056969881057739)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: 1.2826910018920898  (1.2389144897460938)\n",
      "     | > log_mle: 0.3339911699295044  (0.31171610951423645)\n",
      "     | > loss_dur: 0.9486998915672302  (0.9271984398365021)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: 1.2778918743133545  (1.251906951268514)\n",
      "     | > log_mle: 0.2944263815879822  (0.3059528668721517)\n",
      "     | > loss_dur: 0.9834655523300171  (0.9459541440010071)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: 1.290182113647461  (1.2614757418632507)\n",
      "     | > log_mle: 0.27171945571899414  (0.2973945140838623)\n",
      "     | > loss_dur: 1.0184626579284668  (0.964081272482872)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: 1.2368451356887817  (1.2565496206283568)\n",
      "     | > log_mle: 0.2672794461250305  (0.2913715004920959)\n",
      "     | > loss_dur: 0.9695656895637512  (0.9651781558990479)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: 1.309628963470459  (1.2653961777687073)\n",
      "     | > log_mle: 0.24913763999938965  (0.2843325237433116)\n",
      "     | > loss_dur: 1.0604913234710693  (0.9810636838277181)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: 1.2662458419799805  (1.2655175583703178)\n",
      "     | > log_mle: 0.3004688024520874  (0.28663770641599384)\n",
      "     | > loss_dur: 0.9657770991325378  (0.9788798860141209)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: 1.2398499250411987  (1.2623091042041779)\n",
      "     | > log_mle: 0.2896043658256531  (0.28700853884220123)\n",
      "     | > loss_dur: 0.9502455592155457  (0.975300595164299)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: 1.3241889476776123  (1.2691846423678927)\n",
      "     | > log_mle: 0.2876816391944885  (0.28708332777023315)\n",
      "     | > loss_dur: 1.036507248878479  (0.9821013344658746)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: 1.2534573078155518  (1.2676119089126587)\n",
      "     | > log_mle: 0.29140567779541016  (0.28751556277275087)\n",
      "     | > loss_dur: 0.9620516300201416  (0.9800963640213013)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: 1.2554748058319092  (1.2665085359053179)\n",
      "     | > log_mle: 0.27967339754104614  (0.2868026386607777)\n",
      "     | > loss_dur: 0.975801408290863  (0.9797059135003523)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: 1.2467725276947021  (1.2648638685544331)\n",
      "     | > log_mle: 0.2930535078048706  (0.28732354442278546)\n",
      "     | > loss_dur: 0.9537190198898315  (0.9775403390328089)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: 1.3090605735778809  (1.2682636150946984)\n",
      "     | > log_mle: 0.2771136164665222  (0.2865381653492267)\n",
      "     | > loss_dur: 1.0319470167160034  (0.9817254680853623)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: 1.2443946599960327  (1.266558689730508)\n",
      "     | > log_mle: 0.28414392471313477  (0.28636714816093445)\n",
      "     | > loss_dur: 0.960250735282898  (0.980191558599472)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: 1.2687721252441406  (1.2667062520980834)\n",
      "     | > log_mle: 0.2879346013069153  (0.2864716450373332)\n",
      "     | > loss_dur: 0.9808375835418701  (0.9802346269289652)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: 1.2879562377929688  (1.2680343762040138)\n",
      "     | > log_mle: 0.2835370898246765  (0.28628823533654213)\n",
      "     | > loss_dur: 1.0044190883636475  (0.9817461557686329)\n",
      "\n",
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[91m 0.004212915897369385 \u001b[0m(+0.0008684545755386353)\n",
      "     | > avg_loss:\u001b[92m 1.2680343762040138 \u001b[0m(-0.15061195194721222)\n",
      "     | > avg_log_mle:\u001b[92m 0.28628823533654213 \u001b[0m(-0.04649019241333008)\n",
      "     | > avg_loss_dur:\u001b[92m 0.9817461557686329 \u001b[0m(-0.10412174835801147)\n",
      "\n",
      " > BEST MODEL : train/run-February-22-2025_01+01AM-9b6e3e6/best_model_6488.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 8/10\u001b[0m\n",
      " --> train/run-February-22-2025_01+01AM-9b6e3e6\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-22 02:12:02) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:12:07 -- STEP: 12/811 -- GLOBAL_STEP: 6500\u001b[0m\n",
      "     | > loss: 1.2466061115264893  (1.3861116965611775)\n",
      "     | > log_mle: 0.3046932816505432  (0.3209903786579768)\n",
      "     | > loss_dur: 0.941912829875946  (1.0651213079690933)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.5796, device='cuda:0')  (tensor(2.7561, device='cuda:0'))\n",
      "     | > current_lr: 2e-06 \n",
      "     | > step_time: 0.4179  (0.33221296469370526)\n",
      "     | > loader_time: 0.002  (0.004132707913716634)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:12:16 -- STEP: 37/811 -- GLOBAL_STEP: 6525\u001b[0m\n",
      "     | > loss: 1.262139081954956  (1.3410024352975793)\n",
      "     | > log_mle: 0.31535905599594116  (0.3148164217536514)\n",
      "     | > loss_dur: 0.9467800259590149  (1.0261860054892462)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.4390, device='cuda:0')  (tensor(2.6599, device='cuda:0'))\n",
      "     | > current_lr: 2e-06 \n",
      "     | > step_time: 0.2927  (0.324426760544648)\n",
      "     | > loader_time: 0.0044  (0.00427642384090939)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:12:29 -- STEP: 62/811 -- GLOBAL_STEP: 6550\u001b[0m\n",
      "     | > loss: 1.276350498199463  (1.3205792903900144)\n",
      "     | > log_mle: 0.3204198479652405  (0.3146732622577298)\n",
      "     | > loss_dur: 0.9559305906295776  (1.005906024286824)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.4796, device='cuda:0')  (tensor(2.5769, device='cuda:0'))\n",
      "     | > current_lr: 2e-06 \n",
      "     | > step_time: 0.5501  (0.40372255156117093)\n",
      "     | > loader_time: 0.0041  (0.005366483042317051)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:12:42 -- STEP: 87/811 -- GLOBAL_STEP: 6575\u001b[0m\n",
      "     | > loss: 1.2274961471557617  (1.311527650931786)\n",
      "     | > log_mle: 0.3036314845085144  (0.31393747151583085)\n",
      "     | > loss_dur: 0.9238646030426025  (0.9975901794159546)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.3164, device='cuda:0')  (tensor(2.5285, device='cuda:0'))\n",
      "     | > current_lr: 2e-06 \n",
      "     | > step_time: 0.471  (0.43794029060451456)\n",
      "     | > loader_time: 0.0037  (0.00593782019341129)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:12:56 -- STEP: 112/811 -- GLOBAL_STEP: 6600\u001b[0m\n",
      "     | > loss: 1.289825201034546  (1.306422165461949)\n",
      "     | > log_mle: 0.31197595596313477  (0.31092902113284376)\n",
      "     | > loss_dur: 0.9778492450714111  (0.9954931427325519)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.3429, device='cuda:0')  (tensor(2.5201, device='cuda:0'))\n",
      "     | > current_lr: 2e-06 \n",
      "     | > step_time: 0.5656  (0.45768084057739794)\n",
      "     | > loader_time: 0.0038  (0.006190221224512372)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:13:09 -- STEP: 137/811 -- GLOBAL_STEP: 6625\u001b[0m\n",
      "     | > loss: 1.272046446800232  (1.3013486879585434)\n",
      "     | > log_mle: 0.2987781763076782  (0.3090077220958514)\n",
      "     | > loss_dur: 0.9732682704925537  (0.9923409632522693)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.5225, device='cuda:0')  (tensor(2.5095, device='cuda:0'))\n",
      "     | > current_lr: 2e-06 \n",
      "     | > step_time: 0.619  (0.4721120500216519)\n",
      "     | > loader_time: 0.0043  (0.006316318999241738)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:13:22 -- STEP: 162/811 -- GLOBAL_STEP: 6650\u001b[0m\n",
      "     | > loss: 1.2619036436080933  (1.2979816610430503)\n",
      "     | > log_mle: 0.2977207899093628  (0.30663258867499255)\n",
      "     | > loss_dur: 0.9641828536987305  (0.9913490686887575)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.3742, device='cuda:0')  (tensor(2.5064, device='cuda:0'))\n",
      "     | > current_lr: 2e-06 \n",
      "     | > step_time: 0.5534  (0.47727618246902653)\n",
      "     | > loader_time: 0.0039  (0.006490024519555363)\n",
      "\n",
      " > Keyboard interrupt detected.\n",
      " > Saving model before exiting...\n",
      "\n",
      " > CHECKPOINT : train/run-February-22-2025_01+01AM-9b6e3e6/checkpoint_6673.pth\n",
      " ! Run is kept in train/run-February-22-2025_01+01AM-9b6e3e6\n"
     ]
    }
   ],
   "source": [
    "trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resume training\n",
    "\n",
    "trainer_args = TrainerArgs(\n",
    "    restore_path=os.path.join(output_path, \"run-February-22-2025_01+01AM-9b6e3e6/best_model.pth\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " > Training Environment:\n",
      " | > Backend: Torch\n",
      " | > Mixed precision: True\n",
      " | > Precision: fp16\n",
      " | > Current device: 0\n",
      " | > Num. of GPUs: 1\n",
      " | > Num. of CPUs: 16\n",
      " | > Num. of Torch Threads: 8\n",
      " | > Torch seed: 54321\n",
      " | > Torch CUDNN: True\n",
      " | > Torch CUDNN deterministic: False\n",
      " | > Torch CUDNN benchmark: False\n",
      " | > Torch TF32 MatMul: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " > Start Tensorboard: tensorboard --logdir=train/run-February-22-2025_02+19AM-9b6e3e6\n",
      " > Restoring from best_model.pth ...\n",
      " > Restoring Model...\n",
      " > Restoring Optimizer...\n",
      " > Restoring Scaler...\n",
      " > Model restored from step 6488\n",
      "\n",
      " > Model has 28610449 parameters\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    trainer_args, config, output_path, model=model, train_samples=train_samples, eval_samples=eval_samples\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 0/40\u001b[0m\n",
      " --> train/run-February-22-2025_02+19AM-9b6e3e6\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-22 02:19:54) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:20:04 -- STEP: 11/406 -- GLOBAL_STEP: 6500\u001b[0m\n",
      "     | > loss: 1.3386030197143555  (1.357455242763866)\n",
      "     | > log_mle: 0.3208548426628113  (0.3191657066345215)\n",
      "     | > loss_dur: 1.017748236656189  (1.0382895469665527)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.6704, device='cuda:0')  (tensor(2.6417, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.3937  (0.47186381166631525)\n",
      "     | > loader_time: 0.0045  (0.004741213538429954)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:20:20 -- STEP: 36/406 -- GLOBAL_STEP: 6525\u001b[0m\n",
      "     | > loss: 1.287428855895996  (1.3216145667764876)\n",
      "     | > log_mle: 0.3273215889930725  (0.31601093212763476)\n",
      "     | > loss_dur: 0.9601072669029236  (1.0056036346488528)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.3782, device='cuda:0')  (tensor(2.5160, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.8724  (0.5991377168231542)\n",
      "     | > loader_time: 0.0106  (0.007863766617245145)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:20:36 -- STEP: 61/406 -- GLOBAL_STEP: 6550\u001b[0m\n",
      "     | > loss: 1.3375768661499023  (1.3140547021490634)\n",
      "     | > log_mle: 0.305168092250824  (0.31284650134258585)\n",
      "     | > loss_dur: 1.0324087142944336  (1.001208200806477)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.5293, device='cuda:0')  (tensor(2.4894, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.5287  (0.607757490189349)\n",
      "     | > loader_time: 0.0049  (0.008017805756115522)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:20:52 -- STEP: 86/406 -- GLOBAL_STEP: 6575\u001b[0m\n",
      "     | > loss: 1.2729837894439697  (1.309977381728417)\n",
      "     | > log_mle: 0.30541402101516724  (0.3097087325051775)\n",
      "     | > loss_dur: 0.9675697088241577  (1.0002686492232393)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.3551, device='cuda:0')  (tensor(2.4792, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.4611  (0.6137324793394222)\n",
      "     | > loader_time: 0.0051  (0.008901582207790639)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:21:09 -- STEP: 111/406 -- GLOBAL_STEP: 6600\u001b[0m\n",
      "     | > loss: 1.2645504474639893  (1.3043765828416158)\n",
      "     | > log_mle: 0.27929699420928955  (0.3063039065481307)\n",
      "     | > loss_dur: 0.9852534532546997  (0.9980726757565063)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.3638, device='cuda:0')  (tensor(2.4675, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.8783  (0.624652067820231)\n",
      "     | > loader_time: 0.0135  (0.00981094815709569)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:21:27 -- STEP: 136/406 -- GLOBAL_STEP: 6625\u001b[0m\n",
      "     | > loss: 1.3274614810943604  (1.3027280770680487)\n",
      "     | > log_mle: 0.2907090187072754  (0.30350336388630034)\n",
      "     | > loss_dur: 1.036752462387085  (0.9992247131817483)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.4782, device='cuda:0')  (tensor(2.4640, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.5263  (0.6340519032057593)\n",
      "     | > loader_time: 0.0049  (0.010550113285289087)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:21:44 -- STEP: 161/406 -- GLOBAL_STEP: 6650\u001b[0m\n",
      "     | > loss: 1.3351523876190186  (1.302108104184548)\n",
      "     | > log_mle: 0.2862200140953064  (0.30139647063261243)\n",
      "     | > loss_dur: 1.048932433128357  (1.0007116350327956)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.5835, device='cuda:0')  (tensor(2.4650, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.8147  (0.6376579370557891)\n",
      "     | > loader_time: 0.0184  (0.011260947825745765)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:22:02 -- STEP: 186/406 -- GLOBAL_STEP: 6675\u001b[0m\n",
      "     | > loss: 1.3064020872116089  (1.3011103496756615)\n",
      "     | > log_mle: 0.28513336181640625  (0.29951186462115226)\n",
      "     | > loss_dur: 1.0212687253952026  (1.001598486656783)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.4665, device='cuda:0')  (tensor(2.4648, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.5125  (0.6470456495079945)\n",
      "     | > loader_time: 0.0249  (0.012157552985734834)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:22:20 -- STEP: 211/406 -- GLOBAL_STEP: 6700\u001b[0m\n",
      "     | > loss: 1.2667826414108276  (1.300605076749179)\n",
      "     | > log_mle: 0.28487277030944824  (0.2979009083661988)\n",
      "     | > loss_dur: 0.9819098711013794  (1.002704170360384)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.3886, device='cuda:0')  (tensor(2.4653, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.8441  (0.6544580934171993)\n",
      "     | > loader_time: 0.0128  (0.012235416620263555)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:22:38 -- STEP: 236/406 -- GLOBAL_STEP: 6725\u001b[0m\n",
      "     | > loss: 1.284788727760315  (1.2999778061600065)\n",
      "     | > log_mle: 0.30155932903289795  (0.29639338386260855)\n",
      "     | > loss_dur: 0.983229398727417  (1.0035844250755794)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.3934, device='cuda:0')  (tensor(2.4641, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.7567  (0.6598955251402774)\n",
      "     | > loader_time: 0.0058  (0.012463803008451298)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:22:57 -- STEP: 261/406 -- GLOBAL_STEP: 6750\u001b[0m\n",
      "     | > loss: 1.273749828338623  (1.2997388830586878)\n",
      "     | > log_mle: 0.279116690158844  (0.2949020216291435)\n",
      "     | > loss_dur: 0.9946331977844238  (1.0048368634848759)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.4104, device='cuda:0')  (tensor(2.4652, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.7875  (0.667068609332673)\n",
      "     | > loader_time: 0.0084  (0.012425120306197709)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:23:17 -- STEP: 286/406 -- GLOBAL_STEP: 6775\u001b[0m\n",
      "     | > loss: 1.3009999990463257  (1.2995504520156174)\n",
      "     | > log_mle: 0.2796732187271118  (0.2937066557107272)\n",
      "     | > loss_dur: 1.0213267803192139  (1.005843799431007)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.4824, device='cuda:0')  (tensor(2.4645, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.807  (0.6746948849071156)\n",
      "     | > loader_time: 0.0061  (0.012829783913138859)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:23:35 -- STEP: 311/406 -- GLOBAL_STEP: 6800\u001b[0m\n",
      "     | > loss: 1.2959940433502197  (1.2996211918220646)\n",
      "     | > log_mle: 0.2858813405036926  (0.29275916435327554)\n",
      "     | > loss_dur: 1.0101126432418823  (1.006862030535265)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.4170, device='cuda:0')  (tensor(2.4652, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.6126  (0.6789233002248686)\n",
      "     | > loader_time: 0.0147  (0.012841659343510958)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:23:55 -- STEP: 336/406 -- GLOBAL_STEP: 6825\u001b[0m\n",
      "     | > loss: 1.31740140914917  (1.29980545703854)\n",
      "     | > log_mle: 0.2778700590133667  (0.29172456672503844)\n",
      "     | > loss_dur: 1.0395313501358032  (1.0080808938613952)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.5627, device='cuda:0')  (tensor(2.4664, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.5955  (0.6864961861144927)\n",
      "     | > loader_time: 0.0292  (0.013090137214887705)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:24:15 -- STEP: 361/406 -- GLOBAL_STEP: 6850\u001b[0m\n",
      "     | > loss: 1.3034089803695679  (1.3000891809648438)\n",
      "     | > log_mle: 0.28551173210144043  (0.29070578222459703)\n",
      "     | > loss_dur: 1.0178972482681274  (1.0093834027028803)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.4138, device='cuda:0')  (tensor(2.4667, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.8042  (0.6926204451563618)\n",
      "     | > loader_time: 0.0064  (0.013381194540007949)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:24:36 -- STEP: 386/406 -- GLOBAL_STEP: 6875\u001b[0m\n",
      "     | > loss: 1.3101445436477661  (1.299652921721109)\n",
      "     | > log_mle: 0.28311944007873535  (0.2898742954965699)\n",
      "     | > loss_dur: 1.0270251035690308  (1.009778630239358)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.4936, device='cuda:0')  (tensor(2.4656, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.6249  (0.6992477277399962)\n",
      "     | > loader_time: 0.026  (0.013804005835340426)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: 1.2584807872772217  (1.2584807872772217)\n",
      "     | > log_mle: 0.30321425199508667  (0.30321425199508667)\n",
      "     | > loss_dur: 0.9552665948867798  (0.9552665948867798)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: 1.1887123584747314  (1.1887123584747314)\n",
      "     | > log_mle: 0.28629952669143677  (0.28629952669143677)\n",
      "     | > loss_dur: 0.9024127721786499  (0.9024127721786499)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: 1.272483468055725  (1.2305979132652283)\n",
      "     | > log_mle: 0.33087700605392456  (0.30858826637268066)\n",
      "     | > loss_dur: 0.9416064620018005  (0.9220096170902252)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: 1.266908884048462  (1.242701570192973)\n",
      "     | > log_mle: 0.29195547103881836  (0.30304400126139325)\n",
      "     | > loss_dur: 0.9749534130096436  (0.9396575490633646)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: 1.2759772539138794  (1.2510204911231995)\n",
      "     | > log_mle: 0.2687501907348633  (0.29447054862976074)\n",
      "     | > loss_dur: 1.0072270631790161  (0.9565499275922775)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: 1.2328665256500244  (1.2473896980285644)\n",
      "     | > log_mle: 0.26485174894332886  (0.28854678869247435)\n",
      "     | > loss_dur: 0.9680148363113403  (0.9588429093360901)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: 1.2962656021118164  (1.2555356820424397)\n",
      "     | > log_mle: 0.24710679054260254  (0.2816401223341624)\n",
      "     | > loss_dur: 1.0491588115692139  (0.9738955597082773)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: 1.2538315057754517  (1.255292228290013)\n",
      "     | > log_mle: 0.2977904677391052  (0.2839473145348685)\n",
      "     | > loss_dur: 0.9560410380363464  (0.9713449137551444)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: 1.2288473844528198  (1.2519866228103638)\n",
      "     | > log_mle: 0.2867037057876587  (0.2842918634414673)\n",
      "     | > loss_dur: 0.9421436786651611  (0.9676947593688965)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: 1.309128761291504  (1.2583357493082683)\n",
      "     | > log_mle: 0.28505200147628784  (0.284376323223114)\n",
      "     | > loss_dur: 1.0240768194198608  (0.9739594327078925)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: 1.2458381652832031  (1.2570859909057617)\n",
      "     | > log_mle: 0.28872519731521606  (0.28481121063232423)\n",
      "     | > loss_dur: 0.9571129083633423  (0.9722747802734375)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: 1.2484514713287354  (1.2563010345805774)\n",
      "     | > log_mle: 0.27703118324279785  (0.28410393541509454)\n",
      "     | > loss_dur: 0.9714202880859375  (0.9721970991654829)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: 1.2400085926055908  (1.2549433310826619)\n",
      "     | > log_mle: 0.29019254446029663  (0.2846113195021947)\n",
      "     | > loss_dur: 0.9498159885406494  (0.9703320066134135)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: 1.2994798421859741  (1.2583692165521474)\n",
      "     | > log_mle: 0.2746703624725342  (0.28384663049991316)\n",
      "     | > loss_dur: 1.02480947971344  (0.9745225814672617)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: 1.233707308769226  (1.2566076517105103)\n",
      "     | > log_mle: 0.28151649236679077  (0.283680192061833)\n",
      "     | > loss_dur: 0.9521908164024353  (0.9729274553912026)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: 1.2578184604644775  (1.256688372294108)\n",
      "     | > log_mle: 0.2856890559196472  (0.2838141163190206)\n",
      "     | > loss_dur: 0.9721293449401855  (0.9728742480278015)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: 1.2751634120941162  (1.2578430622816086)\n",
      "     | > log_mle: 0.28115445375442505  (0.28364788740873337)\n",
      "     | > loss_dur: 0.9940088987350464  (0.9741951636970043)\n",
      "\n",
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time: 0.0035121291875839233 \u001b[0m(+0.0)\n",
      "     | > avg_loss: 1.2578430622816086 \u001b[0m(+0.0)\n",
      "     | > avg_log_mle: 0.28364788740873337 \u001b[0m(+0.0)\n",
      "     | > avg_loss_dur: 0.9741951636970043 \u001b[0m(+0.0)\n",
      "\n",
      " > BEST MODEL : train/run-February-22-2025_02+19AM-9b6e3e6/best_model_6895.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 1/40\u001b[0m\n",
      " --> train/run-February-22-2025_02+19AM-9b6e3e6\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-22 02:25:01) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:25:05 -- STEP: 5/406 -- GLOBAL_STEP: 6900\u001b[0m\n",
      "     | > loss: 1.3420872688293457  (1.3815287351608276)\n",
      "     | > log_mle: 0.32732290029525757  (0.31863400936126707)\n",
      "     | > loss_dur: 1.014764428138733  (1.0628947257995605)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.3711, device='cuda:0')  (tensor(2.6321, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.2601  (0.3514608383178711)\n",
      "     | > loader_time: 0.0026  (0.00788736343383789)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:25:20 -- STEP: 30/406 -- GLOBAL_STEP: 6925\u001b[0m\n",
      "     | > loss: 1.2895033359527588  (1.3120650847752888)\n",
      "     | > log_mle: 0.315559983253479  (0.3129649102687836)\n",
      "     | > loss_dur: 0.9739434123039246  (0.999100174506505)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.3595, device='cuda:0')  (tensor(2.4809, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.3  (0.5265912691752115)\n",
      "     | > loader_time: 0.0043  (0.008486358324686685)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:25:37 -- STEP: 55/406 -- GLOBAL_STEP: 6950\u001b[0m\n",
      "     | > loss: 1.2577619552612305  (1.304088696566495)\n",
      "     | > log_mle: 0.2859823703765869  (0.31063356507908213)\n",
      "     | > loss_dur: 0.9717795252799988  (0.9934551325711335)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.4733, device='cuda:0')  (tensor(2.4584, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.7527  (0.5956959334286775)\n",
      "     | > loader_time: 0.0131  (0.009714243628761988)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:25:55 -- STEP: 80/406 -- GLOBAL_STEP: 6975\u001b[0m\n",
      "     | > loss: 1.3306818008422852  (1.301139569282532)\n",
      "     | > log_mle: 0.30597323179244995  (0.3076954938471317)\n",
      "     | > loss_dur: 1.0247085094451904  (0.9934440724551676)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.5142, device='cuda:0')  (tensor(2.4548, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.7125  (0.6275190651416778)\n",
      "     | > loader_time: 0.0047  (0.01025705337524414)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:26:12 -- STEP: 105/406 -- GLOBAL_STEP: 7000\u001b[0m\n",
      "     | > loss: 1.2363858222961426  (1.2950044961202711)\n",
      "     | > log_mle: 0.30304741859436035  (0.30418457701092666)\n",
      "     | > loss_dur: 0.9333383440971375  (0.9908199151357013)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.3375, device='cuda:0')  (tensor(2.4440, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.6646  (0.6357055823008219)\n",
      "     | > loader_time: 0.0056  (0.00963208107721238)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:26:29 -- STEP: 130/406 -- GLOBAL_STEP: 7025\u001b[0m\n",
      "     | > loss: 1.2810046672821045  (1.292353933591109)\n",
      "     | > log_mle: 0.29756462574005127  (0.3011715292930602)\n",
      "     | > loss_dur: 0.9834400415420532  (0.9911824001715733)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.4618, device='cuda:0')  (tensor(2.4364, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.8042  (0.6458085335217988)\n",
      "     | > loader_time: 0.0051  (0.009960018671475925)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:26:48 -- STEP: 155/406 -- GLOBAL_STEP: 7050\u001b[0m\n",
      "     | > loss: 1.2267639636993408  (1.2914355862525202)\n",
      "     | > log_mle: 0.2884697914123535  (0.29893600594612846)\n",
      "     | > loss_dur: 0.9382941722869873  (0.992499577999115)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.2790, device='cuda:0')  (tensor(2.4367, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.6431  (0.6590249215402911)\n",
      "     | > loader_time: 0.0175  (0.010800806168586984)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:27:08 -- STEP: 180/406 -- GLOBAL_STEP: 7075\u001b[0m\n",
      "     | > loss: 1.257078766822815  (1.2905860477023652)\n",
      "     | > log_mle: 0.28950929641723633  (0.2970129691892197)\n",
      "     | > loss_dur: 0.9675694704055786  (0.9935730768574609)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.4281, device='cuda:0')  (tensor(2.4380, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 1.2212  (0.6781510300106472)\n",
      "     | > loader_time: 0.0069  (0.011326444149017342)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:27:29 -- STEP: 205/406 -- GLOBAL_STEP: 7100\u001b[0m\n",
      "     | > loss: 1.2964277267456055  (1.2900769501197624)\n",
      "     | > log_mle: 0.2800227999687195  (0.2952745362025933)\n",
      "     | > loss_dur: 1.0164048671722412  (0.9948024118818888)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.5062, device='cuda:0')  (tensor(2.4396, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.698  (0.692809265415843)\n",
      "     | > loader_time: 0.0114  (0.011093583921106856)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:27:50 -- STEP: 230/406 -- GLOBAL_STEP: 7125\u001b[0m\n",
      "     | > loss: 1.2827802896499634  (1.2891047809434968)\n",
      "     | > log_mle: 0.2857004404067993  (0.29368944738222175)\n",
      "     | > loss_dur: 0.9970798492431641  (0.9954153314880703)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.3915, device='cuda:0')  (tensor(2.4381, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 1.3285  (0.706941526869069)\n",
      "     | > loader_time: 0.0069  (0.011212560404901924)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:28:09 -- STEP: 255/406 -- GLOBAL_STEP: 7150\u001b[0m\n",
      "     | > loss: 1.2806016206741333  (1.2891284302169197)\n",
      "     | > log_mle: 0.2825474143028259  (0.29220186822554617)\n",
      "     | > loss_dur: 0.9980542063713074  (0.9969265603551678)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.4615, device='cuda:0')  (tensor(2.4406, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.6723  (0.7125903101528392)\n",
      "     | > loader_time: 0.0056  (0.011633771073584468)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:28:30 -- STEP: 280/406 -- GLOBAL_STEP: 7175\u001b[0m\n",
      "     | > loss: 1.2918152809143066  (1.2886389298098424)\n",
      "     | > log_mle: 0.2646517753601074  (0.2909072041511534)\n",
      "     | > loss_dur: 1.0271635055541992  (0.9977317254458155)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.4967, device='cuda:0')  (tensor(2.4393, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.8113  (0.7224337739603859)\n",
      "     | > loader_time: 0.0053  (0.01176035404205323)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:28:50 -- STEP: 305/406 -- GLOBAL_STEP: 7200\u001b[0m\n",
      "     | > loss: 1.3146138191223145  (1.2888382681080548)\n",
      "     | > log_mle: 0.2777339816093445  (0.2898412503179954)\n",
      "     | > loss_dur: 1.0368797779083252  (0.9989970173992094)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.5057, device='cuda:0')  (tensor(2.4400, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.7528  (0.7271301300799262)\n",
      "     | > loader_time: 0.0075  (0.012224075442454855)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:29:10 -- STEP: 330/406 -- GLOBAL_STEP: 7225\u001b[0m\n",
      "     | > loss: 1.3107316493988037  (1.2884804133212926)\n",
      "     | > log_mle: 0.2678878903388977  (0.288897477677374)\n",
      "     | > loss_dur: 1.0428436994552612  (0.9995829358245387)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.5086, device='cuda:0')  (tensor(2.4391, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.5029  (0.7308793747063839)\n",
      "     | > loader_time: 0.0064  (0.012607342546636409)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:29:33 -- STEP: 355/406 -- GLOBAL_STEP: 7250\u001b[0m\n",
      "     | > loss: 1.3000483512878418  (1.2892820422078515)\n",
      "     | > log_mle: 0.26587069034576416  (0.28780128384979653)\n",
      "     | > loss_dur: 1.0341776609420776  (1.0014807590296568)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.5121, device='cuda:0')  (tensor(2.4414, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.6924  (0.7408388661666652)\n",
      "     | > loader_time: 0.0198  (0.012726087301549777)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:29:54 -- STEP: 380/406 -- GLOBAL_STEP: 7275\u001b[0m\n",
      "     | > loss: 1.285813808441162  (1.2886902529942361)\n",
      "     | > log_mle: 0.28188806772232056  (0.28686817115858954)\n",
      "     | > loss_dur: 1.0039258003234863  (1.001822082463063)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.4978, device='cuda:0')  (tensor(2.4400, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 1.3201  (0.74691068686937)\n",
      "     | > loader_time: 0.0057  (0.012910329668145431)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:30:10 -- STEP: 405/406 -- GLOBAL_STEP: 7300\u001b[0m\n",
      "     | > loss: 1.3208389282226562  (1.288385974036322)\n",
      "     | > log_mle: 0.27022039890289307  (0.28596266213758464)\n",
      "     | > loss_dur: 1.0506185293197632  (1.0024233124874251)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.6168, device='cuda:0')  (tensor(2.4403, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.2893  (0.7383276321269845)\n",
      "     | > loader_time: 0.0034  (0.0127116945054796)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: 1.245973825454712  (1.245973825454712)\n",
      "     | > log_mle: 0.2999037504196167  (0.2999037504196167)\n",
      "     | > loss_dur: 0.9460700750350952  (0.9460700750350952)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: 1.1785101890563965  (1.1785101890563965)\n",
      "     | > log_mle: 0.28295987844467163  (0.28295987844467163)\n",
      "     | > loss_dur: 0.8955502510070801  (0.8955502510070801)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: 1.2630021572113037  (1.22075617313385)\n",
      "     | > log_mle: 0.32758909463882446  (0.30527448654174805)\n",
      "     | > loss_dur: 0.9354130029678345  (0.9154816269874573)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: 1.2662383317947388  (1.2359168926874797)\n",
      "     | > log_mle: 0.2887424826622009  (0.299763818581899)\n",
      "     | > loss_dur: 0.9774958491325378  (0.9361530343691508)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: 1.2605222463607788  (1.2420682311058044)\n",
      "     | > log_mle: 0.2654620409011841  (0.2911883741617203)\n",
      "     | > loss_dur: 0.9950602054595947  (0.9508798271417618)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: 1.2186665534973145  (1.2373878955841064)\n",
      "     | > log_mle: 0.26163822412490845  (0.28527834415435793)\n",
      "     | > loss_dur: 0.9570282697677612  (0.9521095156669617)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: 1.2853683233261108  (1.2453846335411072)\n",
      "     | > log_mle: 0.2439666986465454  (0.27839306990305585)\n",
      "     | > loss_dur: 1.0414016246795654  (0.966991533835729)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: 1.2454290390014648  (1.2453909771783012)\n",
      "     | > log_mle: 0.294719398021698  (0.2807254024914333)\n",
      "     | > loss_dur: 0.9507097005844116  (0.9646655576569694)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: 1.221210241317749  (1.2423683851957321)\n",
      "     | > log_mle: 0.28352028131484985  (0.28107476234436035)\n",
      "     | > loss_dur: 0.9376899600028992  (0.9612936079502106)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: 1.3015689849853516  (1.248946229616801)\n",
      "     | > log_mle: 0.2818567752838135  (0.28116165267096627)\n",
      "     | > loss_dur: 1.019712209701538  (0.967784563700358)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: 1.234285593032837  (1.2474801659584045)\n",
      "     | > log_mle: 0.28555065393447876  (0.2816005527973175)\n",
      "     | > loss_dur: 0.9487349390983582  (0.965879601240158)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: 1.2375288009643555  (1.246575496413491)\n",
      "     | > log_mle: 0.2737423777580261  (0.280886173248291)\n",
      "     | > loss_dur: 0.9637864828109741  (0.9656893177465959)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: 1.229740858078003  (1.2451726098855336)\n",
      "     | > log_mle: 0.28695762157440186  (0.2813921272754669)\n",
      "     | > loss_dur: 0.9427831768989563  (0.9637804726759592)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: 1.2924773693084717  (1.248811437533452)\n",
      "     | > log_mle: 0.2714883089065552  (0.28063029509324294)\n",
      "     | > loss_dur: 1.0209890604019165  (0.9681811332702637)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: 1.2224345207214355  (1.2469273720468794)\n",
      "     | > log_mle: 0.27834147214889526  (0.28046680774007526)\n",
      "     | > loss_dur: 0.9440929889678955  (0.9664605515343803)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: 1.247740387916565  (1.2469815731048584)\n",
      "     | > log_mle: 0.2825026512145996  (0.28060253063837687)\n",
      "     | > loss_dur: 0.9652377367019653  (0.9663790305455525)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: 1.2618083953857422  (1.2479082494974136)\n",
      "     | > log_mle: 0.27810215950012207  (0.28044625744223595)\n",
      "     | > loss_dur: 0.9837062358856201  (0.9674619808793068)\n",
      "\n",
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.0030875205993652344 \u001b[0m(-0.00042460858821868896)\n",
      "     | > avg_loss:\u001b[92m 1.2479082494974136 \u001b[0m(-0.009934812784194946)\n",
      "     | > avg_log_mle:\u001b[92m 0.28044625744223595 \u001b[0m(-0.0032016299664974213)\n",
      "     | > avg_loss_dur:\u001b[92m 0.9674619808793068 \u001b[0m(-0.006733182817697525)\n",
      "\n",
      " > BEST MODEL : train/run-February-22-2025_02+19AM-9b6e3e6/best_model_7301.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 2/40\u001b[0m\n",
      " --> train/run-February-22-2025_02+19AM-9b6e3e6\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-22 02:30:21) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:30:34 -- STEP: 24/406 -- GLOBAL_STEP: 7325\u001b[0m\n",
      "     | > loss: 1.3048324584960938  (1.3034339745839436)\n",
      "     | > log_mle: 0.3089190125465393  (0.31016167749961215)\n",
      "     | > loss_dur: 0.9959134459495544  (0.9932722946008047)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.4270, device='cuda:0')  (tensor(2.4709, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.5312  (0.45617451270421344)\n",
      "     | > loader_time: 0.0226  (0.007762124141057332)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:30:48 -- STEP: 49/406 -- GLOBAL_STEP: 7350\u001b[0m\n",
      "     | > loss: 1.2888128757476807  (1.2934547735720265)\n",
      "     | > log_mle: 0.3080901503562927  (0.30896393255311616)\n",
      "     | > loss_dur: 0.9807226657867432  (0.9844908410189103)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.4525, device='cuda:0')  (tensor(2.4305, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.3018  (0.5037617440126381)\n",
      "     | > loader_time: 0.0043  (0.009475591231365595)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:31:04 -- STEP: 74/406 -- GLOBAL_STEP: 7375\u001b[0m\n",
      "     | > loss: 1.2918869256973267  (1.2882999455606616)\n",
      "     | > log_mle: 0.26719558238983154  (0.3045365133801024)\n",
      "     | > loss_dur: 1.0246913433074951  (0.9837634337914957)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.5698, device='cuda:0')  (tensor(2.4285, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.8646  (0.539163006318582)\n",
      "     | > loader_time: 0.0052  (0.009581124460374986)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:31:18 -- STEP: 99/406 -- GLOBAL_STEP: 7400\u001b[0m\n",
      "     | > loss: 1.2994318008422852  (1.2837870265498312)\n",
      "     | > log_mle: 0.29125088453292847  (0.30130078696241286)\n",
      "     | > loss_dur: 1.008180856704712  (0.9824862377812164)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.4439, device='cuda:0')  (tensor(2.4240, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.3376  (0.5429491587359495)\n",
      "     | > loader_time: 0.0131  (0.010367270671960084)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:31:34 -- STEP: 124/406 -- GLOBAL_STEP: 7425\u001b[0m\n",
      "     | > loss: 1.2399715185165405  (1.2797245296739768)\n",
      "     | > log_mle: 0.2806422710418701  (0.29804802565805383)\n",
      "     | > loss_dur: 0.9593292474746704  (0.9816765054579704)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.3439, device='cuda:0')  (tensor(2.4128, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.4541  (0.5548236946905812)\n",
      "     | > loader_time: 0.0055  (0.010227787879205523)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:31:49 -- STEP: 149/406 -- GLOBAL_STEP: 7450\u001b[0m\n",
      "     | > loss: 1.2689459323883057  (1.2790773474930122)\n",
      "     | > log_mle: 0.28078705072402954  (0.2953958415345058)\n",
      "     | > loss_dur: 0.9881588220596313  (0.9836815063585371)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.3913, device='cuda:0')  (tensor(2.4122, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.4496  (0.5632733626653684)\n",
      "     | > loader_time: 0.0063  (0.010392566655306211)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:32:05 -- STEP: 174/406 -- GLOBAL_STEP: 7475\u001b[0m\n",
      "     | > loss: 1.2657606601715088  (1.2777499549690339)\n",
      "     | > log_mle: 0.27906912565231323  (0.2934214061704176)\n",
      "     | > loss_dur: 0.9866915941238403  (0.9843285491411713)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.3755, device='cuda:0')  (tensor(2.4107, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.7275  (0.5721476996082001)\n",
      "     | > loader_time: 0.0087  (0.010609126639092107)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:32:22 -- STEP: 199/406 -- GLOBAL_STEP: 7500\u001b[0m\n",
      "     | > loss: 1.2787331342697144  (1.2768043171820331)\n",
      "     | > log_mle: 0.2770683765411377  (0.2914619077390162)\n",
      "     | > loss_dur: 1.0016647577285767  (0.9853424103415791)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.4384, device='cuda:0')  (tensor(2.4113, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.5564  (0.5820555459314857)\n",
      "     | > loader_time: 0.0057  (0.010635922302552805)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:32:39 -- STEP: 224/406 -- GLOBAL_STEP: 7525\u001b[0m\n",
      "     | > loss: 1.2638442516326904  (1.2753223276564056)\n",
      "     | > log_mle: 0.2838854193687439  (0.2898001548435006)\n",
      "     | > loss_dur: 0.9799587726593018  (0.985522173345089)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.3786, device='cuda:0')  (tensor(2.4089, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.8958  (0.592680242444788)\n",
      "     | > loader_time: 0.0135  (0.010423471885068078)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:32:57 -- STEP: 249/406 -- GLOBAL_STEP: 7550\u001b[0m\n",
      "     | > loss: 1.2396395206451416  (1.2746715325428302)\n",
      "     | > log_mle: 0.2787933945655823  (0.2883181220077605)\n",
      "     | > loss_dur: 0.9608461260795593  (0.9863534098169411)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.3409, device='cuda:0')  (tensor(2.4085, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.8905  (0.6043627338715828)\n",
      "     | > loader_time: 0.006  (0.010489473381195684)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:33:14 -- STEP: 274/406 -- GLOBAL_STEP: 7575\u001b[0m\n",
      "     | > loss: 1.2757419347763062  (1.2741790400804396)\n",
      "     | > log_mle: 0.2740306854248047  (0.28674819130096985)\n",
      "     | > loss_dur: 1.0017112493515015  (0.9874308487794695)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.4320, device='cuda:0')  (tensor(2.4086, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.5626  (0.6102027397086153)\n",
      "     | > loader_time: 0.0198  (0.011029877801881222)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:33:32 -- STEP: 299/406 -- GLOBAL_STEP: 7600\u001b[0m\n",
      "     | > loss: 1.24430513381958  (1.273825696479517)\n",
      "     | > log_mle: 0.2598523497581482  (0.2855736629221351)\n",
      "     | > loss_dur: 0.9844527840614319  (0.9882520331586883)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.3349, device='cuda:0')  (tensor(2.4081, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 1.1343  (0.6175868870023902)\n",
      "     | > loader_time: 0.0269  (0.01119483832930243)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:33:51 -- STEP: 324/406 -- GLOBAL_STEP: 7625\u001b[0m\n",
      "     | > loss: 1.230698585510254  (1.2731774703220087)\n",
      "     | > log_mle: 0.2656604051589966  (0.28451398585313625)\n",
      "     | > loss_dur: 0.9650382399559021  (0.9886634835490474)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.2642, device='cuda:0')  (tensor(2.4073, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.8769  (0.6265966126948226)\n",
      "     | > loader_time: 0.0077  (0.011472030186358796)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:34:09 -- STEP: 349/406 -- GLOBAL_STEP: 7650\u001b[0m\n",
      "     | > loss: 1.3019473552703857  (1.2738358000971186)\n",
      "     | > log_mle: 0.2710241675376892  (0.2833840935824593)\n",
      "     | > loss_dur: 1.0309231281280518  (0.9904517044652157)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.4239, device='cuda:0')  (tensor(2.4088, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.6474  (0.6326937573003903)\n",
      "     | > loader_time: 0.0087  (0.011815958514937703)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:34:29 -- STEP: 374/406 -- GLOBAL_STEP: 7675\u001b[0m\n",
      "     | > loss: 1.2619822025299072  (1.2729696625056757)\n",
      "     | > log_mle: 0.26907044649124146  (0.2822533418787992)\n",
      "     | > loss_dur: 0.9929117560386658  (0.9907163182363153)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.3293, device='cuda:0')  (tensor(2.4063, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.7014  (0.6415912352781244)\n",
      "     | > loader_time: 0.0141  (0.012377223866508611)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:34:47 -- STEP: 399/406 -- GLOBAL_STEP: 7700\u001b[0m\n",
      "     | > loss: 1.274644136428833  (1.2724226139541854)\n",
      "     | > log_mle: 0.2672026753425598  (0.2813001806873427)\n",
      "     | > loss_dur: 1.007441520690918  (0.9911224308766817)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.4489, device='cuda:0')  (tensor(2.4055, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.4013  (0.6447481744570245)\n",
      "     | > loader_time: 0.0062  (0.012647643125146856)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: 1.229346752166748  (1.229346752166748)\n",
      "     | > log_mle: 0.2932777404785156  (0.2932777404785156)\n",
      "     | > loss_dur: 0.9360689520835876  (0.9360689520835876)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: 1.1548256874084473  (1.1548256874084473)\n",
      "     | > log_mle: 0.27617084980010986  (0.27617084980010986)\n",
      "     | > loss_dur: 0.8786548972129822  (0.8786548972129822)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: 1.246260404586792  (1.2005430459976196)\n",
      "     | > log_mle: 0.3209332823753357  (0.2985520660877228)\n",
      "     | > loss_dur: 0.9253271222114563  (0.9019910097122192)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: 1.2421200275421143  (1.2144020398457844)\n",
      "     | > log_mle: 0.2820841073989868  (0.2930627465248108)\n",
      "     | > loss_dur: 0.9600359797477722  (0.9213393330574036)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: 1.2471923828125  (1.2225996255874634)\n",
      "     | > log_mle: 0.2587524652481079  (0.28448517620563507)\n",
      "     | > loss_dur: 0.9884399175643921  (0.9381144791841507)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: 1.2009127140045166  (1.218262243270874)\n",
      "     | > log_mle: 0.25491583347320557  (0.27857130765914917)\n",
      "     | > loss_dur: 0.9459968209266663  (0.9396909475326538)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: 1.262511968612671  (1.2256371974945068)\n",
      "     | > log_mle: 0.23720651865005493  (0.2716771761576335)\n",
      "     | > loss_dur: 1.0253055095672607  (0.9539600412050883)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: 1.226510763168335  (1.225761992590768)\n",
      "     | > log_mle: 0.28837698698043823  (0.27406286341803415)\n",
      "     | > loss_dur: 0.9381337761878967  (0.9516991462026324)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: 1.2054029703140259  (1.2232171148061752)\n",
      "     | > log_mle: 0.27704232931137085  (0.27443529665470123)\n",
      "     | > loss_dur: 0.928360641002655  (0.9487818330526352)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: 1.2786054611206055  (1.2293713755077786)\n",
      "     | > log_mle: 0.27521437406539917  (0.2745218608114455)\n",
      "     | > loss_dur: 1.003391146659851  (0.954849534564548)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: 1.2175419330596924  (1.22818843126297)\n",
      "     | > log_mle: 0.27901142835617065  (0.27497081756591796)\n",
      "     | > loss_dur: 0.938530445098877  (0.953217625617981)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: 1.2196003198623657  (1.227407693862915)\n",
      "     | > log_mle: 0.2668977975845337  (0.2742369066585194)\n",
      "     | > loss_dur: 0.952702522277832  (0.9531707980416038)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: 1.2043867111206055  (1.2254892786343892)\n",
      "     | > log_mle: 0.2803107500076294  (0.27474306027094525)\n",
      "     | > loss_dur: 0.9240759015083313  (0.9507462233304977)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: 1.273695707321167  (1.229197465456449)\n",
      "     | > log_mle: 0.26477736234664917  (0.2739764681229225)\n",
      "     | > loss_dur: 1.0089184045791626  (0.955221006503472)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: 1.1991256475448608  (1.2270494784627641)\n",
      "     | > log_mle: 0.2717289328575134  (0.273815929889679)\n",
      "     | > loss_dur: 0.9273967146873474  (0.9532335570880345)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: 1.2229347229003906  (1.2267751614252727)\n",
      "     | > log_mle: 0.2757796049118042  (0.2739468415578207)\n",
      "     | > loss_dur: 0.9471550583839417  (0.952828323841095)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: 1.25217866897583  (1.2283628806471825)\n",
      "     | > log_mle: 0.2717830538749695  (0.2738116048276425)\n",
      "     | > loss_dur: 0.9803956151008606  (0.9545512795448303)\n",
      "\n",
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[91m 0.004583090543746948 \u001b[0m(+0.0014955699443817139)\n",
      "     | > avg_loss:\u001b[92m 1.2283628806471825 \u001b[0m(-0.01954536885023117)\n",
      "     | > avg_log_mle:\u001b[92m 0.2738116048276425 \u001b[0m(-0.00663465261459345)\n",
      "     | > avg_loss_dur:\u001b[92m 0.9545512795448303 \u001b[0m(-0.012910701334476471)\n",
      "\n",
      " > BEST MODEL : train/run-February-22-2025_02+19AM-9b6e3e6/best_model_7707.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 3/40\u001b[0m\n",
      " --> train/run-February-22-2025_02+19AM-9b6e3e6\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-22 02:35:01) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:35:15 -- STEP: 18/406 -- GLOBAL_STEP: 7725\u001b[0m\n",
      "     | > loss: 1.2727446556091309  (1.2937806381119623)\n",
      "     | > log_mle: 0.30647987127304077  (0.30222777194446987)\n",
      "     | > loss_dur: 0.9662647843360901  (0.9915528661674924)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.3732, device='cuda:0')  (tensor(2.4697, device='cuda:0'))\n",
      "     | > current_lr: 7.5e-07 \n",
      "     | > step_time: 0.4704  (0.4090483585993449)\n",
      "     | > loader_time: 0.0135  (0.006522708468967014)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:35:30 -- STEP: 43/406 -- GLOBAL_STEP: 7750\u001b[0m\n",
      "     | > loss: 1.2071619033813477  (1.2717021038365914)\n",
      "     | > log_mle: 0.30482017993927  (0.3027410853740781)\n",
      "     | > loss_dur: 0.9023416638374329  (0.9689610226209774)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.2223, device='cuda:0')  (tensor(2.3829, device='cuda:0'))\n",
      "     | > current_lr: 7.5e-07 \n",
      "     | > step_time: 0.5626  (0.49996974301892655)\n",
      "     | > loader_time: 0.004  (0.008723685907763106)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:35:44 -- STEP: 68/406 -- GLOBAL_STEP: 7775\u001b[0m\n",
      "     | > loss: 1.2601172924041748  (1.266602574025883)\n",
      "     | > log_mle: 0.29083651304244995  (0.2989174793748295)\n",
      "     | > loss_dur: 0.9692807197570801  (0.9676850937745151)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.4190, device='cuda:0')  (tensor(2.3790, device='cuda:0'))\n",
      "     | > current_lr: 7.5e-07 \n",
      "     | > step_time: 0.6024  (0.5298415878239799)\n",
      "     | > loader_time: 0.0181  (0.009382829946630145)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:36:00 -- STEP: 93/406 -- GLOBAL_STEP: 7800\u001b[0m\n",
      "     | > loss: 1.1898175477981567  (1.2613823336939656)\n",
      "     | > log_mle: 0.27121490240097046  (0.2948762947513212)\n",
      "     | > loss_dur: 0.9186026453971863  (0.966506036379004)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.3175, device='cuda:0')  (tensor(2.3743, device='cuda:0'))\n",
      "     | > current_lr: 7.5e-07 \n",
      "     | > step_time: 0.4119  (0.5517088341456584)\n",
      "     | > loader_time: 0.0045  (0.010379478495608094)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:36:16 -- STEP: 118/406 -- GLOBAL_STEP: 7825\u001b[0m\n",
      "     | > loss: 1.2175307273864746  (1.256920650853949)\n",
      "     | > log_mle: 0.2732929587364197  (0.291696636858633)\n",
      "     | > loss_dur: 0.9442377686500549  (0.9652240104594473)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.2527, device='cuda:0')  (tensor(2.3628, device='cuda:0'))\n",
      "     | > current_lr: 7.5e-07 \n",
      "     | > step_time: 1.028  (0.5627583548174062)\n",
      "     | > loader_time: 0.024  (0.01019854262723761)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:36:33 -- STEP: 143/406 -- GLOBAL_STEP: 7850\u001b[0m\n",
      "     | > loss: 1.2342462539672852  (1.2554821351191383)\n",
      "     | > log_mle: 0.26873403787612915  (0.28862770662441123)\n",
      "     | > loss_dur: 0.965512216091156  (0.9668544272442797)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.3056, device='cuda:0')  (tensor(2.3590, device='cuda:0'))\n",
      "     | > current_lr: 7.5e-07 \n",
      "     | > step_time: 0.5839  (0.5803216303978763)\n",
      "     | > loader_time: 0.0206  (0.010372128519978555)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:36:49 -- STEP: 168/406 -- GLOBAL_STEP: 7875\u001b[0m\n",
      "     | > loss: 1.2428901195526123  (1.253610325001535)\n",
      "     | > log_mle: 0.2873157262802124  (0.28653383184046977)\n",
      "     | > loss_dur: 0.9555743336677551  (0.967076491741907)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.3104, device='cuda:0')  (tensor(2.3555, device='cuda:0'))\n",
      "     | > current_lr: 7.5e-07 \n",
      "     | > step_time: 0.4994  (0.586872652882621)\n",
      "     | > loader_time: 0.0057  (0.01036427844138372)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:37:07 -- STEP: 193/406 -- GLOBAL_STEP: 7900\u001b[0m\n",
      "     | > loss: 1.2305313348770142  (1.2523723519527847)\n",
      "     | > log_mle: 0.26899075508117676  (0.284392000171187)\n",
      "     | > loss_dur: 0.9615405797958374  (0.9679803486932744)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.3121, device='cuda:0')  (tensor(2.3539, device='cuda:0'))\n",
      "     | > current_lr: 7.5e-07 \n",
      "     | > step_time: 0.8264  (0.6028367052424135)\n",
      "     | > loader_time: 0.0065  (0.01062411224286173)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:37:24 -- STEP: 218/406 -- GLOBAL_STEP: 7925\u001b[0m\n",
      "     | > loss: 1.2475473880767822  (1.250832992956179)\n",
      "     | > log_mle: 0.27683281898498535  (0.282720308511629)\n",
      "     | > loss_dur: 0.9707146286964417  (0.9681126836243026)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.3065, device='cuda:0')  (tensor(2.3542, device='cuda:0'))\n",
      "     | > current_lr: 7.5e-07 \n",
      "     | > step_time: 0.8499  (0.6113262996761073)\n",
      "     | > loader_time: 0.0067  (0.011255687529887625)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:37:41 -- STEP: 243/406 -- GLOBAL_STEP: 7950\u001b[0m\n",
      "     | > loss: 1.2642207145690918  (1.2499998194690594)\n",
      "     | > log_mle: 0.25448155403137207  (0.28097390049278975)\n",
      "     | > loss_dur: 1.0097391605377197  (0.969025918730983)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.5158, device='cuda:0')  (tensor(2.3531, device='cuda:0'))\n",
      "     | > current_lr: 7.5e-07 \n",
      "     | > step_time: 0.7594  (0.6172792744734646)\n",
      "     | > loader_time: 0.02  (0.011784688926037444)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:38:00 -- STEP: 268/406 -- GLOBAL_STEP: 7975\u001b[0m\n",
      "     | > loss: 1.2201387882232666  (1.248885910012829)\n",
      "     | > log_mle: 0.2588649392127991  (0.279548994195995)\n",
      "     | > loss_dur: 0.9612737894058228  (0.969336914259996)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.3843, device='cuda:0')  (tensor(2.3521, device='cuda:0'))\n",
      "     | > current_lr: 7.5e-07 \n",
      "     | > step_time: 0.5438  (0.6259370152630019)\n",
      "     | > loader_time: 0.036  (0.012360366422738602)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:38:18 -- STEP: 293/406 -- GLOBAL_STEP: 8000\u001b[0m\n",
      "     | > loss: 1.2276043891906738  (1.2483616229210295)\n",
      "     | > log_mle: 0.2623423933982849  (0.27818169040484647)\n",
      "     | > loss_dur: 0.9652620553970337  (0.9701799319058961)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.2571, device='cuda:0')  (tensor(2.3507, device='cuda:0'))\n",
      "     | > current_lr: 7.5e-07 \n",
      "     | > step_time: 0.84  (0.6330452925516065)\n",
      "     | > loader_time: 0.0498  (0.01282393891656765)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:38:36 -- STEP: 318/406 -- GLOBAL_STEP: 8025\u001b[0m\n",
      "     | > loss: 1.2422635555267334  (1.247636603109492)\n",
      "     | > log_mle: 0.2648184895515442  (0.27698996344452387)\n",
      "     | > loss_dur: 0.977445125579834  (0.9706466406021478)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.2871, device='cuda:0')  (tensor(2.3495, device='cuda:0'))\n",
      "     | > current_lr: 7.5e-07 \n",
      "     | > step_time: 1.314  (0.6392839832125964)\n",
      "     | > loader_time: 0.011  (0.013301503733269073)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:38:57 -- STEP: 343/406 -- GLOBAL_STEP: 8050\u001b[0m\n",
      "     | > loss: 1.2575469017028809  (1.247460359039529)\n",
      "     | > log_mle: 0.2507455348968506  (0.2757369451898179)\n",
      "     | > loss_dur: 1.0068013668060303  (0.97172341419726)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.4032, device='cuda:0')  (tensor(2.3496, device='cuda:0'))\n",
      "     | > current_lr: 7.5e-07 \n",
      "     | > step_time: 0.5426  (0.6499640705286582)\n",
      "     | > loader_time: 0.0178  (0.013691730471463662)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:39:16 -- STEP: 368/406 -- GLOBAL_STEP: 8075\u001b[0m\n",
      "     | > loss: 1.2436583042144775  (1.2469053061112114)\n",
      "     | > log_mle: 0.258975088596344  (0.27458270979316335)\n",
      "     | > loss_dur: 0.9846831560134888  (0.9723225971278937)\n",
      "     | > amp_scaler: 32768.0  (32857.04347826087)\n",
      "     | > grad_norm: tensor(2.3464, device='cuda:0')  (tensor(2.3408, device='cuda:0'))\n",
      "     | > current_lr: 7.5e-07 \n",
      "     | > step_time: 0.9185  (0.6569572551094961)\n",
      "     | > loader_time: 0.0537  (0.01396761381107828)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:39:36 -- STEP: 393/406 -- GLOBAL_STEP: 8100\u001b[0m\n",
      "     | > loss: 1.2253751754760742  (1.2457921389708382)\n",
      "     | > log_mle: 0.2545167803764343  (0.2735195610359426)\n",
      "     | > loss_dur: 0.9708583354949951  (0.9722725786932249)\n",
      "     | > amp_scaler: 32768.0  (32851.37913486004)\n",
      "     | > grad_norm: tensor(2.2820, device='cuda:0')  (tensor(2.3381, device='cuda:0'))\n",
      "     | > current_lr: 7.5e-07 \n",
      "     | > step_time: 0.4292  (0.6647022686538493)\n",
      "     | > loader_time: 0.0082  (0.014377013417600676)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: 1.2114524841308594  (1.2114524841308594)\n",
      "     | > log_mle: 0.2835842967033386  (0.2835842967033386)\n",
      "     | > loss_dur: 0.9278682470321655  (0.9278682470321655)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: 1.1277074813842773  (1.1277074813842773)\n",
      "     | > log_mle: 0.26633381843566895  (0.26633381843566895)\n",
      "     | > loss_dur: 0.8613736033439636  (0.8613736033439636)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: 1.2181358337402344  (1.1729216575622559)\n",
      "     | > log_mle: 0.31116294860839844  (0.2887483835220337)\n",
      "     | > loss_dur: 0.9069728851318359  (0.8841732442378998)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: 1.21132230758667  (1.1857218742370605)\n",
      "     | > log_mle: 0.2724460959434509  (0.2833142876625061)\n",
      "     | > loss_dur: 0.9388761520385742  (0.9024075468381246)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: 1.2220673561096191  (1.1948082447052002)\n",
      "     | > log_mle: 0.24907124042510986  (0.27475352585315704)\n",
      "     | > loss_dur: 0.9729960560798645  (0.9200546741485596)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: 1.161655306816101  (1.1881776571273803)\n",
      "     | > log_mle: 0.24519610404968262  (0.26884204149246216)\n",
      "     | > loss_dur: 0.9164592027664185  (0.9193355798721313)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: 1.23396635055542  (1.1958091060320537)\n",
      "     | > log_mle: 0.2275645136833191  (0.26196245352427167)\n",
      "     | > loss_dur: 1.006401777267456  (0.9338466127713522)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: 1.2068647146224976  (1.1973884786878313)\n",
      "     | > log_mle: 0.27913743257522583  (0.26441602196012226)\n",
      "     | > loss_dur: 0.9277272820472717  (0.932972422667912)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: 1.1807206869125366  (1.1953050047159195)\n",
      "     | > log_mle: 0.26762014627456665  (0.2648165374994278)\n",
      "     | > loss_dur: 0.91310054063797  (0.9304884374141693)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: 1.2517454624176025  (1.2015761666827731)\n",
      "     | > log_mle: 0.265583336353302  (0.2649017373720805)\n",
      "     | > loss_dur: 0.9861621856689453  (0.9366744094424777)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: 1.1913566589355469  (1.2005542159080504)\n",
      "     | > log_mle: 0.26952701807022095  (0.2653642654418945)\n",
      "     | > loss_dur: 0.9218296408653259  (0.9351899325847626)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: 1.1909255981445312  (1.1996788870204578)\n",
      "     | > log_mle: 0.2569820284843445  (0.2646022439002991)\n",
      "     | > loss_dur: 0.9339436292648315  (0.9350766322829507)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: 1.1805964708328247  (1.1980886856714883)\n",
      "     | > log_mle: 0.2706272006034851  (0.2651043236255646)\n",
      "     | > loss_dur: 0.9099692702293396  (0.9329843521118164)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: 1.2423961162567139  (1.2014969495626595)\n",
      "     | > log_mle: 0.2550968527793884  (0.26433451817585873)\n",
      "     | > loss_dur: 0.9872993230819702  (0.9371624268018283)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: 1.1802003383636475  (1.1999757630484444)\n",
      "     | > log_mle: 0.2621663212776184  (0.26417964696884155)\n",
      "     | > loss_dur: 0.9180339574813843  (0.9357961075646537)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: 1.189662218093872  (1.1992881933848063)\n",
      "     | > log_mle: 0.26600879430770874  (0.264301590124766)\n",
      "     | > loss_dur: 0.9236534237861633  (0.9349865953127543)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: 1.211363434791565  (1.2000428959727287)\n",
      "     | > log_mle: 0.26263296604156494  (0.26419730111956596)\n",
      "     | > loss_dur: 0.94873046875  (0.9358455874025822)\n",
      "\n",
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.0033098161220550537 \u001b[0m(-0.0012732744216918945)\n",
      "     | > avg_loss:\u001b[92m 1.2000428959727287 \u001b[0m(-0.028319984674453735)\n",
      "     | > avg_log_mle:\u001b[92m 0.26419730111956596 \u001b[0m(-0.009614303708076533)\n",
      "     | > avg_loss_dur:\u001b[92m 0.9358455874025822 \u001b[0m(-0.018705692142248154)\n",
      "\n",
      " > BEST MODEL : train/run-February-22-2025_02+19AM-9b6e3e6/best_model_8113.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 4/40\u001b[0m\n",
      " --> train/run-February-22-2025_02+19AM-9b6e3e6\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-22 02:39:53) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:40:00 -- STEP: 12/406 -- GLOBAL_STEP: 8125\u001b[0m\n",
      "     | > loss: 1.2150830030441284  (1.2728767295678456)\n",
      "     | > log_mle: 0.28422069549560547  (0.2957412252823512)\n",
      "     | > loss_dur: 0.930862307548523  (0.977135514219602)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.2252, device='cuda:0')  (tensor(2.4017, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 0.3842  (0.400315781434377)\n",
      "     | > loader_time: 0.0047  (0.00473723808924357)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:40:14 -- STEP: 37/406 -- GLOBAL_STEP: 8150\u001b[0m\n",
      "     | > loss: 1.2504198551177979  (1.2447403733794753)\n",
      "     | > log_mle: 0.294960081577301  (0.29334630515124355)\n",
      "     | > loss_dur: 0.955459713935852  (0.9513940762829136)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.2127, device='cuda:0')  (tensor(2.3239, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 0.6375  (0.5130521155692436)\n",
      "     | > loader_time: 0.0037  (0.010061502456665039)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:40:28 -- STEP: 62/406 -- GLOBAL_STEP: 8175\u001b[0m\n",
      "     | > loss: 1.216888189315796  (1.2371616036661208)\n",
      "     | > log_mle: 0.29274022579193115  (0.289900206750439)\n",
      "     | > loss_dur: 0.92414790391922  (0.9472613988384124)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.2293, device='cuda:0')  (tensor(2.3024, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 0.4206  (0.5256936280958114)\n",
      "     | > loader_time: 0.0043  (0.008738198587971346)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:40:44 -- STEP: 87/406 -- GLOBAL_STEP: 8200\u001b[0m\n",
      "     | > loss: 1.1813665628433228  (1.2321093520898927)\n",
      "     | > log_mle: 0.26456350088119507  (0.2861606389626687)\n",
      "     | > loss_dur: 0.9168030619621277  (0.9459487151825565)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.2490, device='cuda:0')  (tensor(2.2951, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 0.6461  (0.5485558455017789)\n",
      "     | > loader_time: 0.004  (0.010475353262890336)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:41:00 -- STEP: 112/406 -- GLOBAL_STEP: 8225\u001b[0m\n",
      "     | > loss: 1.2223589420318604  (1.2263808197208814)\n",
      "     | > log_mle: 0.26894283294677734  (0.2825696713158061)\n",
      "     | > loss_dur: 0.9534160494804382  (0.9438111505338124)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.2961, device='cuda:0')  (tensor(2.2922, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 0.3202  (0.5658439014639174)\n",
      "     | > loader_time: 0.0055  (0.010291046329907001)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:41:15 -- STEP: 137/406 -- GLOBAL_STEP: 8250\u001b[0m\n",
      "     | > loss: 1.2108776569366455  (1.2238880500306177)\n",
      "     | > log_mle: 0.26605725288391113  (0.27946584851202294)\n",
      "     | > loss_dur: 0.9448203444480896  (0.9444222067394396)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.3241, device='cuda:0')  (tensor(2.2862, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 0.5432  (0.5705328614172274)\n",
      "     | > loader_time: 0.0045  (0.01022833629246175)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:41:32 -- STEP: 162/406 -- GLOBAL_STEP: 8275\u001b[0m\n",
      "     | > loss: 1.201776385307312  (1.222298398429965)\n",
      "     | > log_mle: 0.2567019462585449  (0.2770219728534603)\n",
      "     | > loss_dur: 0.9450744390487671  (0.9452764307275231)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.2249, device='cuda:0')  (tensor(2.2849, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 1.046  (0.5848162762912705)\n",
      "     | > loader_time: 0.014  (0.01116978386302053)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:41:48 -- STEP: 187/406 -- GLOBAL_STEP: 8300\u001b[0m\n",
      "     | > loss: 1.2104451656341553  (1.220706532983219)\n",
      "     | > log_mle: 0.25283151865005493  (0.27482238905952566)\n",
      "     | > loss_dur: 0.9576135873794556  (0.9458841493422973)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.2955, device='cuda:0')  (tensor(2.2829, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 0.6072  (0.5907860987964167)\n",
      "     | > loader_time: 0.0234  (0.01106372236568022)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:42:04 -- STEP: 212/406 -- GLOBAL_STEP: 8325\u001b[0m\n",
      "     | > loss: 1.2192511558532715  (1.219285755224948)\n",
      "     | > log_mle: 0.2415095567703247  (0.27287643979180515)\n",
      "     | > loss_dur: 0.977741539478302  (0.9464093176823742)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.8990, device='cuda:0')  (tensor(2.2887, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 0.5936  (0.5957910362279646)\n",
      "     | > loader_time: 0.0156  (0.011266581292422308)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:42:22 -- STEP: 237/406 -- GLOBAL_STEP: 8350\u001b[0m\n",
      "     | > loss: 1.2156729698181152  (1.217784685424612)\n",
      "     | > log_mle: 0.24192792177200317  (0.2710526135400377)\n",
      "     | > loss_dur: 0.9737449884414673  (0.9467320751540268)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.3417, device='cuda:0')  (tensor(2.2871, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 0.9288  (0.6051034172878994)\n",
      "     | > loader_time: 0.0373  (0.011297001617367254)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:42:39 -- STEP: 262/406 -- GLOBAL_STEP: 8375\u001b[0m\n",
      "     | > loss: 1.1775321960449219  (1.2165939220945348)\n",
      "     | > log_mle: 0.2725476622581482  (0.2693666824857696)\n",
      "     | > loss_dur: 0.9049845933914185  (0.9472272434762417)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.1458, device='cuda:0')  (tensor(2.2874, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 0.68  (0.6101301517195379)\n",
      "     | > loader_time: 0.0108  (0.011500038263451959)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:42:58 -- STEP: 287/406 -- GLOBAL_STEP: 8400\u001b[0m\n",
      "     | > loss: 1.2271515130996704  (1.2158062441423798)\n",
      "     | > log_mle: 0.25071805715560913  (0.2677717937825033)\n",
      "     | > loss_dur: 0.9764334559440613  (0.9480344538904648)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.3649, device='cuda:0')  (tensor(2.2847, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 1.0107  (0.6217949240880565)\n",
      "     | > loader_time: 0.0066  (0.011981249686317577)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:43:17 -- STEP: 312/406 -- GLOBAL_STEP: 8425\u001b[0m\n",
      "     | > loss: 1.229816198348999  (1.2150389223526685)\n",
      "     | > log_mle: 0.24695271253585815  (0.2665039877860973)\n",
      "     | > loss_dur: 0.9828634262084961  (0.9485349381963412)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.2891, device='cuda:0')  (tensor(2.2823, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 1.11  (0.6325315833091739)\n",
      "     | > loader_time: 0.0242  (0.012169231206942827)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:43:37 -- STEP: 337/406 -- GLOBAL_STEP: 8450\u001b[0m\n",
      "     | > loss: 1.203815221786499  (1.2143009685267332)\n",
      "     | > log_mle: 0.2574261426925659  (0.2652146278573779)\n",
      "     | > loss_dur: 0.9463891386985779  (0.9490863447373274)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.2061, device='cuda:0')  (tensor(2.2812, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 0.621  (0.6407148731922188)\n",
      "     | > loader_time: 0.0072  (0.012423648324847578)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:43:56 -- STEP: 362/406 -- GLOBAL_STEP: 8475\u001b[0m\n",
      "     | > loss: 1.1999733448028564  (1.2138058391723845)\n",
      "     | > log_mle: 0.2438429594039917  (0.26386753580846845)\n",
      "     | > loss_dur: 0.9561304450035095  (0.9499383074802589)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.1740, device='cuda:0')  (tensor(2.2783, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 0.8029  (0.6494936264680897)\n",
      "     | > loader_time: 0.0098  (0.012883383266174993)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:44:16 -- STEP: 387/406 -- GLOBAL_STEP: 8500\u001b[0m\n",
      "     | > loss: 1.176692008972168  (1.2124886959406138)\n",
      "     | > log_mle: 0.24514800310134888  (0.262753547316066)\n",
      "     | > loss_dur: 0.9315439462661743  (0.9497351537071149)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.1930, device='cuda:0')  (tensor(2.2745, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 0.5405  (0.6556879882664645)\n",
      "     | > loader_time: 0.0268  (0.013203197671461477)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: 1.1860377788543701  (1.1860377788543701)\n",
      "     | > log_mle: 0.2710147500038147  (0.2710147500038147)\n",
      "     | > loss_dur: 0.9150230884552002  (0.9150230884552002)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: 1.1007746458053589  (1.1007746458053589)\n",
      "     | > log_mle: 0.25375181436538696  (0.25375181436538696)\n",
      "     | > loss_dur: 0.8470228314399719  (0.8470228314399719)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: 1.178100347518921  (1.13943749666214)\n",
      "     | > log_mle: 0.2983246445655823  (0.2760382294654846)\n",
      "     | > loss_dur: 0.8797756433486938  (0.8633992373943329)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: 1.1853007078170776  (1.1547252337137859)\n",
      "     | > log_mle: 0.260251522064209  (0.2707759936650594)\n",
      "     | > loss_dur: 0.9250491857528687  (0.8839492201805115)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: 1.1845791339874268  (1.162188708782196)\n",
      "     | > log_mle: 0.23660492897033691  (0.2622332274913788)\n",
      "     | > loss_dur: 0.9479742646217346  (0.8999554812908173)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: 1.1312060356140137  (1.1559921741485595)\n",
      "     | > log_mle: 0.23290014266967773  (0.2563666105270386)\n",
      "     | > loss_dur: 0.8983058333396912  (0.899625551700592)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: 1.2093541622161865  (1.1648858388264973)\n",
      "     | > log_mle: 0.2156417965888977  (0.24957914153734842)\n",
      "     | > loss_dur: 0.9937124252319336  (0.9153066972891489)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: 1.17498779296875  (1.1663289751325334)\n",
      "     | > log_mle: 0.26713740825653076  (0.2520874653543745)\n",
      "     | > loss_dur: 0.9078503251075745  (0.9142415012632098)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: 1.1377811431884766  (1.1627604961395264)\n",
      "     | > log_mle: 0.25535011291503906  (0.25249529629945755)\n",
      "     | > loss_dur: 0.8824309706687927  (0.9102651849389076)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: 1.2191812992095947  (1.1690294742584229)\n",
      "     | > log_mle: 0.25324469804763794  (0.2525785631603665)\n",
      "     | > loss_dur: 0.9659366607666016  (0.9164509044753181)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: 1.1556451320648193  (1.1676910400390625)\n",
      "     | > log_mle: 0.25730305910110474  (0.2530510127544403)\n",
      "     | > loss_dur: 0.8983420133590698  (0.9146400153636932)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: 1.158530592918396  (1.166858272119002)\n",
      "     | > log_mle: 0.24419313669204712  (0.2522457512942227)\n",
      "     | > loss_dur: 0.9143374562263489  (0.914612509987571)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: 1.1446382999420166  (1.1650066077709198)\n",
      "     | > log_mle: 0.25806277990341187  (0.2527305036783218)\n",
      "     | > loss_dur: 0.88657546043396  (0.9122760891914368)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: 1.2018516063690186  (1.167840838432312)\n",
      "     | > log_mle: 0.2426990270614624  (0.25195885163087106)\n",
      "     | > loss_dur: 0.9591526389122009  (0.9158819776314956)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: 1.1491883993148804  (1.1665085213524955)\n",
      "     | > log_mle: 0.24990057945251465  (0.2518118321895599)\n",
      "     | > loss_dur: 0.8992878198623657  (0.9146966806479863)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: 1.1621756553649902  (1.166219663619995)\n",
      "     | > log_mle: 0.253537654876709  (0.2519268870353698)\n",
      "     | > loss_dur: 0.9086379408836365  (0.9142927646636962)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: 1.1758215427398682  (1.1668197810649872)\n",
      "     | > log_mle: 0.2511447072029114  (0.25187800079584116)\n",
      "     | > loss_dur: 0.924676775932312  (0.9149417653679848)\n",
      "\n",
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.003135278820991516 \u001b[0m(-0.0001745373010635376)\n",
      "     | > avg_loss:\u001b[92m 1.1668197810649872 \u001b[0m(-0.03322311490774155)\n",
      "     | > avg_log_mle:\u001b[92m 0.25187800079584116 \u001b[0m(-0.012319300323724802)\n",
      "     | > avg_loss_dur:\u001b[92m 0.9149417653679848 \u001b[0m(-0.020903822034597397)\n",
      "\n",
      " > BEST MODEL : train/run-February-22-2025_02+19AM-9b6e3e6/best_model_8519.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 5/40\u001b[0m\n",
      " --> train/run-February-22-2025_02+19AM-9b6e3e6\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-22 02:44:40) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:44:45 -- STEP: 6/406 -- GLOBAL_STEP: 8525\u001b[0m\n",
      "     | > loss: 1.1623036861419678  (1.2529955506324768)\n",
      "     | > log_mle: 0.27625662088394165  (0.2852448920408885)\n",
      "     | > loss_dur: 0.8860470652580261  (0.9677506685256958)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.2916, device='cuda:0')  (tensor(2.3568, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-06 \n",
      "     | > step_time: 0.3462  (0.406753142674764)\n",
      "     | > loader_time: 0.0032  (0.004944165547688802)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:44:57 -- STEP: 31/406 -- GLOBAL_STEP: 8550\u001b[0m\n",
      "     | > loss: 1.170801043510437  (1.206681912945163)\n",
      "     | > log_mle: 0.2793620228767395  (0.2805593840537532)\n",
      "     | > loss_dur: 0.8914390206336975  (0.9261225288914096)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.2930, device='cuda:0')  (tensor(2.2584, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-06 \n",
      "     | > step_time: 0.7581  (0.47335737751376245)\n",
      "     | > loader_time: 0.0036  (0.008867325321320564)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:45:12 -- STEP: 56/406 -- GLOBAL_STEP: 8575\u001b[0m\n",
      "     | > loss: 1.1855063438415527  (1.1997218281030655)\n",
      "     | > log_mle: 0.2698119282722473  (0.27776996152741573)\n",
      "     | > loss_dur: 0.9156944155693054  (0.9219518623181752)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.1441, device='cuda:0')  (tensor(2.2248, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-06 \n",
      "     | > step_time: 0.5985  (0.5086178396429334)\n",
      "     | > loader_time: 0.0043  (0.009408073765890939)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:45:27 -- STEP: 81/406 -- GLOBAL_STEP: 8600\u001b[0m\n",
      "     | > loss: 1.1772154569625854  (1.1958713752252088)\n",
      "     | > log_mle: 0.2593119740486145  (0.2744068172242906)\n",
      "     | > loss_dur: 0.917903482913971  (0.9214645491706001)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.1048, device='cuda:0')  (tensor(2.2134, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-06 \n",
      "     | > step_time: 0.5773  (0.5347907042797699)\n",
      "     | > loader_time: 0.0048  (0.009439383024050866)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:45:42 -- STEP: 106/406 -- GLOBAL_STEP: 8625\u001b[0m\n",
      "     | > loss: 1.1570453643798828  (1.188947740590797)\n",
      "     | > log_mle: 0.26584458351135254  (0.27064627802596897)\n",
      "     | > loss_dur: 0.891200840473175  (0.9183014569417486)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.1116, device='cuda:0')  (tensor(2.2032, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-06 \n",
      "     | > step_time: 0.4715  (0.5513523637123824)\n",
      "     | > loader_time: 0.005  (0.00983321216871153)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:45:57 -- STEP: 131/406 -- GLOBAL_STEP: 8650\u001b[0m\n",
      "     | > loss: 1.1748833656311035  (1.185316397033575)\n",
      "     | > log_mle: 0.25548219680786133  (0.26722449155254213)\n",
      "     | > loss_dur: 0.9194011092185974  (0.9180919000210653)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.0906, device='cuda:0')  (tensor(2.1953, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-06 \n",
      "     | > step_time: 0.38  (0.5570550874899357)\n",
      "     | > loader_time: 0.0141  (0.010711826440942191)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:46:15 -- STEP: 156/406 -- GLOBAL_STEP: 8675\u001b[0m\n",
      "     | > loss: 1.186955451965332  (1.1836149639044053)\n",
      "     | > log_mle: 0.24187058210372925  (0.26456817526083715)\n",
      "     | > loss_dur: 0.9450849294662476  (0.9190467840585953)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.2554, device='cuda:0')  (tensor(2.1934, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-06 \n",
      "     | > step_time: 1.2371  (0.5752448332615383)\n",
      "     | > loader_time: 0.0058  (0.011017240010775047)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:46:32 -- STEP: 181/406 -- GLOBAL_STEP: 8700\u001b[0m\n",
      "     | > loss: 1.1568315029144287  (1.1821000477227055)\n",
      "     | > log_mle: 0.251700758934021  (0.26238114629661163)\n",
      "     | > loss_dur: 0.9051308035850525  (0.9197188971450975)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.1515, device='cuda:0')  (tensor(2.1906, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-06 \n",
      "     | > step_time: 0.7662  (0.5887470337567406)\n",
      "     | > loader_time: 0.0154  (0.011547785437568112)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:46:49 -- STEP: 206/406 -- GLOBAL_STEP: 8725\u001b[0m\n",
      "     | > loss: 1.1769819259643555  (1.1809948509179273)\n",
      "     | > log_mle: 0.2427349090576172  (0.2603067590773683)\n",
      "     | > loss_dur: 0.9342470169067383  (0.9206880877897577)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.1675, device='cuda:0')  (tensor(2.1940, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-06 \n",
      "     | > step_time: 0.809  (0.5987021159199831)\n",
      "     | > loader_time: 0.0057  (0.011678716511402312)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:47:07 -- STEP: 231/406 -- GLOBAL_STEP: 8750\u001b[0m\n",
      "     | > loss: 1.1884300708770752  (1.1792440378304683)\n",
      "     | > log_mle: 0.230707049369812  (0.2583662127003523)\n",
      "     | > loss_dur: 0.9577230215072632  (0.920877821775742)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.3397, device='cuda:0')  (tensor(2.1947, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-06 \n",
      "     | > step_time: 0.8991  (0.6089150461799651)\n",
      "     | > loader_time: 0.0065  (0.011806109250881967)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:47:25 -- STEP: 256/406 -- GLOBAL_STEP: 8775\u001b[0m\n",
      "     | > loss: 1.156057357788086  (1.1781853190623224)\n",
      "     | > log_mle: 0.23817062377929688  (0.2566100573167203)\n",
      "     | > loss_dur: 0.9178867340087891  (0.921575260348618)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.1506, device='cuda:0')  (tensor(2.1967, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-06 \n",
      "     | > step_time: 0.9554  (0.6186619857326147)\n",
      "     | > loader_time: 0.0276  (0.01204328145831823)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:47:43 -- STEP: 281/406 -- GLOBAL_STEP: 8800\u001b[0m\n",
      "     | > loss: 1.1527717113494873  (1.1768716433718536)\n",
      "     | > log_mle: 0.24042212963104248  (0.25500336151530306)\n",
      "     | > loss_dur: 0.9123496413230896  (0.9218682807959694)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.0855, device='cuda:0')  (tensor(2.1944, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-06 \n",
      "     | > step_time: 0.7617  (0.6250457526101759)\n",
      "     | > loader_time: 0.0266  (0.012551093865119687)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:48:01 -- STEP: 306/406 -- GLOBAL_STEP: 8825\u001b[0m\n",
      "     | > loss: 1.1647499799728394  (1.1760114010642553)\n",
      "     | > log_mle: 0.2401922345161438  (0.2536115208092856)\n",
      "     | > loss_dur: 0.9245577454566956  (0.9223998783071055)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.1879, device='cuda:0')  (tensor(2.1922, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-06 \n",
      "     | > step_time: 0.5822  (0.6329896255256302)\n",
      "     | > loader_time: 0.0244  (0.012855484594706614)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:48:20 -- STEP: 331/406 -- GLOBAL_STEP: 8850\u001b[0m\n",
      "     | > loss: 1.176767110824585  (1.1747830331865756)\n",
      "     | > log_mle: 0.23568272590637207  (0.25233111712867745)\n",
      "     | > loss_dur: 0.9410844445228577  (0.9224519149774509)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.3431, device='cuda:0')  (tensor(2.1898, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-06 \n",
      "     | > step_time: 0.552  (0.6399803752265307)\n",
      "     | > loader_time: 0.0067  (0.012961872394711589)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:48:40 -- STEP: 356/406 -- GLOBAL_STEP: 8875\u001b[0m\n",
      "     | > loss: 1.1681833267211914  (1.1744193782967127)\n",
      "     | > log_mle: 0.22764497995376587  (0.25088367837198655)\n",
      "     | > loss_dur: 0.9405383467674255  (0.9235356989201533)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.1418, device='cuda:0')  (tensor(2.1899, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-06 \n",
      "     | > step_time: 0.721  (0.6476979289162025)\n",
      "     | > loader_time: 0.0233  (0.013401164767447482)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:48:59 -- STEP: 381/406 -- GLOBAL_STEP: 8900\u001b[0m\n",
      "     | > loss: 1.166792392730713  (1.1729607719761805)\n",
      "     | > log_mle: 0.24300801753997803  (0.249634945173589)\n",
      "     | > loss_dur: 0.9237843155860901  (0.9233258258639356)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.0804, device='cuda:0')  (tensor(2.1843, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-06 \n",
      "     | > step_time: 0.6639  (0.6561401134400854)\n",
      "     | > loader_time: 0.0322  (0.013486173835013483)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: 1.1313492059707642  (1.1313492059707642)\n",
      "     | > log_mle: 0.2558439373970032  (0.2558439373970032)\n",
      "     | > loss_dur: 0.875505268573761  (0.875505268573761)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: 1.0568326711654663  (1.0568326711654663)\n",
      "     | > log_mle: 0.2382557988166809  (0.2382557988166809)\n",
      "     | > loss_dur: 0.8185768723487854  (0.8185768723487854)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: 1.1354984045028687  (1.0961655378341675)\n",
      "     | > log_mle: 0.2824990749359131  (0.260377436876297)\n",
      "     | > loss_dur: 0.8529993295669556  (0.8357881009578705)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: 1.1417477130889893  (1.1113595962524414)\n",
      "     | > log_mle: 0.24533021450042725  (0.2553616960843404)\n",
      "     | > loss_dur: 0.8964174389839172  (0.8559978802998861)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: 1.1323835849761963  (1.1166155934333801)\n",
      "     | > log_mle: 0.22126692533493042  (0.24683800339698792)\n",
      "     | > loss_dur: 0.9111166000366211  (0.8697775602340698)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: 1.0816214084625244  (1.109616756439209)\n",
      "     | > log_mle: 0.21724623441696167  (0.24091964960098267)\n",
      "     | > loss_dur: 0.864375114440918  (0.8686970710754395)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: 1.1571863889694214  (1.1175450285275776)\n",
      "     | > log_mle: 0.20059990882873535  (0.23419969280560812)\n",
      "     | > loss_dur: 0.956586480140686  (0.8833453059196472)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: 1.1349711418151855  (1.1200344732829504)\n",
      "     | > log_mle: 0.2521255612373352  (0.2367605311529977)\n",
      "     | > loss_dur: 0.8828456401824951  (0.8832739251000541)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: 1.1019991636276245  (1.1177800595760345)\n",
      "     | > log_mle: 0.24016284942626953  (0.23718582093715668)\n",
      "     | > loss_dur: 0.861836314201355  (0.8805942237377167)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: 1.1677491664886475  (1.123332182566325)\n",
      "     | > log_mle: 0.23791396617889404  (0.23726672596401638)\n",
      "     | > loss_dur: 0.9298352599143982  (0.8860654499795702)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: 1.1177978515625  (1.1227787494659425)\n",
      "     | > log_mle: 0.2420864701271057  (0.2377487003803253)\n",
      "     | > loss_dur: 0.8757113218307495  (0.8850300371646881)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: 1.1102252006530762  (1.1216375177556819)\n",
      "     | > log_mle: 0.22842317819595337  (0.2369009256362915)\n",
      "     | > loss_dur: 0.8818020224571228  (0.8847365812821821)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: 1.1014915704727173  (1.1199586888154347)\n",
      "     | > log_mle: 0.2425488829612732  (0.23737158874670664)\n",
      "     | > loss_dur: 0.8589426875114441  (0.8825870901346207)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: 1.167379379272461  (1.1236064342352061)\n",
      "     | > log_mle: 0.2268269658088684  (0.23656046390533447)\n",
      "     | > loss_dur: 0.9405523538589478  (0.8870459565749536)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: 1.1103326082229614  (1.12265830380576)\n",
      "     | > log_mle: 0.23454225063323975  (0.23641630581447057)\n",
      "     | > loss_dur: 0.8757903575897217  (0.8862419852188655)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: 1.11749267578125  (1.122313928604126)\n",
      "     | > log_mle: 0.23793399333953857  (0.23651748498280842)\n",
      "     | > loss_dur: 0.8795586228370667  (0.8857964277267456)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: 1.1404451131820679  (1.1234471276402473)\n",
      "     | > log_mle: 0.2367156744003296  (0.2365298718214035)\n",
      "     | > loss_dur: 0.9037294387817383  (0.8869172409176826)\n",
      "\n",
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[91m 0.006439611315727233 \u001b[0m(+0.003304332494735717)\n",
      "     | > avg_loss:\u001b[92m 1.1234471276402473 \u001b[0m(-0.04337265342473984)\n",
      "     | > avg_log_mle:\u001b[92m 0.2365298718214035 \u001b[0m(-0.015348128974437658)\n",
      "     | > avg_loss_dur:\u001b[92m 0.8869172409176826 \u001b[0m(-0.028024524450302124)\n",
      "\n",
      " > BEST MODEL : train/run-February-22-2025_02+19AM-9b6e3e6/best_model_8925.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 6/40\u001b[0m\n",
      " --> train/run-February-22-2025_02+19AM-9b6e3e6\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-22 02:49:28) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:49:30 -- STEP: 0/406 -- GLOBAL_STEP: 8925\u001b[0m\n",
      "     | > loss: 1.304638385772705  (1.304638385772705)\n",
      "     | > log_mle: 0.27691298723220825  (0.27691298723220825)\n",
      "     | > loss_dur: 1.027725338935852  (1.027725338935852)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.4602, device='cuda:0')  (tensor(2.4602, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 1.0281  (1.0281023979187012)\n",
      "     | > loader_time: 0.955  (0.9550230503082275)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:49:41 -- STEP: 25/406 -- GLOBAL_STEP: 8950\u001b[0m\n",
      "     | > loss: 1.2050601243972778  (1.1683736133575442)\n",
      "     | > log_mle: 0.25510090589523315  (0.26611334562301636)\n",
      "     | > loss_dur: 0.9499592185020447  (0.9022602677345276)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.3391, device='cuda:0')  (tensor(2.1588, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 0.7647  (0.44660353660583496)\n",
      "     | > loader_time: 0.0042  (0.007910385131835935)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:49:56 -- STEP: 50/406 -- GLOBAL_STEP: 8975\u001b[0m\n",
      "     | > loss: 1.1769955158233643  (1.1570430278778079)\n",
      "     | > log_mle: 0.23890602588653564  (0.2644149363040924)\n",
      "     | > loss_dur: 0.9380894899368286  (0.8926280975341797)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.1389, device='cuda:0')  (tensor(2.1372, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 0.4849  (0.5130032539367675)\n",
      "     | > loader_time: 0.0047  (0.007610645294189452)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:50:11 -- STEP: 75/406 -- GLOBAL_STEP: 9000\u001b[0m\n",
      "     | > loss: 1.1680166721343994  (1.1513784408569339)\n",
      "     | > log_mle: 0.24683988094329834  (0.2600107018152873)\n",
      "     | > loss_dur: 0.9211767911911011  (0.891367739836375)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.1404, device='cuda:0')  (tensor(2.1269, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 0.6571  (0.5421317386627199)\n",
      "     | > loader_time: 0.0179  (0.007622143427530924)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:50:28 -- STEP: 100/406 -- GLOBAL_STEP: 9025\u001b[0m\n",
      "     | > loss: 1.127152442932129  (1.1460745680332187)\n",
      "     | > log_mle: 0.24273616075515747  (0.2564577704668045)\n",
      "     | > loss_dur: 0.8844163417816162  (0.8896167975664139)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.0975, device='cuda:0')  (tensor(2.1178, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 0.6409  (0.5693121004104613)\n",
      "     | > loader_time: 0.0232  (0.008072478771209715)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:50:44 -- STEP: 125/406 -- GLOBAL_STEP: 9050\u001b[0m\n",
      "     | > loss: 1.1406638622283936  (1.141352221488953)\n",
      "     | > log_mle: 0.2326090931892395  (0.2528014335632325)\n",
      "     | > loss_dur: 0.9080547094345093  (0.8885507888793945)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.1197, device='cuda:0')  (tensor(2.1140, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 0.6834  (0.5804058399200437)\n",
      "     | > loader_time: 0.0134  (0.008783224105834965)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:51:01 -- STEP: 150/406 -- GLOBAL_STEP: 9075\u001b[0m\n",
      "     | > loss: 1.1219619512557983  (1.1395259571075447)\n",
      "     | > log_mle: 0.23498982191085815  (0.24984796166419992)\n",
      "     | > loss_dur: 0.8869721293449402  (0.8896779958407084)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.1157, device='cuda:0')  (tensor(2.1141, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 0.7477  (0.5973125362396238)\n",
      "     | > loader_time: 0.01  (0.009462052981058759)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:51:18 -- STEP: 175/406 -- GLOBAL_STEP: 9100\u001b[0m\n",
      "     | > loss: 1.1176209449768066  (1.137496341296605)\n",
      "     | > log_mle: 0.2276296615600586  (0.2474847524506706)\n",
      "     | > loss_dur: 0.8899913430213928  (0.8900115902083261)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.1515, device='cuda:0')  (tensor(2.1113, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 0.6  (0.6037639617919922)\n",
      "     | > loader_time: 0.0198  (0.00938426017761231)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:51:36 -- STEP: 200/406 -- GLOBAL_STEP: 9125\u001b[0m\n",
      "     | > loss: 1.12554931640625  (1.1360435718297963)\n",
      "     | > log_mle: 0.2353995442390442  (0.2452727964520455)\n",
      "     | > loss_dur: 0.8901497721672058  (0.8907707765698433)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.1615, device='cuda:0')  (tensor(2.1171, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 0.5185  (0.6158222723007201)\n",
      "     | > loader_time: 0.0048  (0.009628022909164438)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:51:53 -- STEP: 225/406 -- GLOBAL_STEP: 9150\u001b[0m\n",
      "     | > loss: 1.104393482208252  (1.1336800124910154)\n",
      "     | > log_mle: 0.22262418270111084  (0.24324066585964632)\n",
      "     | > loss_dur: 0.8817693591117859  (0.8904393479559156)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.0826, device='cuda:0')  (tensor(2.1162, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 0.567  (0.6247998672061497)\n",
      "     | > loader_time: 0.0526  (0.009973578982883034)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:52:11 -- STEP: 250/406 -- GLOBAL_STEP: 9175\u001b[0m\n",
      "     | > loss: 1.1457240581512451  (1.1324153957366951)\n",
      "     | > log_mle: 0.21328037977218628  (0.24139217901229865)\n",
      "     | > loss_dur: 0.9324436783790588  (0.8910232172012329)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.3240, device='cuda:0')  (tensor(2.1154, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 0.6144  (0.6314009656906128)\n",
      "     | > loader_time: 0.0194  (0.010524047851562503)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:52:30 -- STEP: 275/406 -- GLOBAL_STEP: 9200\u001b[0m\n",
      "     | > loss: 1.1233775615692139  (1.130923539941962)\n",
      "     | > log_mle: 0.22377288341522217  (0.23952744158831515)\n",
      "     | > loss_dur: 0.8996047377586365  (0.891396099654111)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.0146, device='cuda:0')  (tensor(2.1155, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 0.6708  (0.6391043871099299)\n",
      "     | > loader_time: 0.0053  (0.01075716712258079)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:52:49 -- STEP: 300/406 -- GLOBAL_STEP: 9225\u001b[0m\n",
      "     | > loss: 1.117656946182251  (1.1296661051114405)\n",
      "     | > log_mle: 0.23381417989730835  (0.23806156416734064)\n",
      "     | > loss_dur: 0.8838427662849426  (0.8916045431296029)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.1423, device='cuda:0')  (tensor(2.1140, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 1.0032  (0.6483061337471007)\n",
      "     | > loader_time: 0.0221  (0.011127057075500494)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:53:08 -- STEP: 325/406 -- GLOBAL_STEP: 9250\u001b[0m\n",
      "     | > loss: 1.1217014789581299  (1.1281955803357644)\n",
      "     | > log_mle: 0.22586315870285034  (0.23663125790082495)\n",
      "     | > loss_dur: 0.8958382606506348  (0.8915643251859223)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.2697, device='cuda:0')  (tensor(2.1123, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 1.0602  (0.6570742819859431)\n",
      "     | > loader_time: 0.008  (0.011348807261540344)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:53:28 -- STEP: 350/406 -- GLOBAL_STEP: 9275\u001b[0m\n",
      "     | > loss: 1.1033604145050049  (1.1278265333175672)\n",
      "     | > log_mle: 0.2107890248298645  (0.23513387663023816)\n",
      "     | > loss_dur: 0.8925714492797852  (0.8926926583903175)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.1726, device='cuda:0')  (tensor(2.1110, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 1.0366  (0.665845475196838)\n",
      "     | > loader_time: 0.0075  (0.011783840315682557)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:53:48 -- STEP: 375/406 -- GLOBAL_STEP: 9300\u001b[0m\n",
      "     | > loss: 1.1169123649597168  (1.1262548761367812)\n",
      "     | > log_mle: 0.20854240655899048  (0.23364483086268112)\n",
      "     | > loss_dur: 0.9083700180053711  (0.8926100467046101)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.1074, device='cuda:0')  (tensor(2.1047, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 0.7004  (0.6731913668314614)\n",
      "     | > loader_time: 0.024  (0.01214142100016277)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:54:07 -- STEP: 400/406 -- GLOBAL_STEP: 9325\u001b[0m\n",
      "     | > loss: 1.1051061153411865  (1.1248034662008302)\n",
      "     | > log_mle: 0.20704376697540283  (0.2323315262794495)\n",
      "     | > loss_dur: 0.8980624079704285  (0.8924719409644603)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.1173, device='cuda:0')  (tensor(2.1025, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 0.5642  (0.6762840235233307)\n",
      "     | > loader_time: 0.0062  (0.012098924517631539)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: 1.0676629543304443  (1.0676629543304443)\n",
      "     | > log_mle: 0.23821252584457397  (0.23821252584457397)\n",
      "     | > loss_dur: 0.8294504284858704  (0.8294504284858704)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: 1.0077314376831055  (1.0077314376831055)\n",
      "     | > log_mle: 0.22022944688796997  (0.22022944688796997)\n",
      "     | > loss_dur: 0.7875019907951355  (0.7875019907951355)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: 1.0882922410964966  (1.048011839389801)\n",
      "     | > log_mle: 0.26405858993530273  (0.24214401841163635)\n",
      "     | > loss_dur: 0.8242336511611938  (0.8058678209781647)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: 1.090586543083191  (1.0622034072875977)\n",
      "     | > log_mle: 0.22801893949508667  (0.23743565877278647)\n",
      "     | > loss_dur: 0.8625676035881042  (0.8247677485148112)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: 1.0824933052062988  (1.067275881767273)\n",
      "     | > log_mle: 0.20337414741516113  (0.22892028093338013)\n",
      "     | > loss_dur: 0.8791192173957825  (0.838355615735054)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: 1.0465656518936157  (1.0631338357925415)\n",
      "     | > log_mle: 0.19900071620941162  (0.22293636798858643)\n",
      "     | > loss_dur: 0.8475649356842041  (0.840197479724884)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: 1.110075831413269  (1.0709575017293294)\n",
      "     | > log_mle: 0.1831255555152893  (0.21630123257637024)\n",
      "     | > loss_dur: 0.9269502758979797  (0.8546562790870667)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: 1.0801472663879395  (1.072270325251988)\n",
      "     | > log_mle: 0.23444175720214844  (0.21889273609433854)\n",
      "     | > loss_dur: 0.8457055687904358  (0.853377606187548)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: 1.0463494062423706  (1.0690302103757858)\n",
      "     | > log_mle: 0.22231554985046387  (0.21932058781385422)\n",
      "     | > loss_dur: 0.8240338563919067  (0.8497096374630928)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: 1.1301310062408447  (1.0758191876941257)\n",
      "     | > log_mle: 0.21997517347335815  (0.2193933195537991)\n",
      "     | > loss_dur: 0.9101557731628418  (0.8564258747630649)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: 1.0773262977600098  (1.075969898700714)\n",
      "     | > log_mle: 0.2241559624671936  (0.21986958384513855)\n",
      "     | > loss_dur: 0.8531703948974609  (0.8561003267765045)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: 1.0563089847564697  (1.074182542887601)\n",
      "     | > log_mle: 0.21006864309310913  (0.2189785892313177)\n",
      "     | > loss_dur: 0.8462403416633606  (0.8552039644934915)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: 1.0543994903564453  (1.0725339551766713)\n",
      "     | > log_mle: 0.22447913885116577  (0.21943696836630502)\n",
      "     | > loss_dur: 0.8299204111099243  (0.8530970017115275)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: 1.1115278005599976  (1.0755334817446196)\n",
      "     | > log_mle: 0.20830559730529785  (0.21858070905391985)\n",
      "     | > loss_dur: 0.9032222032546997  (0.8569527864456177)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: 1.0662814378738403  (1.0748726214681354)\n",
      "     | > log_mle: 0.2165602445602417  (0.21843639016151428)\n",
      "     | > loss_dur: 0.8497211933135986  (0.8564362440790448)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: 1.0767359733581543  (1.0749968449274698)\n",
      "     | > log_mle: 0.21963036060333252  (0.21851598819096882)\n",
      "     | > loss_dur: 0.8571056723594666  (0.856480872631073)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: 1.0790891647338867  (1.075252614915371)\n",
      "     | > log_mle: 0.2197474241256714  (0.21859295293688774)\n",
      "     | > loss_dur: 0.8593417406082153  (0.8566596768796444)\n",
      "\n",
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.003786996006965637 \u001b[0m(-0.002652615308761596)\n",
      "     | > avg_loss:\u001b[92m 1.075252614915371 \u001b[0m(-0.048194512724876404)\n",
      "     | > avg_log_mle:\u001b[92m 0.21859295293688774 \u001b[0m(-0.017936918884515762)\n",
      "     | > avg_loss_dur:\u001b[92m 0.8566596768796444 \u001b[0m(-0.030257564038038254)\n",
      "\n",
      " > BEST MODEL : train/run-February-22-2025_02+19AM-9b6e3e6/best_model_9331.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 7/40\u001b[0m\n",
      " --> train/run-February-22-2025_02+19AM-9b6e3e6\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-22 02:54:22) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:54:32 -- STEP: 19/406 -- GLOBAL_STEP: 9350\u001b[0m\n",
      "     | > loss: 1.1265357732772827  (1.1209120123009932)\n",
      "     | > log_mle: 0.25635915994644165  (0.24810834307419627)\n",
      "     | > loss_dur: 0.8701766133308411  (0.8728036566784507)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.0152, device='cuda:0')  (tensor(2.1283, device='cuda:0'))\n",
      "     | > current_lr: 1.75e-06 \n",
      "     | > step_time: 0.284  (0.4146484450290078)\n",
      "     | > loader_time: 0.0032  (0.004660568739238538)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:54:47 -- STEP: 44/406 -- GLOBAL_STEP: 9375\u001b[0m\n",
      "     | > loss: 1.082690715789795  (1.1050357358022174)\n",
      "     | > log_mle: 0.24436640739440918  (0.24773972684686835)\n",
      "     | > loss_dur: 0.838324248790741  (0.8572959994727914)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(1.9250, device='cuda:0')  (tensor(2.0332, device='cuda:0'))\n",
      "     | > current_lr: 1.75e-06 \n",
      "     | > step_time: 0.4222  (0.5075645067475059)\n",
      "     | > loader_time: 0.0039  (0.007440642877058549)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:55:02 -- STEP: 69/406 -- GLOBAL_STEP: 9400\u001b[0m\n",
      "     | > loss: 1.0954639911651611  (1.1017951049666477)\n",
      "     | > log_mle: 0.2287837266921997  (0.24346029585686282)\n",
      "     | > loss_dur: 0.8666802048683167  (0.8583348065182783)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.0469, device='cuda:0')  (tensor(2.0322, device='cuda:0'))\n",
      "     | > current_lr: 1.75e-06 \n",
      "     | > step_time: 0.7582  (0.5376850038334944)\n",
      "     | > loader_time: 0.0075  (0.00878065219823865)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:55:18 -- STEP: 94/406 -- GLOBAL_STEP: 9425\u001b[0m\n",
      "     | > loss: 1.0385926961898804  (1.095790987319134)\n",
      "     | > log_mle: 0.21953225135803223  (0.23907619144054168)\n",
      "     | > loss_dur: 0.8190604448318481  (0.8567147939763171)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(1.9486, device='cuda:0')  (tensor(2.0193, device='cuda:0'))\n",
      "     | > current_lr: 1.75e-06 \n",
      "     | > step_time: 0.6179  (0.5547660614581819)\n",
      "     | > loader_time: 0.0051  (0.009191566325248555)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:55:33 -- STEP: 119/406 -- GLOBAL_STEP: 9450\u001b[0m\n",
      "     | > loss: 1.0690405368804932  (1.09161657445571)\n",
      "     | > log_mle: 0.2128620147705078  (0.23558743961718903)\n",
      "     | > loss_dur: 0.8561784625053406  (0.8560291363411591)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(1.9421, device='cuda:0')  (tensor(2.0073, device='cuda:0'))\n",
      "     | > current_lr: 1.75e-06 \n",
      "     | > step_time: 0.3286  (0.5625602878442333)\n",
      "     | > loader_time: 0.0061  (0.009857197769549714)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:55:49 -- STEP: 144/406 -- GLOBAL_STEP: 9475\u001b[0m\n",
      "     | > loss: 1.0659853219985962  (1.0895000331931641)\n",
      "     | > log_mle: 0.21219950914382935  (0.23229046621256405)\n",
      "     | > loss_dur: 0.8537858128547668  (0.8572095694641272)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.0226, device='cuda:0')  (tensor(2.0018, device='cuda:0'))\n",
      "     | > current_lr: 1.75e-06 \n",
      "     | > step_time: 0.7748  (0.5753988573948543)\n",
      "     | > loader_time: 0.0264  (0.00980837477578057)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:56:05 -- STEP: 169/406 -- GLOBAL_STEP: 9500\u001b[0m\n",
      "     | > loss: 1.0967121124267578  (1.0876934267360074)\n",
      "     | > log_mle: 0.2175198793411255  (0.229973048853451)\n",
      "     | > loss_dur: 0.8791922330856323  (0.8577203789406275)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(1.9961, device='cuda:0')  (tensor(2.0000, device='cuda:0'))\n",
      "     | > current_lr: 1.75e-06 \n",
      "     | > step_time: 0.574  (0.5815817209390495)\n",
      "     | > loader_time: 0.0389  (0.010246477183505628)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:56:22 -- STEP: 194/406 -- GLOBAL_STEP: 9525\u001b[0m\n",
      "     | > loss: 1.08976411819458  (1.0859205397133966)\n",
      "     | > log_mle: 0.21193397045135498  (0.22751498222351074)\n",
      "     | > loss_dur: 0.8778301477432251  (0.8584055602550507)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(1.9378, device='cuda:0')  (tensor(1.9966, device='cuda:0'))\n",
      "     | > current_lr: 1.75e-06 \n",
      "     | > step_time: 1.1129  (0.594189761840191)\n",
      "     | > loader_time: 0.0044  (0.01037166290676471)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:56:39 -- STEP: 219/406 -- GLOBAL_STEP: 9550\u001b[0m\n",
      "     | > loss: 1.0426887273788452  (1.0835289546888163)\n",
      "     | > log_mle: 0.21246039867401123  (0.22554004899987348)\n",
      "     | > loss_dur: 0.830228328704834  (0.85798890704978)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(1.7793, device='cuda:0')  (tensor(1.9997, device='cuda:0'))\n",
      "     | > current_lr: 1.75e-06 \n",
      "     | > step_time: 0.9331  (0.6039651583318838)\n",
      "     | > loader_time: 0.0058  (0.01031757598598254)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:56:58 -- STEP: 244/406 -- GLOBAL_STEP: 9575\u001b[0m\n",
      "     | > loss: 1.0606799125671387  (1.0820920858226835)\n",
      "     | > log_mle: 0.20727145671844482  (0.22343309541217615)\n",
      "     | > loss_dur: 0.8534083962440491  (0.8586589911433516)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(1.9380, device='cuda:0')  (tensor(2.0017, device='cuda:0'))\n",
      "     | > current_lr: 1.75e-06 \n",
      "     | > step_time: 0.6346  (0.6174072486455321)\n",
      "     | > loader_time: 0.0152  (0.010572554635219888)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:57:16 -- STEP: 269/406 -- GLOBAL_STEP: 9600\u001b[0m\n",
      "     | > loss: 1.066387414932251  (1.0803178256329102)\n",
      "     | > log_mle: 0.20432007312774658  (0.22167742894927808)\n",
      "     | > loss_dur: 0.8620672821998596  (0.85864039712679)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.0314, device='cuda:0')  (tensor(2.0054, device='cuda:0'))\n",
      "     | > current_lr: 1.75e-06 \n",
      "     | > step_time: 0.5618  (0.6248058492809421)\n",
      "     | > loader_time: 0.0065  (0.010971217350445718)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:57:36 -- STEP: 294/406 -- GLOBAL_STEP: 9625\u001b[0m\n",
      "     | > loss: 1.0829585790634155  (1.0790079061676854)\n",
      "     | > log_mle: 0.19284141063690186  (0.21993522072324942)\n",
      "     | > loss_dur: 0.8901171684265137  (0.8590726852416992)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(1.9716, device='cuda:0')  (tensor(2.0036, device='cuda:0'))\n",
      "     | > current_lr: 1.75e-06 \n",
      "     | > step_time: 0.6734  (0.6369158402592142)\n",
      "     | > loader_time: 0.0278  (0.011376528512863889)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:57:55 -- STEP: 319/406 -- GLOBAL_STEP: 9650\u001b[0m\n",
      "     | > loss: 1.0589041709899902  (1.0774024904334807)\n",
      "     | > log_mle: 0.19971877336502075  (0.21842012192388308)\n",
      "     | > loss_dur: 0.8591854572296143  (0.8589823685095975)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(1.8986, device='cuda:0')  (tensor(2.0020, device='cuda:0'))\n",
      "     | > current_lr: 1.75e-06 \n",
      "     | > step_time: 1.0037  (0.6451255131664692)\n",
      "     | > loader_time: 0.0241  (0.011768132541620624)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:58:15 -- STEP: 344/406 -- GLOBAL_STEP: 9675\u001b[0m\n",
      "     | > loss: 1.0874831676483154  (1.0765652670416725)\n",
      "     | > log_mle: 0.2045964002609253  (0.2168679168057996)\n",
      "     | > loss_dur: 0.8828868269920349  (0.8596973504091419)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(1.9413, device='cuda:0')  (tensor(2.0047, device='cuda:0'))\n",
      "     | > current_lr: 1.75e-06 \n",
      "     | > step_time: 0.8801  (0.654291076022525)\n",
      "     | > loader_time: 0.0124  (0.01190718384676202)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:58:36 -- STEP: 369/406 -- GLOBAL_STEP: 9700\u001b[0m\n",
      "     | > loss: 1.0391507148742676  (1.0751370204496515)\n",
      "     | > log_mle: 0.19254302978515625  (0.21532524019722044)\n",
      "     | > loss_dur: 0.8466076254844666  (0.8598117815446724)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(1.8833, device='cuda:0')  (tensor(2.0011, device='cuda:0'))\n",
      "     | > current_lr: 1.75e-06 \n",
      "     | > step_time: 0.7879  (0.6656454727255552)\n",
      "     | > loader_time: 0.0074  (0.01216033739126149)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:58:56 -- STEP: 394/406 -- GLOBAL_STEP: 9725\u001b[0m\n",
      "     | > loss: 1.0582499504089355  (1.0734033430288288)\n",
      "     | > log_mle: 0.18991434574127197  (0.21388901021274814)\n",
      "     | > loss_dur: 0.8683356642723083  (0.8595143341776078)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.1064, device='cuda:0')  (tensor(2.0002, device='cuda:0'))\n",
      "     | > current_lr: 1.75e-06 \n",
      "     | > step_time: 0.5456  (0.6727750234797516)\n",
      "     | > loader_time: 0.006  (0.012213637986158966)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: 1.0210745334625244  (1.0210745334625244)\n",
      "     | > log_mle: 0.21822136640548706  (0.21822136640548706)\n",
      "     | > loss_dur: 0.8028532266616821  (0.8028532266616821)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: 0.9680102467536926  (0.9680102467536926)\n",
      "     | > log_mle: 0.19996708631515503  (0.19996708631515503)\n",
      "     | > loss_dur: 0.7680431604385376  (0.7680431604385376)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: 1.0339415073394775  (1.000975877046585)\n",
      "     | > log_mle: 0.24291467666625977  (0.2214408814907074)\n",
      "     | > loss_dur: 0.7910268902778625  (0.7795350253582001)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: 1.0345412492752075  (1.012164334456126)\n",
      "     | > log_mle: 0.2086506485939026  (0.2171774705251058)\n",
      "     | > loss_dur: 0.8258906006813049  (0.794986883799235)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: 1.0238447189331055  (1.0150844305753708)\n",
      "     | > log_mle: 0.18343478441238403  (0.20874179899692535)\n",
      "     | > loss_dur: 0.8404098749160767  (0.8063426315784454)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: 1.0087001323699951  (1.0138075709342957)\n",
      "     | > log_mle: 0.1792556643486023  (0.20284457206726075)\n",
      "     | > loss_dur: 0.829444408416748  (0.8109629869461059)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: 1.0572474002838135  (1.0210475424925487)\n",
      "     | > log_mle: 0.1643880009651184  (0.19643514355023703)\n",
      "     | > loss_dur: 0.8928594589233398  (0.8246123989423116)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: 1.025312900543213  (1.0216568793569292)\n",
      "     | > log_mle: 0.21441996097564697  (0.19900440318243845)\n",
      "     | > loss_dur: 0.8108929991722107  (0.8226524846894401)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: 0.99098140001297  (1.0178224444389343)\n",
      "     | > log_mle: 0.20216447114944458  (0.1993994116783142)\n",
      "     | > loss_dur: 0.7888169288635254  (0.8184230402112007)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: 1.0665760040283203  (1.0232395066155329)\n",
      "     | > log_mle: 0.1999230980873108  (0.1994575990570916)\n",
      "     | > loss_dur: 0.8666529655456543  (0.8237819208039178)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: 1.0286061763763428  (1.0237761735916138)\n",
      "     | > log_mle: 0.20409244298934937  (0.1999210834503174)\n",
      "     | > loss_dur: 0.8245137333869934  (0.8238551020622253)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: 0.9997783303260803  (1.0215945514765652)\n",
      "     | > log_mle: 0.18973487615585327  (0.1989950646053661)\n",
      "     | > loss_dur: 0.810043454170227  (0.8225994977084073)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: 0.9969883561134338  (1.0195440351963043)\n",
      "     | > log_mle: 0.2043357491493225  (0.1994401216506958)\n",
      "     | > loss_dur: 0.7926526069641113  (0.820103923479716)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: 1.0525239706039429  (1.0220809533045843)\n",
      "     | > log_mle: 0.1880618929862976  (0.19856487329189593)\n",
      "     | > loss_dur: 0.8644620776176453  (0.8235160891826336)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: 1.01881742477417  (1.0218478441238403)\n",
      "     | > log_mle: 0.19636791944503784  (0.19840794801712036)\n",
      "     | > loss_dur: 0.8224495649337769  (0.8234399088791439)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: 1.0266324281692505  (1.0221668163935342)\n",
      "     | > log_mle: 0.19916844367980957  (0.19845864772796631)\n",
      "     | > loss_dur: 0.8274639844894409  (0.823708180586497)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: 1.0197193622589111  (1.0220138505101204)\n",
      "     | > log_mle: 0.20097506046295166  (0.1986159235239029)\n",
      "     | > loss_dur: 0.8187443017959595  (0.8233979381620884)\n",
      "\n",
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.003607422113418579 \u001b[0m(-0.0001795738935470581)\n",
      "     | > avg_loss:\u001b[92m 1.0220138505101204 \u001b[0m(-0.05323876440525055)\n",
      "     | > avg_log_mle:\u001b[92m 0.1986159235239029 \u001b[0m(-0.019977029412984848)\n",
      "     | > avg_loss_dur:\u001b[92m 0.8233979381620884 \u001b[0m(-0.033261738717556)\n",
      "\n",
      " > BEST MODEL : train/run-February-22-2025_02+19AM-9b6e3e6/best_model_9737.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 8/40\u001b[0m\n",
      " --> train/run-February-22-2025_02+19AM-9b6e3e6\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-22 02:59:14) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:59:21 -- STEP: 13/406 -- GLOBAL_STEP: 9750\u001b[0m\n",
      "     | > loss: 1.0095731019973755  (1.0693258505601149)\n",
      "     | > log_mle: 0.21785950660705566  (0.22880330911049476)\n",
      "     | > loss_dur: 0.7917135953903198  (0.8405225276947021)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(1.9117, device='cuda:0')  (tensor(2.0097, device='cuda:0'))\n",
      "     | > current_lr: 2e-06 \n",
      "     | > step_time: 0.4113  (0.37114134201636684)\n",
      "     | > loader_time: 0.0029  (0.005106357427743765)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:59:36 -- STEP: 38/406 -- GLOBAL_STEP: 9775\u001b[0m\n",
      "     | > loss: 1.062101125717163  (1.054755637520238)\n",
      "     | > log_mle: 0.21480292081832886  (0.2268999391480496)\n",
      "     | > loss_dur: 0.847298264503479  (0.8278556968036451)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(1.6833, device='cuda:0')  (tensor(1.9210, device='cuda:0'))\n",
      "     | > current_lr: 2e-06 \n",
      "     | > step_time: 0.7701  (0.49462607032374334)\n",
      "     | > loader_time: 0.0292  (0.006546177362140857)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:59:50 -- STEP: 63/406 -- GLOBAL_STEP: 9800\u001b[0m\n",
      "     | > loss: 1.0197362899780273  (1.0478655620226784)\n",
      "     | > log_mle: 0.21467316150665283  (0.22343000911530994)\n",
      "     | > loss_dur: 0.8050631284713745  (0.8244355529073685)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(1.8939, device='cuda:0')  (tensor(1.9248, device='cuda:0'))\n",
      "     | > current_lr: 2e-06 \n",
      "     | > step_time: 0.504  (0.5289880131918286)\n",
      "     | > loader_time: 0.0043  (0.006709098815917969)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:00:07 -- STEP: 88/406 -- GLOBAL_STEP: 9825\u001b[0m\n",
      "     | > loss: 1.0229045152664185  (1.0426835932514884)\n",
      "     | > log_mle: 0.2232467532157898  (0.2195291512391784)\n",
      "     | > loss_dur: 0.7996577620506287  (0.8231544440442865)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(1.9438, device='cuda:0')  (tensor(1.9194, device='cuda:0'))\n",
      "     | > current_lr: 2e-06 \n",
      "     | > step_time: 0.8037  (0.5582856698469681)\n",
      "     | > loader_time: 0.0093  (0.008963224562731655)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:00:22 -- STEP: 113/406 -- GLOBAL_STEP: 9850\u001b[0m\n",
      "     | > loss: 1.0235557556152344  (1.0369871374780106)\n",
      "     | > log_mle: 0.2079957127571106  (0.2155390650825163)\n",
      "     | > loss_dur: 0.8155600428581238  (0.8214480739779177)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(1.8450, device='cuda:0')  (tensor(1.9239, device='cuda:0'))\n",
      "     | > current_lr: 2e-06 \n",
      "     | > step_time: 0.3072  (0.5703829094371959)\n",
      "     | > loader_time: 0.0043  (0.00963577338024578)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:00:39 -- STEP: 138/406 -- GLOBAL_STEP: 9875\u001b[0m\n",
      "     | > loss: 1.0516363382339478  (1.0344898886438738)\n",
      "     | > log_mle: 0.1922588348388672  (0.21211479496264804)\n",
      "     | > loss_dur: 0.8593775033950806  (0.8223750936812249)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.0519, device='cuda:0')  (tensor(1.9128, device='cuda:0'))\n",
      "     | > current_lr: 2e-06 \n",
      "     | > step_time: 0.8143  (0.5816936492919917)\n",
      "     | > loader_time: 0.0293  (0.01021597005318904)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:00:56 -- STEP: 163/406 -- GLOBAL_STEP: 9900\u001b[0m\n",
      "     | > loss: 1.026195764541626  (1.0322767949543126)\n",
      "     | > log_mle: 0.1804984211921692  (0.20938053416328192)\n",
      "     | > loss_dur: 0.8456973433494568  (0.8228962618880477)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.0482, device='cuda:0')  (tensor(1.9110, device='cuda:0'))\n",
      "     | > current_lr: 2e-06 \n",
      "     | > step_time: 0.8166  (0.5955699323876501)\n",
      "     | > loader_time: 0.0121  (0.011097760288261926)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:01:13 -- STEP: 188/406 -- GLOBAL_STEP: 9925\u001b[0m\n",
      "     | > loss: 1.0576152801513672  (1.0303885724316257)\n",
      "     | > log_mle: 0.17591071128845215  (0.2069174121034906)\n",
      "     | > loss_dur: 0.8817045092582703  (0.8234711619133644)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.0135, device='cuda:0')  (tensor(1.9080, device='cuda:0'))\n",
      "     | > current_lr: 2e-06 \n",
      "     | > step_time: 0.7606  (0.6032384405744834)\n",
      "     | > loader_time: 0.0055  (0.01140975064419685)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:01:30 -- STEP: 213/406 -- GLOBAL_STEP: 9950\u001b[0m\n",
      "     | > loss: 0.9915821552276611  (1.0278883165037132)\n",
      "     | > log_mle: 0.18057262897491455  (0.20476047785629126)\n",
      "     | > loss_dur: 0.8110095262527466  (0.8231278406062597)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(1.8526, device='cuda:0')  (tensor(1.9102, device='cuda:0'))\n",
      "     | > current_lr: 2e-06 \n",
      "     | > step_time: 0.8653  (0.61227234540411)\n",
      "     | > loader_time: 0.0398  (0.012263357359478727)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:01:48 -- STEP: 238/406 -- GLOBAL_STEP: 9975\u001b[0m\n",
      "     | > loss: 1.0172837972640991  (1.0259860859197727)\n",
      "     | > log_mle: 0.1788892149925232  (0.20264805214745654)\n",
      "     | > loss_dur: 0.8383945822715759  (0.8233380352749544)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(1.8341, device='cuda:0')  (tensor(1.9052, device='cuda:0'))\n",
      "     | > current_lr: 2e-06 \n",
      "     | > step_time: 1.1733  (0.6229431629180908)\n",
      "     | > loader_time: 0.0072  (0.012264352886616679)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:02:07 -- STEP: 263/406 -- GLOBAL_STEP: 10000\u001b[0m\n",
      "     | > loss: 1.0152101516723633  (1.0242736446086895)\n",
      "     | > log_mle: 0.1754423975944519  (0.2007112362538907)\n",
      "     | > loss_dur: 0.8397678136825562  (0.8235624103945017)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.2972, device='cuda:0')  (tensor(1.9170, device='cuda:0'))\n",
      "     | > current_lr: 2e-06 \n",
      "     | > step_time: 0.984  (0.6327244736849128)\n",
      "     | > loader_time: 0.0401  (0.012462027625892548)\n",
      "\n",
      "\n",
      " > CHECKPOINT : train/run-February-22-2025_02+19AM-9b6e3e6/checkpoint_10000.pth\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:02:29 -- STEP: 288/406 -- GLOBAL_STEP: 10025\u001b[0m\n",
      "     | > loss: 0.9949197769165039  (1.0226540971133447)\n",
      "     | > log_mle: 0.18171167373657227  (0.19889376084837648)\n",
      "     | > loss_dur: 0.8132081031799316  (0.8237603385415342)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(1.8116, device='cuda:0')  (tensor(1.9229, device='cuda:0'))\n",
      "     | > current_lr: 2e-06 \n",
      "     | > step_time: 0.6403  (0.6404401221209103)\n",
      "     | > loader_time: 0.008  (0.012485586106777184)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:02:49 -- STEP: 313/406 -- GLOBAL_STEP: 10050\u001b[0m\n",
      "     | > loss: 0.9912552833557129  (1.0214036278450451)\n",
      "     | > log_mle: 0.1802278757095337  (0.19737546798139338)\n",
      "     | > loss_dur: 0.8110274076461792  (0.8240281613870931)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(1.8133, device='cuda:0')  (tensor(1.9209, device='cuda:0'))\n",
      "     | > current_lr: 2e-06 \n",
      "     | > step_time: 0.8314  (0.6488154155377764)\n",
      "     | > loader_time: 0.0062  (0.012650533986929504)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:03:08 -- STEP: 338/406 -- GLOBAL_STEP: 10075\u001b[0m\n",
      "     | > loss: 1.0070946216583252  (1.0200899989294585)\n",
      "     | > log_mle: 0.17449545860290527  (0.19582178589154986)\n",
      "     | > loss_dur: 0.8325991034507751  (0.8242682146250143)\n",
      "     | > amp_scaler: 65536.0  (34513.04142011834)\n",
      "     | > grad_norm: tensor(1.9053, device='cuda:0')  (tensor(1.9193, device='cuda:0'))\n",
      "     | > current_lr: 2e-06 \n",
      "     | > step_time: 0.7533  (0.6582245551622833)\n",
      "     | > loader_time: 0.0073  (0.012652486739073982)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:03:29 -- STEP: 363/406 -- GLOBAL_STEP: 10100\u001b[0m\n",
      "     | > loss: 0.9813366532325745  (1.0188419249103742)\n",
      "     | > log_mle: 0.16892880201339722  (0.19419504344955954)\n",
      "     | > loss_dur: 0.8124078512191772  (0.8246468826102159)\n",
      "     | > amp_scaler: 65536.0  (36649.60881542699)\n",
      "     | > grad_norm: tensor(1.9298, device='cuda:0')  (tensor(1.9208, device='cuda:0'))\n",
      "     | > current_lr: 2e-06 \n",
      "     | > step_time: 0.7876  (0.6681050761672094)\n",
      "     | > loader_time: 0.012  (0.012929175510879388)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:03:51 -- STEP: 388/406 -- GLOBAL_STEP: 10125\u001b[0m\n",
      "     | > loss: 0.9854854345321655  (1.0170438735140968)\n",
      "     | > log_mle: 0.1654394268989563  (0.19278028469110275)\n",
      "     | > loss_dur: 0.8200460076332092  (0.8242635897447154)\n",
      "     | > amp_scaler: 65536.0  (38510.845360824744)\n",
      "     | > grad_norm: tensor(1.8609, device='cuda:0')  (tensor(1.9202, device='cuda:0'))\n",
      "     | > current_lr: 2e-06 \n",
      "     | > step_time: 0.9142  (0.6793861376870541)\n",
      "     | > loader_time: 0.0066  (0.01295325375094856)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: 0.9678548574447632  (0.9678548574447632)\n",
      "     | > log_mle: 0.19618868827819824  (0.19618868827819824)\n",
      "     | > loss_dur: 0.7716661691665649  (0.7716661691665649)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: 0.9259226322174072  (0.9259226322174072)\n",
      "     | > log_mle: 0.17744266986846924  (0.17744266986846924)\n",
      "     | > loss_dur: 0.748479962348938  (0.748479962348938)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: 0.9768629670143127  (0.95139279961586)\n",
      "     | > log_mle: 0.21919649839401245  (0.19831958413124084)\n",
      "     | > loss_dur: 0.7576664686203003  (0.7530732154846191)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: 0.971792459487915  (0.9581926862398783)\n",
      "     | > log_mle: 0.18717652559280396  (0.19460523128509521)\n",
      "     | > loss_dur: 0.7846159338951111  (0.7635874549547831)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: 0.9634120464324951  (0.9594975262880325)\n",
      "     | > log_mle: 0.16122084856033325  (0.18625913560390472)\n",
      "     | > loss_dur: 0.8021911978721619  (0.7732383906841278)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: 0.9480869174003601  (0.957215404510498)\n",
      "     | > log_mle: 0.15738415718078613  (0.180484139919281)\n",
      "     | > loss_dur: 0.790702760219574  (0.776731264591217)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: 0.9905829429626465  (0.9627766609191895)\n",
      "     | > log_mle: 0.14353036880493164  (0.17432517806688944)\n",
      "     | > loss_dur: 0.8470525741577148  (0.7884514828523)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: 0.9561832547187805  (0.9618347457477024)\n",
      "     | > log_mle: 0.19170308113098145  (0.176807735647474)\n",
      "     | > loss_dur: 0.7644801735877991  (0.7850270101002285)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: 0.9530695080757141  (0.9607390910387039)\n",
      "     | > log_mle: 0.179648756980896  (0.17716286331415176)\n",
      "     | > loss_dur: 0.7734207510948181  (0.7835762277245522)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: 1.018570065498352  (0.9671647548675537)\n",
      "     | > log_mle: 0.17732208967208862  (0.1771805551317003)\n",
      "     | > loss_dur: 0.8412479758262634  (0.7899841997358534)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: 0.9611868262290955  (0.9665669620037078)\n",
      "     | > log_mle: 0.18162500858306885  (0.17762500047683716)\n",
      "     | > loss_dur: 0.7795618176460266  (0.7889419615268707)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: 0.9420644640922546  (0.9643394621935758)\n",
      "     | > log_mle: 0.16716152429580688  (0.17667377536947076)\n",
      "     | > loss_dur: 0.7749029397964478  (0.787665686824105)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: 0.9425439834594727  (0.9625231722990671)\n",
      "     | > log_mle: 0.18169713020324707  (0.17709238827228546)\n",
      "     | > loss_dur: 0.7608468532562256  (0.7854307840267817)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: 1.0000591278076172  (0.9654105534920325)\n",
      "     | > log_mle: 0.16521495580673218  (0.17617873962108904)\n",
      "     | > loss_dur: 0.8348442316055298  (0.7892318184559162)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: 0.9615349769592285  (0.9651337265968323)\n",
      "     | > log_mle: 0.1736081838607788  (0.17599512849535262)\n",
      "     | > loss_dur: 0.7879267930984497  (0.7891386023589543)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: 0.9677085876464844  (0.9653053840001424)\n",
      "     | > log_mle: 0.17626315355300903  (0.17601299683252972)\n",
      "     | > loss_dur: 0.7914454340934753  (0.7892923911412557)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: 0.9666264057159424  (0.9653879478573799)\n",
      "     | > log_mle: 0.17961955070495605  (0.17623840644955635)\n",
      "     | > loss_dur: 0.7870068550109863  (0.7891495451331139)\n",
      "\n",
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.0035561174154281616 \u001b[0m(-5.130469799041748e-05)\n",
      "     | > avg_loss:\u001b[92m 0.9653879478573799 \u001b[0m(-0.05662590265274048)\n",
      "     | > avg_log_mle:\u001b[92m 0.17623840644955635 \u001b[0m(-0.022377517074346542)\n",
      "     | > avg_loss_dur:\u001b[92m 0.7891495451331139 \u001b[0m(-0.03424839302897453)\n",
      "\n",
      " > BEST MODEL : train/run-February-22-2025_02+19AM-9b6e3e6/best_model_10143.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 9/40\u001b[0m\n",
      " --> train/run-February-22-2025_02+19AM-9b6e3e6\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-22 03:04:15) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:04:20 -- STEP: 7/406 -- GLOBAL_STEP: 10150\u001b[0m\n",
      "     | > loss: 0.9991438984870911  (1.0231366327830724)\n",
      "     | > log_mle: 0.21571952104568481  (0.21102377346583776)\n",
      "     | > loss_dur: 0.7834243774414062  (0.8121128508022853)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.8715, device='cuda:0')  (tensor(1.9288, device='cuda:0'))\n",
      "     | > current_lr: 2.25e-06 \n",
      "     | > step_time: 0.4976  (0.445044789995466)\n",
      "     | > loader_time: 0.0033  (0.003992523465837751)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:04:32 -- STEP: 32/406 -- GLOBAL_STEP: 10175\u001b[0m\n",
      "     | > loss: 1.0083889961242676  (0.9939283635467291)\n",
      "     | > log_mle: 0.20388835668563843  (0.20493090711534023)\n",
      "     | > loss_dur: 0.8045005798339844  (0.7889974471181631)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.7298, device='cuda:0')  (tensor(1.8233, device='cuda:0'))\n",
      "     | > current_lr: 2.25e-06 \n",
      "     | > step_time: 0.5784  (0.4845234602689743)\n",
      "     | > loader_time: 0.0043  (0.007079564034938812)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:04:47 -- STEP: 57/406 -- GLOBAL_STEP: 10200\u001b[0m\n",
      "     | > loss: 0.9805697798728943  (0.9888781037246972)\n",
      "     | > log_mle: 0.20034444332122803  (0.2019225798155132)\n",
      "     | > loss_dur: 0.7802253365516663  (0.7869555186807063)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.8187, device='cuda:0')  (tensor(1.8241, device='cuda:0'))\n",
      "     | > current_lr: 2.25e-06 \n",
      "     | > step_time: 0.3708  (0.5283232028024238)\n",
      "     | > loader_time: 0.0047  (0.008388155385067587)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:05:02 -- STEP: 82/406 -- GLOBAL_STEP: 10225\u001b[0m\n",
      "     | > loss: 0.979219377040863  (0.9849791708515911)\n",
      "     | > log_mle: 0.18379926681518555  (0.19809090945778823)\n",
      "     | > loss_dur: 0.7954201102256775  (0.7868882563056016)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.8995, device='cuda:0')  (tensor(1.8308, device='cuda:0'))\n",
      "     | > current_lr: 2.25e-06 \n",
      "     | > step_time: 0.4931  (0.5423574389480964)\n",
      "     | > loader_time: 0.0351  (0.010428251289739841)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:05:18 -- STEP: 107/406 -- GLOBAL_STEP: 10250\u001b[0m\n",
      "     | > loss: 0.9282000064849854  (0.9785789708110774)\n",
      "     | > log_mle: 0.18018168210983276  (0.19408702627520694)\n",
      "     | > loss_dur: 0.7480183243751526  (0.7844919406365012)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.9745, device='cuda:0')  (tensor(1.8356, device='cuda:0'))\n",
      "     | > current_lr: 2.25e-06 \n",
      "     | > step_time: 0.7104  (0.5593819038890232)\n",
      "     | > loader_time: 0.0105  (0.011205519471213085)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:05:35 -- STEP: 132/406 -- GLOBAL_STEP: 10275\u001b[0m\n",
      "     | > loss: 0.9438515901565552  (0.9746694880904574)\n",
      "     | > log_mle: 0.16115999221801758  (0.1903021362694827)\n",
      "     | > loss_dur: 0.7826915979385376  (0.7843673486601223)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.7623, device='cuda:0')  (tensor(1.8720, device='cuda:0'))\n",
      "     | > current_lr: 2.25e-06 \n",
      "     | > step_time: 0.8639  (0.576832140936996)\n",
      "     | > loader_time: 0.0104  (0.011116436033537895)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:05:51 -- STEP: 157/406 -- GLOBAL_STEP: 10300\u001b[0m\n",
      "     | > loss: 0.9550081491470337  (0.9727798366242912)\n",
      "     | > log_mle: 0.18094557523727417  (0.187552106608251)\n",
      "     | > loss_dur: 0.7740625739097595  (0.7852277273585084)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.8818, device='cuda:0')  (tensor(1.8564, device='cuda:0'))\n",
      "     | > current_lr: 2.25e-06 \n",
      "     | > step_time: 0.4769  (0.5876882531840332)\n",
      "     | > loader_time: 0.0065  (0.011891620174335071)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:06:09 -- STEP: 182/406 -- GLOBAL_STEP: 10325\u001b[0m\n",
      "     | > loss: 0.9636198282241821  (0.9709921983572153)\n",
      "     | > log_mle: 0.16044080257415771  (0.1849726913394508)\n",
      "     | > loss_dur: 0.8031790256500244  (0.7860195050527763)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(2.0607, device='cuda:0')  (tensor(1.8581, device='cuda:0'))\n",
      "     | > current_lr: 2.25e-06 \n",
      "     | > step_time: 0.9855  (0.6013999116289748)\n",
      "     | > loader_time: 0.02  (0.01227629708719778)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:06:26 -- STEP: 207/406 -- GLOBAL_STEP: 10350\u001b[0m\n",
      "     | > loss: 0.9481439590454102  (0.969111860950212)\n",
      "     | > log_mle: 0.1706448197364807  (0.1826785555208362)\n",
      "     | > loss_dur: 0.7774991393089294  (0.7864333037017049)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(2.1110, device='cuda:0')  (tensor(1.8572, device='cuda:0'))\n",
      "     | > current_lr: 2.25e-06 \n",
      "     | > step_time: 0.6834  (0.6078607391044138)\n",
      "     | > loader_time: 0.0119  (0.012477135312729992)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:06:44 -- STEP: 232/406 -- GLOBAL_STEP: 10375\u001b[0m\n",
      "     | > loss: 0.9259375333786011  (0.9665962187894459)\n",
      "     | > log_mle: 0.15742111206054688  (0.18034328905672856)\n",
      "     | > loss_dur: 0.7685164213180542  (0.7862529281912181)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.5783, device='cuda:0')  (tensor(1.8514, device='cuda:0'))\n",
      "     | > current_lr: 2.25e-06 \n",
      "     | > step_time: 0.681  (0.6176099212005222)\n",
      "     | > loader_time: 0.0116  (0.012382401474590963)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:07:03 -- STEP: 257/406 -- GLOBAL_STEP: 10400\u001b[0m\n",
      "     | > loss: 0.9311169385910034  (0.9651287369690981)\n",
      "     | > log_mle: 0.15720969438552856  (0.17828633001342353)\n",
      "     | > loss_dur: 0.7739072442054749  (0.7868424055641264)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.8506, device='cuda:0')  (tensor(1.8559, device='cuda:0'))\n",
      "     | > current_lr: 2.25e-06 \n",
      "     | > step_time: 0.9026  (0.6282426151320165)\n",
      "     | > loader_time: 0.0264  (0.012643134083729314)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:07:21 -- STEP: 282/406 -- GLOBAL_STEP: 10425\u001b[0m\n",
      "     | > loss: 0.9260426163673401  (0.9632543209174)\n",
      "     | > log_mle: 0.14492255449295044  (0.17634118681258337)\n",
      "     | > loss_dur: 0.7811200618743896  (0.7869131328366326)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.7699, device='cuda:0')  (tensor(1.8526, device='cuda:0'))\n",
      "     | > current_lr: 2.25e-06 \n",
      "     | > step_time: 0.5754  (0.6356122476834778)\n",
      "     | > loader_time: 0.0114  (0.012807250868344142)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:07:40 -- STEP: 307/406 -- GLOBAL_STEP: 10450\u001b[0m\n",
      "     | > loss: 0.9173713326454163  (0.9618322515332349)\n",
      "     | > log_mle: 0.15612387657165527  (0.17470041490144753)\n",
      "     | > loss_dur: 0.761247456073761  (0.7871318354668756)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.8805, device='cuda:0')  (tensor(1.8515, device='cuda:0'))\n",
      "     | > current_lr: 2.25e-06 \n",
      "     | > step_time: 0.7557  (0.6452964944249255)\n",
      "     | > loader_time: 0.0326  (0.01316539550060558)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:08:00 -- STEP: 332/406 -- GLOBAL_STEP: 10475\u001b[0m\n",
      "     | > loss: 0.9346389174461365  (0.9599792664668646)\n",
      "     | > log_mle: 0.1557033658027649  (0.17312891368406355)\n",
      "     | > loss_dur: 0.7789355516433716  (0.7868503517056085)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.8189, device='cuda:0')  (tensor(1.8522, device='cuda:0'))\n",
      "     | > current_lr: 2.25e-06 \n",
      "     | > step_time: 0.5583  (0.6541465413139526)\n",
      "     | > loader_time: 0.0071  (0.013286521635859846)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:08:21 -- STEP: 357/406 -- GLOBAL_STEP: 10500\u001b[0m\n",
      "     | > loss: 0.9329552054405212  (0.9589111965243556)\n",
      "     | > log_mle: 0.15361136198043823  (0.17142061592817956)\n",
      "     | > loss_dur: 0.779343843460083  (0.7874905795944169)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.7022, device='cuda:0')  (tensor(1.8550, device='cuda:0'))\n",
      "     | > current_lr: 2.25e-06 \n",
      "     | > step_time: 0.6291  (0.6661582119992465)\n",
      "     | > loader_time: 0.0063  (0.013643039040872697)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:08:42 -- STEP: 382/406 -- GLOBAL_STEP: 10525\u001b[0m\n",
      "     | > loss: 0.9054004549980164  (0.9570030913303036)\n",
      "     | > log_mle: 0.13864123821258545  (0.16984371677119048)\n",
      "     | > loss_dur: 0.7667592167854309  (0.7871593736229141)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.7998, device='cuda:0')  (tensor(1.8522, device='cuda:0'))\n",
      "     | > current_lr: 2.25e-06 \n",
      "     | > step_time: 0.9991  (0.6748462509734465)\n",
      "     | > loader_time: 0.0227  (0.013822412615671208)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: 0.8834071159362793  (0.8834071159362793)\n",
      "     | > log_mle: 0.17287558317184448  (0.17287558317184448)\n",
      "     | > loss_dur: 0.7105315327644348  (0.7105315327644348)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: 0.8587344884872437  (0.8587344884872437)\n",
      "     | > log_mle: 0.15313726663589478  (0.15313726663589478)\n",
      "     | > loss_dur: 0.7055972218513489  (0.7055972218513489)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: 0.9166382551193237  (0.8876863718032837)\n",
      "     | > log_mle: 0.19382518529891968  (0.17348122596740723)\n",
      "     | > loss_dur: 0.722813069820404  (0.7142051458358765)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: 0.9173701405525208  (0.8975809613863627)\n",
      "     | > log_mle: 0.16413724422454834  (0.17036656538645426)\n",
      "     | > loss_dur: 0.7532328963279724  (0.7272143959999084)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: 0.9214742183685303  (0.9035542756319046)\n",
      "     | > log_mle: 0.1374356746673584  (0.1621338427066803)\n",
      "     | > loss_dur: 0.7840385437011719  (0.7414204329252243)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: 0.9015591740608215  (0.903155255317688)\n",
      "     | > log_mle: 0.1337708830833435  (0.15646125078201295)\n",
      "     | > loss_dur: 0.767788290977478  (0.746694004535675)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: 0.9394240975379944  (0.9092000623544058)\n",
      "     | > log_mle: 0.12065976858139038  (0.15049433708190918)\n",
      "     | > loss_dur: 0.818764328956604  (0.7587057252724966)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: 0.8887134194374084  (0.9062733990805489)\n",
      "     | > log_mle: 0.16711091995239258  (0.15286813463483537)\n",
      "     | > loss_dur: 0.7216024994850159  (0.7534052644457135)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: 0.8761001825332642  (0.9025017470121384)\n",
      "     | > log_mle: 0.1553216576576233  (0.15317482501268387)\n",
      "     | > loss_dur: 0.7207785248756409  (0.7493269219994545)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: 0.945389449596405  (0.9072670472992791)\n",
      "     | > log_mle: 0.15280002355575562  (0.1531331804063585)\n",
      "     | > loss_dur: 0.7925894260406494  (0.7541338668929206)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: 0.89118891954422  (0.9056592345237732)\n",
      "     | > log_mle: 0.157440185546875  (0.15356388092041015)\n",
      "     | > loss_dur: 0.733748733997345  (0.752095353603363)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: 0.8766815066337585  (0.9030248956246809)\n",
      "     | > log_mle: 0.14300572872161865  (0.1526040489023382)\n",
      "     | > loss_dur: 0.7336757779121399  (0.7504208467223428)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: 0.8887199759483337  (0.9018328189849854)\n",
      "     | > log_mle: 0.15722250938415527  (0.15298892060915628)\n",
      "     | > loss_dur: 0.7314974665641785  (0.7488438983758291)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: 0.9296741485595703  (0.9039744597214919)\n",
      "     | > log_mle: 0.1405181884765625  (0.1520296335220337)\n",
      "     | > loss_dur: 0.7891559600830078  (0.7519448261994582)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: 0.9002614617347717  (0.9037092455795833)\n",
      "     | > log_mle: 0.149000346660614  (0.15181325588907515)\n",
      "     | > loss_dur: 0.7512611150741577  (0.7518959896905082)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: 0.902345597743988  (0.903618335723877)\n",
      "     | > log_mle: 0.1515880823135376  (0.15179824431737263)\n",
      "     | > loss_dur: 0.7507575154304504  (0.7518200914065043)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: 0.9097183346748352  (0.9039995856583118)\n",
      "     | > log_mle: 0.15595906972885132  (0.15205829590559006)\n",
      "     | > loss_dur: 0.7537592649459839  (0.7519412897527218)\n",
      "\n",
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[91m 0.008396908640861511 \u001b[0m(+0.00484079122543335)\n",
      "     | > avg_loss:\u001b[92m 0.9039995856583118 \u001b[0m(-0.06138836219906807)\n",
      "     | > avg_log_mle:\u001b[92m 0.15205829590559006 \u001b[0m(-0.024180110543966293)\n",
      "     | > avg_loss_dur:\u001b[92m 0.7519412897527218 \u001b[0m(-0.037208255380392075)\n",
      "\n",
      " > BEST MODEL : train/run-February-22-2025_02+19AM-9b6e3e6/best_model_10549.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 10/40\u001b[0m\n",
      " --> train/run-February-22-2025_02+19AM-9b6e3e6\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-22 03:09:10) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:09:13 -- STEP: 1/406 -- GLOBAL_STEP: 10550\u001b[0m\n",
      "     | > loss: 0.9343941807746887  (0.9343941807746887)\n",
      "     | > log_mle: 0.18055623769760132  (0.18055623769760132)\n",
      "     | > loss_dur: 0.7538379430770874  (0.7538379430770874)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.8979, device='cuda:0')  (tensor(1.8979, device='cuda:0'))\n",
      "     | > current_lr: 2.4999999999999998e-06 \n",
      "     | > step_time: 0.7678  (0.7677710056304932)\n",
      "     | > loader_time: 0.0087  (0.008684396743774414)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:09:24 -- STEP: 26/406 -- GLOBAL_STEP: 10575\u001b[0m\n",
      "     | > loss: 0.9102672338485718  (0.9320535636865176)\n",
      "     | > log_mle: 0.17546576261520386  (0.18086371742762053)\n",
      "     | > loss_dur: 0.7348014712333679  (0.7511898462588971)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.8570, device='cuda:0')  (tensor(1.7895, device='cuda:0'))\n",
      "     | > current_lr: 2.4999999999999998e-06 \n",
      "     | > step_time: 0.4016  (0.4560729907109187)\n",
      "     | > loader_time: 0.0036  (0.005621433258056641)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:09:39 -- STEP: 51/406 -- GLOBAL_STEP: 10600\u001b[0m\n",
      "     | > loss: 0.9234290719032288  (0.9271286480567035)\n",
      "     | > log_mle: 0.15683352947235107  (0.1785005856962765)\n",
      "     | > loss_dur: 0.7665955424308777  (0.748628062360427)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.7261, device='cuda:0')  (tensor(1.7335, device='cuda:0'))\n",
      "     | > current_lr: 2.4999999999999998e-06 \n",
      "     | > step_time: 0.6589  (0.5209646785960477)\n",
      "     | > loader_time: 0.0036  (0.007563114166259766)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:09:55 -- STEP: 76/406 -- GLOBAL_STEP: 10625\u001b[0m\n",
      "     | > loss: 0.9343475699424744  (0.9222433676845149)\n",
      "     | > log_mle: 0.17038166522979736  (0.17437698103879629)\n",
      "     | > loss_dur: 0.763965904712677  (0.7478663866457186)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.6513, device='cuda:0')  (tensor(1.7422, device='cuda:0'))\n",
      "     | > current_lr: 2.4999999999999998e-06 \n",
      "     | > step_time: 0.4889  (0.5491426587104795)\n",
      "     | > loader_time: 0.004  (0.008537838333531432)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:10:10 -- STEP: 101/406 -- GLOBAL_STEP: 10650\u001b[0m\n",
      "     | > loss: 0.9122135639190674  (0.9170599113596548)\n",
      "     | > log_mle: 0.16011691093444824  (0.17060319090833756)\n",
      "     | > loss_dur: 0.7520966529846191  (0.7464567204513172)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.7289, device='cuda:0')  (tensor(1.7372, device='cuda:0'))\n",
      "     | > current_lr: 2.4999999999999998e-06 \n",
      "     | > step_time: 0.396  (0.559814700985899)\n",
      "     | > loader_time: 0.0165  (0.009202494479642056)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:10:27 -- STEP: 126/406 -- GLOBAL_STEP: 10675\u001b[0m\n",
      "     | > loss: 0.8752497434616089  (0.9125471640200842)\n",
      "     | > log_mle: 0.15271824598312378  (0.16676539088052414)\n",
      "     | > loss_dur: 0.7225314974784851  (0.7457817731395601)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.6408, device='cuda:0')  (tensor(1.7493, device='cuda:0'))\n",
      "     | > current_lr: 2.4999999999999998e-06 \n",
      "     | > step_time: 0.5793  (0.5795885343400257)\n",
      "     | > loader_time: 0.0054  (0.009941453025454567)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:10:44 -- STEP: 151/406 -- GLOBAL_STEP: 10700\u001b[0m\n",
      "     | > loss: 0.9195940494537354  (0.9107945391673915)\n",
      "     | > log_mle: 0.1579318642616272  (0.16371180679624445)\n",
      "     | > loss_dur: 0.7616621851921082  (0.7470827323711469)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.8566, device='cuda:0')  (tensor(1.7539, device='cuda:0'))\n",
      "     | > current_lr: 2.4999999999999998e-06 \n",
      "     | > step_time: 0.4897  (0.5942912780685928)\n",
      "     | > loader_time: 0.0041  (0.010843971707173527)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:11:02 -- STEP: 176/406 -- GLOBAL_STEP: 10725\u001b[0m\n",
      "     | > loss: 0.8849796056747437  (0.908460009843111)\n",
      "     | > log_mle: 0.14934730529785156  (0.16112626682628278)\n",
      "     | > loss_dur: 0.7356323003768921  (0.747333743016828)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.7569, device='cuda:0')  (tensor(1.7530, device='cuda:0'))\n",
      "     | > current_lr: 2.4999999999999998e-06 \n",
      "     | > step_time: 0.7496  (0.6059893112290987)\n",
      "     | > loader_time: 0.02  (0.010908851569349107)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:11:19 -- STEP: 201/406 -- GLOBAL_STEP: 10750\u001b[0m\n",
      "     | > loss: 0.8705925941467285  (0.9062031160539655)\n",
      "     | > log_mle: 0.1487906575202942  (0.15867956746276923)\n",
      "     | > loss_dur: 0.7218019366264343  (0.7475235485911961)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.6386, device='cuda:0')  (tensor(1.7579, device='cuda:0'))\n",
      "     | > current_lr: 2.4999999999999998e-06 \n",
      "     | > step_time: 0.6004  (0.6157800012560032)\n",
      "     | > loader_time: 0.0052  (0.011062990966720952)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:11:37 -- STEP: 226/406 -- GLOBAL_STEP: 10775\u001b[0m\n",
      "     | > loss: 0.8681038618087769  (0.9035916302056439)\n",
      "     | > log_mle: 0.13486367464065552  (0.1563597841072926)\n",
      "     | > loss_dur: 0.7332401871681213  (0.7472318460983511)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.8422, device='cuda:0')  (tensor(1.7714, device='cuda:0'))\n",
      "     | > current_lr: 2.4999999999999998e-06 \n",
      "     | > step_time: 0.9016  (0.6246054288560309)\n",
      "     | > loader_time: 0.0249  (0.011680114585741424)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:11:55 -- STEP: 251/406 -- GLOBAL_STEP: 10800\u001b[0m\n",
      "     | > loss: 0.8879903554916382  (0.9020112418083556)\n",
      "     | > log_mle: 0.1313859224319458  (0.15425640962038376)\n",
      "     | > loss_dur: 0.7566044330596924  (0.7477548321879717)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(2.4552, device='cuda:0')  (tensor(1.7770, device='cuda:0'))\n",
      "     | > current_lr: 2.4999999999999998e-06 \n",
      "     | > step_time: 0.6587  (0.6314642448349301)\n",
      "     | > loader_time: 0.0183  (0.011872030349366687)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:12:13 -- STEP: 276/406 -- GLOBAL_STEP: 10825\u001b[0m\n",
      "     | > loss: 0.876941978931427  (0.9001078666120337)\n",
      "     | > log_mle: 0.13567233085632324  (0.15223847264828885)\n",
      "     | > loss_dur: 0.7412696480751038  (0.7478693939637446)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.6608, device='cuda:0')  (tensor(1.8020, device='cuda:0'))\n",
      "     | > current_lr: 2.4999999999999998e-06 \n",
      "     | > step_time: 0.931  (0.6391341332076251)\n",
      "     | > loader_time: 0.0081  (0.012181385703708806)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:12:32 -- STEP: 301/406 -- GLOBAL_STEP: 10850\u001b[0m\n",
      "     | > loss: 0.897348940372467  (0.8985793376681812)\n",
      "     | > log_mle: 0.11975622177124023  (0.1505664268205332)\n",
      "     | > loss_dur: 0.7775927186012268  (0.748012910847648)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(2.3891, device='cuda:0')  (tensor(1.8001, device='cuda:0'))\n",
      "     | > current_lr: 2.4999999999999998e-06 \n",
      "     | > step_time: 0.9241  (0.6458907222430965)\n",
      "     | > loader_time: 0.015  (0.012735493555417483)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:12:50 -- STEP: 326/406 -- GLOBAL_STEP: 10875\u001b[0m\n",
      "     | > loss: 0.8466463685035706  (0.8966680693845808)\n",
      "     | > log_mle: 0.13230961561203003  (0.14901222809692102)\n",
      "     | > loss_dur: 0.7143367528915405  (0.7476558412876595)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.6136, device='cuda:0')  (tensor(1.7943, device='cuda:0'))\n",
      "     | > current_lr: 2.4999999999999998e-06 \n",
      "     | > step_time: 0.5606  (0.6505103242909249)\n",
      "     | > loader_time: 0.0171  (0.012905935568312191)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:13:10 -- STEP: 351/406 -- GLOBAL_STEP: 10900\u001b[0m\n",
      "     | > loss: 0.876837432384491  (0.8956179359020331)\n",
      "     | > log_mle: 0.13501602411270142  (0.14738671392457095)\n",
      "     | > loss_dur: 0.7418214082717896  (0.7482312219774618)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.5036, device='cuda:0')  (tensor(1.7989, device='cuda:0'))\n",
      "     | > current_lr: 2.4999999999999998e-06 \n",
      "     | > step_time: 0.9772  (0.6589564027270023)\n",
      "     | > loader_time: 0.0335  (0.012988305159783428)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:13:31 -- STEP: 376/406 -- GLOBAL_STEP: 10925\u001b[0m\n",
      "     | > loss: 0.8718127012252808  (0.8936673396445335)\n",
      "     | > log_mle: 0.12504100799560547  (0.14570656196868167)\n",
      "     | > loss_dur: 0.7467716932296753  (0.7479607776758516)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.7025, device='cuda:0')  (tensor(1.7963, device='cuda:0'))\n",
      "     | > current_lr: 2.4999999999999998e-06 \n",
      "     | > step_time: 0.8173  (0.6706663820337743)\n",
      "     | > loader_time: 0.0238  (0.013142184374180244)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:13:50 -- STEP: 401/406 -- GLOBAL_STEP: 10950\u001b[0m\n",
      "     | > loss: 0.8505430221557617  (0.891683667526578)\n",
      "     | > log_mle: 0.11769223213195801  (0.1441921130974691)\n",
      "     | > loss_dur: 0.7328507900238037  (0.7474915544291086)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(2.0830, device='cuda:0')  (tensor(1.7981, device='cuda:0'))\n",
      "     | > current_lr: 2.4999999999999998e-06 \n",
      "     | > step_time: 0.5787  (0.675302839635911)\n",
      "     | > loader_time: 0.0061  (0.013142440087182858)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: 0.8370707035064697  (0.8370707035064697)\n",
      "     | > log_mle: 0.14873754978179932  (0.14873754978179932)\n",
      "     | > loss_dur: 0.6883331537246704  (0.6883331537246704)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: 0.7949338555335999  (0.7949338555335999)\n",
      "     | > log_mle: 0.12813270092010498  (0.12813270092010498)\n",
      "     | > loss_dur: 0.6668011546134949  (0.6668011546134949)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: 0.8541955947875977  (0.8245647251605988)\n",
      "     | > log_mle: 0.16802608966827393  (0.14807939529418945)\n",
      "     | > loss_dur: 0.6861695051193237  (0.6764853298664093)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: 0.8346050977706909  (0.8279115160306295)\n",
      "     | > log_mle: 0.13948333263397217  (0.14521404107411703)\n",
      "     | > loss_dur: 0.6951217651367188  (0.6826974749565125)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: 0.8466646075248718  (0.8325997889041901)\n",
      "     | > log_mle: 0.11281973123550415  (0.1371154636144638)\n",
      "     | > loss_dur: 0.7338448762893677  (0.6954843252897263)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: 0.842022180557251  (0.8344842672348023)\n",
      "     | > log_mle: 0.10862940549850464  (0.13141825199127197)\n",
      "     | > loss_dur: 0.7333927750587463  (0.7030660152435303)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: 0.8865787982940674  (0.8431666890780131)\n",
      "     | > log_mle: 0.09614008665084839  (0.12553855776786804)\n",
      "     | > loss_dur: 0.790438711643219  (0.717628131310145)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: 0.8343192338943481  (0.8419027669089181)\n",
      "     | > log_mle: 0.14157068729400635  (0.1278288619858878)\n",
      "     | > loss_dur: 0.6927485466003418  (0.7140739049230304)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: 0.8097443580627441  (0.8378829658031464)\n",
      "     | > log_mle: 0.13007324934005737  (0.128109410405159)\n",
      "     | > loss_dur: 0.6796711087226868  (0.7097735553979874)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: 0.8842713832855225  (0.8430372344122993)\n",
      "     | > log_mle: 0.12690013647079468  (0.12797504663467407)\n",
      "     | > loss_dur: 0.7573712468147278  (0.7150621877776252)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: 0.8295244574546814  (0.8416859567165375)\n",
      "     | > log_mle: 0.13214033842086792  (0.12839157581329347)\n",
      "     | > loss_dur: 0.6973841190338135  (0.713294380903244)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: 0.8150331974029541  (0.8392629785971208)\n",
      "     | > log_mle: 0.11775809526443481  (0.12742489576339722)\n",
      "     | > loss_dur: 0.6972751021385193  (0.7118380828337236)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: 0.8229767680168152  (0.8379057943820953)\n",
      "     | > log_mle: 0.13173198699951172  (0.12778382003307343)\n",
      "     | > loss_dur: 0.6912447810173035  (0.7101219743490219)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: 0.8663156628608704  (0.8400911688804626)\n",
      "     | > log_mle: 0.1147271990776062  (0.12677946457496056)\n",
      "     | > loss_dur: 0.7515884637832642  (0.7133117043055021)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: 0.8423876762390137  (0.8402552051203591)\n",
      "     | > log_mle: 0.12339842319488525  (0.12653796161924089)\n",
      "     | > loss_dur: 0.7189892530441284  (0.7137172435011182)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: 0.8402817249298096  (0.8402569731076558)\n",
      "     | > log_mle: 0.12573224306106567  (0.12648424704869587)\n",
      "     | > loss_dur: 0.7145494818687439  (0.7137727260589599)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: 0.8385897874832153  (0.8401527740061283)\n",
      "     | > log_mle: 0.13034284114837646  (0.12672540917992592)\n",
      "     | > loss_dur: 0.7082469463348389  (0.7134273648262024)\n",
      "\n",
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.0036416053771972656 \u001b[0m(-0.004755303263664246)\n",
      "     | > avg_loss:\u001b[92m 0.8401527740061283 \u001b[0m(-0.06384681165218353)\n",
      "     | > avg_log_mle:\u001b[92m 0.12672540917992592 \u001b[0m(-0.02533288672566414)\n",
      "     | > avg_loss_dur:\u001b[92m 0.7134273648262024 \u001b[0m(-0.038513924926519394)\n",
      "\n",
      " > BEST MODEL : train/run-February-22-2025_02+19AM-9b6e3e6/best_model_10955.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 11/40\u001b[0m\n",
      " --> train/run-February-22-2025_02+19AM-9b6e3e6\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-22 03:14:05) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:14:16 -- STEP: 20/406 -- GLOBAL_STEP: 10975\u001b[0m\n",
      "     | > loss: 0.832024872303009  (0.8703258574008942)\n",
      "     | > log_mle: 0.17556864023208618  (0.15738437175750733)\n",
      "     | > loss_dur: 0.6564562320709229  (0.7129414856433869)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.4702, device='cuda:0')  (tensor(1.7032, device='cuda:0'))\n",
      "     | > current_lr: 2.75e-06 \n",
      "     | > step_time: 0.4325  (0.41110767126083375)\n",
      "     | > loader_time: 0.0059  (0.005980432033538818)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:14:30 -- STEP: 45/406 -- GLOBAL_STEP: 11000\u001b[0m\n",
      "     | > loss: 0.8407660126686096  (0.8611234519216749)\n",
      "     | > log_mle: 0.15254318714141846  (0.15556106302473277)\n",
      "     | > loss_dur: 0.6882228255271912  (0.7055623888969421)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.4783, device='cuda:0')  (tensor(1.6451, device='cuda:0'))\n",
      "     | > current_lr: 2.75e-06 \n",
      "     | > step_time: 0.6353  (0.4945274458991157)\n",
      "     | > loader_time: 0.004  (0.008711666531032987)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:14:44 -- STEP: 70/406 -- GLOBAL_STEP: 11025\u001b[0m\n",
      "     | > loss: 0.81913822889328  (0.8575465057577406)\n",
      "     | > log_mle: 0.13267165422439575  (0.1510357158524649)\n",
      "     | > loss_dur: 0.6864665746688843  (0.7065107899052758)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.5852, device='cuda:0')  (tensor(1.7132, device='cuda:0'))\n",
      "     | > current_lr: 2.75e-06 \n",
      "     | > step_time: 0.8147  (0.5168776580265588)\n",
      "     | > loader_time: 0.0053  (0.010018553052629744)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:15:00 -- STEP: 95/406 -- GLOBAL_STEP: 11050\u001b[0m\n",
      "     | > loss: 0.8214819431304932  (0.8527882005039015)\n",
      "     | > log_mle: 0.13758808374404907  (0.14671771338111475)\n",
      "     | > loss_dur: 0.6838938593864441  (0.706070487122787)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.8238, device='cuda:0')  (tensor(1.7211, device='cuda:0'))\n",
      "     | > current_lr: 2.75e-06 \n",
      "     | > step_time: 0.4925  (0.5381490581913996)\n",
      "     | > loader_time: 0.0044  (0.010624787681981135)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:15:15 -- STEP: 120/406 -- GLOBAL_STEP: 11075\u001b[0m\n",
      "     | > loss: 0.8421723246574402  (0.8490284830331802)\n",
      "     | > log_mle: 0.1280733346939087  (0.1430425932010015)\n",
      "     | > loss_dur: 0.7140989899635315  (0.705985889832179)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.6121, device='cuda:0')  (tensor(1.7033, device='cuda:0'))\n",
      "     | > current_lr: 2.75e-06 \n",
      "     | > step_time: 0.6838  (0.5544479946295421)\n",
      "     | > loader_time: 0.0054  (0.011144719521204629)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:15:32 -- STEP: 145/406 -- GLOBAL_STEP: 11100\u001b[0m\n",
      "     | > loss: 0.828456699848175  (0.8465262680218137)\n",
      "     | > log_mle: 0.139756441116333  (0.13978617684594516)\n",
      "     | > loss_dur: 0.688700258731842  (0.7067400911758688)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.5081, device='cuda:0')  (tensor(1.6991, device='cuda:0'))\n",
      "     | > current_lr: 2.75e-06 \n",
      "     | > step_time: 0.8145  (0.572048151082006)\n",
      "     | > loader_time: 0.0051  (0.011095060151198814)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:15:49 -- STEP: 170/406 -- GLOBAL_STEP: 11125\u001b[0m\n",
      "     | > loss: 0.81831955909729  (0.8445955847992617)\n",
      "     | > log_mle: 0.12082803249359131  (0.13723133311552166)\n",
      "     | > loss_dur: 0.6974915266036987  (0.70736425168374)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.5324, device='cuda:0')  (tensor(1.6907, device='cuda:0'))\n",
      "     | > current_lr: 2.75e-06 \n",
      "     | > step_time: 0.5687  (0.5868597914190853)\n",
      "     | > loader_time: 0.0218  (0.010785059367909154)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:16:07 -- STEP: 195/406 -- GLOBAL_STEP: 11150\u001b[0m\n",
      "     | > loss: 0.8243203163146973  (0.842581242781419)\n",
      "     | > log_mle: 0.13104331493377686  (0.1347530206044516)\n",
      "     | > loss_dur: 0.6932770013809204  (0.7078282221769675)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(2.0399, device='cuda:0')  (tensor(1.6891, device='cuda:0'))\n",
      "     | > current_lr: 2.75e-06 \n",
      "     | > step_time: 1.0236  (0.5997261426387689)\n",
      "     | > loader_time: 0.0239  (0.01136031762147561)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:16:25 -- STEP: 220/406 -- GLOBAL_STEP: 11175\u001b[0m\n",
      "     | > loss: 0.8056503534317017  (0.8398090722885999)\n",
      "     | > log_mle: 0.09641999006271362  (0.13250772898847413)\n",
      "     | > loss_dur: 0.709230363368988  (0.7073013433001258)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.8965, device='cuda:0')  (tensor(1.7107, device='cuda:0'))\n",
      "     | > current_lr: 2.75e-06 \n",
      "     | > step_time: 0.5978  (0.6097565520893443)\n",
      "     | > loader_time: 0.0142  (0.01168020096692172)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:16:43 -- STEP: 245/406 -- GLOBAL_STEP: 11200\u001b[0m\n",
      "     | > loss: 0.8310209512710571  (0.8379660341204429)\n",
      "     | > log_mle: 0.11624979972839355  (0.13037827915074884)\n",
      "     | > loss_dur: 0.7147711515426636  (0.7075877549696942)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.7059, device='cuda:0')  (tensor(1.7113, device='cuda:0'))\n",
      "     | > current_lr: 2.75e-06 \n",
      "     | > step_time: 0.6252  (0.6191739413203026)\n",
      "     | > loader_time: 0.0075  (0.011768073451762296)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:17:01 -- STEP: 270/406 -- GLOBAL_STEP: 11225\u001b[0m\n",
      "     | > loss: 0.8213451504707336  (0.8358261247475941)\n",
      "     | > log_mle: 0.1038392186164856  (0.12848027017381466)\n",
      "     | > loss_dur: 0.717505931854248  (0.7073458545737796)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.5835, device='cuda:0')  (tensor(1.7295, device='cuda:0'))\n",
      "     | > current_lr: 2.75e-06 \n",
      "     | > step_time: 0.5478  (0.6289806136378535)\n",
      "     | > loader_time: 0.019  (0.012096193984702781)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:17:20 -- STEP: 295/406 -- GLOBAL_STEP: 11250\u001b[0m\n",
      "     | > loss: 0.7985625267028809  (0.8339702022277704)\n",
      "     | > log_mle: 0.11183518171310425  (0.12670187263165494)\n",
      "     | > loss_dur: 0.6867273449897766  (0.7072683295961154)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.3788, device='cuda:0')  (tensor(1.7430, device='cuda:0'))\n",
      "     | > current_lr: 2.75e-06 \n",
      "     | > step_time: 0.5711  (0.6364088236275368)\n",
      "     | > loader_time: 0.0073  (0.012368154525756835)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:17:40 -- STEP: 320/406 -- GLOBAL_STEP: 11275\u001b[0m\n",
      "     | > loss: 0.7971875071525574  (0.8320332311093811)\n",
      "     | > log_mle: 0.11291611194610596  (0.1250734820961953)\n",
      "     | > loss_dur: 0.6842713952064514  (0.7069597490131854)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.3400, device='cuda:0')  (tensor(1.7352, device='cuda:0'))\n",
      "     | > current_lr: 2.75e-06 \n",
      "     | > step_time: 0.6022  (0.6471253573894502)\n",
      "     | > loader_time: 0.0194  (0.012600499391555785)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:18:01 -- STEP: 345/406 -- GLOBAL_STEP: 11300\u001b[0m\n",
      "     | > loss: 0.8056168556213379  (0.8305577585662623)\n",
      "     | > log_mle: 0.0981188416481018  (0.12340640399767011)\n",
      "     | > loss_dur: 0.7074980139732361  (0.7071513545685918)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.4906, device='cuda:0')  (tensor(1.7268, device='cuda:0'))\n",
      "     | > current_lr: 2.75e-06 \n",
      "     | > step_time: 0.6336  (0.6604313802028052)\n",
      "     | > loader_time: 0.016  (0.012561326787091683)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:18:21 -- STEP: 370/406 -- GLOBAL_STEP: 11325\u001b[0m\n",
      "     | > loss: 0.7767356038093567  (0.8286160547991059)\n",
      "     | > log_mle: 0.07919096946716309  (0.1217118242302457)\n",
      "     | > loss_dur: 0.6975446343421936  (0.7069042305688599)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.8399, device='cuda:0')  (tensor(1.7245, device='cuda:0'))\n",
      "     | > current_lr: 2.75e-06 \n",
      "     | > step_time: 0.6348  (0.6691731736466693)\n",
      "     | > loader_time: 0.0364  (0.013078009115683065)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:18:41 -- STEP: 395/406 -- GLOBAL_STEP: 11350\u001b[0m\n",
      "     | > loss: 0.7855163812637329  (0.8265574921535543)\n",
      "     | > log_mle: 0.09103924036026001  (0.12020812079876289)\n",
      "     | > loss_dur: 0.6944771409034729  (0.706349371354791)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.4991, device='cuda:0')  (tensor(1.7203, device='cuda:0'))\n",
      "     | > current_lr: 2.75e-06 \n",
      "     | > step_time: 0.5748  (0.6764970604377459)\n",
      "     | > loader_time: 0.0075  (0.013524774961833713)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: 0.7773341536521912  (0.7773341536521912)\n",
      "     | > log_mle: 0.12516379356384277  (0.12516379356384277)\n",
      "     | > loss_dur: 0.6521703600883484  (0.6521703600883484)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: 0.7242133021354675  (0.7242133021354675)\n",
      "     | > log_mle: 0.10302066802978516  (0.10302066802978516)\n",
      "     | > loss_dur: 0.6211926341056824  (0.6211926341056824)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: 0.7879360318183899  (0.7560746669769287)\n",
      "     | > log_mle: 0.14274758100509644  (0.1228841245174408)\n",
      "     | > loss_dur: 0.6451884508132935  (0.6331905424594879)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: 0.7642304301261902  (0.7587932546933492)\n",
      "     | > log_mle: 0.11585283279418945  (0.12054036060969035)\n",
      "     | > loss_dur: 0.6483775973320007  (0.6382528940836588)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: 0.7826690077781677  (0.7647621929645538)\n",
      "     | > log_mle: 0.08886092901229858  (0.11262050271034241)\n",
      "     | > loss_dur: 0.6938080787658691  (0.6521416902542114)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: 0.7678086757659912  (0.7653714895248414)\n",
      "     | > log_mle: 0.0850222110748291  (0.10710084438323975)\n",
      "     | > loss_dur: 0.6827864646911621  (0.6582706451416016)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: 0.8250344395637512  (0.7753153145313263)\n",
      "     | > log_mle: 0.0730506181716919  (0.10142580668131511)\n",
      "     | > loss_dur: 0.7519838213920593  (0.6738895078500112)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: 0.7836679220199585  (0.7765085441725594)\n",
      "     | > log_mle: 0.11658734083175659  (0.10359174013137817)\n",
      "     | > loss_dur: 0.6670805811882019  (0.6729168040411813)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: 0.7604748010635376  (0.7745043262839317)\n",
      "     | > log_mle: 0.10582476854324341  (0.10387086868286133)\n",
      "     | > loss_dur: 0.6546500325202942  (0.6706334576010704)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: 0.8147908449172974  (0.7789806061320834)\n",
      "     | > log_mle: 0.1022002100944519  (0.10368523995081584)\n",
      "     | > loss_dur: 0.7125906348228455  (0.6752953661812676)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: 0.774003267288208  (0.778482872247696)\n",
      "     | > log_mle: 0.10766667127609253  (0.1040833830833435)\n",
      "     | > loss_dur: 0.6663365960121155  (0.6743994891643524)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: 0.747615396976471  (0.77567673813213)\n",
      "     | > log_mle: 0.09332716464996338  (0.10310554504394531)\n",
      "     | > loss_dur: 0.6542882323265076  (0.6725711930881847)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: 0.7716084122657776  (0.7753377109766006)\n",
      "     | > log_mle: 0.10680800676345825  (0.1034140835205714)\n",
      "     | > loss_dur: 0.6648004055023193  (0.6719236274560293)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: 0.7875169515609741  (0.776274575636937)\n",
      "     | > log_mle: 0.09009140729904175  (0.10238926227276142)\n",
      "     | > loss_dur: 0.6974255442619324  (0.6738853133641757)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: 0.7767652273178101  (0.7763096221855709)\n",
      "     | > log_mle: 0.0984376072883606  (0.10210700120244708)\n",
      "     | > loss_dur: 0.6783276200294495  (0.6742026209831238)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: 0.7721492052078247  (0.7760322610537211)\n",
      "     | > log_mle: 0.10113728046417236  (0.10204235315322877)\n",
      "     | > loss_dur: 0.6710119247436523  (0.6739899079004924)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: 0.7745313048362732  (0.7759384512901306)\n",
      "     | > log_mle: 0.10589313507080078  (0.10228302702307701)\n",
      "     | > loss_dur: 0.6686381697654724  (0.6736554242670536)\n",
      "\n",
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[91m 0.003820255398750305 \u001b[0m(+0.00017865002155303955)\n",
      "     | > avg_loss:\u001b[92m 0.7759384512901306 \u001b[0m(-0.0642143227159977)\n",
      "     | > avg_log_mle:\u001b[92m 0.10228302702307701 \u001b[0m(-0.024442382156848907)\n",
      "     | > avg_loss_dur:\u001b[92m 0.6736554242670536 \u001b[0m(-0.03977194055914879)\n",
      "\n",
      " > BEST MODEL : train/run-February-22-2025_02+19AM-9b6e3e6/best_model_11361.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 12/40\u001b[0m\n",
      " --> train/run-February-22-2025_02+19AM-9b6e3e6\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-22 03:19:01) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:19:08 -- STEP: 14/406 -- GLOBAL_STEP: 11375\u001b[0m\n",
      "     | > loss: 0.7891893982887268  (0.8121236775602613)\n",
      "     | > log_mle: 0.11480337381362915  (0.1324602408068521)\n",
      "     | > loss_dur: 0.6743860244750977  (0.6796634367534092)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.8696, device='cuda:0')  (tensor(1.5506, device='cuda:0'))\n",
      "     | > current_lr: 3e-06 \n",
      "     | > step_time: 0.7583  (0.39332664012908936)\n",
      "     | > loader_time: 0.0041  (0.0062563419342041016)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:19:22 -- STEP: 39/406 -- GLOBAL_STEP: 11400\u001b[0m\n",
      "     | > loss: 0.8113996386528015  (0.8010950241333399)\n",
      "     | > log_mle: 0.12920427322387695  (0.13097506914383328)\n",
      "     | > loss_dur: 0.6821953654289246  (0.6701199549895067)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.5056, device='cuda:0')  (tensor(1.5641, device='cuda:0'))\n",
      "     | > current_lr: 3e-06 \n",
      "     | > step_time: 0.2837  (0.4850832926921355)\n",
      "     | > loader_time: 0.0238  (0.008050802426460465)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:19:37 -- STEP: 64/406 -- GLOBAL_STEP: 11425\u001b[0m\n",
      "     | > loss: 0.7586213946342468  (0.794597483240068)\n",
      "     | > log_mle: 0.11933386325836182  (0.12733375001698732)\n",
      "     | > loss_dur: 0.639287531375885  (0.6672637332230807)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.7894, device='cuda:0')  (tensor(1.6306, device='cuda:0'))\n",
      "     | > current_lr: 3e-06 \n",
      "     | > step_time: 0.4779  (0.5251910649240018)\n",
      "     | > loader_time: 0.0055  (0.009040940552949909)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:19:52 -- STEP: 89/406 -- GLOBAL_STEP: 11450\u001b[0m\n",
      "     | > loss: 0.7914619445800781  (0.7900638037853027)\n",
      "     | > log_mle: 0.11295509338378906  (0.1232607230711519)\n",
      "     | > loss_dur: 0.6785068511962891  (0.6668030807141511)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.6606, device='cuda:0')  (tensor(1.6077, device='cuda:0'))\n",
      "     | > current_lr: 3e-06 \n",
      "     | > step_time: 0.4445  (0.5384897542803476)\n",
      "     | > loader_time: 0.0054  (0.009304418992460445)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:20:08 -- STEP: 114/406 -- GLOBAL_STEP: 11475\u001b[0m\n",
      "     | > loss: 0.7773200869560242  (0.7842519712029842)\n",
      "     | > log_mle: 0.08036297559738159  (0.11898522941689742)\n",
      "     | > loss_dur: 0.6969571113586426  (0.665266741786087)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.8459, device='cuda:0')  (tensor(1.6172, device='cuda:0'))\n",
      "     | > current_lr: 3e-06 \n",
      "     | > step_time: 0.3301  (0.5602015528762547)\n",
      "     | > loader_time: 0.0051  (0.009328434341832214)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:20:24 -- STEP: 139/406 -- GLOBAL_STEP: 11500\u001b[0m\n",
      "     | > loss: 0.7726681232452393  (0.7819482169562965)\n",
      "     | > log_mle: 0.0984048843383789  (0.11576180921184073)\n",
      "     | > loss_dur: 0.6742632389068604  (0.6661864077444559)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.5932, device='cuda:0')  (tensor(1.5982, device='cuda:0'))\n",
      "     | > current_lr: 3e-06 \n",
      "     | > step_time: 0.4605  (0.5709444155795966)\n",
      "     | > loader_time: 0.005  (0.009842918931151468)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:20:40 -- STEP: 164/406 -- GLOBAL_STEP: 11525\u001b[0m\n",
      "     | > loss: 0.7923397421836853  (0.7793162443288943)\n",
      "     | > log_mle: 0.10927152633666992  (0.11307815843965949)\n",
      "     | > loss_dur: 0.6830682158470154  (0.6662380858892348)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.3469, device='cuda:0')  (tensor(1.6276, device='cuda:0'))\n",
      "     | > current_lr: 3e-06 \n",
      "     | > step_time: 0.4252  (0.5764297334159293)\n",
      "     | > loader_time: 0.0051  (0.010339241202284653)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:20:57 -- STEP: 189/406 -- GLOBAL_STEP: 11550\u001b[0m\n",
      "     | > loss: 0.7571796774864197  (0.7768935949083359)\n",
      "     | > log_mle: 0.08750015497207642  (0.11048470760779407)\n",
      "     | > loss_dur: 0.6696795225143433  (0.6664088873005418)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.7460, device='cuda:0')  (tensor(1.6594, device='cuda:0'))\n",
      "     | > current_lr: 3e-06 \n",
      "     | > step_time: 0.637  (0.5873554888225735)\n",
      "     | > loader_time: 0.0157  (0.010689181625527684)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:21:14 -- STEP: 214/406 -- GLOBAL_STEP: 11575\u001b[0m\n",
      "     | > loss: 0.7532162666320801  (0.7744650715422408)\n",
      "     | > log_mle: 0.0885387659072876  (0.10832881565405944)\n",
      "     | > loss_dur: 0.6646775007247925  (0.6661362558881813)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.6582, device='cuda:0')  (tensor(1.7489, device='cuda:0'))\n",
      "     | > current_lr: 3e-06 \n",
      "     | > step_time: 0.689  (0.598966325554892)\n",
      "     | > loader_time: 0.005  (0.010810887702157568)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:21:33 -- STEP: 239/406 -- GLOBAL_STEP: 11600\u001b[0m\n",
      "     | > loss: 0.7626655101776123  (0.7723639108645866)\n",
      "     | > log_mle: 0.08630359172821045  (0.10618890005175538)\n",
      "     | > loss_dur: 0.6763619184494019  (0.6661750108128313)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.3892, device='cuda:0')  (tensor(1.7985, device='cuda:0'))\n",
      "     | > current_lr: 3e-06 \n",
      "     | > step_time: 0.8959  (0.6133268966834413)\n",
      "     | > loader_time: 0.0446  (0.010896119113746551)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:21:50 -- STEP: 264/406 -- GLOBAL_STEP: 11625\u001b[0m\n",
      "     | > loss: 0.742237389087677  (0.7701128258398084)\n",
      "     | > log_mle: 0.0876426100730896  (0.10424035381187093)\n",
      "     | > loss_dur: 0.6545947790145874  (0.6658724720279375)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.4844, device='cuda:0')  (tensor(1.8032, device='cuda:0'))\n",
      "     | > current_lr: 3e-06 \n",
      "     | > step_time: 0.5945  (0.6192719891215813)\n",
      "     | > loader_time: 0.0058  (0.01085540020104611)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:22:09 -- STEP: 289/406 -- GLOBAL_STEP: 11650\u001b[0m\n",
      "     | > loss: 0.7394795417785645  (0.768035124536204)\n",
      "     | > log_mle: 0.09303826093673706  (0.102402485778175)\n",
      "     | > loss_dur: 0.6464412808418274  (0.665632638758029)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.7528, device='cuda:0')  (tensor(1.8003, device='cuda:0'))\n",
      "     | > current_lr: 3e-06 \n",
      "     | > step_time: 0.8701  (0.6299378954415503)\n",
      "     | > loader_time: 0.0257  (0.011303824949429529)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:22:28 -- STEP: 314/406 -- GLOBAL_STEP: 11675\u001b[0m\n",
      "     | > loss: 0.7288073301315308  (0.7662525983752717)\n",
      "     | > log_mle: 0.07109189033508301  (0.10072140708850447)\n",
      "     | > loss_dur: 0.6577154397964478  (0.6655311912867674)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.7775, device='cuda:0')  (tensor(1.8113, device='cuda:0'))\n",
      "     | > current_lr: 3e-06 \n",
      "     | > step_time: 0.8311  (0.6392898346967755)\n",
      "     | > loader_time: 0.0151  (0.011571407318115234)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:22:49 -- STEP: 339/406 -- GLOBAL_STEP: 11700\u001b[0m\n",
      "     | > loss: 0.7306990027427673  (0.7646452376624473)\n",
      "     | > log_mle: 0.07551342248916626  (0.09912521631668451)\n",
      "     | > loss_dur: 0.6551855802536011  (0.6655200213457629)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.3927, device='cuda:0')  (tensor(1.7962, device='cuda:0'))\n",
      "     | > current_lr: 3e-06 \n",
      "     | > step_time: 0.9109  (0.6502975721274853)\n",
      "     | > loader_time: 0.016  (0.011812892986961525)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:23:09 -- STEP: 364/406 -- GLOBAL_STEP: 11725\u001b[0m\n",
      "     | > loss: 0.7308448553085327  (0.7629884779453274)\n",
      "     | > log_mle: 0.08026093244552612  (0.09745340098391522)\n",
      "     | > loss_dur: 0.6505839228630066  (0.6655350769614126)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.2752, device='cuda:0')  (tensor(1.7822, device='cuda:0'))\n",
      "     | > current_lr: 3e-06 \n",
      "     | > step_time: 0.6908  (0.6590061940989649)\n",
      "     | > loader_time: 0.0105  (0.011904798366211276)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:23:29 -- STEP: 389/406 -- GLOBAL_STEP: 11750\u001b[0m\n",
      "     | > loss: 0.7325031757354736  (0.7609552452987138)\n",
      "     | > log_mle: 0.07458990812301636  (0.09595418512667972)\n",
      "     | > loss_dur: 0.6579132676124573  (0.6650010601720343)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.5847, device='cuda:0')  (tensor(1.7656, device='cuda:0'))\n",
      "     | > current_lr: 3e-06 \n",
      "     | > step_time: 0.5385  (0.6678737294704562)\n",
      "     | > loader_time: 0.0104  (0.01199103627535862)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: 0.7156827449798584  (0.7156827449798584)\n",
      "     | > log_mle: 0.10136473178863525  (0.10136473178863525)\n",
      "     | > loss_dur: 0.6143180131912231  (0.6143180131912231)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: 0.6723400950431824  (0.6723400950431824)\n",
      "     | > log_mle: 0.07793807983398438  (0.07793807983398438)\n",
      "     | > loss_dur: 0.594402015209198  (0.594402015209198)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: 0.7388288974761963  (0.7055844962596893)\n",
      "     | > log_mle: 0.11710464954376221  (0.09752136468887329)\n",
      "     | > loss_dur: 0.6217242479324341  (0.608063131570816)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: 0.7202391028404236  (0.7104693651199341)\n",
      "     | > log_mle: 0.09119951725006104  (0.09541408220926921)\n",
      "     | > loss_dur: 0.6290395855903625  (0.6150552829106649)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: 0.721912682056427  (0.7133301943540573)\n",
      "     | > log_mle: 0.06437110900878906  (0.08765333890914917)\n",
      "     | > loss_dur: 0.6575415730476379  (0.6256768554449081)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: 0.695133626461029  (0.7096908807754516)\n",
      "     | > log_mle: 0.059036970138549805  (0.08193006515502929)\n",
      "     | > loss_dur: 0.6360966563224792  (0.6277608156204224)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: 0.7398990392684937  (0.7147255738576254)\n",
      "     | > log_mle: 0.048151254653930664  (0.07630026340484619)\n",
      "     | > loss_dur: 0.691747784614563  (0.6384253104527792)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: 0.7324046492576599  (0.7172511560576302)\n",
      "     | > log_mle: 0.09076476097106934  (0.07836662020002093)\n",
      "     | > loss_dur: 0.6416398882865906  (0.6388845358576093)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: 0.6906493902206421  (0.7139259353280067)\n",
      "     | > log_mle: 0.08099585771560669  (0.07869527488946915)\n",
      "     | > loss_dur: 0.6096535325050354  (0.6352306604385376)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: 0.7438316941261292  (0.717248797416687)\n",
      "     | > log_mle: 0.07647621631622314  (0.07844871282577515)\n",
      "     | > loss_dur: 0.667355477809906  (0.6388000845909119)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: 0.7182782888412476  (0.717351746559143)\n",
      "     | > log_mle: 0.08253884315490723  (0.07885772585868836)\n",
      "     | > loss_dur: 0.6357394456863403  (0.6384940207004547)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: 0.6837397813796997  (0.7142961133610118)\n",
      "     | > log_mle: 0.06816339492797852  (0.07788551395589655)\n",
      "     | > loss_dur: 0.6155763864517212  (0.6364105994051154)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: 0.7189318537712097  (0.7146824250618616)\n",
      "     | > log_mle: 0.08110016584396362  (0.07815340161323547)\n",
      "     | > loss_dur: 0.6378316879272461  (0.6365290234486263)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: 0.7283741235733032  (0.7157356326396649)\n",
      "     | > log_mle: 0.06414908170700073  (0.0770761462358328)\n",
      "     | > loss_dur: 0.6642250418663025  (0.6386594864038321)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: 0.7247990965843201  (0.716383022921426)\n",
      "     | > log_mle: 0.07274138927459717  (0.07676652073860168)\n",
      "     | > loss_dur: 0.6520577073097229  (0.6396165021828243)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: 0.7270448803901672  (0.7170938134193421)\n",
      "     | > log_mle: 0.07555925846099854  (0.07668603658676147)\n",
      "     | > loss_dur: 0.6514856219291687  (0.6404077768325805)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: 0.7068911790847778  (0.7164561487734318)\n",
      "     | > log_mle: 0.07996034622192383  (0.07689068093895912)\n",
      "     | > loss_dur: 0.626930832862854  (0.6395654678344727)\n",
      "\n",
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[91m 0.008781224489212036 \u001b[0m(+0.004960969090461731)\n",
      "     | > avg_loss:\u001b[92m 0.7164561487734318 \u001b[0m(-0.05948230251669884)\n",
      "     | > avg_log_mle:\u001b[92m 0.07689068093895912 \u001b[0m(-0.02539234608411789)\n",
      "     | > avg_loss_dur:\u001b[92m 0.6395654678344727 \u001b[0m(-0.03408995643258095)\n",
      "\n",
      " > BEST MODEL : train/run-February-22-2025_02+19AM-9b6e3e6/best_model_11767.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 13/40\u001b[0m\n",
      " --> train/run-February-22-2025_02+19AM-9b6e3e6\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-22 03:23:52) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:23:58 -- STEP: 8/406 -- GLOBAL_STEP: 11775\u001b[0m\n",
      "     | > loss: 0.7571706771850586  (0.7545569613575935)\n",
      "     | > log_mle: 0.10562652349472046  (0.112691730260849)\n",
      "     | > loss_dur: 0.6515441536903381  (0.6418652310967445)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.3475, device='cuda:0')  (tensor(1.4578, device='cuda:0'))\n",
      "     | > current_lr: 3.25e-06 \n",
      "     | > step_time: 0.2762  (0.3594105541706085)\n",
      "     | > loader_time: 0.0047  (0.009312629699707031)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:24:11 -- STEP: 33/406 -- GLOBAL_STEP: 11800\u001b[0m\n",
      "     | > loss: 0.7580585479736328  (0.736882457227418)\n",
      "     | > log_mle: 0.10328197479248047  (0.10680476824442546)\n",
      "     | > loss_dur: 0.6547765731811523  (0.6300776889829924)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.3757, device='cuda:0')  (tensor(1.3890, device='cuda:0'))\n",
      "     | > current_lr: 3.25e-06 \n",
      "     | > step_time: 0.7315  (0.4732231082338275)\n",
      "     | > loader_time: 0.0046  (0.007869380893129295)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:24:24 -- STEP: 58/406 -- GLOBAL_STEP: 11825\u001b[0m\n",
      "     | > loss: 0.7647093534469604  (0.7315361006506558)\n",
      "     | > log_mle: 0.09563326835632324  (0.1036746450539293)\n",
      "     | > loss_dur: 0.6690760850906372  (0.6278614555967266)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.4641, device='cuda:0')  (tensor(1.4829, device='cuda:0'))\n",
      "     | > current_lr: 3.25e-06 \n",
      "     | > step_time: 0.2679  (0.5005431134125282)\n",
      "     | > loader_time: 0.0041  (0.009112658171818173)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:24:39 -- STEP: 83/406 -- GLOBAL_STEP: 11850\u001b[0m\n",
      "     | > loss: 0.7071940898895264  (0.7270203383572132)\n",
      "     | > log_mle: 0.08510762453079224  (0.09986800170806517)\n",
      "     | > loss_dur: 0.6220864653587341  (0.6271523366491479)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.3525, device='cuda:0')  (tensor(1.5330, device='cuda:0'))\n",
      "     | > current_lr: 3.25e-06 \n",
      "     | > step_time: 0.4262  (0.5253659443682935)\n",
      "     | > loader_time: 0.0048  (0.008996219520109244)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:24:55 -- STEP: 108/406 -- GLOBAL_STEP: 11875\u001b[0m\n",
      "     | > loss: 0.6937934160232544  (0.721506417349533)\n",
      "     | > log_mle: 0.0863986611366272  (0.09605323882014663)\n",
      "     | > loss_dur: 0.6073947548866272  (0.6254531785293862)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.1732, device='cuda:0')  (tensor(1.5941, device='cuda:0'))\n",
      "     | > current_lr: 3.25e-06 \n",
      "     | > step_time: 0.5019  (0.5460033637505992)\n",
      "     | > loader_time: 0.0064  (0.009777000656834352)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:25:12 -- STEP: 133/406 -- GLOBAL_STEP: 11900\u001b[0m\n",
      "     | > loss: 0.7014217972755432  (0.7184914632847437)\n",
      "     | > log_mle: 0.07458782196044922  (0.0923061720410684)\n",
      "     | > loss_dur: 0.626833975315094  (0.6261852912436751)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.3824, device='cuda:0')  (tensor(1.6680, device='cuda:0'))\n",
      "     | > current_lr: 3.25e-06 \n",
      "     | > step_time: 0.8649  (0.5670666569157653)\n",
      "     | > loader_time: 0.0046  (0.010240760960973292)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:25:28 -- STEP: 158/406 -- GLOBAL_STEP: 11925\u001b[0m\n",
      "     | > loss: 0.7156909108161926  (0.7162513291533992)\n",
      "     | > log_mle: 0.06779760122299194  (0.08962276917469654)\n",
      "     | > loss_dur: 0.6478933095932007  (0.6266285599787025)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(2.1360, device='cuda:0')  (tensor(1.7000, device='cuda:0'))\n",
      "     | > current_lr: 3.25e-06 \n",
      "     | > step_time: 0.5381  (0.5760737219943278)\n",
      "     | > loader_time: 0.0049  (0.010364598865750467)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:25:45 -- STEP: 183/406 -- GLOBAL_STEP: 11950\u001b[0m\n",
      "     | > loss: 0.6708167195320129  (0.714122208415485)\n",
      "     | > log_mle: 0.06798321008682251  (0.08718947536958373)\n",
      "     | > loss_dur: 0.6028335094451904  (0.626932733045901)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.8461, device='cuda:0')  (tensor(1.6808, device='cuda:0'))\n",
      "     | > current_lr: 3.25e-06 \n",
      "     | > step_time: 0.7493  (0.5886481498759956)\n",
      "     | > loader_time: 0.0172  (0.01057111891241021)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:26:02 -- STEP: 208/406 -- GLOBAL_STEP: 11975\u001b[0m\n",
      "     | > loss: 0.6711376309394836  (0.7119426274528872)\n",
      "     | > log_mle: 0.058420658111572266  (0.08493326948239253)\n",
      "     | > loss_dur: 0.6127169728279114  (0.6270093579704942)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(2.7586, device='cuda:0')  (tensor(1.7127, device='cuda:0'))\n",
      "     | > current_lr: 3.25e-06 \n",
      "     | > step_time: 0.7843  (0.5992252035782891)\n",
      "     | > loader_time: 0.0062  (0.01099644715969379)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:26:21 -- STEP: 233/406 -- GLOBAL_STEP: 12000\u001b[0m\n",
      "     | > loss: 0.7117541432380676  (0.7096516044866374)\n",
      "     | > log_mle: 0.060473859310150146  (0.08267188123367375)\n",
      "     | > loss_dur: 0.6512802839279175  (0.6269797232529634)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.4167, device='cuda:0')  (tensor(1.7485, device='cuda:0'))\n",
      "     | > current_lr: 3.25e-06 \n",
      "     | > step_time: 0.6798  (0.6108752852345746)\n",
      "     | > loader_time: 0.0074  (0.011427801566062566)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:26:38 -- STEP: 258/406 -- GLOBAL_STEP: 12025\u001b[0m\n",
      "     | > loss: 0.7074096202850342  (0.707851483840351)\n",
      "     | > log_mle: 0.0733637809753418  (0.08070548976114554)\n",
      "     | > loss_dur: 0.6340458393096924  (0.6271459940792052)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.7955, device='cuda:0')  (tensor(1.7804, device='cuda:0'))\n",
      "     | > current_lr: 3.25e-06 \n",
      "     | > step_time: 0.6465  (0.6190410196319112)\n",
      "     | > loader_time: 0.0061  (0.011642880217973576)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:26:58 -- STEP: 283/406 -- GLOBAL_STEP: 12050\u001b[0m\n",
      "     | > loss: 0.6877713203430176  (0.7058307715945026)\n",
      "     | > log_mle: 0.059262871742248535  (0.07876514777699123)\n",
      "     | > loss_dur: 0.628508448600769  (0.6270656238175109)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(2.0511, device='cuda:0')  (tensor(1.8014, device='cuda:0'))\n",
      "     | > current_lr: 3.25e-06 \n",
      "     | > step_time: 0.7642  (0.6311001322715951)\n",
      "     | > loader_time: 0.0076  (0.012302818230942366)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:27:17 -- STEP: 308/406 -- GLOBAL_STEP: 12075\u001b[0m\n",
      "     | > loss: 0.6762620806694031  (0.7041669284755536)\n",
      "     | > log_mle: 0.05662083625793457  (0.07716805110504098)\n",
      "     | > loss_dur: 0.6196412444114685  (0.6269988773705116)\n",
      "     | > amp_scaler: 131072.0  (69366.02597402598)\n",
      "     | > grad_norm: tensor(1.6532, device='cuda:0')  (tensor(1.8131, device='cuda:0'))\n",
      "     | > current_lr: 3.25e-06 \n",
      "     | > step_time: 0.7209  (0.639541869813746)\n",
      "     | > loader_time: 0.0059  (0.012464968415049767)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:27:36 -- STEP: 333/406 -- GLOBAL_STEP: 12100\u001b[0m\n",
      "     | > loss: 0.6741331219673157  (0.702436304128206)\n",
      "     | > log_mle: 0.047915518283843994  (0.07562524151873652)\n",
      "     | > loss_dur: 0.6262176036834717  (0.6268110626094684)\n",
      "     | > amp_scaler: 131072.0  (73998.60660660661)\n",
      "     | > grad_norm: tensor(2.2097, device='cuda:0')  (tensor(1.7852, device='cuda:0'))\n",
      "     | > current_lr: 3.25e-06 \n",
      "     | > step_time: 0.724  (0.6476482049122948)\n",
      "     | > loader_time: 0.0201  (0.012865103758849184)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:27:56 -- STEP: 358/406 -- GLOBAL_STEP: 12125\u001b[0m\n",
      "     | > loss: 0.650984525680542  (0.7009410883128315)\n",
      "     | > log_mle: 0.03570491075515747  (0.07393550989348122)\n",
      "     | > loss_dur: 0.6152796149253845  (0.6270055784193486)\n",
      "     | > amp_scaler: 131072.0  (77984.17877094973)\n",
      "     | > grad_norm: tensor(1.3227, device='cuda:0')  (tensor(1.7729, device='cuda:0'))\n",
      "     | > current_lr: 3.25e-06 \n",
      "     | > step_time: 0.8525  (0.6565980225301992)\n",
      "     | > loader_time: 0.0276  (0.013015960847865273)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:28:17 -- STEP: 383/406 -- GLOBAL_STEP: 12150\u001b[0m\n",
      "     | > loss: 0.6771038174629211  (0.6990554987917375)\n",
      "     | > log_mle: 0.059259772300720215  (0.07243839583259958)\n",
      "     | > loss_dur: 0.6178440451622009  (0.6266171029591361)\n",
      "     | > amp_scaler: 131072.0  (81449.44125326372)\n",
      "     | > grad_norm: tensor(0.9995, device='cuda:0')  (tensor(1.7581, device='cuda:0'))\n",
      "     | > current_lr: 3.25e-06 \n",
      "     | > step_time: 0.9949  (0.6667128474531849)\n",
      "     | > loader_time: 0.0167  (0.013103021965325659)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: 0.6787985563278198  (0.6787985563278198)\n",
      "     | > log_mle: 0.07824784517288208  (0.07824784517288208)\n",
      "     | > loss_dur: 0.6005507111549377  (0.6005507111549377)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: 0.6295714378356934  (0.6295714378356934)\n",
      "     | > log_mle: 0.05291759967803955  (0.05291759967803955)\n",
      "     | > loss_dur: 0.5766538381576538  (0.5766538381576538)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: 0.6902204751968384  (0.6598959565162659)\n",
      "     | > log_mle: 0.09215551614761353  (0.07253655791282654)\n",
      "     | > loss_dur: 0.5980649590492249  (0.5873593986034393)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: 0.6469526886940002  (0.655581533908844)\n",
      "     | > log_mle: 0.06773942708969116  (0.07093751430511475)\n",
      "     | > loss_dur: 0.5792132616043091  (0.5846440196037292)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: 0.6330778002738953  (0.6499556005001068)\n",
      "     | > log_mle: 0.040372252464294434  (0.06329619884490967)\n",
      "     | > loss_dur: 0.5927055478096008  (0.5866594016551971)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: 0.6291247606277466  (0.6457894325256348)\n",
      "     | > log_mle: 0.03547024726867676  (0.057731008529663085)\n",
      "     | > loss_dur: 0.5936545133590698  (0.5880584239959716)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: 0.6780531406402588  (0.6511667172114054)\n",
      "     | > log_mle: 0.0250852108001709  (0.05229004224141439)\n",
      "     | > loss_dur: 0.6529679298400879  (0.5988766749699911)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: 0.6830665469169617  (0.6557238357407706)\n",
      "     | > log_mle: 0.06609135866165161  (0.05426165887287685)\n",
      "     | > loss_dur: 0.6169751882553101  (0.6014621768678937)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: 0.6227821111679077  (0.6516061201691628)\n",
      "     | > log_mle: 0.057503461837768555  (0.05466688424348831)\n",
      "     | > loss_dur: 0.5652786493301392  (0.5969392359256744)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: 0.691321074962616  (0.6560188929239908)\n",
      "     | > log_mle: 0.05218541622161865  (0.054391165574391685)\n",
      "     | > loss_dur: 0.6391356587409973  (0.6016277273495992)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: 0.65911865234375  (0.6563288688659668)\n",
      "     | > log_mle: 0.05850285291671753  (0.054802334308624266)\n",
      "     | > loss_dur: 0.6006157994270325  (0.6015265345573425)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: 0.6312157511711121  (0.6540458581664346)\n",
      "     | > log_mle: 0.04419523477554321  (0.053838052532889626)\n",
      "     | > loss_dur: 0.5870205163955688  (0.6002078056335449)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: 0.6530307531356812  (0.6539612660805384)\n",
      "     | > log_mle: 0.056709468364715576  (0.054077337185541786)\n",
      "     | > loss_dur: 0.5963212847709656  (0.5998839288949966)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: 0.6646113395690918  (0.6547805025027349)\n",
      "     | > log_mle: 0.03993254899978638  (0.0529892765558683)\n",
      "     | > loss_dur: 0.6246787905693054  (0.6017912259468665)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: 0.65213543176651  (0.6545915688787188)\n",
      "     | > log_mle: 0.04803466796875  (0.052635375942502706)\n",
      "     | > loss_dur: 0.60410076379776  (0.601956192936216)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: 0.6628932952880859  (0.6551450173060099)\n",
      "     | > log_mle: 0.05151247978210449  (0.052560516198476154)\n",
      "     | > loss_dur: 0.6113808155059814  (0.6025845011075338)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: 0.6456122398376465  (0.6545492187142372)\n",
      "     | > log_mle: 0.05593067407608032  (0.052771151065826416)\n",
      "     | > loss_dur: 0.5896815657615662  (0.6017780676484108)\n",
      "\n",
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.00498567521572113 \u001b[0m(-0.0037955492734909058)\n",
      "     | > avg_loss:\u001b[92m 0.6545492187142372 \u001b[0m(-0.061906930059194565)\n",
      "     | > avg_log_mle:\u001b[92m 0.052771151065826416 \u001b[0m(-0.024119529873132706)\n",
      "     | > avg_loss_dur:\u001b[92m 0.6017780676484108 \u001b[0m(-0.03778740018606186)\n",
      "\n",
      " > BEST MODEL : train/run-February-22-2025_02+19AM-9b6e3e6/best_model_12173.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 14/40\u001b[0m\n",
      " --> train/run-February-22-2025_02+19AM-9b6e3e6\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-22 03:28:45) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:28:49 -- STEP: 2/406 -- GLOBAL_STEP: 12175\u001b[0m\n",
      "     | > loss: 0.6862742304801941  (0.6757094860076904)\n",
      "     | > log_mle: 0.07853704690933228  (0.08203431963920593)\n",
      "     | > loss_dur: 0.6077371835708618  (0.5936751663684845)\n",
      "     | > amp_scaler: 131072.0  (131072.0)\n",
      "     | > grad_norm: tensor(2.2301, device='cuda:0')  (tensor(1.7955, device='cuda:0'))\n",
      "     | > current_lr: 3.5e-06 \n",
      "     | > step_time: 0.2822  (0.7285671234130859)\n",
      "     | > loader_time: 0.0035  (0.008091211318969727)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:29:01 -- STEP: 27/406 -- GLOBAL_STEP: 12200\u001b[0m\n",
      "     | > loss: 0.6496603488922119  (0.6759219434526231)\n",
      "     | > log_mle: 0.08641552925109863  (0.08338464410216721)\n",
      "     | > loss_dur: 0.5632448196411133  (0.592537299350456)\n",
      "     | > amp_scaler: 131072.0  (131072.0)\n",
      "     | > grad_norm: tensor(0.9741, device='cuda:0')  (tensor(1.3408, device='cuda:0'))\n",
      "     | > current_lr: 3.5e-06 \n",
      "     | > step_time: 0.6647  (0.47499840347855177)\n",
      "     | > loader_time: 0.0155  (0.008067334139788593)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:29:15 -- STEP: 52/406 -- GLOBAL_STEP: 12225\u001b[0m\n",
      "     | > loss: 0.669312596321106  (0.6724778539859333)\n",
      "     | > log_mle: 0.07311874628067017  (0.08067514460820419)\n",
      "     | > loss_dur: 0.5961938500404358  (0.5918027093777288)\n",
      "     | > amp_scaler: 131072.0  (131072.0)\n",
      "     | > grad_norm: tensor(1.1768, device='cuda:0')  (tensor(1.3098, device='cuda:0'))\n",
      "     | > current_lr: 3.5e-06 \n",
      "     | > step_time: 0.4595  (0.5211903773821318)\n",
      "     | > loader_time: 0.007  (0.01065985973064716)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:29:31 -- STEP: 77/406 -- GLOBAL_STEP: 12250\u001b[0m\n",
      "     | > loss: 0.6726915836334229  (0.6681944449226578)\n",
      "     | > log_mle: 0.07563269138336182  (0.0768959421616096)\n",
      "     | > loss_dur: 0.597058892250061  (0.591298502761048)\n",
      "     | > amp_scaler: 131072.0  (131072.0)\n",
      "     | > grad_norm: tensor(1.0667, device='cuda:0')  (tensor(1.3141, device='cuda:0'))\n",
      "     | > current_lr: 3.5e-06 \n",
      "     | > step_time: 0.5388  (0.5510481828218933)\n",
      "     | > loader_time: 0.0095  (0.01030314742744743)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:29:47 -- STEP: 102/406 -- GLOBAL_STEP: 12275\u001b[0m\n",
      "     | > loss: 0.6504002809524536  (0.6640873627335417)\n",
      "     | > log_mle: 0.04553425312042236  (0.07291630377956469)\n",
      "     | > loss_dur: 0.6048660278320312  (0.5911710589539771)\n",
      "     | > amp_scaler: 131072.0  (131072.0)\n",
      "     | > grad_norm: tensor(1.4363, device='cuda:0')  (tensor(1.3990, device='cuda:0'))\n",
      "     | > current_lr: 3.5e-06 \n",
      "     | > step_time: 1.1558  (0.564576943715414)\n",
      "     | > loader_time: 0.0167  (0.010785203354031431)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:30:04 -- STEP: 127/406 -- GLOBAL_STEP: 12300\u001b[0m\n",
      "     | > loss: 0.641799807548523  (0.6598625624273705)\n",
      "     | > log_mle: 0.05011254549026489  (0.06928555796465541)\n",
      "     | > loss_dur: 0.5916872620582581  (0.5905770044627152)\n",
      "     | > amp_scaler: 131072.0  (131072.0)\n",
      "     | > grad_norm: tensor(2.8814, device='cuda:0')  (tensor(1.5485, device='cuda:0'))\n",
      "     | > current_lr: 3.5e-06 \n",
      "     | > step_time: 0.8522  (0.5835437042506668)\n",
      "     | > loader_time: 0.0052  (0.01112586869968204)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:30:22 -- STEP: 152/406 -- GLOBAL_STEP: 12325\u001b[0m\n",
      "     | > loss: 0.6337723731994629  (0.6580731457001286)\n",
      "     | > log_mle: 0.05042833089828491  (0.06640480654804333)\n",
      "     | > loss_dur: 0.583344042301178  (0.5916683391520854)\n",
      "     | > amp_scaler: 131072.0  (131072.0)\n",
      "     | > grad_norm: tensor(1.4564, device='cuda:0')  (tensor(1.6040, device='cuda:0'))\n",
      "     | > current_lr: 3.5e-06 \n",
      "     | > step_time: 1.119  (0.6065130296506386)\n",
      "     | > loader_time: 0.0183  (0.01129146469266791)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:30:43 -- STEP: 177/406 -- GLOBAL_STEP: 12350\u001b[0m\n",
      "     | > loss: 0.6578220129013062  (0.6561936096283004)\n",
      "     | > log_mle: 0.04462027549743652  (0.06395532249730862)\n",
      "     | > loss_dur: 0.6132017374038696  (0.5922382871309919)\n",
      "     | > amp_scaler: 131072.0  (131072.0)\n",
      "     | > grad_norm: tensor(1.9805, device='cuda:0')  (tensor(1.6419, device='cuda:0'))\n",
      "     | > current_lr: 3.5e-06 \n",
      "     | > step_time: 0.8594  (0.634452947788993)\n",
      "     | > loader_time: 0.011  (0.011783256369122)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:31:02 -- STEP: 202/406 -- GLOBAL_STEP: 12375\u001b[0m\n",
      "     | > loss: 0.6414884328842163  (0.6544129913396177)\n",
      "     | > log_mle: 0.055328309535980225  (0.06171425645894348)\n",
      "     | > loss_dur: 0.5861601233482361  (0.5926987348806739)\n",
      "     | > amp_scaler: 131072.0  (131072.0)\n",
      "     | > grad_norm: tensor(1.6912, device='cuda:0')  (tensor(1.6498, device='cuda:0'))\n",
      "     | > current_lr: 3.5e-06 \n",
      "     | > step_time: 0.4893  (0.6488553604277058)\n",
      "     | > loader_time: 0.0057  (0.012207463236138368)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:31:20 -- STEP: 227/406 -- GLOBAL_STEP: 12400\u001b[0m\n",
      "     | > loss: 0.6430321335792542  (0.6519050897480635)\n",
      "     | > log_mle: 0.045066773891448975  (0.059479035207353544)\n",
      "     | > loss_dur: 0.5979653596878052  (0.5924260545407097)\n",
      "     | > amp_scaler: 65536.0  (126452.72246696035)\n",
      "     | > grad_norm: tensor(1.4787, device='cuda:0')  (tensor(1.7641, device='cuda:0'))\n",
      "     | > current_lr: 3.5e-06 \n",
      "     | > step_time: 0.4345  (0.6540922225834518)\n",
      "     | > loader_time: 0.0063  (0.01206080924046722)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:31:39 -- STEP: 252/406 -- GLOBAL_STEP: 12425\u001b[0m\n",
      "     | > loss: 0.6284830570220947  (0.6503427577397182)\n",
      "     | > log_mle: 0.041114628314971924  (0.0574665838290775)\n",
      "     | > loss_dur: 0.5873684287071228  (0.5928761739106405)\n",
      "     | > amp_scaler: 65536.0  (120409.39682539682)\n",
      "     | > grad_norm: tensor(1.9168, device='cuda:0')  (tensor(1.7905, device='cuda:0'))\n",
      "     | > current_lr: 3.5e-06 \n",
      "     | > step_time: 0.9849  (0.6634248485640878)\n",
      "     | > loader_time: 0.0181  (0.012221722375778921)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:31:58 -- STEP: 277/406 -- GLOBAL_STEP: 12450\u001b[0m\n",
      "     | > loss: 0.6199931502342224  (0.6485704017890491)\n",
      "     | > log_mle: 0.04002267122268677  (0.05553613285725732)\n",
      "     | > loss_dur: 0.5799704790115356  (0.5930342689317917)\n",
      "     | > amp_scaler: 65536.0  (115456.92418772558)\n",
      "     | > grad_norm: tensor(1.2988, device='cuda:0')  (tensor(1.7981, device='cuda:0'))\n",
      "     | > current_lr: 3.5e-06 \n",
      "     | > step_time: 1.243  (0.6715683971501433)\n",
      "     | > loader_time: 0.0253  (0.012541868196067394)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:32:18 -- STEP: 302/406 -- GLOBAL_STEP: 12475\u001b[0m\n",
      "     | > loss: 0.6348526477813721  (0.6470915627795342)\n",
      "     | > log_mle: 0.0300520658493042  (0.05387976114323602)\n",
      "     | > loss_dur: 0.6048005819320679  (0.5932118016362978)\n",
      "     | > amp_scaler: 65536.0  (111324.39735099336)\n",
      "     | > grad_norm: tensor(1.1690, device='cuda:0')  (tensor(1.7909, device='cuda:0'))\n",
      "     | > current_lr: 3.5e-06 \n",
      "     | > step_time: 0.9769  (0.6792153206882101)\n",
      "     | > loader_time: 0.0167  (0.012755657663408493)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:32:38 -- STEP: 327/406 -- GLOBAL_STEP: 12500\u001b[0m\n",
      "     | > loss: 0.6343968510627747  (0.6453188674165568)\n",
      "     | > log_mle: 0.03641855716705322  (0.05239116945033413)\n",
      "     | > loss_dur: 0.5979782938957214  (0.5929276979662225)\n",
      "     | > amp_scaler: 65536.0  (107823.75535168193)\n",
      "     | > grad_norm: tensor(1.4312, device='cuda:0')  (tensor(1.7599, device='cuda:0'))\n",
      "     | > current_lr: 3.5e-06 \n",
      "     | > step_time: 0.6496  (0.6860444779060667)\n",
      "     | > loader_time: 0.0066  (0.013288409702639331)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:32:58 -- STEP: 352/406 -- GLOBAL_STEP: 12525\u001b[0m\n",
      "     | > loss: 0.6224995255470276  (0.6441206263208931)\n",
      "     | > log_mle: 0.03170979022979736  (0.05080743608149619)\n",
      "     | > loss_dur: 0.5907897353172302  (0.5933131902393967)\n",
      "     | > amp_scaler: 65536.0  (104820.36363636362)\n",
      "     | > grad_norm: tensor(1.2946, device='cuda:0')  (tensor(1.7679, device='cuda:0'))\n",
      "     | > current_lr: 3.5e-06 \n",
      "     | > step_time: 0.6883  (0.6926649720831353)\n",
      "     | > loader_time: 0.0064  (0.013553742658008228)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:33:19 -- STEP: 377/406 -- GLOBAL_STEP: 12550\u001b[0m\n",
      "     | > loss: 0.6238546967506409  (0.642427687777764)\n",
      "     | > log_mle: 0.028650522232055664  (0.049170587676273456)\n",
      "     | > loss_dur: 0.5952041745185852  (0.5932571001014909)\n",
      "     | > amp_scaler: 65536.0  (102215.299734748)\n",
      "     | > grad_norm: tensor(1.2228, device='cuda:0')  (tensor(1.7386, device='cuda:0'))\n",
      "     | > current_lr: 3.5e-06 \n",
      "     | > step_time: 0.6399  (0.700103988065644)\n",
      "     | > loader_time: 0.0075  (0.013766529705543417)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:33:37 -- STEP: 402/406 -- GLOBAL_STEP: 12575\u001b[0m\n",
      "     | > loss: 0.6098595261573792  (0.6406313504152624)\n",
      "     | > log_mle: 0.01798146963119507  (0.047677167464251574)\n",
      "     | > loss_dur: 0.5918780565261841  (0.592954182951011)\n",
      "     | > amp_scaler: 65536.0  (99934.24875621889)\n",
      "     | > grad_norm: tensor(2.1633, device='cuda:0')  (tensor(1.7387, device='cuda:0'))\n",
      "     | > current_lr: 3.5e-06 \n",
      "     | > step_time: 0.4963  (0.700290833539631)\n",
      "     | > loader_time: 0.0078  (0.013710354691121116)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: 0.6367348432540894  (0.6367348432540894)\n",
      "     | > log_mle: 0.056045711040496826  (0.056045711040496826)\n",
      "     | > loss_dur: 0.5806891322135925  (0.5806891322135925)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: 0.5919617414474487  (0.5919617414474487)\n",
      "     | > log_mle: 0.029099345207214355  (0.029099345207214355)\n",
      "     | > loss_dur: 0.5628623962402344  (0.5628623962402344)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: 0.624457597732544  (0.6082096695899963)\n",
      "     | > log_mle: 0.06796872615814209  (0.04853403568267822)\n",
      "     | > loss_dur: 0.5564888715744019  (0.5596756339073181)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: 0.5835342407226562  (0.5999845266342163)\n",
      "     | > log_mle: 0.045332908630371094  (0.04746699333190918)\n",
      "     | > loss_dur: 0.5382013320922852  (0.5525175333023071)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: 0.6010841727256775  (0.6002594381570816)\n",
      "     | > log_mle: 0.01724720001220703  (0.03991204500198364)\n",
      "     | > loss_dur: 0.5838369727134705  (0.560347393155098)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: 0.5892743468284607  (0.5980624198913574)\n",
      "     | > log_mle: 0.012723565101623535  (0.03447434902191162)\n",
      "     | > loss_dur: 0.5765507817268372  (0.5635880708694458)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: 0.6348333358764648  (0.6041909058888754)\n",
      "     | > log_mle: 0.0029511451721191406  (0.029220481713612873)\n",
      "     | > loss_dur: 0.6318821907043457  (0.5749704241752625)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: 0.6205800771713257  (0.6065322160720825)\n",
      "     | > log_mle: 0.04239773750305176  (0.03110294682638986)\n",
      "     | > loss_dur: 0.5781823396682739  (0.5754292692456927)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: 0.5766228437423706  (0.6027935445308685)\n",
      "     | > log_mle: 0.03484255075454712  (0.031570397317409515)\n",
      "     | > loss_dur: 0.5417802929878235  (0.571223147213459)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: 0.6417155265808105  (0.6071182092030843)\n",
      "     | > log_mle: 0.028652429580688477  (0.031246178679996066)\n",
      "     | > loss_dur: 0.6130630970001221  (0.5758720305230882)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: 0.6208431124687195  (0.6084906995296478)\n",
      "     | > log_mle: 0.03547114133834839  (0.031668674945831296)\n",
      "     | > loss_dur: 0.5853719711303711  (0.5768220245838165)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: 0.5738686323165894  (0.6053432388739153)\n",
      "     | > log_mle: 0.021050453186035156  (0.030703382058577103)\n",
      "     | > loss_dur: 0.5528181791305542  (0.5746398568153381)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: 0.5914366841316223  (0.6041843593120575)\n",
      "     | > log_mle: 0.033332884311676025  (0.030922507246335346)\n",
      "     | > loss_dur: 0.5581037998199463  (0.5732618520657221)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: 0.615074872970581  (0.6050220911319439)\n",
      "     | > log_mle: 0.0162428617477417  (0.02979330374644353)\n",
      "     | > loss_dur: 0.5988320112228394  (0.5752287873855004)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: 0.603391170501709  (0.6049055968012128)\n",
      "     | > log_mle: 0.024340450763702393  (0.029403814247676303)\n",
      "     | > loss_dur: 0.5790507197380066  (0.5755017825535366)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: 0.6161012053489685  (0.6056519707043966)\n",
      "     | > log_mle: 0.02839946746826172  (0.02933685779571533)\n",
      "     | > loss_dur: 0.5877017378807068  (0.5763151129086812)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: 0.589205801486969  (0.6046240851283073)\n",
      "     | > log_mle: 0.03254246711730957  (0.029537208378314972)\n",
      "     | > loss_dur: 0.5566633343696594  (0.5750868767499924)\n",
      "\n",
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[91m 0.005595847964286804 \u001b[0m(+0.0006101727485656738)\n",
      "     | > avg_loss:\u001b[92m 0.6046240851283073 \u001b[0m(-0.04992513358592987)\n",
      "     | > avg_log_mle:\u001b[92m 0.029537208378314972 \u001b[0m(-0.023233942687511444)\n",
      "     | > avg_loss_dur:\u001b[92m 0.5750868767499924 \u001b[0m(-0.026691190898418427)\n",
      "\n",
      " > BEST MODEL : train/run-February-22-2025_02+19AM-9b6e3e6/best_model_12579.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 15/40\u001b[0m\n",
      " --> train/run-February-22-2025_02+19AM-9b6e3e6\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-22 03:33:52) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:34:04 -- STEP: 21/406 -- GLOBAL_STEP: 12600\u001b[0m\n",
      "     | > loss: 0.5942083597183228  (0.6224008401234945)\n",
      "     | > log_mle: 0.05551421642303467  (0.06039770728065854)\n",
      "     | > loss_dur: 0.5386941432952881  (0.5620031328428359)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.0299, device='cuda:0')  (tensor(1.3160, device='cuda:0'))\n",
      "     | > current_lr: 3.7499999999999997e-06 \n",
      "     | > step_time: 0.3734  (0.4387403102148147)\n",
      "     | > loader_time: 0.0091  (0.007384640829903739)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:34:18 -- STEP: 46/406 -- GLOBAL_STEP: 12625\u001b[0m\n",
      "     | > loss: 0.6097651720046997  (0.620885466751845)\n",
      "     | > log_mle: 0.05979067087173462  (0.05877853994784148)\n",
      "     | > loss_dur: 0.5499745011329651  (0.5621069268040035)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(0.9784, device='cuda:0')  (tensor(1.3359, device='cuda:0'))\n",
      "     | > current_lr: 3.7499999999999997e-06 \n",
      "     | > step_time: 0.7163  (0.5135917352593464)\n",
      "     | > loader_time: 0.0103  (0.007276794184809146)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:34:33 -- STEP: 71/406 -- GLOBAL_STEP: 12650\u001b[0m\n",
      "     | > loss: 0.6134986877441406  (0.6168356646954174)\n",
      "     | > log_mle: 0.04160374402999878  (0.054333222583985666)\n",
      "     | > loss_dur: 0.5718949437141418  (0.5625024421114319)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.6624, device='cuda:0')  (tensor(1.4490, device='cuda:0'))\n",
      "     | > current_lr: 3.7499999999999997e-06 \n",
      "     | > step_time: 0.5683  (0.532707966549296)\n",
      "     | > loader_time: 0.0048  (0.007408111867770343)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:34:48 -- STEP: 96/406 -- GLOBAL_STEP: 12675\u001b[0m\n",
      "     | > loss: 0.6218846440315247  (0.6132780425250529)\n",
      "     | > log_mle: 0.03456598520278931  (0.050254602606097855)\n",
      "     | > loss_dur: 0.5873186588287354  (0.5630234399189552)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(2.1191, device='cuda:0')  (tensor(1.5948, device='cuda:0'))\n",
      "     | > current_lr: 3.7499999999999997e-06 \n",
      "     | > step_time: 0.403  (0.5515007898211484)\n",
      "     | > loader_time: 0.0138  (0.008455055455366768)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:35:05 -- STEP: 121/406 -- GLOBAL_STEP: 12700\u001b[0m\n",
      "     | > loss: 0.6004223227500916  (0.6106722783451236)\n",
      "     | > log_mle: 0.034577131271362305  (0.04686363570946307)\n",
      "     | > loss_dur: 0.5658451914787292  (0.5638086426356608)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.2791, device='cuda:0')  (tensor(1.7268, device='cuda:0'))\n",
      "     | > current_lr: 3.7499999999999997e-06 \n",
      "     | > step_time: 0.8071  (0.5695988895479314)\n",
      "     | > loader_time: 0.0048  (0.009697920034739597)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:35:21 -- STEP: 146/406 -- GLOBAL_STEP: 12725\u001b[0m\n",
      "     | > loss: 0.5665673017501831  (0.6086170285531918)\n",
      "     | > log_mle: 0.0323294997215271  (0.04382312338646144)\n",
      "     | > loss_dur: 0.534237802028656  (0.5647939051667304)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.1870, device='cuda:0')  (tensor(1.8291, device='cuda:0'))\n",
      "     | > current_lr: 3.7499999999999997e-06 \n",
      "     | > step_time: 0.8821  (0.5836143199711631)\n",
      "     | > loader_time: 0.0058  (0.009819179365079696)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:35:38 -- STEP: 171/406 -- GLOBAL_STEP: 12750\u001b[0m\n",
      "     | > loss: 0.584945023059845  (0.6066351156485708)\n",
      "     | > log_mle: 0.022497594356536865  (0.041391685343625265)\n",
      "     | > loss_dur: 0.5624474287033081  (0.5652434303049456)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.2602, device='cuda:0')  (tensor(1.7645, device='cuda:0'))\n",
      "     | > current_lr: 3.7499999999999997e-06 \n",
      "     | > step_time: 0.7283  (0.5926025318123441)\n",
      "     | > loader_time: 0.0199  (0.010865395529228342)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:35:56 -- STEP: 196/406 -- GLOBAL_STEP: 12775\u001b[0m\n",
      "     | > loss: 0.5972509980201721  (0.6052414522487287)\n",
      "     | > log_mle: 0.022121429443359375  (0.03903079093719017)\n",
      "     | > loss_dur: 0.5751295685768127  (0.5662106613115389)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.7120, device='cuda:0')  (tensor(1.7475, device='cuda:0'))\n",
      "     | > current_lr: 3.7499999999999997e-06 \n",
      "     | > step_time: 0.4827  (0.6040285545952465)\n",
      "     | > loader_time: 0.0259  (0.011406379086630685)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:36:13 -- STEP: 221/406 -- GLOBAL_STEP: 12800\u001b[0m\n",
      "     | > loss: 0.610150158405304  (0.6032150732985446)\n",
      "     | > log_mle: 0.02218341827392578  (0.036914817078620606)\n",
      "     | > loss_dur: 0.5879667401313782  (0.5663002562199245)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.0833, device='cuda:0')  (tensor(1.7328, device='cuda:0'))\n",
      "     | > current_lr: 3.7499999999999997e-06 \n",
      "     | > step_time: 1.0507  (0.6139057383817782)\n",
      "     | > loader_time: 0.0142  (0.01177219136268305)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:36:31 -- STEP: 246/406 -- GLOBAL_STEP: 12825\u001b[0m\n",
      "     | > loss: 0.579206645488739  (0.6017004709418224)\n",
      "     | > log_mle: 0.01984506845474243  (0.034905114794165144)\n",
      "     | > loss_dur: 0.5593615770339966  (0.5667953561476575)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(2.0770, device='cuda:0')  (tensor(1.7978, device='cuda:0'))\n",
      "     | > current_lr: 3.7499999999999997e-06 \n",
      "     | > step_time: 0.5914  (0.6199907742864715)\n",
      "     | > loader_time: 0.0049  (0.011989232970447076)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:36:49 -- STEP: 271/406 -- GLOBAL_STEP: 12850\u001b[0m\n",
      "     | > loss: 0.5888124704360962  (0.6001243437348255)\n",
      "     | > log_mle: 0.0021023154258728027  (0.03307921926033894)\n",
      "     | > loss_dur: 0.5867101550102234  (0.5670451244744869)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(2.8578, device='cuda:0')  (tensor(1.8355, device='cuda:0'))\n",
      "     | > current_lr: 3.7499999999999997e-06 \n",
      "     | > step_time: 1.014  (0.6297040056038604)\n",
      "     | > loader_time: 0.0058  (0.012102181621143298)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:37:08 -- STEP: 296/406 -- GLOBAL_STEP: 12875\u001b[0m\n",
      "     | > loss: 0.5826550126075745  (0.5988713829098519)\n",
      "     | > log_mle: 0.009714603424072266  (0.031463086000970905)\n",
      "     | > loss_dur: 0.5729404091835022  (0.5674082969088813)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(2.1239, device='cuda:0')  (tensor(1.8245, device='cuda:0'))\n",
      "     | > current_lr: 3.7499999999999997e-06 \n",
      "     | > step_time: 0.7181  (0.6389319429526457)\n",
      "     | > loader_time: 0.0113  (0.012227132513716415)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:37:29 -- STEP: 321/406 -- GLOBAL_STEP: 12900\u001b[0m\n",
      "     | > loss: 0.5780423879623413  (0.5973084622825788)\n",
      "     | > log_mle: 0.011555850505828857  (0.029950180714746883)\n",
      "     | > loss_dur: 0.5664865374565125  (0.567358281567832)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(0.9279, device='cuda:0')  (tensor(1.8154, device='cuda:0'))\n",
      "     | > current_lr: 3.7499999999999997e-06 \n",
      "     | > step_time: 0.9622  (0.6531880206408158)\n",
      "     | > loader_time: 0.0067  (0.01268324599459164)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:37:50 -- STEP: 346/406 -- GLOBAL_STEP: 12925\u001b[0m\n",
      "     | > loss: 0.5747830271720886  (0.5964269679405781)\n",
      "     | > log_mle: 0.00182265043258667  (0.02839328753465863)\n",
      "     | > loss_dur: 0.572960376739502  (0.5680336804059195)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(4.3247, device='cuda:0')  (tensor(1.8509, device='cuda:0'))\n",
      "     | > current_lr: 3.7499999999999997e-06 \n",
      "     | > step_time: 0.685  (0.6635634547713172)\n",
      "     | > loader_time: 0.0234  (0.013017741241896084)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:38:10 -- STEP: 371/406 -- GLOBAL_STEP: 12950\u001b[0m\n",
      "     | > loss: 0.5741164684295654  (0.5949568772573028)\n",
      "     | > log_mle: 0.00534898042678833  (0.02684237291870735)\n",
      "     | > loss_dur: 0.5687674880027771  (0.5681145043385958)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.2055, device='cuda:0')  (tensor(1.8650, device='cuda:0'))\n",
      "     | > current_lr: 3.7499999999999997e-06 \n",
      "     | > step_time: 0.8629  (0.6726793709469608)\n",
      "     | > loader_time: 0.0138  (0.013163260051182337)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:38:29 -- STEP: 396/406 -- GLOBAL_STEP: 12975\u001b[0m\n",
      "     | > loss: 0.5578027963638306  (0.5935351966005377)\n",
      "     | > log_mle: -0.0006009340286254883  (0.02544367132764875)\n",
      "     | > loss_dur: 0.558403730392456  (0.5680915252728891)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.4955, device='cuda:0')  (tensor(1.8587, device='cuda:0'))\n",
      "     | > current_lr: 3.7499999999999997e-06 \n",
      "     | > step_time: 0.5588  (0.677305434689377)\n",
      "     | > loader_time: 0.0061  (0.013279832974828855)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: 0.5911483764648438  (0.5911483764648438)\n",
      "     | > log_mle: 0.03480100631713867  (0.03480100631713867)\n",
      "     | > loss_dur: 0.5563473701477051  (0.5563473701477051)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: 0.5446999669075012  (0.5446999669075012)\n",
      "     | > log_mle: 0.006380200386047363  (0.006380200386047363)\n",
      "     | > loss_dur: 0.5383197665214539  (0.5383197665214539)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: 0.5743751525878906  (0.5595375597476959)\n",
      "     | > log_mle: 0.045100390911102295  (0.02574029564857483)\n",
      "     | > loss_dur: 0.5292747616767883  (0.5337972640991211)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: 0.5570639967918396  (0.5587130387624105)\n",
      "     | > log_mle: 0.02410101890563965  (0.025193870067596436)\n",
      "     | > loss_dur: 0.5329629778862  (0.5335191686948141)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: 0.549419641494751  (0.5563896894454956)\n",
      "     | > log_mle: -0.0048705339431762695  (0.01767776906490326)\n",
      "     | > loss_dur: 0.5542901754379272  (0.5387119203805923)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: 0.5635308623313904  (0.5578179240226746)\n",
      "     | > log_mle: -0.00883859395980835  (0.012374496459960938)\n",
      "     | > loss_dur: 0.5723694562911987  (0.5454434275627136)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: 0.578244686126709  (0.5612223843733469)\n",
      "     | > log_mle: -0.01806926727294922  (0.007300535837809245)\n",
      "     | > loss_dur: 0.5963139533996582  (0.5539218485355377)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: 0.5847207903862  (0.5645792995180402)\n",
      "     | > log_mle: 0.020161926746368408  (0.00913787739617484)\n",
      "     | > loss_dur: 0.5645588636398315  (0.5554414221218654)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: 0.5267423987388611  (0.5598496869206429)\n",
      "     | > log_mle: 0.013218581676483154  (0.009647965431213379)\n",
      "     | > loss_dur: 0.5135238170623779  (0.5502017214894295)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: 0.6042462587356567  (0.5647826393445333)\n",
      "     | > log_mle: 0.006354272365570068  (0.00928199953503079)\n",
      "     | > loss_dur: 0.5978919863700867  (0.5555006398095025)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: 0.5827481746673584  (0.5665791928768158)\n",
      "     | > log_mle: 0.01340705156326294  (0.009694504737854003)\n",
      "     | > loss_dur: 0.5693411231040955  (0.5568846881389617)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: 0.5188279151916504  (0.5622381676327098)\n",
      "     | > log_mle: -0.0008890628814697266  (0.008732362227006392)\n",
      "     | > loss_dur: 0.5197169780731201  (0.5535058054057035)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: 0.5568456649780273  (0.5617887924114863)\n",
      "     | > log_mle: 0.011005103588104248  (0.008921757340431213)\n",
      "     | > loss_dur: 0.5458405613899231  (0.5528670350710551)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: 0.5701489448547363  (0.5624318810609671)\n",
      "     | > log_mle: -0.005639314651489258  (0.007801674879514254)\n",
      "     | > loss_dur: 0.5757882595062256  (0.5546302061814529)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: 0.5594090819358826  (0.5622159668377468)\n",
      "     | > log_mle: 0.001849055290222168  (0.00737648776599339)\n",
      "     | > loss_dur: 0.5575600266456604  (0.5548394790717535)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: 0.5680774450302124  (0.5626067320505778)\n",
      "     | > log_mle: 0.00648266077041626  (0.007316899299621582)\n",
      "     | > loss_dur: 0.5615947842597961  (0.5552898327509563)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: 0.5654727816581726  (0.5627858601510525)\n",
      "     | > log_mle: 0.01097649335861206  (0.007545623928308487)\n",
      "     | > loss_dur: 0.5544962882995605  (0.5552402362227441)\n",
      "\n",
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.003228709101676941 \u001b[0m(-0.0023671388626098633)\n",
      "     | > avg_loss:\u001b[92m 0.5627858601510525 \u001b[0m(-0.04183822497725487)\n",
      "     | > avg_log_mle:\u001b[92m 0.007545623928308487 \u001b[0m(-0.021991584450006485)\n",
      "     | > avg_loss_dur:\u001b[92m 0.5552402362227441 \u001b[0m(-0.01984664052724827)\n",
      "\n",
      " > BEST MODEL : train/run-February-22-2025_02+19AM-9b6e3e6/best_model_12985.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 16/40\u001b[0m\n",
      " --> train/run-February-22-2025_02+19AM-9b6e3e6\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-22 03:38:49) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:38:57 -- STEP: 15/406 -- GLOBAL_STEP: 13000\u001b[0m\n",
      "     | > loss: 0.5893611907958984  (0.5764748692512512)\n",
      "     | > log_mle: 0.030453205108642578  (0.037761815388997394)\n",
      "     | > loss_dur: 0.5589079856872559  (0.5387130538622539)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(0.8192, device='cuda:0')  (tensor(1.2158, device='cuda:0'))\n",
      "     | > current_lr: 4e-06 \n",
      "     | > step_time: 0.6184  (0.37401809692382815)\n",
      "     | > loader_time: 0.0043  (0.004034121831258137)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:39:11 -- STEP: 40/406 -- GLOBAL_STEP: 13025\u001b[0m\n",
      "     | > loss: 0.5841807126998901  (0.5781545817852021)\n",
      "     | > log_mle: 0.05205190181732178  (0.037510566413402564)\n",
      "     | > loss_dur: 0.5321288108825684  (0.5406440153717995)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(0.6445, device='cuda:0')  (tensor(1.4619, device='cuda:0'))\n",
      "     | > current_lr: 4e-06 \n",
      "     | > step_time: 0.8495  (0.48220465779304506)\n",
      "     | > loader_time: 0.0053  (0.005837953090667725)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:39:25 -- STEP: 65/406 -- GLOBAL_STEP: 13050\u001b[0m\n",
      "     | > loss: 0.5429414510726929  (0.5740139539425188)\n",
      "     | > log_mle: 0.03578305244445801  (0.03376387174312885)\n",
      "     | > loss_dur: 0.5071583986282349  (0.5402500821993901)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(0.8534, device='cuda:0')  (tensor(1.4629, device='cuda:0'))\n",
      "     | > current_lr: 4e-06 \n",
      "     | > step_time: 0.6318  (0.5141474723815918)\n",
      "     | > loader_time: 0.0176  (0.00695032339829665)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:39:40 -- STEP: 90/406 -- GLOBAL_STEP: 13075\u001b[0m\n",
      "     | > loss: 0.56788569688797  (0.5718172358142003)\n",
      "     | > log_mle: 0.01198488473892212  (0.029661083221435538)\n",
      "     | > loss_dur: 0.5559008121490479  (0.542156152592765)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.1938, device='cuda:0')  (tensor(1.4307, device='cuda:0'))\n",
      "     | > current_lr: 4e-06 \n",
      "     | > step_time: 0.5801  (0.5365021308263146)\n",
      "     | > loader_time: 0.0047  (0.007912617259555395)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:39:57 -- STEP: 115/406 -- GLOBAL_STEP: 13100\u001b[0m\n",
      "     | > loss: 0.5781440734863281  (0.5690833039905712)\n",
      "     | > log_mle: 0.02661263942718506  (0.0258076496746229)\n",
      "     | > loss_dur: 0.5515314340591431  (0.5432756543159486)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.7029, device='cuda:0')  (tensor(1.6379, device='cuda:0'))\n",
      "     | > current_lr: 4e-06 \n",
      "     | > step_time: 0.8612  (0.5576870586561125)\n",
      "     | > loader_time: 0.0234  (0.008858104374097744)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:40:13 -- STEP: 140/406 -- GLOBAL_STEP: 13125\u001b[0m\n",
      "     | > loss: 0.5539876818656921  (0.5676737312759671)\n",
      "     | > log_mle: 0.0011712312698364258  (0.022694076384816846)\n",
      "     | > loss_dur: 0.5528164505958557  (0.5449796548911503)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(4.3757, device='cuda:0')  (tensor(1.9527, device='cuda:0'))\n",
      "     | > current_lr: 4e-06 \n",
      "     | > step_time: 0.635  (0.568438519750323)\n",
      "     | > loader_time: 0.027  (0.00918902329036168)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:40:29 -- STEP: 165/406 -- GLOBAL_STEP: 13150\u001b[0m\n",
      "     | > loss: 0.5623378157615662  (0.5659622459700613)\n",
      "     | > log_mle: -0.010819613933563232  (0.020241666201389192)\n",
      "     | > loss_dur: 0.5731574296951294  (0.5457205797686717)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(5.6970, device='cuda:0')  (tensor(1.9743, device='cuda:0'))\n",
      "     | > current_lr: 4e-06 \n",
      "     | > step_time: 0.9669  (0.5800587567416108)\n",
      "     | > loader_time: 0.0138  (0.009613538510871659)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:40:47 -- STEP: 190/406 -- GLOBAL_STEP: 13175\u001b[0m\n",
      "     | > loss: 0.557554304599762  (0.5648086350215108)\n",
      "     | > log_mle: -0.009549379348754883  (0.017926555871963498)\n",
      "     | > loss_dur: 0.5671036839485168  (0.5468820791495466)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(2.4149, device='cuda:0')  (tensor(2.0126, device='cuda:0'))\n",
      "     | > current_lr: 4e-06 \n",
      "     | > step_time: 0.8988  (0.5945809954091121)\n",
      "     | > loader_time: 0.0674  (0.010095035402398363)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:41:04 -- STEP: 215/406 -- GLOBAL_STEP: 13200\u001b[0m\n",
      "     | > loss: 0.5535568594932556  (0.5629075538280401)\n",
      "     | > log_mle: 0.0016414523124694824  (0.016043122701866676)\n",
      "     | > loss_dur: 0.5519154071807861  (0.5468644311261724)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(2.3016, device='cuda:0')  (tensor(2.0407, device='cuda:0'))\n",
      "     | > current_lr: 4e-06 \n",
      "     | > step_time: 0.5457  (0.6030413771784582)\n",
      "     | > loader_time: 0.0109  (0.010532809412756635)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:41:22 -- STEP: 240/406 -- GLOBAL_STEP: 13225\u001b[0m\n",
      "     | > loss: 0.534746527671814  (0.5616402323047325)\n",
      "     | > log_mle: -0.011975467205047607  (0.014015234758456546)\n",
      "     | > loss_dur: 0.5467219948768616  (0.547624997546275)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(2.2944, device='cuda:0')  (tensor(2.0285, device='cuda:0'))\n",
      "     | > current_lr: 4e-06 \n",
      "     | > step_time: 1.0305  (0.6144753724336623)\n",
      "     | > loader_time: 0.0225  (0.010875001549720768)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:41:40 -- STEP: 265/406 -- GLOBAL_STEP: 13250\u001b[0m\n",
      "     | > loss: 0.543364405632019  (0.5604420520224666)\n",
      "     | > log_mle: -0.009982824325561523  (0.012269376133972743)\n",
      "     | > loss_dur: 0.5533472299575806  (0.5481726758884929)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(4.0593, device='cuda:0')  (tensor(2.1214, device='cuda:0'))\n",
      "     | > current_lr: 4e-06 \n",
      "     | > step_time: 0.4021  (0.62337582066374)\n",
      "     | > loader_time: 0.0075  (0.010921759875315544)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:41:58 -- STEP: 290/406 -- GLOBAL_STEP: 13275\u001b[0m\n",
      "     | > loss: 0.531041145324707  (0.5591438755906866)\n",
      "     | > log_mle: -0.018949449062347412  (0.010615431851354138)\n",
      "     | > loss_dur: 0.5499905943870544  (0.5485284437393314)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(4.6862, device='cuda:0')  (tensor(2.1746, device='cuda:0'))\n",
      "     | > current_lr: 4e-06 \n",
      "     | > step_time: 1.0523  (0.6308298119183245)\n",
      "     | > loader_time: 0.0201  (0.010923707896265492)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:42:18 -- STEP: 315/406 -- GLOBAL_STEP: 13300\u001b[0m\n",
      "     | > loss: 0.5448557138442993  (0.5578769044270596)\n",
      "     | > log_mle: -0.011132597923278809  (0.009155698995741587)\n",
      "     | > loss_dur: 0.5559883117675781  (0.5487212054313166)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.5939, device='cuda:0')  (tensor(2.2249, device='cuda:0'))\n",
      "     | > current_lr: 4e-06 \n",
      "     | > step_time: 0.7067  (0.640254813905746)\n",
      "     | > loader_time: 0.0062  (0.0114174381135002)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:42:37 -- STEP: 340/406 -- GLOBAL_STEP: 13325\u001b[0m\n",
      "     | > loss: 0.5570237040519714  (0.5570128333919193)\n",
      "     | > log_mle: -0.004918217658996582  (0.0078023205785190345)\n",
      "     | > loss_dur: 0.561941921710968  (0.549210512813399)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.9653, device='cuda:0')  (tensor(2.2786, device='cuda:0'))\n",
      "     | > current_lr: 4e-06 \n",
      "     | > step_time: 0.6826  (0.6499564430292913)\n",
      "     | > loader_time: 0.0061  (0.011708343730253328)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:42:57 -- STEP: 365/406 -- GLOBAL_STEP: 13350\u001b[0m\n",
      "     | > loss: 0.5245540738105774  (0.5558262740096007)\n",
      "     | > log_mle: -0.013599038124084473  (0.006303673084468057)\n",
      "     | > loss_dur: 0.5381531119346619  (0.5495226009251313)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(5.8956, device='cuda:0')  (tensor(2.3635, device='cuda:0'))\n",
      "     | > current_lr: 4e-06 \n",
      "     | > step_time: 0.7029  (0.6585712530841564)\n",
      "     | > loader_time: 0.0079  (0.011951836494550307)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:43:18 -- STEP: 390/406 -- GLOBAL_STEP: 13375\u001b[0m\n",
      "     | > loss: 0.5292574763298035  (0.5545092536852911)\n",
      "     | > log_mle: -0.028948724269866943  (0.00491684140303196)\n",
      "     | > loss_dur: 0.5582062005996704  (0.5495924122822584)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.9326, device='cuda:0')  (tensor(2.3928, device='cuda:0'))\n",
      "     | > current_lr: 4e-06 \n",
      "     | > step_time: 1.0059  (0.6685844250214402)\n",
      "     | > loader_time: 0.0088  (0.012167761876032898)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: 0.5584506392478943  (0.5584506392478943)\n",
      "     | > log_mle: 0.015331268310546875  (0.015331268310546875)\n",
      "     | > loss_dur: 0.5431193709373474  (0.5431193709373474)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: 0.5251531600952148  (0.5251531600952148)\n",
      "     | > log_mle: -0.014411091804504395  (-0.014411091804504395)\n",
      "     | > loss_dur: 0.5395642518997192  (0.5395642518997192)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: 0.5401512384414673  (0.5326521992683411)\n",
      "     | > log_mle: 0.02426624298095703  (0.004927575588226318)\n",
      "     | > loss_dur: 0.5158849954605103  (0.5277246236801147)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: 0.5192641019821167  (0.528189500172933)\n",
      "     | > log_mle: 0.00452035665512085  (0.004791835943857829)\n",
      "     | > loss_dur: 0.5147437453269958  (0.5233976642290751)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: 0.5082652568817139  (0.5232084393501282)\n",
      "     | > log_mle: -0.025185227394104004  (-0.0027024298906326294)\n",
      "     | > loss_dur: 0.5334504842758179  (0.5259108692407608)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: 0.5346727967262268  (0.5255013108253479)\n",
      "     | > log_mle: -0.02871096134185791  (-0.007904136180877685)\n",
      "     | > loss_dur: 0.5633837580680847  (0.5334054470062256)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: 0.5395007729530334  (0.5278345545132955)\n",
      "     | > log_mle: -0.037524640560150146  (-0.01284088691075643)\n",
      "     | > loss_dur: 0.5770254135131836  (0.5406754414240519)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: 0.5468157529830933  (0.5305461542946952)\n",
      "     | > log_mle: -0.0002714395523071289  (-0.0110452515738351)\n",
      "     | > loss_dur: 0.5470871925354004  (0.5415914058685303)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: 0.49450111389160156  (0.5260405242443085)\n",
      "     | > log_mle: -0.006648600101470947  (-0.010495670139789581)\n",
      "     | > loss_dur: 0.5011497139930725  (0.536536194384098)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: 0.5747507214546204  (0.5314527683787875)\n",
      "     | > log_mle: -0.014253199100494385  (-0.01091317335764567)\n",
      "     | > loss_dur: 0.5890039205551147  (0.5423659417364333)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: 0.5338436365127563  (0.5316918551921844)\n",
      "     | > log_mle: -0.0067372918128967285  (-0.010495585203170777)\n",
      "     | > loss_dur: 0.5405809283256531  (0.5421874403953553)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: 0.5031482577323914  (0.5290969826958396)\n",
      "     | > log_mle: -0.020970165729522705  (-0.011447819796475496)\n",
      "     | > loss_dur: 0.5241184234619141  (0.5405448024923151)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: 0.5195562243461609  (0.528301919500033)\n",
      "     | > log_mle: -0.009355902671813965  (-0.01127349336942037)\n",
      "     | > loss_dur: 0.5289121270179749  (0.5395754128694533)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: 0.5082201361656189  (0.5267571669358474)\n",
      "     | > log_mle: -0.025918424129486084  (-0.012400026504810039)\n",
      "     | > loss_dur: 0.534138560295105  (0.5391571934406573)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: 0.524236261844635  (0.5265771022864751)\n",
      "     | > log_mle: -0.01872074604034424  (-0.012851506471633911)\n",
      "     | > loss_dur: 0.5429570078849792  (0.5394286087581088)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: 0.528976321220398  (0.5267370502154034)\n",
      "     | > log_mle: -0.013704180717468262  (-0.012908351421356202)\n",
      "     | > loss_dur: 0.5426805019378662  (0.5396454016367593)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: 0.5355149507522583  (0.5272856689989569)\n",
      "     | > log_mle: -0.008929133415222168  (-0.012659650295972824)\n",
      "     | > loss_dur: 0.5444440841674805  (0.5399453192949294)\n",
      "\n",
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[91m 0.00660400092601776 \u001b[0m(+0.0033752918243408194)\n",
      "     | > avg_loss:\u001b[92m 0.5272856689989569 \u001b[0m(-0.03550019115209557)\n",
      "     | > avg_log_mle:\u001b[92m -0.012659650295972824 \u001b[0m(-0.02020527422428131)\n",
      "     | > avg_loss_dur:\u001b[92m 0.5399453192949294 \u001b[0m(-0.015294916927814706)\n",
      "\n",
      " > BEST MODEL : train/run-February-22-2025_02+19AM-9b6e3e6/best_model_13391.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 17/40\u001b[0m\n",
      " --> train/run-February-22-2025_02+19AM-9b6e3e6\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-22 03:43:43) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:43:48 -- STEP: 9/406 -- GLOBAL_STEP: 13400\u001b[0m\n",
      "     | > loss: 0.525807797908783  (0.537365992863973)\n",
      "     | > log_mle: 0.011729240417480469  (0.021074487103356257)\n",
      "     | > loss_dur: 0.5140785574913025  (0.5162915024492476)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.2889, device='cuda:0')  (tensor(1.0772, device='cuda:0'))\n",
      "     | > current_lr: 4.25e-06 \n",
      "     | > step_time: 0.241  (0.37694456842210555)\n",
      "     | > loader_time: 0.0035  (0.005437903934054905)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:44:01 -- STEP: 34/406 -- GLOBAL_STEP: 13425\u001b[0m\n",
      "     | > loss: 0.5384066104888916  (0.5406151098363541)\n",
      "     | > log_mle: 0.020950376987457275  (0.01692482653786154)\n",
      "     | > loss_dur: 0.5174562335014343  (0.5236902824219536)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(0.9462, device='cuda:0')  (tensor(1.1243, device='cuda:0'))\n",
      "     | > current_lr: 4.25e-06 \n",
      "     | > step_time: 0.901  (0.4878273851731244)\n",
      "     | > loader_time: 0.0077  (0.006333975230946261)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:44:16 -- STEP: 59/406 -- GLOBAL_STEP: 13450\u001b[0m\n",
      "     | > loss: 0.5296661257743835  (0.5380354038739609)\n",
      "     | > log_mle: 0.0040763020515441895  (0.013691049511149782)\n",
      "     | > loss_dur: 0.5255898237228394  (0.5243443533525626)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.8789, device='cuda:0')  (tensor(1.2452, device='cuda:0'))\n",
      "     | > current_lr: 4.25e-06 \n",
      "     | > step_time: 0.7542  (0.5219703569250591)\n",
      "     | > loader_time: 0.0368  (0.008024037894556078)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:44:31 -- STEP: 84/406 -- GLOBAL_STEP: 13475\u001b[0m\n",
      "     | > loss: 0.5076268911361694  (0.5345788562581651)\n",
      "     | > log_mle: -0.00394439697265625  (0.010038438297453382)\n",
      "     | > loss_dur: 0.5115712881088257  (0.5245404176059223)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.5031, device='cuda:0')  (tensor(1.3454, device='cuda:0'))\n",
      "     | > current_lr: 4.25e-06 \n",
      "     | > step_time: 0.7023  (0.5418918586912607)\n",
      "     | > loader_time: 0.0313  (0.009898716495150613)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:44:46 -- STEP: 109/406 -- GLOBAL_STEP: 13500\u001b[0m\n",
      "     | > loss: 0.5239662528038025  (0.5316391598194017)\n",
      "     | > log_mle: -0.018724381923675537  (0.0063616496707321335)\n",
      "     | > loss_dur: 0.542690634727478  (0.5252775098752535)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(2.6713, device='cuda:0')  (tensor(1.4192, device='cuda:0'))\n",
      "     | > current_lr: 4.25e-06 \n",
      "     | > step_time: 0.6772  (0.5529997151926022)\n",
      "     | > loader_time: 0.0132  (0.010672109936355454)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:45:03 -- STEP: 134/406 -- GLOBAL_STEP: 13525\u001b[0m\n",
      "     | > loss: 0.5310125350952148  (0.5301338674417183)\n",
      "     | > log_mle: -0.006163120269775391  (0.003038416157907517)\n",
      "     | > loss_dur: 0.5371756553649902  (0.5270954510614049)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.6561, device='cuda:0')  (tensor(1.6366, device='cuda:0'))\n",
      "     | > current_lr: 4.25e-06 \n",
      "     | > step_time: 0.5252  (0.5724479511602599)\n",
      "     | > loader_time: 0.0166  (0.011405046306439303)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:45:20 -- STEP: 159/406 -- GLOBAL_STEP: 13550\u001b[0m\n",
      "     | > loss: 0.5227338075637817  (0.5288913549867066)\n",
      "     | > log_mle: -0.01628410816192627  (0.0005722634447445682)\n",
      "     | > loss_dur: 0.539017915725708  (0.5283190913545258)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.4511, device='cuda:0')  (tensor(1.6191, device='cuda:0'))\n",
      "     | > current_lr: 4.25e-06 \n",
      "     | > step_time: 0.7211  (0.5839784895099183)\n",
      "     | > loader_time: 0.0149  (0.011418429560631327)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:45:37 -- STEP: 184/406 -- GLOBAL_STEP: 13575\u001b[0m\n",
      "     | > loss: 0.5433856844902039  (0.5278418481997821)\n",
      "     | > log_mle: -0.02437901496887207  (-0.0016607836536739163)\n",
      "     | > loss_dur: 0.5677646994590759  (0.5295026316914868)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(2.9622, device='cuda:0')  (tensor(1.7843, device='cuda:0'))\n",
      "     | > current_lr: 4.25e-06 \n",
      "     | > step_time: 0.8124  (0.5969886248526365)\n",
      "     | > loader_time: 0.0052  (0.011353508285854172)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:45:57 -- STEP: 209/406 -- GLOBAL_STEP: 13600\u001b[0m\n",
      "     | > loss: 0.49508583545684814  (0.5261833297008532)\n",
      "     | > log_mle: -0.02513962984085083  (-0.003636345338593257)\n",
      "     | > loss_dur: 0.520225465297699  (0.5298196748968517)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(5.8454, device='cuda:0')  (tensor(1.9599, device='cuda:0'))\n",
      "     | > current_lr: 4.25e-06 \n",
      "     | > step_time: 0.7165  (0.6155750979647112)\n",
      "     | > loader_time: 0.0077  (0.011837086609105742)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:46:15 -- STEP: 234/406 -- GLOBAL_STEP: 13625\u001b[0m\n",
      "     | > loss: 0.5162469744682312  (0.5249676128737948)\n",
      "     | > log_mle: -0.03288722038269043  (-0.005663035517064932)\n",
      "     | > loss_dur: 0.5491341948509216  (0.5306306482634993)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(3.9519, device='cuda:0')  (tensor(2.0433, device='cuda:0'))\n",
      "     | > current_lr: 4.25e-06 \n",
      "     | > step_time: 0.7905  (0.6255014003851475)\n",
      "     | > loader_time: 0.0156  (0.011914585390661515)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:46:32 -- STEP: 259/406 -- GLOBAL_STEP: 13650\u001b[0m\n",
      "     | > loss: 0.5174577236175537  (0.523958100085093)\n",
      "     | > log_mle: -0.03960275650024414  (-0.007424471461174569)\n",
      "     | > loss_dur: 0.5570604801177979  (0.5313825714312005)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(2.2364, device='cuda:0')  (tensor(2.1112, device='cuda:0'))\n",
      "     | > current_lr: 4.25e-06 \n",
      "     | > step_time: 1.03  (0.6311799743460872)\n",
      "     | > loader_time: 0.0199  (0.011850008172878426)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:46:50 -- STEP: 284/406 -- GLOBAL_STEP: 13675\u001b[0m\n",
      "     | > loss: 0.49113500118255615  (0.5225686563152666)\n",
      "     | > log_mle: -0.030631422996520996  (-0.009081116234752492)\n",
      "     | > loss_dur: 0.5217664241790771  (0.5316497724450809)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(2.4643, device='cuda:0')  (tensor(2.1440, device='cuda:0'))\n",
      "     | > current_lr: 4.25e-06 \n",
      "     | > step_time: 0.5253  (0.6363436764394735)\n",
      "     | > loader_time: 0.0111  (0.012058888522671982)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:47:09 -- STEP: 309/406 -- GLOBAL_STEP: 13700\u001b[0m\n",
      "     | > loss: 0.5086780786514282  (0.5213322367482975)\n",
      "     | > log_mle: -0.025827765464782715  (-0.010437143659128727)\n",
      "     | > loss_dur: 0.5345058441162109  (0.5317693803109784)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(3.9579, device='cuda:0')  (tensor(2.1721, device='cuda:0'))\n",
      "     | > current_lr: 4.25e-06 \n",
      "     | > step_time: 0.9828  (0.6443393230438231)\n",
      "     | > loader_time: 0.0322  (0.012264560341449229)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:47:29 -- STEP: 334/406 -- GLOBAL_STEP: 13725\u001b[0m\n",
      "     | > loss: 0.5109215378761292  (0.5203158216562099)\n",
      "     | > log_mle: -0.03552579879760742  (-0.011755961144041874)\n",
      "     | > loss_dur: 0.5464473366737366  (0.5320717827110234)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(2.4389, device='cuda:0')  (tensor(2.1517, device='cuda:0'))\n",
      "     | > current_lr: 4.25e-06 \n",
      "     | > step_time: 0.8337  (0.6540006984493688)\n",
      "     | > loader_time: 0.0226  (0.012504175037680983)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:47:50 -- STEP: 359/406 -- GLOBAL_STEP: 13750\u001b[0m\n",
      "     | > loss: 0.4981120824813843  (0.5191576578822971)\n",
      "     | > log_mle: -0.022197604179382324  (-0.013152111705631271)\n",
      "     | > loss_dur: 0.5203096866607666  (0.5323097695049139)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.0972, device='cuda:0')  (tensor(2.1515, device='cuda:0'))\n",
      "     | > current_lr: 4.25e-06 \n",
      "     | > step_time: 0.9218  (0.6654465789582404)\n",
      "     | > loader_time: 0.0121  (0.012908043635588833)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:48:10 -- STEP: 384/406 -- GLOBAL_STEP: 13775\u001b[0m\n",
      "     | > loss: 0.4826463460922241  (0.5177083231198288)\n",
      "     | > log_mle: -0.0359078049659729  (-0.014468501942853138)\n",
      "     | > loss_dur: 0.518554151058197  (0.5321768249850723)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(3.7999, device='cuda:0')  (tensor(2.1813, device='cuda:0'))\n",
      "     | > current_lr: 4.25e-06 \n",
      "     | > step_time: 0.8995  (0.6732708880056938)\n",
      "     | > loader_time: 0.0123  (0.013167047252257662)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: 0.5174082517623901  (0.5174082517623901)\n",
      "     | > log_mle: -0.0026999711990356445  (-0.0026999711990356445)\n",
      "     | > loss_dur: 0.5201082229614258  (0.5201082229614258)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: 0.4644020199775696  (0.4644020199775696)\n",
      "     | > log_mle: -0.03348565101623535  (-0.03348565101623535)\n",
      "     | > loss_dur: 0.49788767099380493  (0.49788767099380493)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: 0.5032142400741577  (0.48380813002586365)\n",
      "     | > log_mle: 0.005116879940032959  (-0.014184385538101196)\n",
      "     | > loss_dur: 0.49809733033180237  (0.49799250066280365)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: 0.46624264121055603  (0.4779529670874278)\n",
      "     | > log_mle: -0.013744473457336426  (-0.014037748177846273)\n",
      "     | > loss_dur: 0.47998711466789246  (0.49199070533116657)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: 0.4412352442741394  (0.4687735363841057)\n",
      "     | > log_mle: -0.043816983699798584  (-0.02148255705833435)\n",
      "     | > loss_dur: 0.485052227973938  (0.49025608599185944)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: 0.49012863636016846  (0.47304455637931825)\n",
      "     | > log_mle: -0.04709291458129883  (-0.026604628562927245)\n",
      "     | > loss_dur: 0.5372215509414673  (0.499649178981781)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: 0.5028135776519775  (0.4780060599247615)\n",
      "     | > log_mle: -0.05562317371368408  (-0.031441052754720054)\n",
      "     | > loss_dur: 0.5584367513656616  (0.5094471077124277)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: 0.48867493867874146  (0.4795301854610443)\n",
      "     | > log_mle: -0.018953263759613037  (-0.029657082898276194)\n",
      "     | > loss_dur: 0.5076282024383545  (0.5091872641018459)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: 0.4569013714790344  (0.4767015837132931)\n",
      "     | > log_mle: -0.025036513805389404  (-0.029079511761665344)\n",
      "     | > loss_dur: 0.48193788528442383  (0.5057810917496681)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: 0.5307263731956482  (0.4827043381002214)\n",
      "     | > log_mle: -0.033338308334350586  (-0.029552711380852595)\n",
      "     | > loss_dur: 0.5640646815299988  (0.5122570461697049)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: 0.4862649440765381  (0.4830603986978531)\n",
      "     | > log_mle: -0.02535068988800049  (-0.029132509231567384)\n",
      "     | > loss_dur: 0.5116156339645386  (0.5121929049491882)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: 0.4560401141643524  (0.48060400919480756)\n",
      "     | > log_mle: -0.03942906856536865  (-0.030068560080094772)\n",
      "     | > loss_dur: 0.49546918272972107  (0.5106725665656003)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: 0.4874630570411682  (0.48117559651533764)\n",
      "     | > log_mle: -0.02814316749572754  (-0.029908110698064167)\n",
      "     | > loss_dur: 0.5156062245368958  (0.511083704729875)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: 0.47899508476257324  (0.48100786484204805)\n",
      "     | > log_mle: -0.04456895589828491  (-0.031035868021158073)\n",
      "     | > loss_dur: 0.5235640406608582  (0.5120437305707198)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: 0.47881168127059937  (0.4808509945869446)\n",
      "     | > log_mle: -0.037708401679992676  (-0.031512477568217685)\n",
      "     | > loss_dur: 0.516520082950592  (0.512363470026425)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: 0.4978277087211609  (0.4819827755292257)\n",
      "     | > log_mle: -0.03259700536727905  (-0.03158477942148844)\n",
      "     | > loss_dur: 0.5304247140884399  (0.5135675529638927)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: 0.48024052381515503  (0.48187388479709625)\n",
      "     | > log_mle: -0.027402877807617188  (-0.03132341057062149)\n",
      "     | > loss_dur: 0.5076434016227722  (0.5131972935050726)\n",
      "\n",
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.0033974498510360718 \u001b[0m(-0.0032065510749816886)\n",
      "     | > avg_loss:\u001b[92m 0.48187388479709625 \u001b[0m(-0.04541178420186065)\n",
      "     | > avg_log_mle:\u001b[92m -0.03132341057062149 \u001b[0m(-0.018663760274648666)\n",
      "     | > avg_loss_dur:\u001b[92m 0.5131972935050726 \u001b[0m(-0.0267480257898568)\n",
      "\n",
      " > BEST MODEL : train/run-February-22-2025_02+19AM-9b6e3e6/best_model_13797.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 18/40\u001b[0m\n",
      " --> train/run-February-22-2025_02+19AM-9b6e3e6\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-22 03:48:37) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:48:41 -- STEP: 3/406 -- GLOBAL_STEP: 13800\u001b[0m\n",
      "     | > loss: 0.5024204850196838  (0.4790619909763336)\n",
      "     | > log_mle: -0.0025611519813537598  (-0.0029579599698384604)\n",
      "     | > loss_dur: 0.5049816370010376  (0.48201995094617206)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.1964, device='cuda:0')  (tensor(1.3680, device='cuda:0'))\n",
      "     | > current_lr: 4.5e-06 \n",
      "     | > step_time: 0.5282  (0.5537115732828776)\n",
      "     | > loader_time: 0.0037  (0.005505561828613281)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:48:53 -- STEP: 28/406 -- GLOBAL_STEP: 13825\u001b[0m\n",
      "     | > loss: 0.5027146935462952  (0.49823294260672163)\n",
      "     | > log_mle: -0.005265176296234131  (-0.0012176356145313808)\n",
      "     | > loss_dur: 0.5079798698425293  (0.499450578221253)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(3.2458, device='cuda:0')  (tensor(1.6325, device='cuda:0'))\n",
      "     | > current_lr: 4.5e-06 \n",
      "     | > step_time: 0.5501  (0.4744672349521092)\n",
      "     | > loader_time: 0.0063  (0.008193569523947578)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:49:08 -- STEP: 53/406 -- GLOBAL_STEP: 13850\u001b[0m\n",
      "     | > loss: 0.490018755197525  (0.49668490493072653)\n",
      "     | > log_mle: -0.004648983478546143  (-0.0038164809065045053)\n",
      "     | > loss_dur: 0.49466773867607117  (0.500501386399539)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(2.4104, device='cuda:0')  (tensor(1.8539, device='cuda:0'))\n",
      "     | > current_lr: 4.5e-06 \n",
      "     | > step_time: 0.6301  (0.5168646281620243)\n",
      "     | > loader_time: 0.0038  (0.008540774291416383)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:49:23 -- STEP: 78/406 -- GLOBAL_STEP: 13875\u001b[0m\n",
      "     | > loss: 0.474984735250473  (0.49355713564615983)\n",
      "     | > log_mle: -0.012685179710388184  (-0.007449494722561958)\n",
      "     | > loss_dur: 0.4876699149608612  (0.501006630750803)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.8074, device='cuda:0')  (tensor(1.8900, device='cuda:0'))\n",
      "     | > current_lr: 4.5e-06 \n",
      "     | > step_time: 0.5569  (0.5396225910920364)\n",
      "     | > loader_time: 0.0135  (0.008854413643861426)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:49:38 -- STEP: 103/406 -- GLOBAL_STEP: 13900\u001b[0m\n",
      "     | > loss: 0.46306341886520386  (0.49103984323520106)\n",
      "     | > log_mle: -0.0336185097694397  (-0.011303156324960654)\n",
      "     | > loss_dur: 0.49668192863464355  (0.5023429998495048)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(9.6648, device='cuda:0')  (tensor(2.2222, device='cuda:0'))\n",
      "     | > current_lr: 4.5e-06 \n",
      "     | > step_time: 0.6256  (0.5564138588396089)\n",
      "     | > loader_time: 0.0043  (0.009861700743147466)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:49:55 -- STEP: 128/406 -- GLOBAL_STEP: 13925\u001b[0m\n",
      "     | > loss: 0.48182833194732666  (0.48847343400120735)\n",
      "     | > log_mle: -0.025668978691101074  (-0.014466364867985249)\n",
      "     | > loss_dur: 0.5074973106384277  (0.5029397991020237)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.1792, device='cuda:0')  (tensor(2.4068, device='cuda:0'))\n",
      "     | > current_lr: 4.5e-06 \n",
      "     | > step_time: 0.7077  (0.572287693619728)\n",
      "     | > loader_time: 0.0167  (0.010467672720551487)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:50:11 -- STEP: 153/406 -- GLOBAL_STEP: 13950\u001b[0m\n",
      "     | > loss: 0.4708717465400696  (0.48683257722387124)\n",
      "     | > log_mle: -0.03696185350418091  (-0.017064355557260946)\n",
      "     | > loss_dur: 0.5078336000442505  (0.5038969329759192)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.7047, device='cuda:0')  (tensor(2.4181, device='cuda:0'))\n",
      "     | > current_lr: 4.5e-06 \n",
      "     | > step_time: 0.4584  (0.5831611312292759)\n",
      "     | > loader_time: 0.016  (0.010659353405821555)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:50:28 -- STEP: 178/406 -- GLOBAL_STEP: 13975\u001b[0m\n",
      "     | > loss: 0.4759489595890045  (0.4854843263210875)\n",
      "     | > log_mle: -0.019598662853240967  (-0.019045928221070364)\n",
      "     | > loss_dur: 0.4955476224422455  (0.5045302547095869)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(2.0786, device='cuda:0')  (tensor(2.3545, device='cuda:0'))\n",
      "     | > current_lr: 4.5e-06 \n",
      "     | > step_time: 0.6294  (0.5927120380187303)\n",
      "     | > loader_time: 0.0057  (0.01129936502220925)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:50:46 -- STEP: 203/406 -- GLOBAL_STEP: 14000\u001b[0m\n",
      "     | > loss: 0.4758293032646179  (0.48388075681742776)\n",
      "     | > log_mle: -0.030457377433776855  (-0.02107037229490984)\n",
      "     | > loss_dur: 0.5062866806983948  (0.504951129259147)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(2.0205, device='cuda:0')  (tensor(2.3513, device='cuda:0'))\n",
      "     | > current_lr: 4.5e-06 \n",
      "     | > step_time: 0.4565  (0.6068477888999899)\n",
      "     | > loader_time: 0.0159  (0.0117497185768165)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:51:03 -- STEP: 228/406 -- GLOBAL_STEP: 14025\u001b[0m\n",
      "     | > loss: 0.4686840772628784  (0.4820625485296835)\n",
      "     | > log_mle: -0.03962355852127075  (-0.023082940202010297)\n",
      "     | > loss_dur: 0.5083076357841492  (0.505145488862406)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.8581, device='cuda:0')  (tensor(2.3142, device='cuda:0'))\n",
      "     | > current_lr: 4.5e-06 \n",
      "     | > step_time: 0.9544  (0.6147895852724709)\n",
      "     | > loader_time: 0.0056  (0.011740634315892267)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:51:22 -- STEP: 253/406 -- GLOBAL_STEP: 14050\u001b[0m\n",
      "     | > loss: 0.46671682596206665  (0.48065038749822986)\n",
      "     | > log_mle: -0.05567079782485962  (-0.02489864802643244)\n",
      "     | > loss_dur: 0.5223876237869263  (0.5055490356424583)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(2.8218, device='cuda:0')  (tensor(2.2779, device='cuda:0'))\n",
      "     | > current_lr: 4.5e-06 \n",
      "     | > step_time: 0.6345  (0.6238032687794076)\n",
      "     | > loader_time: 0.0306  (0.011941804245055428)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:51:40 -- STEP: 278/406 -- GLOBAL_STEP: 14075\u001b[0m\n",
      "     | > loss: 0.4616720378398895  (0.4792959768351891)\n",
      "     | > log_mle: -0.034379661083221436  (-0.026445539306393626)\n",
      "     | > loss_dur: 0.49605169892311096  (0.5057415162487855)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.4767, device='cuda:0')  (tensor(2.3218, device='cuda:0'))\n",
      "     | > current_lr: 4.5e-06 \n",
      "     | > step_time: 0.7348  (0.6323419998018003)\n",
      "     | > loader_time: 0.011  (0.012057673159263115)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:52:00 -- STEP: 303/406 -- GLOBAL_STEP: 14100\u001b[0m\n",
      "     | > loss: 0.46212369203567505  (0.47767528881727667)\n",
      "     | > log_mle: -0.04219400882720947  (-0.027838829130229382)\n",
      "     | > loss_dur: 0.5043177008628845  (0.505514118045864)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(2.1676, device='cuda:0')  (tensor(2.3584, device='cuda:0'))\n",
      "     | > current_lr: 4.5e-06 \n",
      "     | > step_time: 0.9948  (0.6438607248929467)\n",
      "     | > loader_time: 0.0214  (0.012261713298633941)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:52:21 -- STEP: 328/406 -- GLOBAL_STEP: 14125\u001b[0m\n",
      "     | > loss: 0.4720304608345032  (0.4763160664133909)\n",
      "     | > log_mle: -0.053996264934539795  (-0.02909078267289371)\n",
      "     | > loss_dur: 0.526026725769043  (0.5054068491771455)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(2.3523, device='cuda:0')  (tensor(2.3537, device='cuda:0'))\n",
      "     | > current_lr: 4.5e-06 \n",
      "     | > step_time: 0.9221  (0.6566855653030115)\n",
      "     | > loader_time: 0.0075  (0.012849355616220614)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:52:40 -- STEP: 353/406 -- GLOBAL_STEP: 14150\u001b[0m\n",
      "     | > loss: 0.45667213201522827  (0.4752376757498841)\n",
      "     | > log_mle: -0.05737072229385376  (-0.030420413773728498)\n",
      "     | > loss_dur: 0.514042854309082  (0.5056580896080385)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(2.4486, device='cuda:0')  (tensor(2.3368, device='cuda:0'))\n",
      "     | > current_lr: 4.5e-06 \n",
      "     | > step_time: 0.7223  (0.6638284702138928)\n",
      "     | > loader_time: 0.0064  (0.01299430628336185)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:53:00 -- STEP: 378/406 -- GLOBAL_STEP: 14175\u001b[0m\n",
      "     | > loss: 0.44920897483825684  (0.47363536588098637)\n",
      "     | > log_mle: -0.04660296440124512  (-0.03177277546711069)\n",
      "     | > loss_dur: 0.49581193923950195  (0.5054081414269391)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(3.6705, device='cuda:0')  (tensor(2.3487, device='cuda:0'))\n",
      "     | > current_lr: 4.5e-06 \n",
      "     | > step_time: 1.1962  (0.6719772203889472)\n",
      "     | > loader_time: 0.0071  (0.013082378125064588)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:53:18 -- STEP: 403/406 -- GLOBAL_STEP: 14200\u001b[0m\n",
      "     | > loss: 0.4381389319896698  (0.4720061070865792)\n",
      "     | > log_mle: -0.047744691371917725  (-0.033032770488161604)\n",
      "     | > loss_dur: 0.4858836233615875  (0.5050388776486918)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(2.7642, device='cuda:0')  (tensor(2.3790, device='cuda:0'))\n",
      "     | > current_lr: 4.5e-06 \n",
      "     | > step_time: 0.5471  (0.6732079000686002)\n",
      "     | > loader_time: 0.0055  (0.012973029323606278)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: 0.47475665807724  (0.47475665807724)\n",
      "     | > log_mle: -0.01900458335876465  (-0.01900458335876465)\n",
      "     | > loss_dur: 0.49376124143600464  (0.49376124143600464)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: 0.41531050205230713  (0.41531050205230713)\n",
      "     | > log_mle: -0.05067729949951172  (-0.05067729949951172)\n",
      "     | > loss_dur: 0.46598780155181885  (0.46598780155181885)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: 0.46606385707855225  (0.4406871795654297)\n",
      "     | > log_mle: -0.012071490287780762  (-0.03137439489364624)\n",
      "     | > loss_dur: 0.478135347366333  (0.4720615744590759)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: 0.4165407717227936  (0.43263837695121765)\n",
      "     | > log_mle: -0.029958009719848633  (-0.03090226650238037)\n",
      "     | > loss_dur: 0.4464987814426422  (0.463540643453598)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: 0.397275447845459  (0.423797644674778)\n",
      "     | > log_mle: -0.06018686294555664  (-0.03822341561317444)\n",
      "     | > loss_dur: 0.4574623107910156  (0.4620210602879524)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: 0.4493976831436157  (0.4289176523685455)\n",
      "     | > log_mle: -0.06281596422195435  (-0.04314192533493042)\n",
      "     | > loss_dur: 0.5122136473655701  (0.47205957770347595)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: 0.4662160277366638  (0.43513404826323193)\n",
      "     | > log_mle: -0.07096439599990845  (-0.04777900377909342)\n",
      "     | > loss_dur: 0.5371804237365723  (0.4829130520423253)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: 0.448540061712265  (0.43704919304166523)\n",
      "     | > log_mle: -0.0353662371635437  (-0.04600575140544346)\n",
      "     | > loss_dur: 0.4839062988758087  (0.48305494444710867)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: 0.43011346459388733  (0.436182226985693)\n",
      "     | > log_mle: -0.04130363464355469  (-0.04541798681020737)\n",
      "     | > loss_dur: 0.471417099237442  (0.48160021379590034)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: 0.49632102251052856  (0.4428643153773414)\n",
      "     | > log_mle: -0.0498507022857666  (-0.04591051075193617)\n",
      "     | > loss_dur: 0.5461717247962952  (0.48877482612927753)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: 0.43970170617103577  (0.4425480544567108)\n",
      "     | > log_mle: -0.0418705940246582  (-0.04550651907920837)\n",
      "     | > loss_dur: 0.48157230019569397  (0.4880545735359192)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: 0.41600301861763  (0.4401348693804307)\n",
      "     | > log_mle: -0.05565178394317627  (-0.046428815885023636)\n",
      "     | > loss_dur: 0.4716548025608063  (0.4865636852654544)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: 0.4425579011440277  (0.44033678869406384)\n",
      "     | > log_mle: -0.04473984241485596  (-0.046288068095842995)\n",
      "     | > loss_dur: 0.48729774355888367  (0.4866248567899068)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: 0.42463135719299316  (0.43912867857859683)\n",
      "     | > log_mle: -0.06067866086959839  (-0.04739503677074726)\n",
      "     | > loss_dur: 0.48531001806259155  (0.48652371534934413)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: 0.4349542558193207  (0.4388305055243628)\n",
      "     | > log_mle: -0.05436217784881592  (-0.04789268970489502)\n",
      "     | > loss_dur: 0.4893164336681366  (0.48672319522925783)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: 0.4513568878173828  (0.43966559767723085)\n",
      "     | > log_mle: -0.04921156167984009  (-0.04798061450322469)\n",
      "     | > loss_dur: 0.5005684494972229  (0.4876462121804555)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: 0.43367859721183777  (0.43929141014814377)\n",
      "     | > log_mle: -0.043135225772857666  (-0.04767777770757675)\n",
      "     | > loss_dur: 0.47681382298469543  (0.4869691878557205)\n",
      "\n",
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[91m 0.0033997446298599243 \u001b[0m(+2.294778823852539e-06)\n",
      "     | > avg_loss:\u001b[92m 0.43929141014814377 \u001b[0m(-0.042582474648952484)\n",
      "     | > avg_log_mle:\u001b[92m -0.04767777770757675 \u001b[0m(-0.01635436713695526)\n",
      "     | > avg_loss_dur:\u001b[92m 0.4869691878557205 \u001b[0m(-0.026228105649352074)\n",
      "\n",
      " > BEST MODEL : train/run-February-22-2025_02+19AM-9b6e3e6/best_model_14203.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 19/40\u001b[0m\n",
      " --> train/run-February-22-2025_02+19AM-9b6e3e6\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-22 03:53:33) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:53:45 -- STEP: 22/406 -- GLOBAL_STEP: 14225\u001b[0m\n",
      "     | > loss: 0.43964889645576477  (0.4491064250469208)\n",
      "     | > log_mle: -0.01115429401397705  (-0.017080978913740677)\n",
      "     | > loss_dur: 0.4508031904697418  (0.46618740396066144)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.3288, device='cuda:0')  (tensor(2.2129, device='cuda:0'))\n",
      "     | > current_lr: 4.749999999999999e-06 \n",
      "     | > step_time: 0.4546  (0.41791148619218305)\n",
      "     | > loader_time: 0.0043  (0.006463235074823553)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:53:59 -- STEP: 47/406 -- GLOBAL_STEP: 14250\u001b[0m\n",
      "     | > loss: 0.42921701073646545  (0.44880035519599915)\n",
      "     | > log_mle: -0.044840872287750244  (-0.01925793860821013)\n",
      "     | > loss_dur: 0.4740578830242157  (0.46805829380420927)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(4.7745, device='cuda:0')  (tensor(2.3595, device='cuda:0'))\n",
      "     | > current_lr: 4.749999999999999e-06 \n",
      "     | > step_time: 0.3099  (0.4954167477628018)\n",
      "     | > loader_time: 0.0047  (0.007312079693408723)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:54:15 -- STEP: 72/406 -- GLOBAL_STEP: 14275\u001b[0m\n",
      "     | > loss: 0.44033578038215637  (0.44648124153415364)\n",
      "     | > log_mle: -0.01912522315979004  (-0.02284746865431467)\n",
      "     | > loss_dur: 0.4594610035419464  (0.4693287101884683)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.2580, device='cuda:0')  (tensor(2.3898, device='cuda:0'))\n",
      "     | > current_lr: 4.749999999999999e-06 \n",
      "     | > step_time: 0.7437  (0.5379981133672926)\n",
      "     | > loader_time: 0.0125  (0.008822765615251329)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:54:30 -- STEP: 97/406 -- GLOBAL_STEP: 14300\u001b[0m\n",
      "     | > loss: 0.44363319873809814  (0.4429567662096515)\n",
      "     | > log_mle: -0.03617584705352783  (-0.02680663472598361)\n",
      "     | > loss_dur: 0.479809045791626  (0.4697634009356351)\n",
      "     | > amp_scaler: 32768.0  (63509.113402061856)\n",
      "     | > grad_norm: tensor(4.9525, device='cuda:0')  (tensor(2.9270, device='cuda:0'))\n",
      "     | > current_lr: 4.749999999999999e-06 \n",
      "     | > step_time: 0.7938  (0.551240173811765)\n",
      "     | > loader_time: 0.004  (0.00907189575667233)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:54:46 -- STEP: 122/406 -- GLOBAL_STEP: 14325\u001b[0m\n",
      "     | > loss: 0.42256274819374084  (0.4405695439362135)\n",
      "     | > log_mle: -0.033930420875549316  (-0.029868674082834213)\n",
      "     | > loss_dur: 0.45649316906929016  (0.4704382180190477)\n",
      "     | > amp_scaler: 32768.0  (57209.70491803279)\n",
      "     | > grad_norm: tensor(1.0613, device='cuda:0')  (tensor(3.2259, device='cuda:0'))\n",
      "     | > current_lr: 4.749999999999999e-06 \n",
      "     | > step_time: 0.9494  (0.5632585638859234)\n",
      "     | > loader_time: 0.0056  (0.009082645666403846)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:55:03 -- STEP: 147/406 -- GLOBAL_STEP: 14350\u001b[0m\n",
      "     | > loss: 0.42709866166114807  (0.4392701938849728)\n",
      "     | > log_mle: -0.04309391975402832  (-0.032607572013829036)\n",
      "     | > loss_dur: 0.4701925814151764  (0.4718777658988018)\n",
      "     | > amp_scaler: 32768.0  (53052.95238095239)\n",
      "     | > grad_norm: tensor(2.6475, device='cuda:0')  (tensor(3.0204, device='cuda:0'))\n",
      "     | > current_lr: 4.749999999999999e-06 \n",
      "     | > step_time: 0.3978  (0.5766623312113238)\n",
      "     | > loader_time: 0.0052  (0.009498229643114564)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:55:20 -- STEP: 172/406 -- GLOBAL_STEP: 14375\u001b[0m\n",
      "     | > loss: 0.41840529441833496  (0.4384296931499659)\n",
      "     | > log_mle: -0.048684656620025635  (-0.034736792708552164)\n",
      "     | > loss_dur: 0.4670899510383606  (0.473166485858518)\n",
      "     | > amp_scaler: 32768.0  (50104.55813953489)\n",
      "     | > grad_norm: tensor(1.8827, device='cuda:0')  (tensor(2.8858, device='cuda:0'))\n",
      "     | > current_lr: 4.749999999999999e-06 \n",
      "     | > step_time: 0.8183  (0.5914056495178581)\n",
      "     | > loader_time: 0.0072  (0.009717199691506313)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:55:37 -- STEP: 197/406 -- GLOBAL_STEP: 14400\u001b[0m\n",
      "     | > loss: 0.41937482357025146  (0.4370961290628172)\n",
      "     | > log_mle: -0.047661662101745605  (-0.03679104262802203)\n",
      "     | > loss_dur: 0.46703648567199707  (0.4738871716908392)\n",
      "     | > amp_scaler: 32768.0  (47904.48730964468)\n",
      "     | > grad_norm: tensor(1.7635, device='cuda:0')  (tensor(2.9016, device='cuda:0'))\n",
      "     | > current_lr: 4.749999999999999e-06 \n",
      "     | > step_time: 0.6887  (0.5984344022528169)\n",
      "     | > loader_time: 0.0168  (0.010432238506181584)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:55:56 -- STEP: 222/406 -- GLOBAL_STEP: 14425\u001b[0m\n",
      "     | > loss: 0.4206739664077759  (0.43519992213528436)\n",
      "     | > log_mle: -0.052263498306274414  (-0.03870194506000828)\n",
      "     | > loss_dur: 0.4729374647140503  (0.47390186719529265)\n",
      "     | > amp_scaler: 32768.0  (46199.927927927936)\n",
      "     | > grad_norm: tensor(2.3964, device='cuda:0')  (tensor(2.8816, device='cuda:0'))\n",
      "     | > current_lr: 4.749999999999999e-06 \n",
      "     | > step_time: 1.1991  (0.6146444672936789)\n",
      "     | > loader_time: 0.0244  (0.010811299891085232)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:56:15 -- STEP: 247/406 -- GLOBAL_STEP: 14450\u001b[0m\n",
      "     | > loss: 0.42152273654937744  (0.43381652404904847)\n",
      "     | > log_mle: -0.04078179597854614  (-0.0404457925302297)\n",
      "     | > loss_dur: 0.4623045325279236  (0.4742623165792782)\n",
      "     | > amp_scaler: 32768.0  (44840.42105263159)\n",
      "     | > grad_norm: tensor(2.1399, device='cuda:0')  (tensor(2.8394, device='cuda:0'))\n",
      "     | > current_lr: 4.749999999999999e-06 \n",
      "     | > step_time: 0.766  (0.6280686015542217)\n",
      "     | > loader_time: 0.0507  (0.011623981993208042)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:56:34 -- STEP: 272/406 -- GLOBAL_STEP: 14475\u001b[0m\n",
      "     | > loss: 0.4160239100456238  (0.4325182642787695)\n",
      "     | > log_mle: -0.06762123107910156  (-0.04212074222810128)\n",
      "     | > loss_dur: 0.48364514112472534  (0.4746390065068708)\n",
      "     | > amp_scaler: 32768.0  (43730.82352941177)\n",
      "     | > grad_norm: tensor(9.3091, device='cuda:0')  (tensor(2.9743, device='cuda:0'))\n",
      "     | > current_lr: 4.749999999999999e-06 \n",
      "     | > step_time: 0.4957  (0.6395631239694705)\n",
      "     | > loader_time: 0.0063  (0.011627030723235182)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:56:53 -- STEP: 297/406 -- GLOBAL_STEP: 14500\u001b[0m\n",
      "     | > loss: 0.4037667214870453  (0.4310691737968111)\n",
      "     | > log_mle: -0.058119118213653564  (-0.04341531863517634)\n",
      "     | > loss_dur: 0.46188583970069885  (0.4744844924319874)\n",
      "     | > amp_scaler: 32768.0  (42808.02693602694)\n",
      "     | > grad_norm: tensor(4.5083, device='cuda:0')  (tensor(3.0230, device='cuda:0'))\n",
      "     | > current_lr: 4.749999999999999e-06 \n",
      "     | > step_time: 1.1016  (0.6484647029979459)\n",
      "     | > loader_time: 0.0225  (0.011866000364926525)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:57:13 -- STEP: 322/406 -- GLOBAL_STEP: 14525\u001b[0m\n",
      "     | > loss: 0.4081690311431885  (0.42977022847033436)\n",
      "     | > log_mle: -0.060733795166015625  (-0.04465692661563805)\n",
      "     | > loss_dur: 0.4689028263092041  (0.4744271550859724)\n",
      "     | > amp_scaler: 32768.0  (42028.52173913043)\n",
      "     | > grad_norm: tensor(2.9238, device='cuda:0')  (tensor(3.0356, device='cuda:0'))\n",
      "     | > current_lr: 4.749999999999999e-06 \n",
      "     | > step_time: 0.9924  (0.6566054413777698)\n",
      "     | > loader_time: 0.0255  (0.012086205600951767)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:57:32 -- STEP: 347/406 -- GLOBAL_STEP: 14550\u001b[0m\n",
      "     | > loss: 0.3973027765750885  (0.4287007450198578)\n",
      "     | > log_mle: -0.05975675582885742  (-0.04589843853062784)\n",
      "     | > loss_dur: 0.4570595324039459  (0.47459918355048564)\n",
      "     | > amp_scaler: 32768.0  (41361.33717579252)\n",
      "     | > grad_norm: tensor(8.8897, device='cuda:0')  (tensor(3.0767, device='cuda:0'))\n",
      "     | > current_lr: 4.749999999999999e-06 \n",
      "     | > step_time: 0.5749  (0.6631594398179724)\n",
      "     | > loader_time: 0.0063  (0.012532717899905156)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:57:54 -- STEP: 372/406 -- GLOBAL_STEP: 14575\u001b[0m\n",
      "     | > loss: 0.4187481999397278  (0.4273290792780538)\n",
      "     | > log_mle: -0.056823551654815674  (-0.047152031813898376)\n",
      "     | > loss_dur: 0.47557175159454346  (0.4744811110919522)\n",
      "     | > amp_scaler: 32768.0  (40783.827956989255)\n",
      "     | > grad_norm: tensor(11.3381, device='cuda:0')  (tensor(3.3348, device='cuda:0'))\n",
      "     | > current_lr: 4.749999999999999e-06 \n",
      "     | > step_time: 0.8645  (0.6763935877430822)\n",
      "     | > loader_time: 0.0207  (0.012708015339348903)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:58:13 -- STEP: 397/406 -- GLOBAL_STEP: 14600\u001b[0m\n",
      "     | > loss: 0.40059971809387207  (0.4259271319927437)\n",
      "     | > log_mle: -0.07369381189346313  (-0.04832570769024134)\n",
      "     | > loss_dur: 0.4742935299873352  (0.47425283968298504)\n",
      "     | > amp_scaler: 32768.0  (40279.05289672544)\n",
      "     | > grad_norm: tensor(6.5904, device='cuda:0')  (tensor(3.5021, device='cuda:0'))\n",
      "     | > current_lr: 4.749999999999999e-06 \n",
      "     | > step_time: 0.5216  (0.6813092892356122)\n",
      "     | > loader_time: 0.0059  (0.012759235103424608)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: 0.4118615984916687  (0.4118615984916687)\n",
      "     | > log_mle: -0.0333823561668396  (-0.0333823561668396)\n",
      "     | > loss_dur: 0.4452439546585083  (0.4452439546585083)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: 0.3798059821128845  (0.3798059821128845)\n",
      "     | > log_mle: -0.06639426946640015  (-0.06639426946640015)\n",
      "     | > loss_dur: 0.44620025157928467  (0.44620025157928467)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: 0.4183489978313446  (0.39907748997211456)\n",
      "     | > log_mle: -0.027177870273590088  (-0.04678606986999512)\n",
      "     | > loss_dur: 0.4455268681049347  (0.4458635598421097)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: 0.3829491436481476  (0.39370137453079224)\n",
      "     | > log_mle: -0.04494738578796387  (-0.0461731751759847)\n",
      "     | > loss_dur: 0.42789652943611145  (0.4398745497067769)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: 0.3609969913959503  (0.38552527874708176)\n",
      "     | > log_mle: -0.07509076595306396  (-0.05340257287025452)\n",
      "     | > loss_dur: 0.4360877573490143  (0.4389278516173363)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: 0.40379929542541504  (0.3891800820827484)\n",
      "     | > log_mle: -0.07780057191848755  (-0.05828217267990112)\n",
      "     | > loss_dur: 0.4815998673439026  (0.44746225476264956)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: 0.4153696298599243  (0.3935450067122777)\n",
      "     | > log_mle: -0.08642029762268066  (-0.06297186017036438)\n",
      "     | > loss_dur: 0.501789927482605  (0.4565168668826421)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: 0.41877517104148865  (0.397149315902165)\n",
      "     | > log_mle: -0.050408005714416504  (-0.06117702381951468)\n",
      "     | > loss_dur: 0.46918317675590515  (0.4583263397216797)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: 0.39944273233413696  (0.3974359929561615)\n",
      "     | > log_mle: -0.055972933769226074  (-0.06052651256322861)\n",
      "     | > loss_dur: 0.45541566610336304  (0.4579625055193901)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: 0.43564969301223755  (0.40168195962905884)\n",
      "     | > log_mle: -0.06574869155883789  (-0.06110675467385186)\n",
      "     | > loss_dur: 0.5013983845710754  (0.4627887143029107)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: 0.4007662236690521  (0.4015903860330582)\n",
      "     | > log_mle: -0.05663859844207764  (-0.06065993905067444)\n",
      "     | > loss_dur: 0.45740482211112976  (0.4622503250837326)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: 0.3866553008556366  (0.40023265101692895)\n",
      "     | > log_mle: -0.07060098648071289  (-0.06156367063522339)\n",
      "     | > loss_dur: 0.4572562873363495  (0.46179632165215234)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: 0.3976711928844452  (0.40001919617255527)\n",
      "     | > log_mle: -0.05955237150192261  (-0.06139606237411499)\n",
      "     | > loss_dur: 0.4572235643863678  (0.46141525854667026)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: 0.3725302219390869  (0.3979046596930577)\n",
      "     | > log_mle: -0.07656145095825195  (-0.06256263072674091)\n",
      "     | > loss_dur: 0.44909167289733887  (0.4604672904197986)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: 0.38232678174972534  (0.39679195412567686)\n",
      "     | > log_mle: -0.06973510980606079  (-0.06307495066097804)\n",
      "     | > loss_dur: 0.45206189155578613  (0.4598669047866549)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: 0.3971560597419739  (0.39681622783342996)\n",
      "     | > log_mle: -0.06430238485336304  (-0.06315677960713705)\n",
      "     | > loss_dur: 0.4614584445953369  (0.459973007440567)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: 0.39275097846984863  (0.39656214974820614)\n",
      "     | > log_mle: -0.058751046657562256  (-0.06288142129778862)\n",
      "     | > loss_dur: 0.4515020251274109  (0.45944357104599476)\n",
      "\n",
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[91m 0.004576727747917175 \u001b[0m(+0.001176983118057251)\n",
      "     | > avg_loss:\u001b[92m 0.39656214974820614 \u001b[0m(-0.04272926039993763)\n",
      "     | > avg_log_mle:\u001b[92m -0.06288142129778862 \u001b[0m(-0.015203643590211868)\n",
      "     | > avg_loss_dur:\u001b[92m 0.45944357104599476 \u001b[0m(-0.02752561680972576)\n",
      "\n",
      " > BEST MODEL : train/run-February-22-2025_02+19AM-9b6e3e6/best_model_14609.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 20/40\u001b[0m\n",
      " --> train/run-February-22-2025_02+19AM-9b6e3e6\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-22 03:58:34) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:58:43 -- STEP: 16/406 -- GLOBAL_STEP: 14625\u001b[0m\n",
      "     | > loss: 0.41289570927619934  (0.4093863032758236)\n",
      "     | > log_mle: -0.03704041242599487  (-0.033242709934711456)\n",
      "     | > loss_dur: 0.4499361217021942  (0.44262901321053505)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.5210, device='cuda:0')  (tensor(1.6287, device='cuda:0'))\n",
      "     | > current_lr: 4.9999999999999996e-06 \n",
      "     | > step_time: 0.4473  (0.3674720227718353)\n",
      "     | > loader_time: 0.0052  (0.006148800253868103)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:58:58 -- STEP: 41/406 -- GLOBAL_STEP: 14650\u001b[0m\n",
      "     | > loss: 0.406344473361969  (0.4095251044122184)\n",
      "     | > log_mle: -0.03402447700500488  (-0.032950920302693434)\n",
      "     | > loss_dur: 0.4403689503669739  (0.4424760247149119)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.0264, device='cuda:0')  (tensor(1.6436, device='cuda:0'))\n",
      "     | > current_lr: 4.9999999999999996e-06 \n",
      "     | > step_time: 0.7772  (0.5144376929213361)\n",
      "     | > loader_time: 0.0042  (0.008510269769808142)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:59:13 -- STEP: 66/406 -- GLOBAL_STEP: 14675\u001b[0m\n",
      "     | > loss: 0.4201758801937103  (0.40642644555279706)\n",
      "     | > log_mle: -0.04681956768035889  (-0.036474333568052804)\n",
      "     | > loss_dur: 0.4669954478740692  (0.44290077912084985)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.1871, device='cuda:0')  (tensor(1.8339, device='cuda:0'))\n",
      "     | > current_lr: 4.9999999999999996e-06 \n",
      "     | > step_time: 0.7612  (0.5410215637900613)\n",
      "     | > loader_time: 0.0042  (0.008972027085044167)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:59:29 -- STEP: 91/406 -- GLOBAL_STEP: 14700\u001b[0m\n",
      "     | > loss: 0.3994402587413788  (0.4031851589679718)\n",
      "     | > log_mle: -0.05893439054489136  (-0.040247885080484234)\n",
      "     | > loss_dur: 0.45837464928627014  (0.44343304404845607)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(1.7342, device='cuda:0')  (tensor(1.9246, device='cuda:0'))\n",
      "     | > current_lr: 4.9999999999999996e-06 \n",
      "     | > step_time: 0.3453  (0.5638829875778364)\n",
      "     | > loader_time: 0.0047  (0.00867851749881283)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 03:59:44 -- STEP: 116/406 -- GLOBAL_STEP: 14725\u001b[0m\n",
      "     | > loss: 0.3989788889884949  (0.40062230825424194)\n",
      "     | > log_mle: -0.04830116033554077  (-0.04362782373510557)\n",
      "     | > loss_dur: 0.44728004932403564  (0.44425013198934754)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(7.3778, device='cuda:0')  (tensor(2.5284, device='cuda:0'))\n",
      "     | > current_lr: 4.9999999999999996e-06 \n",
      "     | > step_time: 0.4714  (0.5702981291146114)\n",
      "     | > loader_time: 0.0052  (0.009285630850956357)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:00:00 -- STEP: 141/406 -- GLOBAL_STEP: 14750\u001b[0m\n",
      "     | > loss: 0.3998134732246399  (0.3986896346224115)\n",
      "     | > log_mle: -0.06266254186630249  (-0.04651091200240115)\n",
      "     | > loss_dur: 0.4624760150909424  (0.4452005466248127)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(3.2969, device='cuda:0')  (tensor(2.7815, device='cuda:0'))\n",
      "     | > current_lr: 4.9999999999999996e-06 \n",
      "     | > step_time: 0.3578  (0.578606942021255)\n",
      "     | > loader_time: 0.027  (0.009490312413966404)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:00:17 -- STEP: 166/406 -- GLOBAL_STEP: 14775\u001b[0m\n",
      "     | > loss: 0.38496050238609314  (0.3971035940101348)\n",
      "     | > log_mle: -0.06655269861221313  (-0.04866489588496196)\n",
      "     | > loss_dur: 0.4515132009983063  (0.44576848989509676)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.3499, device='cuda:0')  (tensor(2.8831, device='cuda:0'))\n",
      "     | > current_lr: 4.9999999999999996e-06 \n",
      "     | > step_time: 0.8981  (0.5880052282149535)\n",
      "     | > loader_time: 0.0052  (0.010075221578758885)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:00:34 -- STEP: 191/406 -- GLOBAL_STEP: 14800\u001b[0m\n",
      "     | > loss: 0.3688187301158905  (0.39563424924281254)\n",
      "     | > log_mle: -0.05872839689254761  (-0.05064577706821301)\n",
      "     | > loss_dur: 0.4275471270084381  (0.4462800263110256)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.0205, device='cuda:0')  (tensor(2.9053, device='cuda:0'))\n",
      "     | > current_lr: 4.9999999999999996e-06 \n",
      "     | > step_time: 0.7646  (0.5970003480062439)\n",
      "     | > loader_time: 0.022  (0.010726852566783969)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:00:51 -- STEP: 216/406 -- GLOBAL_STEP: 14825\u001b[0m\n",
      "     | > loss: 0.38059794902801514  (0.3936406048359694)\n",
      "     | > log_mle: -0.07503467798233032  (-0.05234573781490325)\n",
      "     | > loss_dur: 0.45563262701034546  (0.44598634265087267)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(5.9857, device='cuda:0')  (tensor(2.9429, device='cuda:0'))\n",
      "     | > current_lr: 4.9999999999999996e-06 \n",
      "     | > step_time: 0.6482  (0.6079024109575484)\n",
      "     | > loader_time: 0.0062  (0.011115824734723131)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:01:08 -- STEP: 241/406 -- GLOBAL_STEP: 14850\u001b[0m\n",
      "     | > loss: 0.382791668176651  (0.39260888619046985)\n",
      "     | > log_mle: -0.06400173902511597  (-0.05407806971261115)\n",
      "     | > loss_dur: 0.44679340720176697  (0.446686955903081)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.3746, device='cuda:0')  (tensor(3.0071, device='cuda:0'))\n",
      "     | > current_lr: 4.9999999999999996e-06 \n",
      "     | > step_time: 0.7256  (0.6136033535003662)\n",
      "     | > loader_time: 0.0171  (0.011208315607917758)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:01:27 -- STEP: 266/406 -- GLOBAL_STEP: 14875\u001b[0m\n",
      "     | > loss: 0.37711185216903687  (0.39125976246550564)\n",
      "     | > log_mle: -0.06966471672058105  (-0.05562854530219744)\n",
      "     | > loss_dur: 0.4467765688896179  (0.4468883077677031)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(4.3575, device='cuda:0')  (tensor(3.1193, device='cuda:0'))\n",
      "     | > current_lr: 4.9999999999999996e-06 \n",
      "     | > step_time: 0.7492  (0.6235830667323636)\n",
      "     | > loader_time: 0.0058  (0.011317521109616849)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:01:46 -- STEP: 291/406 -- GLOBAL_STEP: 14900\u001b[0m\n",
      "     | > loss: 0.3692840337753296  (0.389900847194121)\n",
      "     | > log_mle: -0.06685066223144531  (-0.057043330980740055)\n",
      "     | > loss_dur: 0.4361346960067749  (0.4469441781748611)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(3.0589, device='cuda:0')  (tensor(3.2630, device='cuda:0'))\n",
      "     | > current_lr: 4.9999999999999996e-06 \n",
      "     | > step_time: 0.5855  (0.6335047479347675)\n",
      "     | > loader_time: 0.0062  (0.011680976631715132)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:02:05 -- STEP: 316/406 -- GLOBAL_STEP: 14925\u001b[0m\n",
      "     | > loss: 0.37499552965164185  (0.38870827231226085)\n",
      "     | > log_mle: -0.079204261302948  (-0.05834873944898195)\n",
      "     | > loss_dur: 0.45419979095458984  (0.44705701176124285)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(5.9299, device='cuda:0')  (tensor(3.2622, device='cuda:0'))\n",
      "     | > current_lr: 4.9999999999999996e-06 \n",
      "     | > step_time: 0.4756  (0.6416737520242042)\n",
      "     | > loader_time: 0.0304  (0.012182001071640218)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:02:25 -- STEP: 341/406 -- GLOBAL_STEP: 14950\u001b[0m\n",
      "     | > loss: 0.36248883605003357  (0.38774106404648484)\n",
      "     | > log_mle: -0.07565265893936157  (-0.05947230778132016)\n",
      "     | > loss_dur: 0.43814149498939514  (0.44721337182780513)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(3.8159, device='cuda:0')  (tensor(3.2752, device='cuda:0'))\n",
      "     | > current_lr: 4.9999999999999996e-06 \n",
      "     | > step_time: 0.5862  (0.6520177723725172)\n",
      "     | > loader_time: 0.0062  (0.012354671081140255)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:02:45 -- STEP: 366/406 -- GLOBAL_STEP: 14975\u001b[0m\n",
      "     | > loss: 0.35492491722106934  (0.3863958915888936)\n",
      "     | > log_mle: -0.08315646648406982  (-0.06077822179742198)\n",
      "     | > loss_dur: 0.43808138370513916  (0.44717411338631574)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(4.1075, device='cuda:0')  (tensor(3.3903, device='cuda:0'))\n",
      "     | > current_lr: 4.9999999999999996e-06 \n",
      "     | > step_time: 0.921  (0.6618220877777682)\n",
      "     | > loader_time: 0.0299  (0.012846009327414268)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:03:07 -- STEP: 391/406 -- GLOBAL_STEP: 15000\u001b[0m\n",
      "     | > loss: 0.36746466159820557  (0.38506370195952205)\n",
      "     | > log_mle: -0.08628928661346436  (-0.06195222005209959)\n",
      "     | > loss_dur: 0.4537539482116699  (0.44701592201162177)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(4.9545, device='cuda:0')  (tensor(3.4229, device='cuda:0'))\n",
      "     | > current_lr: 4.9999999999999996e-06 \n",
      "     | > step_time: 0.6143  (0.6728778415933593)\n",
      "     | > loader_time: 0.0085  (0.013230231716809685)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: 0.35554495453834534  (0.35554495453834534)\n",
      "     | > log_mle: -0.04704582691192627  (-0.04704582691192627)\n",
      "     | > loss_dur: 0.4025907814502716  (0.4025907814502716)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: 0.3452661335468292  (0.3452661335468292)\n",
      "     | > log_mle: -0.08089810609817505  (-0.08089810609817505)\n",
      "     | > loss_dur: 0.4261642396450043  (0.4261642396450043)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: 0.3904551565647125  (0.3678606450557709)\n",
      "     | > log_mle: -0.041610538959503174  (-0.06125432252883911)\n",
      "     | > loss_dur: 0.4320656955242157  (0.42911496758461)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: 0.34830713272094727  (0.36134280761082965)\n",
      "     | > log_mle: -0.05892181396484375  (-0.06047681967417399)\n",
      "     | > loss_dur: 0.407228946685791  (0.42181962728500366)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: 0.3275415003299713  (0.3528924807906151)\n",
      "     | > log_mle: -0.08876574039459229  (-0.06754904985427856)\n",
      "     | > loss_dur: 0.4163072407245636  (0.42044153064489365)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: 0.3757912218570709  (0.35747222900390624)\n",
      "     | > log_mle: -0.0915381908416748  (-0.07234687805175781)\n",
      "     | > loss_dur: 0.4673294126987457  (0.42981910705566406)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: 0.38760823011398315  (0.36249489585558575)\n",
      "     | > log_mle: -0.10017585754394531  (-0.07698504130045573)\n",
      "     | > loss_dur: 0.48778408765792847  (0.43947993715604144)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: 0.3522036373615265  (0.3610247160707201)\n",
      "     | > log_mle: -0.06438934803009033  (-0.07518565654754639)\n",
      "     | > loss_dur: 0.4165929853916168  (0.4362103726182665)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: 0.3503781259059906  (0.35969389230012894)\n",
      "     | > log_mle: -0.06972670555114746  (-0.07450328767299652)\n",
      "     | > loss_dur: 0.42010483145713806  (0.43419717997312546)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: 0.3873496353626251  (0.3627667526404063)\n",
      "     | > log_mle: -0.07991611957550049  (-0.0751047134399414)\n",
      "     | > loss_dur: 0.4672657549381256  (0.4378714660803477)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: 0.34508341550827026  (0.3609984189271927)\n",
      "     | > log_mle: -0.07035380601882935  (-0.0746296226978302)\n",
      "     | > loss_dur: 0.4154372215270996  (0.4356280416250229)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: 0.3402349650859833  (0.35911083221435547)\n",
      "     | > log_mle: -0.0844264030456543  (-0.07552023909308693)\n",
      "     | > loss_dur: 0.4246613681316376  (0.4346310713074424)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: 0.35743436217308044  (0.35897112637758255)\n",
      "     | > log_mle: -0.07344096899032593  (-0.07534696658452351)\n",
      "     | > loss_dur: 0.43087533116340637  (0.43431809296210605)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: 0.32181990146636963  (0.3561133398459508)\n",
      "     | > log_mle: -0.09101569652557373  (-0.07655225350306584)\n",
      "     | > loss_dur: 0.41283559799194336  (0.4326655933490166)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: 0.350671648979187  (0.35572464764118195)\n",
      "     | > log_mle: -0.08385396003723145  (-0.07707380396979195)\n",
      "     | > loss_dur: 0.43452560901641846  (0.4327984516109739)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: 0.3689909875392914  (0.35660907030105593)\n",
      "     | > log_mle: -0.0784461498260498  (-0.07716529369354248)\n",
      "     | > loss_dur: 0.4474371373653412  (0.4337743639945984)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: 0.35315924882888794  (0.3563934564590454)\n",
      "     | > log_mle: -0.07281959056854248  (-0.07689368724822998)\n",
      "     | > loss_dur: 0.4259788393974304  (0.4332871437072754)\n",
      "\n",
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.003669947385787964 \u001b[0m(-0.0009067803621292114)\n",
      "     | > avg_loss:\u001b[92m 0.3563934564590454 \u001b[0m(-0.04016869328916073)\n",
      "     | > avg_log_mle:\u001b[92m -0.07689368724822998 \u001b[0m(-0.01401226595044136)\n",
      "     | > avg_loss_dur:\u001b[92m 0.4332871437072754 \u001b[0m(-0.026156427338719368)\n",
      "\n",
      " > BEST MODEL : train/run-February-22-2025_02+19AM-9b6e3e6/best_model_15015.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 21/40\u001b[0m\n",
      " --> train/run-February-22-2025_02+19AM-9b6e3e6\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-22 04:03:29) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:03:35 -- STEP: 10/406 -- GLOBAL_STEP: 15025\u001b[0m\n",
      "     | > loss: 0.3486236035823822  (0.36211203038692474)\n",
      "     | > log_mle: -0.04861319065093994  (-0.044254010915756224)\n",
      "     | > loss_dur: 0.39723679423332214  (0.40636604130268095)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(0.9955, device='cuda:0')  (tensor(1.7619, device='cuda:0'))\n",
      "     | > current_lr: 5.25e-06 \n",
      "     | > step_time: 0.4206  (0.38516602516174314)\n",
      "     | > loader_time: 0.004  (0.005086493492126465)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:03:49 -- STEP: 35/406 -- GLOBAL_STEP: 15050\u001b[0m\n",
      "     | > loss: 0.33653998374938965  (0.3667915804045541)\n",
      "     | > log_mle: -0.059231579303741455  (-0.047251803534371514)\n",
      "     | > loss_dur: 0.3957715630531311  (0.4140433839389256)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(1.9114, device='cuda:0')  (tensor(1.9227, device='cuda:0'))\n",
      "     | > current_lr: 5.25e-06 \n",
      "     | > step_time: 0.9325  (0.498550135748727)\n",
      "     | > loader_time: 0.0146  (0.007693174907139369)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:04:04 -- STEP: 60/406 -- GLOBAL_STEP: 15075\u001b[0m\n",
      "     | > loss: 0.34563368558883667  (0.3658762375513713)\n",
      "     | > log_mle: -0.05784475803375244  (-0.04988367259502411)\n",
      "     | > loss_dur: 0.4034784436225891  (0.41575991014639535)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(3.0157, device='cuda:0')  (tensor(2.3110, device='cuda:0'))\n",
      "     | > current_lr: 5.25e-06 \n",
      "     | > step_time: 0.486  (0.5326425274213152)\n",
      "     | > loader_time: 0.0048  (0.008931306997934981)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:04:19 -- STEP: 85/406 -- GLOBAL_STEP: 15100\u001b[0m\n",
      "     | > loss: 0.33121389150619507  (0.36238628380438853)\n",
      "     | > log_mle: -0.07849687337875366  (-0.05330665111541748)\n",
      "     | > loss_dur: 0.40971076488494873  (0.4156929349198061)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(8.8993, device='cuda:0')  (tensor(3.0724, device='cuda:0'))\n",
      "     | > current_lr: 5.25e-06 \n",
      "     | > step_time: 0.4243  (0.5523888644050149)\n",
      "     | > loader_time: 0.0052  (0.00927256135379567)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:04:35 -- STEP: 110/406 -- GLOBAL_STEP: 15125\u001b[0m\n",
      "     | > loss: 0.3660552501678467  (0.3598089231686158)\n",
      "     | > log_mle: -0.07916146516799927  (-0.05658023465763439)\n",
      "     | > loss_dur: 0.44521671533584595  (0.41638915782625024)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(4.4767, device='cuda:0')  (tensor(3.2125, device='cuda:0'))\n",
      "     | > current_lr: 5.25e-06 \n",
      "     | > step_time: 0.7529  (0.5658374179493297)\n",
      "     | > loader_time: 0.0046  (0.00932512716813521)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:04:51 -- STEP: 135/406 -- GLOBAL_STEP: 15150\u001b[0m\n",
      "     | > loss: 0.3513143062591553  (0.3579826277715188)\n",
      "     | > log_mle: -0.07407855987548828  (-0.05953357881969876)\n",
      "     | > loss_dur: 0.42539286613464355  (0.4175162065912176)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(5.3605, device='cuda:0')  (tensor(3.3767, device='cuda:0'))\n",
      "     | > current_lr: 5.25e-06 \n",
      "     | > step_time: 0.6548  (0.5788740687900119)\n",
      "     | > loader_time: 0.005  (0.009758285239890769)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:05:08 -- STEP: 160/406 -- GLOBAL_STEP: 15175\u001b[0m\n",
      "     | > loss: 0.35906335711479187  (0.3573862137272953)\n",
      "     | > log_mle: -0.07631343603134155  (-0.06169468834996224)\n",
      "     | > loss_dur: 0.4353767931461334  (0.4190809020772576)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(1.2440, device='cuda:0')  (tensor(3.2415, device='cuda:0'))\n",
      "     | > current_lr: 5.25e-06 \n",
      "     | > step_time: 0.6956  (0.5930126428604127)\n",
      "     | > loader_time: 0.0102  (0.010227492451667788)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:05:26 -- STEP: 185/406 -- GLOBAL_STEP: 15200\u001b[0m\n",
      "     | > loss: 0.33327093720436096  (0.35651581045743574)\n",
      "     | > log_mle: -0.08193707466125488  (-0.06368564560606672)\n",
      "     | > loss_dur: 0.41520801186561584  (0.42020145606350257)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(4.7798, device='cuda:0')  (tensor(3.3296, device='cuda:0'))\n",
      "     | > current_lr: 5.25e-06 \n",
      "     | > step_time: 0.5906  (0.6052511318309889)\n",
      "     | > loader_time: 0.0051  (0.010195201152079815)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:05:43 -- STEP: 210/406 -- GLOBAL_STEP: 15225\u001b[0m\n",
      "     | > loss: 0.3189842402935028  (0.35474725039232335)\n",
      "     | > log_mle: -0.07845479249954224  (-0.06543464036214919)\n",
      "     | > loss_dur: 0.39743903279304504  (0.42018189075447265)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.9886, device='cuda:0')  (tensor(3.3169, device='cuda:0'))\n",
      "     | > current_lr: 5.25e-06 \n",
      "     | > step_time: 0.4509  (0.6132944572539558)\n",
      "     | > loader_time: 0.0067  (0.010278286252702986)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:06:02 -- STEP: 235/406 -- GLOBAL_STEP: 15250\u001b[0m\n",
      "     | > loss: 0.3352983295917511  (0.35362600392483645)\n",
      "     | > log_mle: -0.07745641469955444  (-0.06728558210616414)\n",
      "     | > loss_dur: 0.41275474429130554  (0.42091158603100065)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(1.6282, device='cuda:0')  (tensor(3.2458, device='cuda:0'))\n",
      "     | > current_lr: 5.25e-06 \n",
      "     | > step_time: 0.9119  (0.6277765121865782)\n",
      "     | > loader_time: 0.0085  (0.010726086636807056)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:06:21 -- STEP: 260/406 -- GLOBAL_STEP: 15275\u001b[0m\n",
      "     | > loss: 0.34486639499664307  (0.35212412270215837)\n",
      "     | > log_mle: -0.09101521968841553  (-0.06887380091043618)\n",
      "     | > loss_dur: 0.4358816146850586  (0.4209979236125946)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(7.7408, device='cuda:0')  (tensor(3.3207, device='cuda:0'))\n",
      "     | > current_lr: 5.25e-06 \n",
      "     | > step_time: 1.2333  (0.6377165638483488)\n",
      "     | > loader_time: 0.0283  (0.010881601847135103)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:06:40 -- STEP: 285/406 -- GLOBAL_STEP: 15300\u001b[0m\n",
      "     | > loss: 0.32958874106407166  (0.35068933838292166)\n",
      "     | > log_mle: -0.07825177907943726  (-0.07025616336287113)\n",
      "     | > loss_dur: 0.4078405201435089  (0.42094550174579287)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(4.7193, device='cuda:0')  (tensor(3.4536, device='cuda:0'))\n",
      "     | > current_lr: 5.25e-06 \n",
      "     | > step_time: 0.5823  (0.6476211096111099)\n",
      "     | > loader_time: 0.0065  (0.010988043065656695)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:06:59 -- STEP: 310/406 -- GLOBAL_STEP: 15325\u001b[0m\n",
      "     | > loss: 0.3221527338027954  (0.3496074224672011)\n",
      "     | > log_mle: -0.08671998977661133  (-0.07146610809910685)\n",
      "     | > loss_dur: 0.40887272357940674  (0.42107353056630764)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(5.0852, device='cuda:0')  (tensor(3.5655, device='cuda:0'))\n",
      "     | > current_lr: 5.25e-06 \n",
      "     | > step_time: 0.8956  (0.655193602654242)\n",
      "     | > loader_time: 0.0218  (0.011163964579182289)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:07:19 -- STEP: 335/406 -- GLOBAL_STEP: 15350\u001b[0m\n",
      "     | > loss: 0.3439231812953949  (0.34876912147251543)\n",
      "     | > log_mle: -0.09111487865447998  (-0.0726033150260128)\n",
      "     | > loss_dur: 0.4350380599498749  (0.4213724364985279)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(5.3305, device='cuda:0')  (tensor(3.6089, device='cuda:0'))\n",
      "     | > current_lr: 5.25e-06 \n",
      "     | > step_time: 0.8087  (0.6635033408207679)\n",
      "     | > loader_time: 0.006  (0.011257748817329981)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:07:38 -- STEP: 360/406 -- GLOBAL_STEP: 15375\u001b[0m\n",
      "     | > loss: 0.31490418314933777  (0.3475978832277988)\n",
      "     | > log_mle: -0.0929940938949585  (-0.07381785760323206)\n",
      "     | > loss_dur: 0.40789827704429626  (0.42141574083103056)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(6.6373, device='cuda:0')  (tensor(3.6849, device='cuda:0'))\n",
      "     | > current_lr: 5.25e-06 \n",
      "     | > step_time: 0.5521  (0.6702349470721348)\n",
      "     | > loader_time: 0.0068  (0.011513332525889082)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:07:58 -- STEP: 385/406 -- GLOBAL_STEP: 15400\u001b[0m\n",
      "     | > loss: 0.3284132182598114  (0.3464317543166025)\n",
      "     | > log_mle: -0.08330976963043213  (-0.0749156549379423)\n",
      "     | > loss_dur: 0.41172298789024353  (0.4213474092545446)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.8322, device='cuda:0')  (tensor(3.6621, device='cuda:0'))\n",
      "     | > current_lr: 5.25e-06 \n",
      "     | > step_time: 0.6284  (0.6777833040658531)\n",
      "     | > loader_time: 0.0077  (0.011825722533387026)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: 0.3222646713256836  (0.3222646713256836)\n",
      "     | > log_mle: -0.05953514575958252  (-0.05953514575958252)\n",
      "     | > loss_dur: 0.3817998170852661  (0.3817998170852661)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: 0.2977159917354584  (0.2977159917354584)\n",
      "     | > log_mle: -0.09440696239471436  (-0.09440696239471436)\n",
      "     | > loss_dur: 0.39212295413017273  (0.39212295413017273)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: 0.35402870178222656  (0.32587234675884247)\n",
      "     | > log_mle: -0.05495405197143555  (-0.07468050718307495)\n",
      "     | > loss_dur: 0.4089827537536621  (0.4005528539419174)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: 0.30601832270622253  (0.3192543387413025)\n",
      "     | > log_mle: -0.07243931293487549  (-0.07393344243367513)\n",
      "     | > loss_dur: 0.378457635641098  (0.3931877811749776)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: 0.2893558442592621  (0.3117797151207924)\n",
      "     | > log_mle: -0.10163390636444092  (-0.08085855841636658)\n",
      "     | > loss_dur: 0.390989750623703  (0.39263827353715897)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: 0.3159617483615875  (0.3126161217689514)\n",
      "     | > log_mle: -0.10618114471435547  (-0.08592307567596436)\n",
      "     | > loss_dur: 0.422142893075943  (0.3985391974449158)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: 0.331371009349823  (0.31574193636576336)\n",
      "     | > log_mle: -0.11461830139160156  (-0.09070561329523723)\n",
      "     | > loss_dur: 0.44598931074142456  (0.40644754966100055)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: 0.3159489333629608  (0.31577150736536297)\n",
      "     | > log_mle: -0.07800161838531494  (-0.08889075687953404)\n",
      "     | > loss_dur: 0.39395055174827576  (0.40466226424489704)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: 0.30627793073654175  (0.31458481028676033)\n",
      "     | > log_mle: -0.08291864395141602  (-0.08814424276351929)\n",
      "     | > loss_dur: 0.38919657468795776  (0.4027290530502796)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: 0.3430577218532562  (0.3177484671274821)\n",
      "     | > log_mle: -0.09442019462585449  (-0.0888415707482232)\n",
      "     | > loss_dur: 0.4374779164791107  (0.4065900378757053)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: 0.32365846633911133  (0.318339467048645)\n",
      "     | > log_mle: -0.08362901210784912  (-0.08832031488418579)\n",
      "     | > loss_dur: 0.40728747844696045  (0.4066597819328308)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: 0.3045492470264435  (0.31708581068299035)\n",
      "     | > log_mle: -0.09789037704467773  (-0.0891903205351396)\n",
      "     | > loss_dur: 0.4024396240711212  (0.40627613121812994)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: 0.31353411078453064  (0.316789835691452)\n",
      "     | > log_mle: -0.08655703067779541  (-0.08897087971369426)\n",
      "     | > loss_dur: 0.40009114146232605  (0.4057607154051463)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: 0.28711017966270447  (0.3145067852277022)\n",
      "     | > log_mle: -0.10562944412231445  (-0.09025230774512658)\n",
      "     | > loss_dur: 0.3927396237850189  (0.4047590929728288)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: 0.3143500089645386  (0.3144955869231905)\n",
      "     | > log_mle: -0.09748709201812744  (-0.09076907805034093)\n",
      "     | > loss_dur: 0.411837100982666  (0.4052646649735315)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: 0.3268824517726898  (0.3153213779131571)\n",
      "     | > log_mle: -0.09217023849487305  (-0.09086248874664307)\n",
      "     | > loss_dur: 0.41905269026756287  (0.4061838666598002)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: 0.3040410876274109  (0.314616359770298)\n",
      "     | > log_mle: -0.08711361885070801  (-0.09062818437814713)\n",
      "     | > loss_dur: 0.3911547064781189  (0.40524454414844513)\n",
      "\n",
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[91m 0.006162852048873901 \u001b[0m(+0.0024929046630859375)\n",
      "     | > avg_loss:\u001b[92m 0.314616359770298 \u001b[0m(-0.041777096688747406)\n",
      "     | > avg_log_mle:\u001b[92m -0.09062818437814713 \u001b[0m(-0.013734497129917145)\n",
      "     | > avg_loss_dur:\u001b[92m 0.40524454414844513 \u001b[0m(-0.02804259955883026)\n",
      "\n",
      " > BEST MODEL : train/run-February-22-2025_02+19AM-9b6e3e6/best_model_15421.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 22/40\u001b[0m\n",
      " --> train/run-February-22-2025_02+19AM-9b6e3e6\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-22 04:08:26) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:08:31 -- STEP: 4/406 -- GLOBAL_STEP: 15425\u001b[0m\n",
      "     | > loss: 0.37564170360565186  (0.3460579365491867)\n",
      "     | > log_mle: -0.037746548652648926  (-0.055755242705345154)\n",
      "     | > loss_dur: 0.4133882522583008  (0.40181317925453186)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(1.0285, device='cuda:0')  (tensor(1.8458, device='cuda:0'))\n",
      "     | > current_lr: 5.5e-06 \n",
      "     | > step_time: 0.3599  (0.40238481760025024)\n",
      "     | > loader_time: 0.0025  (0.00535738468170166)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:08:43 -- STEP: 29/406 -- GLOBAL_STEP: 15450\u001b[0m\n",
      "     | > loss: 0.30968210101127625  (0.32897488824252424)\n",
      "     | > log_mle: -0.06707918643951416  (-0.05986233004208269)\n",
      "     | > loss_dur: 0.3767612874507904  (0.38883721828460693)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(1.3045, device='cuda:0')  (tensor(2.1100, device='cuda:0'))\n",
      "     | > current_lr: 5.5e-06 \n",
      "     | > step_time: 0.4278  (0.48032812414498166)\n",
      "     | > loader_time: 0.0145  (0.006206915296357253)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:08:59 -- STEP: 54/406 -- GLOBAL_STEP: 15475\u001b[0m\n",
      "     | > loss: 0.3233725428581238  (0.3312148070997662)\n",
      "     | > log_mle: -0.06765329837799072  (-0.06177899793342308)\n",
      "     | > loss_dur: 0.3910258412361145  (0.3929938050331892)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(1.6787, device='cuda:0')  (tensor(2.8387, device='cuda:0'))\n",
      "     | > current_lr: 5.5e-06 \n",
      "     | > step_time: 0.4783  (0.5293817166928891)\n",
      "     | > loader_time: 0.0045  (0.008319170386702924)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:09:14 -- STEP: 79/406 -- GLOBAL_STEP: 15500\u001b[0m\n",
      "     | > loss: 0.3086107671260834  (0.32789979441256467)\n",
      "     | > log_mle: -0.07715713977813721  (-0.0650999115992196)\n",
      "     | > loss_dur: 0.3857679069042206  (0.3929997060117842)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(3.8188, device='cuda:0')  (tensor(2.8384, device='cuda:0'))\n",
      "     | > current_lr: 5.5e-06 \n",
      "     | > step_time: 0.6839  (0.5499500262586376)\n",
      "     | > loader_time: 0.0047  (0.008852599542352214)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:09:29 -- STEP: 104/406 -- GLOBAL_STEP: 15525\u001b[0m\n",
      "     | > loss: 0.32051369547843933  (0.32514964445279176)\n",
      "     | > log_mle: -0.07621920108795166  (-0.06859726516100076)\n",
      "     | > loss_dur: 0.396732896566391  (0.39374690961379266)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(4.8003, device='cuda:0')  (tensor(3.0100, device='cuda:0'))\n",
      "     | > current_lr: 5.5e-06 \n",
      "     | > step_time: 0.7986  (0.5625156599741717)\n",
      "     | > loader_time: 0.0422  (0.009932380456190841)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:09:46 -- STEP: 129/406 -- GLOBAL_STEP: 15550\u001b[0m\n",
      "     | > loss: 0.29932767152786255  (0.3229422463003053)\n",
      "     | > log_mle: -0.09073781967163086  (-0.07155818209167597)\n",
      "     | > loss_dur: 0.3900654911994934  (0.39450042839198146)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(7.1018, device='cuda:0')  (tensor(3.5126, device='cuda:0'))\n",
      "     | > current_lr: 5.5e-06 \n",
      "     | > step_time: 0.5229  (0.5769534425217978)\n",
      "     | > loader_time: 0.0052  (0.009942422541537025)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:10:03 -- STEP: 154/406 -- GLOBAL_STEP: 15575\u001b[0m\n",
      "     | > loss: 0.3255575895309448  (0.3220245329203541)\n",
      "     | > log_mle: -0.06934356689453125  (-0.07376841639543506)\n",
      "     | > loss_dur: 0.3949011564254761  (0.39579294931578934)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.0445, device='cuda:0')  (tensor(3.5386, device='cuda:0'))\n",
      "     | > current_lr: 5.5e-06 \n",
      "     | > step_time: 0.3378  (0.5957479879453588)\n",
      "     | > loader_time: 0.0046  (0.009838940261246319)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:10:20 -- STEP: 179/406 -- GLOBAL_STEP: 15600\u001b[0m\n",
      "     | > loss: 0.3020845353603363  (0.32092886713629964)\n",
      "     | > log_mle: -0.09781134128570557  (-0.07570432750872391)\n",
      "     | > loss_dur: 0.39989587664604187  (0.3966331946450237)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(6.3937, device='cuda:0')  (tensor(3.5688, device='cuda:0'))\n",
      "     | > current_lr: 5.5e-06 \n",
      "     | > step_time: 0.4462  (0.6044230181411662)\n",
      "     | > loader_time: 0.0185  (0.010282549778176414)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:10:37 -- STEP: 204/406 -- GLOBAL_STEP: 15625\u001b[0m\n",
      "     | > loss: 0.3001009523868561  (0.3195452729568759)\n",
      "     | > log_mle: -0.09101951122283936  (-0.07743672646728214)\n",
      "     | > loss_dur: 0.39112046360969543  (0.39698199942415824)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(1.8683, device='cuda:0')  (tensor(3.6644, device='cuda:0'))\n",
      "     | > current_lr: 5.5e-06 \n",
      "     | > step_time: 0.9056  (0.6119379892068753)\n",
      "     | > loader_time: 0.0291  (0.010553333104825483)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:10:55 -- STEP: 229/406 -- GLOBAL_STEP: 15650\u001b[0m\n",
      "     | > loss: 0.3043540418148041  (0.3181358515955993)\n",
      "     | > log_mle: -0.08943569660186768  (-0.07920638702842343)\n",
      "     | > loss_dur: 0.39378973841667175  (0.3973422386240229)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(4.4077, device='cuda:0')  (tensor(3.5881, device='cuda:0'))\n",
      "     | > current_lr: 5.5e-06 \n",
      "     | > step_time: 0.7706  (0.6205481160676117)\n",
      "     | > loader_time: 0.0065  (0.011240223089159833)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:11:12 -- STEP: 254/406 -- GLOBAL_STEP: 15675\u001b[0m\n",
      "     | > loss: 0.29726043343544006  (0.3170261840651352)\n",
      "     | > log_mle: -0.09045398235321045  (-0.08082752903615394)\n",
      "     | > loss_dur: 0.3877144157886505  (0.3978537131012893)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(1.4477, device='cuda:0')  (tensor(3.7683, device='cuda:0'))\n",
      "     | > current_lr: 5.5e-06 \n",
      "     | > step_time: 1.1551  (0.6260782921408107)\n",
      "     | > loader_time: 0.0064  (0.011245781981100244)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:11:31 -- STEP: 279/406 -- GLOBAL_STEP: 15700\u001b[0m\n",
      "     | > loss: 0.31087827682495117  (0.3156781317298984)\n",
      "     | > log_mle: -0.08613431453704834  (-0.08214001352214469)\n",
      "     | > loss_dur: 0.3970125913619995  (0.3978181452520431)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(4.7373, device='cuda:0')  (tensor(3.9715, device='cuda:0'))\n",
      "     | > current_lr: 5.5e-06 \n",
      "     | > step_time: 0.8048  (0.6343693152123455)\n",
      "     | > loader_time: 0.0151  (0.011595777285996301)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:11:51 -- STEP: 304/406 -- GLOBAL_STEP: 15725\u001b[0m\n",
      "     | > loss: 0.2930089235305786  (0.3146869949016131)\n",
      "     | > log_mle: -0.09710955619812012  (-0.08338875303927218)\n",
      "     | > loss_dur: 0.39011847972869873  (0.39807574794088546)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(4.9995, device='cuda:0')  (tensor(4.0169, device='cuda:0'))\n",
      "     | > current_lr: 5.5e-06 \n",
      "     | > step_time: 0.6995  (0.6471904100556122)\n",
      "     | > loader_time: 0.0234  (0.011896689471445582)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:12:11 -- STEP: 329/406 -- GLOBAL_STEP: 15750\u001b[0m\n",
      "     | > loss: 0.3051380515098572  (0.31384467879327227)\n",
      "     | > log_mle: -0.0865546464920044  (-0.08440613692292326)\n",
      "     | > loss_dur: 0.3916926980018616  (0.3982508157161958)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(1.8148, device='cuda:0')  (tensor(4.0273, device='cuda:0'))\n",
      "     | > current_lr: 5.5e-06 \n",
      "     | > step_time: 0.736  (0.6552869077873807)\n",
      "     | > loader_time: 0.0152  (0.01229041977856297)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:12:31 -- STEP: 354/406 -- GLOBAL_STEP: 15775\u001b[0m\n",
      "     | > loss: 0.2885255217552185  (0.31307547998293633)\n",
      "     | > log_mle: -0.10063695907592773  (-0.08558836478298)\n",
      "     | > loss_dur: 0.38916248083114624  (0.39866384476591654)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.1031, device='cuda:0')  (tensor(3.9978, device='cuda:0'))\n",
      "     | > current_lr: 5.5e-06 \n",
      "     | > step_time: 0.5825  (0.6647516300449263)\n",
      "     | > loader_time: 0.033  (0.012548363141420871)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:12:52 -- STEP: 379/406 -- GLOBAL_STEP: 15800\u001b[0m\n",
      "     | > loss: 0.2982344627380371  (0.31176798088883967)\n",
      "     | > log_mle: -0.1025618314743042  (-0.08677177142971115)\n",
      "     | > loss_dur: 0.4007962942123413  (0.398539752318551)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(5.3671, device='cuda:0')  (tensor(4.0651, device='cuda:0'))\n",
      "     | > current_lr: 5.5e-06 \n",
      "     | > step_time: 0.5852  (0.6740439938366569)\n",
      "     | > loader_time: 0.0246  (0.01282575828733419)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:13:09 -- STEP: 404/406 -- GLOBAL_STEP: 15825\u001b[0m\n",
      "     | > loss: 0.2874135375022888  (0.310535992726241)\n",
      "     | > log_mle: -0.1012885570526123  (-0.08784379714196276)\n",
      "     | > loss_dur: 0.3887020945549011  (0.3983797898682039)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(3.0912, device='cuda:0')  (tensor(4.1366, device='cuda:0'))\n",
      "     | > current_lr: 5.5e-06 \n",
      "     | > step_time: 0.5605  (0.6734264038576937)\n",
      "     | > loader_time: 0.0063  (0.012734937195730682)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: 0.29131466150283813  (0.29131466150283813)\n",
      "     | > log_mle: -0.07105493545532227  (-0.07105493545532227)\n",
      "     | > loss_dur: 0.3623695969581604  (0.3623695969581604)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: 0.275349885225296  (0.275349885225296)\n",
      "     | > log_mle: -0.10606622695922852  (-0.10606622695922852)\n",
      "     | > loss_dur: 0.38141611218452454  (0.38141611218452454)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: 0.316866934299469  (0.2961084097623825)\n",
      "     | > log_mle: -0.06681680679321289  (-0.0864415168762207)\n",
      "     | > loss_dur: 0.3836837410926819  (0.3825499266386032)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: 0.277626097202301  (0.28994763890902203)\n",
      "     | > log_mle: -0.08374989032745361  (-0.08554430802663167)\n",
      "     | > loss_dur: 0.36137598752975464  (0.3754919469356537)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: 0.267252117395401  (0.28427375853061676)\n",
      "     | > log_mle: -0.11232078075408936  (-0.0922384262084961)\n",
      "     | > loss_dur: 0.37957289814949036  (0.37651218473911285)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: 0.2860836982727051  (0.28463574647903445)\n",
      "     | > log_mle: -0.11612260341644287  (-0.09701526165008545)\n",
      "     | > loss_dur: 0.40220630168914795  (0.3816510081291199)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: 0.30477219820022583  (0.28799182176589966)\n",
      "     | > log_mle: -0.12430703639984131  (-0.10156389077504475)\n",
      "     | > loss_dur: 0.42907923460006714  (0.3895557125409444)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: 0.2954828143119812  (0.289061963558197)\n",
      "     | > log_mle: -0.0887451171875  (-0.09973263740539551)\n",
      "     | > loss_dur: 0.3842279314994812  (0.38879460096359253)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: 0.27333807945251465  (0.2870964780449867)\n",
      "     | > log_mle: -0.09391593933105469  (-0.0990055501461029)\n",
      "     | > loss_dur: 0.36725401878356934  (0.38610202819108963)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: 0.30527007579803467  (0.2891157666842143)\n",
      "     | > log_mle: -0.10504329204559326  (-0.0996764103571574)\n",
      "     | > loss_dur: 0.41031336784362793  (0.38879217704137164)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: 0.29570984840393066  (0.2897751748561859)\n",
      "     | > log_mle: -0.09448039531707764  (-0.09915680885314941)\n",
      "     | > loss_dur: 0.3901902437210083  (0.38893198370933535)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: 0.28223997354507446  (0.2890901565551758)\n",
      "     | > log_mle: -0.10871624946594238  (-0.10002584890885786)\n",
      "     | > loss_dur: 0.39095622301101685  (0.38911600546403363)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: 0.2769794762134552  (0.28808093319336575)\n",
      "     | > log_mle: -0.09763967990875244  (-0.09982700149218242)\n",
      "     | > loss_dur: 0.37461915612220764  (0.38790793468554813)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: 0.25483438372612  (0.2855235063112699)\n",
      "     | > log_mle: -0.11618006229400635  (-0.10108492924616887)\n",
      "     | > loss_dur: 0.37101444602012634  (0.3866084355574388)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: 0.2952428162097931  (0.286217742732593)\n",
      "     | > log_mle: -0.10850918292999268  (-0.10161523308072772)\n",
      "     | > loss_dur: 0.40375199913978577  (0.3878329758133207)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: 0.29176509380340576  (0.28658756613731384)\n",
      "     | > log_mle: -0.10338318347930908  (-0.10173309644063314)\n",
      "     | > loss_dur: 0.39514827728271484  (0.388320662577947)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: 0.28327494859695435  (0.2863805275410414)\n",
      "     | > log_mle: -0.09737420082092285  (-0.10146066546440125)\n",
      "     | > loss_dur: 0.3806491494178772  (0.3878411930054426)\n",
      "\n",
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.00438515841960907 \u001b[0m(-0.0017776936292648315)\n",
      "     | > avg_loss:\u001b[92m 0.2863805275410414 \u001b[0m(-0.02823583222925663)\n",
      "     | > avg_log_mle:\u001b[92m -0.10146066546440125 \u001b[0m(-0.01083248108625412)\n",
      "     | > avg_loss_dur:\u001b[92m 0.3878411930054426 \u001b[0m(-0.01740335114300251)\n",
      "\n",
      " > BEST MODEL : train/run-February-22-2025_02+19AM-9b6e3e6/best_model_15827.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 23/40\u001b[0m\n",
      " --> train/run-February-22-2025_02+19AM-9b6e3e6\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-22 04:13:24) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:13:37 -- STEP: 23/406 -- GLOBAL_STEP: 15850\u001b[0m\n",
      "     | > loss: 0.2881169021129608  (0.30214550832043524)\n",
      "     | > log_mle: -0.0782318115234375  (-0.0703921914100647)\n",
      "     | > loss_dur: 0.3663487136363983  (0.37253769973049994)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(1.9322, device='cuda:0')  (tensor(2.7781, device='cuda:0'))\n",
      "     | > current_lr: 5.75e-06 \n",
      "     | > step_time: 0.5365  (0.4664670073467752)\n",
      "     | > loader_time: 0.0194  (0.007597218389096467)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:13:52 -- STEP: 48/406 -- GLOBAL_STEP: 15875\u001b[0m\n",
      "     | > loss: 0.3146502673625946  (0.2996104036768278)\n",
      "     | > log_mle: -0.06841731071472168  (-0.07182913646101952)\n",
      "     | > loss_dur: 0.3830675780773163  (0.37143954013784725)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(1.7580, device='cuda:0')  (tensor(2.9630, device='cuda:0'))\n",
      "     | > current_lr: 5.75e-06 \n",
      "     | > step_time: 0.5167  (0.5272922764221827)\n",
      "     | > loader_time: 0.0183  (0.009491021434466044)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:14:06 -- STEP: 73/406 -- GLOBAL_STEP: 15900\u001b[0m\n",
      "     | > loss: 0.2748517394065857  (0.2968389559282016)\n",
      "     | > log_mle: -0.092598557472229  (-0.07536074559982509)\n",
      "     | > loss_dur: 0.3674502968788147  (0.3721997015280266)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.6566, device='cuda:0')  (tensor(2.9275, device='cuda:0'))\n",
      "     | > current_lr: 5.75e-06 \n",
      "     | > step_time: 0.4206  (0.5382456387559026)\n",
      "     | > loader_time: 0.0044  (0.008724872380086818)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:14:22 -- STEP: 98/406 -- GLOBAL_STEP: 15925\u001b[0m\n",
      "     | > loss: 0.30735841393470764  (0.294063780380755)\n",
      "     | > log_mle: -0.07748556137084961  (-0.07877274496214727)\n",
      "     | > loss_dur: 0.38484397530555725  (0.37283652534290235)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(4.9399, device='cuda:0')  (tensor(3.2053, device='cuda:0'))\n",
      "     | > current_lr: 5.75e-06 \n",
      "     | > step_time: 0.3803  (0.5538405812516505)\n",
      "     | > loader_time: 0.0045  (0.0095675380862489)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:14:37 -- STEP: 123/406 -- GLOBAL_STEP: 15950\u001b[0m\n",
      "     | > loss: 0.2907096743583679  (0.29156576351421626)\n",
      "     | > log_mle: -0.10109817981719971  (-0.08178279458022696)\n",
      "     | > loss_dur: 0.3918078541755676  (0.37334855809444334)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(9.4900, device='cuda:0')  (tensor(3.5930, device='cuda:0'))\n",
      "     | > current_lr: 5.75e-06 \n",
      "     | > step_time: 0.3954  (0.5627091279843959)\n",
      "     | > loader_time: 0.0367  (0.009826016619922665)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:14:53 -- STEP: 148/406 -- GLOBAL_STEP: 15975\u001b[0m\n",
      "     | > loss: 0.2729794979095459  (0.2905115207304824)\n",
      "     | > log_mle: -0.10216844081878662  (-0.08425668365246541)\n",
      "     | > loss_dur: 0.3751479387283325  (0.374768204382948)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(1.8855, device='cuda:0')  (tensor(3.5445, device='cuda:0'))\n",
      "     | > current_lr: 5.75e-06 \n",
      "     | > step_time: 0.4614  (0.5761653974249554)\n",
      "     | > loader_time: 0.0052  (0.009896344429737807)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:15:11 -- STEP: 173/406 -- GLOBAL_STEP: 16000\u001b[0m\n",
      "     | > loss: 0.2866031527519226  (0.2899154073241129)\n",
      "     | > log_mle: -0.09542703628540039  (-0.08614891354059202)\n",
      "     | > loss_dur: 0.382030189037323  (0.376064320864705)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(4.7693, device='cuda:0')  (tensor(3.7034, device='cuda:0'))\n",
      "     | > current_lr: 5.75e-06 \n",
      "     | > step_time: 0.4131  (0.5913407857707467)\n",
      "     | > loader_time: 0.0212  (0.010203295360410829)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:15:28 -- STEP: 198/406 -- GLOBAL_STEP: 16025\u001b[0m\n",
      "     | > loss: 0.2913840413093567  (0.2889674733383487)\n",
      "     | > log_mle: -0.10287582874298096  (-0.08803811067282544)\n",
      "     | > loss_dur: 0.39425987005233765  (0.37700558401117423)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(1.3477, device='cuda:0')  (tensor(3.7791, device='cuda:0'))\n",
      "     | > current_lr: 5.75e-06 \n",
      "     | > step_time: 1.1685  (0.6012726492351954)\n",
      "     | > loader_time: 0.0166  (0.010457453101572362)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:15:45 -- STEP: 223/406 -- GLOBAL_STEP: 16050\u001b[0m\n",
      "     | > loss: 0.2772306501865387  (0.2877136982075301)\n",
      "     | > log_mle: -0.10383403301239014  (-0.08972444261670641)\n",
      "     | > loss_dur: 0.38106468319892883  (0.37743814082423666)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.5302, device='cuda:0')  (tensor(3.7363, device='cuda:0'))\n",
      "     | > current_lr: 5.75e-06 \n",
      "     | > step_time: 0.399  (0.6083249896096539)\n",
      "     | > loader_time: 0.0142  (0.010555814734488857)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:16:04 -- STEP: 248/406 -- GLOBAL_STEP: 16075\u001b[0m\n",
      "     | > loss: 0.2620508074760437  (0.2867839738966957)\n",
      "     | > log_mle: -0.10216355323791504  (-0.09124930659609451)\n",
      "     | > loss_dur: 0.36421436071395874  (0.3780332804927903)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.3423, device='cuda:0')  (tensor(3.7250, device='cuda:0'))\n",
      "     | > current_lr: 5.75e-06 \n",
      "     | > step_time: 0.6915  (0.621901891885265)\n",
      "     | > loader_time: 0.0058  (0.010845480426665274)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:16:23 -- STEP: 273/406 -- GLOBAL_STEP: 16100\u001b[0m\n",
      "     | > loss: 0.273388147354126  (0.2855201275139065)\n",
      "     | > log_mle: -0.10769784450531006  (-0.09274099925498817)\n",
      "     | > loss_dur: 0.38108599185943604  (0.37826112676889473)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(3.2549, device='cuda:0')  (tensor(3.8358, device='cuda:0'))\n",
      "     | > current_lr: 5.75e-06 \n",
      "     | > step_time: 0.6097  (0.6308828692733148)\n",
      "     | > loader_time: 0.0058  (0.011390290417514007)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:16:42 -- STEP: 298/406 -- GLOBAL_STEP: 16125\u001b[0m\n",
      "     | > loss: 0.27801594138145447  (0.28459745275494236)\n",
      "     | > log_mle: -0.09854376316070557  (-0.09382778226129157)\n",
      "     | > loss_dur: 0.37655970454216003  (0.37842523501623415)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(5.4145, device='cuda:0')  (tensor(4.0980, device='cuda:0'))\n",
      "     | > current_lr: 5.75e-06 \n",
      "     | > step_time: 0.8346  (0.6420458827242753)\n",
      "     | > loader_time: 0.007  (0.011523426779164566)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:17:02 -- STEP: 323/406 -- GLOBAL_STEP: 16150\u001b[0m\n",
      "     | > loss: 0.28586089611053467  (0.2836089363039095)\n",
      "     | > log_mle: -0.11251616477966309  (-0.09494995092828942)\n",
      "     | > loss_dur: 0.39837706089019775  (0.37855888723219905)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(4.5674, device='cuda:0')  (tensor(4.1817, device='cuda:0'))\n",
      "     | > current_lr: 5.75e-06 \n",
      "     | > step_time: 0.8887  (0.6507981975012148)\n",
      "     | > loader_time: 0.0058  (0.011859004342519096)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:17:23 -- STEP: 348/406 -- GLOBAL_STEP: 16175\u001b[0m\n",
      "     | > loss: 0.270239919424057  (0.28296576671559254)\n",
      "     | > log_mle: -0.11172747611999512  (-0.0960361561898527)\n",
      "     | > loss_dur: 0.3819673955440521  (0.37900192290544527)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(10.0732, device='cuda:0')  (tensor(4.3035, device='cuda:0'))\n",
      "     | > current_lr: 5.75e-06 \n",
      "     | > step_time: 0.7955  (0.6639966478292969)\n",
      "     | > loader_time: 0.0511  (0.012213352082789631)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:17:44 -- STEP: 373/406 -- GLOBAL_STEP: 16200\u001b[0m\n",
      "     | > loss: 0.2494353950023651  (0.2817460266578615)\n",
      "     | > log_mle: -0.11900150775909424  (-0.0971705601937649)\n",
      "     | > loss_dur: 0.36843690276145935  (0.3789165868516264)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(8.4577, device='cuda:0')  (tensor(4.4165, device='cuda:0'))\n",
      "     | > current_lr: 5.75e-06 \n",
      "     | > step_time: 0.7848  (0.6746433791142686)\n",
      "     | > loader_time: 0.0129  (0.012328466844942234)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:18:03 -- STEP: 398/406 -- GLOBAL_STEP: 16225\u001b[0m\n",
      "     | > loss: 0.2606200575828552  (0.2806565029986543)\n",
      "     | > log_mle: -0.11419343948364258  (-0.09822382834089458)\n",
      "     | > loss_dur: 0.3748134970664978  (0.37888033133954874)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(5.5231, device='cuda:0')  (tensor(4.6128, device='cuda:0'))\n",
      "     | > current_lr: 5.75e-06 \n",
      "     | > step_time: 0.5653  (0.6778937907674205)\n",
      "     | > loader_time: 0.0087  (0.012342771094049044)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: 0.2562854290008545  (0.2562854290008545)\n",
      "     | > log_mle: -0.08183670043945312  (-0.08183670043945312)\n",
      "     | > loss_dur: 0.3381221294403076  (0.3381221294403076)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: 0.23095953464508057  (0.23095953464508057)\n",
      "     | > log_mle: -0.11784946918487549  (-0.11784946918487549)\n",
      "     | > loss_dur: 0.34880900382995605  (0.34880900382995605)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: 0.2874917685985565  (0.25922565162181854)\n",
      "     | > log_mle: -0.07813704013824463  (-0.09799325466156006)\n",
      "     | > loss_dur: 0.36562880873680115  (0.3572189062833786)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: 0.24433064460754395  (0.254260649283727)\n",
      "     | > log_mle: -0.09528529644012451  (-0.09709060192108154)\n",
      "     | > loss_dur: 0.33961594104766846  (0.35135125120480853)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: 0.24578005075454712  (0.25214049965143204)\n",
      "     | > log_mle: -0.12338817119598389  (-0.10366499423980713)\n",
      "     | > loss_dur: 0.369168221950531  (0.35580549389123917)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: 0.24959126114845276  (0.25163065195083617)\n",
      "     | > log_mle: -0.1274627447128296  (-0.10842454433441162)\n",
      "     | > loss_dur: 0.37705400586128235  (0.3600551962852478)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: 0.2758364975452423  (0.25566495954990387)\n",
      "     | > log_mle: -0.13623225688934326  (-0.1130591630935669)\n",
      "     | > loss_dur: 0.41206875443458557  (0.36872412264347076)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: 0.24831807613372803  (0.25461540477616446)\n",
      "     | > log_mle: -0.10006058216094971  (-0.11120222296033587)\n",
      "     | > loss_dur: 0.34837865829467773  (0.36581762773650034)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: 0.23830077052116394  (0.2525760754942894)\n",
      "     | > log_mle: -0.10500431060791016  (-0.11042748391628265)\n",
      "     | > loss_dur: 0.3433050811290741  (0.36300355941057205)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: 0.27341970801353455  (0.2548920346630944)\n",
      "     | > log_mle: -0.1170649528503418  (-0.11116498046451145)\n",
      "     | > loss_dur: 0.39048466086387634  (0.36605701512760586)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: 0.2579410672187805  (0.25519693791866305)\n",
      "     | > log_mle: -0.1056596040725708  (-0.11061444282531738)\n",
      "     | > loss_dur: 0.3636006712913513  (0.3658113807439804)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: 0.2450362741947174  (0.25427324121648615)\n",
      "     | > log_mle: -0.12002420425415039  (-0.11146987568248402)\n",
      "     | > loss_dur: 0.3650604784488678  (0.36574311689897016)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: 0.24383658170700073  (0.2534035195906957)\n",
      "     | > log_mle: -0.1085822582244873  (-0.11122924089431763)\n",
      "     | > loss_dur: 0.35241883993148804  (0.3646327604850133)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: 0.21779495477676392  (0.25066439922039324)\n",
      "     | > log_mle: -0.12794625759124756  (-0.11251516525561993)\n",
      "     | > loss_dur: 0.3457412123680115  (0.3631795644760132)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: 0.27172133326530457  (0.25216846593788694)\n",
      "     | > log_mle: -0.12009203433990479  (-0.11305637019021171)\n",
      "     | > loss_dur: 0.39181336760520935  (0.36522483612809864)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: 0.2359045147895813  (0.2510842025279999)\n",
      "     | > log_mle: -0.11466896533966064  (-0.1131638765335083)\n",
      "     | > loss_dur: 0.35057348012924194  (0.3642480790615082)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: 0.24628764390945435  (0.2507844176143408)\n",
      "     | > log_mle: -0.10927212238311768  (-0.11292064189910889)\n",
      "     | > loss_dur: 0.355559766292572  (0.36370505951344967)\n",
      "\n",
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.003059953451156616 \u001b[0m(-0.0013252049684524536)\n",
      "     | > avg_loss:\u001b[92m 0.2507844176143408 \u001b[0m(-0.03559610992670059)\n",
      "     | > avg_log_mle:\u001b[92m -0.11292064189910889 \u001b[0m(-0.011459976434707642)\n",
      "     | > avg_loss_dur:\u001b[92m 0.36370505951344967 \u001b[0m(-0.02413613349199295)\n",
      "\n",
      " > BEST MODEL : train/run-February-22-2025_02+19AM-9b6e3e6/best_model_16233.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 24/40\u001b[0m\n",
      " --> train/run-February-22-2025_02+19AM-9b6e3e6\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-22 04:18:23) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:18:32 -- STEP: 17/406 -- GLOBAL_STEP: 16250\u001b[0m\n",
      "     | > loss: 0.28376662731170654  (0.2704715413205764)\n",
      "     | > log_mle: -0.08374989032745361  (-0.08260578968945671)\n",
      "     | > loss_dur: 0.36751651763916016  (0.3530773310100331)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(1.4040, device='cuda:0')  (tensor(1.9222, device='cuda:0'))\n",
      "     | > current_lr: 6e-06 \n",
      "     | > step_time: 0.4022  (0.44203927937675924)\n",
      "     | > loader_time: 0.0046  (0.00588690533357508)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:18:47 -- STEP: 42/406 -- GLOBAL_STEP: 16275\u001b[0m\n",
      "     | > loss: 0.23675501346588135  (0.27009904668444684)\n",
      "     | > log_mle: -0.0895540714263916  (-0.08172057639984857)\n",
      "     | > loss_dur: 0.32630908489227295  (0.3518196230842954)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(1.8609, device='cuda:0')  (tensor(2.1899, device='cuda:0'))\n",
      "     | > current_lr: 6e-06 \n",
      "     | > step_time: 0.7325  (0.5125996612367176)\n",
      "     | > loader_time: 0.0047  (0.007896900177001953)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:19:02 -- STEP: 67/406 -- GLOBAL_STEP: 16300\u001b[0m\n",
      "     | > loss: 0.2739141881465912  (0.26876914234303717)\n",
      "     | > log_mle: -0.09655141830444336  (-0.0848754813422018)\n",
      "     | > loss_dur: 0.37046560645103455  (0.353644623685239)\n",
      "     | > amp_scaler: 65536.0  (35702.44776119403)\n",
      "     | > grad_norm: tensor(2.8270, device='cuda:0')  (tensor(2.6498, device='cuda:0'))\n",
      "     | > current_lr: 6e-06 \n",
      "     | > step_time: 0.4247  (0.5450844159766811)\n",
      "     | > loader_time: 0.005  (0.007961266076386864)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:19:16 -- STEP: 92/406 -- GLOBAL_STEP: 16325\u001b[0m\n",
      "     | > loss: 0.25843724608421326  (0.2665448234133097)\n",
      "     | > log_mle: -0.11123323440551758  (-0.08845225753991497)\n",
      "     | > loss_dur: 0.36967048048973083  (0.354997080953225)\n",
      "     | > amp_scaler: 32768.0  (41316.17391304348)\n",
      "     | > grad_norm: tensor(8.2830, device='cuda:0')  (tensor(3.6716, device='cuda:0'))\n",
      "     | > current_lr: 6e-06 \n",
      "     | > step_time: 0.3149  (0.5504787356957145)\n",
      "     | > loader_time: 0.0052  (0.008582908174265989)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:19:32 -- STEP: 117/406 -- GLOBAL_STEP: 16350\u001b[0m\n",
      "     | > loss: 0.2503393590450287  (0.2646291072552019)\n",
      "     | > log_mle: -0.10354733467102051  (-0.09150384124527626)\n",
      "     | > loss_dur: 0.3538866937160492  (0.3561329485004785)\n",
      "     | > amp_scaler: 32768.0  (39489.64102564102)\n",
      "     | > grad_norm: tensor(4.2521, device='cuda:0')  (tensor(4.2221, device='cuda:0'))\n",
      "     | > current_lr: 6e-06 \n",
      "     | > step_time: 0.4174  (0.5653209013816637)\n",
      "     | > loader_time: 0.0076  (0.008871210945977108)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:19:49 -- STEP: 142/406 -- GLOBAL_STEP: 16375\u001b[0m\n",
      "     | > loss: 0.22754287719726562  (0.26237499357109323)\n",
      "     | > log_mle: -0.11216259002685547  (-0.09424234360036712)\n",
      "     | > loss_dur: 0.3397054672241211  (0.3566173371714607)\n",
      "     | > amp_scaler: 32768.0  (38306.25352112677)\n",
      "     | > grad_norm: tensor(4.0924, device='cuda:0')  (tensor(4.5296, device='cuda:0'))\n",
      "     | > current_lr: 6e-06 \n",
      "     | > step_time: 0.6252  (0.579715935277267)\n",
      "     | > loader_time: 0.0058  (0.008955767456914341)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:20:06 -- STEP: 167/406 -- GLOBAL_STEP: 16400\u001b[0m\n",
      "     | > loss: 0.2526787519454956  (0.26130029077301453)\n",
      "     | > log_mle: -0.10573971271514893  (-0.09620162826812191)\n",
      "     | > loss_dur: 0.35841846466064453  (0.3575019190411371)\n",
      "     | > amp_scaler: 32768.0  (37477.17365269462)\n",
      "     | > grad_norm: tensor(15.3806, device='cuda:0')  (tensor(4.8860, device='cuda:0'))\n",
      "     | > current_lr: 6e-06 \n",
      "     | > step_time: 0.8019  (0.5932306757944071)\n",
      "     | > loader_time: 0.0051  (0.009196065857024963)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:20:22 -- STEP: 192/406 -- GLOBAL_STEP: 16425\u001b[0m\n",
      "     | > loss: 0.2512100338935852  (0.2603599180777865)\n",
      "     | > log_mle: -0.11415410041809082  (-0.09804836226006346)\n",
      "     | > loss_dur: 0.365364134311676  (0.3584082803378505)\n",
      "     | > amp_scaler: 32768.0  (36863.99999999999)\n",
      "     | > grad_norm: tensor(9.9931, device='cuda:0')  (tensor(5.0175, device='cuda:0'))\n",
      "     | > current_lr: 6e-06 \n",
      "     | > step_time: 0.5261  (0.5999518297612664)\n",
      "     | > loader_time: 0.0066  (0.009514018893241874)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:20:41 -- STEP: 217/406 -- GLOBAL_STEP: 16450\u001b[0m\n",
      "     | > loss: 0.2577162981033325  (0.2592601287200153)\n",
      "     | > log_mle: -0.11646854877471924  (-0.09964746978425756)\n",
      "     | > loss_dur: 0.37418484687805176  (0.35890759850427323)\n",
      "     | > amp_scaler: 32768.0  (36392.11059907836)\n",
      "     | > grad_norm: tensor(5.0928, device='cuda:0')  (tensor(5.1137, device='cuda:0'))\n",
      "     | > current_lr: 6e-06 \n",
      "     | > step_time: 1.4834  (0.6158381673048167)\n",
      "     | > loader_time: 0.008  (0.009758134042063061)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:21:03 -- STEP: 242/406 -- GLOBAL_STEP: 16475\u001b[0m\n",
      "     | > loss: 0.2482580840587616  (0.2588141655380075)\n",
      "     | > log_mle: -0.12254750728607178  (-0.10129269292531917)\n",
      "     | > loss_dur: 0.3708055913448334  (0.36010685846332696)\n",
      "     | > amp_scaler: 32768.0  (36017.71900826448)\n",
      "     | > grad_norm: tensor(6.1217, device='cuda:0')  (tensor(5.0092, device='cuda:0'))\n",
      "     | > current_lr: 6e-06 \n",
      "     | > step_time: 0.5579  (0.639097634425833)\n",
      "     | > loader_time: 0.0056  (0.010376466207267818)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:21:23 -- STEP: 267/406 -- GLOBAL_STEP: 16500\u001b[0m\n",
      "     | > loss: 0.2527042031288147  (0.2575617074296715)\n",
      "     | > log_mle: -0.11130380630493164  (-0.10262858465816195)\n",
      "     | > loss_dur: 0.36400800943374634  (0.3601902920878337)\n",
      "     | > amp_scaler: 32768.0  (35713.438202247205)\n",
      "     | > grad_norm: tensor(4.7247, device='cuda:0')  (tensor(4.9048, device='cuda:0'))\n",
      "     | > current_lr: 6e-06 \n",
      "     | > step_time: 0.7486  (0.6530885883931361)\n",
      "     | > loader_time: 0.0197  (0.010796012949854243)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:21:44 -- STEP: 292/406 -- GLOBAL_STEP: 16525\u001b[0m\n",
      "     | > loss: 0.2591532766819  (0.2565749454988191)\n",
      "     | > log_mle: -0.10841286182403564  (-0.10383945948457061)\n",
      "     | > loss_dur: 0.36756613850593567  (0.3604144049833901)\n",
      "     | > amp_scaler: 16384.0  (34787.94520547947)\n",
      "     | > grad_norm: tensor(9.0579, device='cuda:0')  (tensor(5.2396, device='cuda:0'))\n",
      "     | > current_lr: 6e-06 \n",
      "     | > step_time: 0.7255  (0.6651305197036428)\n",
      "     | > loader_time: 0.0183  (0.011540237354905631)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:22:06 -- STEP: 317/406 -- GLOBAL_STEP: 16550\u001b[0m\n",
      "     | > loss: 0.25657767057418823  (0.25575007361944535)\n",
      "     | > log_mle: -0.11846518516540527  (-0.10499006754216333)\n",
      "     | > loss_dur: 0.3750428557395935  (0.3607401411616089)\n",
      "     | > amp_scaler: 16384.0  (33336.52996845428)\n",
      "     | > grad_norm: tensor(12.7115, device='cuda:0')  (tensor(5.7632, device='cuda:0'))\n",
      "     | > current_lr: 6e-06 \n",
      "     | > step_time: 1.0632  (0.6805582520337509)\n",
      "     | > loader_time: 0.0588  (0.011962810149328183)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:22:29 -- STEP: 342/406 -- GLOBAL_STEP: 16575\u001b[0m\n",
      "     | > loss: 0.23985859751701355  (0.2551350658922864)\n",
      "     | > log_mle: -0.13416016101837158  (-0.10594353724641407)\n",
      "     | > loss_dur: 0.37401875853538513  (0.3610786031387007)\n",
      "     | > amp_scaler: 16384.0  (32097.30994152049)\n",
      "     | > grad_norm: tensor(24.8995, device='cuda:0')  (tensor(6.1914, device='cuda:0'))\n",
      "     | > current_lr: 6e-06 \n",
      "     | > step_time: 0.6838  (0.6964222081223422)\n",
      "     | > loader_time: 0.0069  (0.012214843989812835)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:22:50 -- STEP: 367/406 -- GLOBAL_STEP: 16600\u001b[0m\n",
      "     | > loss: 0.24505770206451416  (0.25444843772321685)\n",
      "     | > log_mle: -0.12334239482879639  (-0.10698628880347476)\n",
      "     | > loss_dur: 0.36840009689331055  (0.3614347265266919)\n",
      "     | > amp_scaler: 16384.0  (31026.92098092645)\n",
      "     | > grad_norm: tensor(9.6864, device='cuda:0')  (tensor(6.5849, device='cuda:0'))\n",
      "     | > current_lr: 6e-06 \n",
      "     | > step_time: 0.915  (0.7051171132589229)\n",
      "     | > loader_time: 0.0102  (0.012405928863816425)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:23:14 -- STEP: 392/406 -- GLOBAL_STEP: 16625\u001b[0m\n",
      "     | > loss: 0.23280730843544006  (0.2536752547840681)\n",
      "     | > log_mle: -0.11856317520141602  (-0.1079127119511974)\n",
      "     | > loss_dur: 0.3513704836368561  (0.36158796673526583)\n",
      "     | > amp_scaler: 16384.0  (30093.061224489815)\n",
      "     | > grad_norm: tensor(9.6766, device='cuda:0')  (tensor(6.8552, device='cuda:0'))\n",
      "     | > current_lr: 6e-06 \n",
      "     | > step_time: 0.5673  (0.7203598405633652)\n",
      "     | > loader_time: 0.0078  (0.01256876454061391)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: 0.23127615451812744  (0.23127615451812744)\n",
      "     | > log_mle: -0.09041476249694824  (-0.09041476249694824)\n",
      "     | > loss_dur: 0.3216909170150757  (0.3216909170150757)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: 0.21345263719558716  (0.21345263719558716)\n",
      "     | > log_mle: -0.12604939937591553  (-0.12604939937591553)\n",
      "     | > loss_dur: 0.3395020365715027  (0.3395020365715027)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: 0.2590358853340149  (0.23624426126480103)\n",
      "     | > log_mle: -0.08649265766143799  (-0.10627102851867676)\n",
      "     | > loss_dur: 0.3455285429954529  (0.3425152897834778)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: 0.21200865507125854  (0.22816572586695352)\n",
      "     | > log_mle: -0.1025773286819458  (-0.10503979523976643)\n",
      "     | > loss_dur: 0.31458598375320435  (0.33320552110671997)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: 0.25605592131614685  (0.23513827472925186)\n",
      "     | > log_mle: -0.13027870655059814  (-0.11134952306747437)\n",
      "     | > loss_dur: 0.386334627866745  (0.3464877977967262)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: 0.22209560871124268  (0.23252974152565004)\n",
      "     | > log_mle: -0.13149726390838623  (-0.11537907123565674)\n",
      "     | > loss_dur: 0.3535928726196289  (0.34790881276130675)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: 0.2541351318359375  (0.23613063991069794)\n",
      "     | > log_mle: -0.14025115966796875  (-0.11952441930770874)\n",
      "     | > loss_dur: 0.39438629150390625  (0.3556550592184067)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: 0.2344767451286316  (0.2358943692275456)\n",
      "     | > log_mle: -0.10665953159332275  (-0.1176865782056536)\n",
      "     | > loss_dur: 0.34113627672195435  (0.3535809474331992)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: 0.2294619083404541  (0.23509031161665916)\n",
      "     | > log_mle: -0.11219871044158936  (-0.11700059473514557)\n",
      "     | > loss_dur: 0.34166061878204346  (0.35209090635180473)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: 0.25960662961006165  (0.23781434694925943)\n",
      "     | > log_mle: -0.12287187576293945  (-0.11765295929378933)\n",
      "     | > loss_dur: 0.3824785053730011  (0.3554673062430488)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: 0.23772546648979187  (0.23780545890331267)\n",
      "     | > log_mle: -0.11265122890472412  (-0.11715278625488282)\n",
      "     | > loss_dur: 0.350376695394516  (0.3549582451581955)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: 0.21618756651878357  (0.2358401959592646)\n",
      "     | > log_mle: -0.12663543224334717  (-0.11801484498110684)\n",
      "     | > loss_dur: 0.34282299876213074  (0.3538550409403714)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: 0.22317278385162354  (0.23478457828362784)\n",
      "     | > log_mle: -0.11586546897888184  (-0.11783573031425476)\n",
      "     | > loss_dur: 0.33903825283050537  (0.35262030859788257)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: 0.19409382343292236  (0.23165452021818894)\n",
      "     | > log_mle: -0.13310539722442627  (-0.11901032007657565)\n",
      "     | > loss_dur: 0.32719922065734863  (0.3506648402947646)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: 0.2559349238872528  (0.23338883476597921)\n",
      "     | > log_mle: -0.12696599960327148  (-0.11957858289991107)\n",
      "     | > loss_dur: 0.3829009234905243  (0.3529674176658903)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: 0.2176940143108368  (0.23234251340230305)\n",
      "     | > log_mle: -0.12147033214569092  (-0.11970469951629639)\n",
      "     | > loss_dur: 0.3391643464565277  (0.3520472129185995)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: 0.22384893894195557  (0.23181166499853134)\n",
      "     | > log_mle: -0.11475622653961182  (-0.1193954199552536)\n",
      "     | > loss_dur: 0.3386051654815674  (0.35120708495378494)\n",
      "\n",
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[91m 0.005814075469970703 \u001b[0m(+0.002754122018814087)\n",
      "     | > avg_loss:\u001b[92m 0.23181166499853134 \u001b[0m(-0.01897275261580944)\n",
      "     | > avg_log_mle:\u001b[92m -0.1193954199552536 \u001b[0m(-0.006474778056144714)\n",
      "     | > avg_loss_dur:\u001b[92m 0.35120708495378494 \u001b[0m(-0.012497974559664726)\n",
      "\n",
      " > BEST MODEL : train/run-February-22-2025_02+19AM-9b6e3e6/best_model_16639.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 25/40\u001b[0m\n",
      " --> train/run-February-22-2025_02+19AM-9b6e3e6\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-22 04:23:38) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:23:44 -- STEP: 11/406 -- GLOBAL_STEP: 16650\u001b[0m\n",
      "     | > loss: 0.23133441805839539  (0.24583791873671793)\n",
      "     | > log_mle: -0.0849536657333374  (-0.08749560334465721)\n",
      "     | > loss_dur: 0.3162880837917328  (0.3333335220813751)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(1.7870, device='cuda:0')  (tensor(1.7415, device='cuda:0'))\n",
      "     | > current_lr: 6.2499999999999995e-06 \n",
      "     | > step_time: 0.3254  (0.36006899313493207)\n",
      "     | > loader_time: 0.0044  (0.0064945220947265625)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:23:59 -- STEP: 36/406 -- GLOBAL_STEP: 16675\u001b[0m\n",
      "     | > loss: 0.24338403344154358  (0.2488612574007776)\n",
      "     | > log_mle: -0.08652794361114502  (-0.09010476536220974)\n",
      "     | > loss_dur: 0.3299119770526886  (0.3389660227629874)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(1.5399, device='cuda:0')  (tensor(2.2072, device='cuda:0'))\n",
      "     | > current_lr: 6.2499999999999995e-06 \n",
      "     | > step_time: 0.5277  (0.5106213887532552)\n",
      "     | > loader_time: 0.0046  (0.008642613887786867)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:24:15 -- STEP: 61/406 -- GLOBAL_STEP: 16700\u001b[0m\n",
      "     | > loss: 0.24534136056900024  (0.2464874548013093)\n",
      "     | > log_mle: -0.1024864912033081  (-0.09275267749536233)\n",
      "     | > loss_dur: 0.34782785177230835  (0.3392401322966717)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(1.7781, device='cuda:0')  (tensor(3.1859, device='cuda:0'))\n",
      "     | > current_lr: 6.2499999999999995e-06 \n",
      "     | > step_time: 0.4671  (0.5547005543943314)\n",
      "     | > loader_time: 0.0225  (0.010460916112680905)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:24:32 -- STEP: 86/406 -- GLOBAL_STEP: 16725\u001b[0m\n",
      "     | > loss: 0.2538831830024719  (0.2447157945743827)\n",
      "     | > log_mle: -0.0989612340927124  (-0.09599298515985179)\n",
      "     | > loss_dur: 0.3528444170951843  (0.34070877973423447)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(2.7983, device='cuda:0')  (tensor(3.6347, device='cuda:0'))\n",
      "     | > current_lr: 6.2499999999999995e-06 \n",
      "     | > step_time: 0.7672  (0.5841474311296331)\n",
      "     | > loader_time: 0.0175  (0.009930341742759528)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:24:49 -- STEP: 111/406 -- GLOBAL_STEP: 16750\u001b[0m\n",
      "     | > loss: 0.2326889932155609  (0.24253514355367367)\n",
      "     | > log_mle: -0.12781000137329102  (-0.0993197168315853)\n",
      "     | > loss_dur: 0.36049899458885193  (0.341854860385259)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(6.7042, device='cuda:0')  (tensor(3.8784, device='cuda:0'))\n",
      "     | > current_lr: 6.2499999999999995e-06 \n",
      "     | > step_time: 0.9377  (0.6011058854627179)\n",
      "     | > loader_time: 0.0099  (0.01008332097852552)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:25:07 -- STEP: 136/406 -- GLOBAL_STEP: 16775\u001b[0m\n",
      "     | > loss: 0.24799901247024536  (0.24061400333748145)\n",
      "     | > log_mle: -0.11870074272155762  (-0.10198154519586002)\n",
      "     | > loss_dur: 0.366699755191803  (0.34259554853334145)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(5.5019, device='cuda:0')  (tensor(4.7628, device='cuda:0'))\n",
      "     | > current_lr: 6.2499999999999995e-06 \n",
      "     | > step_time: 0.7075  (0.6183426818426918)\n",
      "     | > loader_time: 0.0081  (0.010668146259644448)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:25:24 -- STEP: 161/406 -- GLOBAL_STEP: 16800\u001b[0m\n",
      "     | > loss: 0.22990569472312927  (0.23984741479713725)\n",
      "     | > log_mle: -0.11354982852935791  (-0.10398105953050696)\n",
      "     | > loss_dur: 0.3434555232524872  (0.3438284743276443)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.7147, device='cuda:0')  (tensor(4.6464, device='cuda:0'))\n",
      "     | > current_lr: 6.2499999999999995e-06 \n",
      "     | > step_time: 0.4735  (0.6303456392347444)\n",
      "     | > loader_time: 0.0302  (0.010913986597001922)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:25:43 -- STEP: 186/406 -- GLOBAL_STEP: 16825\u001b[0m\n",
      "     | > loss: 0.24800467491149902  (0.23919956418134833)\n",
      "     | > log_mle: -0.12151575088500977  (-0.10590031070093955)\n",
      "     | > loss_dur: 0.3695204257965088  (0.34509987488228805)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(5.4628, device='cuda:0')  (tensor(4.7708, device='cuda:0'))\n",
      "     | > current_lr: 6.2499999999999995e-06 \n",
      "     | > step_time: 0.7448  (0.6417363882064823)\n",
      "     | > loader_time: 0.0081  (0.011438301814499723)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:26:02 -- STEP: 211/406 -- GLOBAL_STEP: 16850\u001b[0m\n",
      "     | > loss: 0.21263158321380615  (0.23780465578015947)\n",
      "     | > log_mle: -0.12536096572875977  (-0.10752509951026519)\n",
      "     | > loss_dur: 0.3379925489425659  (0.3453297552904248)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(11.1406, device='cuda:0')  (tensor(5.4963, device='cuda:0'))\n",
      "     | > current_lr: 6.2499999999999995e-06 \n",
      "     | > step_time: 0.6175  (0.652695905540792)\n",
      "     | > loader_time: 0.005  (0.012156330578700062)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:26:22 -- STEP: 236/406 -- GLOBAL_STEP: 16875\u001b[0m\n",
      "     | > loss: 0.23854005336761475  (0.23733497145822494)\n",
      "     | > log_mle: -0.10934960842132568  (-0.10915954789872896)\n",
      "     | > loss_dur: 0.34788966178894043  (0.346494519356954)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(11.9274, device='cuda:0')  (tensor(6.1961, device='cuda:0'))\n",
      "     | > current_lr: 6.2499999999999995e-06 \n",
      "     | > step_time: 0.5849  (0.6652637912055196)\n",
      "     | > loader_time: 0.0176  (0.01268012341806444)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:26:42 -- STEP: 261/406 -- GLOBAL_STEP: 16900\u001b[0m\n",
      "     | > loss: 0.22749963402748108  (0.23621006555484172)\n",
      "     | > log_mle: -0.12401187419891357  (-0.1106661256702467)\n",
      "     | > loss_dur: 0.35151150822639465  (0.3468761912250885)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.5222, device='cuda:0')  (tensor(6.2199, device='cuda:0'))\n",
      "     | > current_lr: 6.2499999999999995e-06 \n",
      "     | > step_time: 0.5074  (0.6748165472257185)\n",
      "     | > loader_time: 0.0056  (0.012815206900410268)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:27:02 -- STEP: 286/406 -- GLOBAL_STEP: 16925\u001b[0m\n",
      "     | > loss: 0.23709386587142944  (0.23531167063262912)\n",
      "     | > log_mle: -0.12348282337188721  (-0.11186109556184783)\n",
      "     | > loss_dur: 0.36057668924331665  (0.3471727661944772)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(9.6941, device='cuda:0')  (tensor(6.4772, device='cuda:0'))\n",
      "     | > current_lr: 6.2499999999999995e-06 \n",
      "     | > step_time: 0.5967  (0.6858238190204116)\n",
      "     | > loader_time: 0.007  (0.012893277448374076)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:27:24 -- STEP: 311/406 -- GLOBAL_STEP: 16950\u001b[0m\n",
      "     | > loss: 0.22502094507217407  (0.23462033818005748)\n",
      "     | > log_mle: -0.12316203117370605  (-0.11289947975870114)\n",
      "     | > loss_dur: 0.3481829762458801  (0.34751981793875875)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(2.8797, device='cuda:0')  (tensor(6.5831, device='cuda:0'))\n",
      "     | > current_lr: 6.2499999999999995e-06 \n",
      "     | > step_time: 0.668  (0.697157317802454)\n",
      "     | > loader_time: 0.0092  (0.013350204639496144)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:27:45 -- STEP: 336/406 -- GLOBAL_STEP: 16975\u001b[0m\n",
      "     | > loss: 0.21183991432189941  (0.2340805626341275)\n",
      "     | > log_mle: -0.1285402774810791  (-0.11389805057219096)\n",
      "     | > loss_dur: 0.3403801918029785  (0.34797861320631873)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(11.3184, device='cuda:0')  (tensor(6.4433, device='cuda:0'))\n",
      "     | > current_lr: 6.2499999999999995e-06 \n",
      "     | > step_time: 0.7402  (0.7063835497413369)\n",
      "     | > loader_time: 0.0076  (0.013404910763104757)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:28:07 -- STEP: 361/406 -- GLOBAL_STEP: 17000\u001b[0m\n",
      "     | > loss: 0.234796941280365  (0.23342046364522706)\n",
      "     | > log_mle: -0.12513744831085205  (-0.1149571037688744)\n",
      "     | > loss_dur: 0.35993438959121704  (0.34837756741410164)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(6.8376, device='cuda:0')  (tensor(6.6579, device='cuda:0'))\n",
      "     | > current_lr: 6.2499999999999995e-06 \n",
      "     | > step_time: 0.6136  (0.7170528539990461)\n",
      "     | > loader_time: 0.0311  (0.013739944494992412)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:28:30 -- STEP: 386/406 -- GLOBAL_STEP: 17025\u001b[0m\n",
      "     | > loss: 0.2257043719291687  (0.23257809638050553)\n",
      "     | > log_mle: -0.12906086444854736  (-0.11590451434486271)\n",
      "     | > loss_dur: 0.35476523637771606  (0.3484826107253684)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(5.9622, device='cuda:0')  (tensor(7.0997, device='cuda:0'))\n",
      "     | > current_lr: 6.2499999999999995e-06 \n",
      "     | > step_time: 1.2009  (0.729978528665138)\n",
      "     | > loader_time: 0.0108  (0.014365815128069467)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: 0.21175962686538696  (0.21175962686538696)\n",
      "     | > log_mle: -0.0986328125  (-0.0986328125)\n",
      "     | > loss_dur: 0.31039243936538696  (0.31039243936538696)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: 0.20537933707237244  (0.20537933707237244)\n",
      "     | > log_mle: -0.13288629055023193  (-0.13288629055023193)\n",
      "     | > loss_dur: 0.33826562762260437  (0.33826562762260437)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: 0.2311170995235443  (0.21824821829795837)\n",
      "     | > log_mle: -0.09389281272888184  (-0.11338955163955688)\n",
      "     | > loss_dur: 0.32500991225242615  (0.33163776993751526)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: 0.19946300983428955  (0.2119864821434021)\n",
      "     | > log_mle: -0.1085667610168457  (-0.11178195476531982)\n",
      "     | > loss_dur: 0.30802977085113525  (0.3237684369087219)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: 0.23549050092697144  (0.21786248683929443)\n",
      "     | > log_mle: -0.13584208488464355  (-0.11779698729515076)\n",
      "     | > loss_dur: 0.371332585811615  (0.3356594741344452)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: 0.21349501609802246  (0.21698899269104005)\n",
      "     | > log_mle: -0.13070452213287354  (-0.12037849426269531)\n",
      "     | > loss_dur: 0.344199538230896  (0.33736748695373536)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: 0.2348824143409729  (0.21997122963269553)\n",
      "     | > log_mle: -0.13995909690856934  (-0.12364192803700765)\n",
      "     | > loss_dur: 0.37484151124954224  (0.3436131576697032)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: 0.23741409182548523  (0.22246306708880834)\n",
      "     | > log_mle: -0.11143100261688232  (-0.12189751011984688)\n",
      "     | > loss_dur: 0.34884509444236755  (0.3443605772086552)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: 0.21278566122055054  (0.2212533913552761)\n",
      "     | > log_mle: -0.11800801753997803  (-0.12141132354736328)\n",
      "     | > loss_dur: 0.33079367876052856  (0.3426647149026394)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: 0.2441333532333374  (0.22379560934172738)\n",
      "     | > log_mle: -0.12610268592834473  (-0.12193258603413899)\n",
      "     | > loss_dur: 0.37023603916168213  (0.34572819537586635)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: 0.22568196058273315  (0.22398424446582793)\n",
      "     | > log_mle: -0.11713767051696777  (-0.12145309448242188)\n",
      "     | > loss_dur: 0.3428196310997009  (0.3454373389482498)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: 0.20336535573005676  (0.22210980003530328)\n",
      "     | > log_mle: -0.13121676445007324  (-0.12234070084311745)\n",
      "     | > loss_dur: 0.33458212018013  (0.3444505008784207)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: 0.20665928721427917  (0.22082225730021796)\n",
      "     | > log_mle: -0.12166690826416016  (-0.12228455146153767)\n",
      "     | > loss_dur: 0.32832619547843933  (0.34310680876175564)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: 0.16807106137275696  (0.21676447299810556)\n",
      "     | > log_mle: -0.13525164127349854  (-0.1232820199086116)\n",
      "     | > loss_dur: 0.3033227026462555  (0.3400464929067172)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: 0.23987290263175964  (0.21841507511479513)\n",
      "     | > log_mle: -0.13127648830413818  (-0.12385305336543492)\n",
      "     | > loss_dur: 0.3711493909358978  (0.3422681284802301)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: 0.20362547039985657  (0.21742910146713257)\n",
      "     | > log_mle: -0.12589681148529053  (-0.12398930390675862)\n",
      "     | > loss_dur: 0.3295222818851471  (0.3414184053738912)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: 0.20621097087860107  (0.21672796830534935)\n",
      "     | > log_mle: -0.11800694465637207  (-0.12361540645360947)\n",
      "     | > loss_dur: 0.32421791553497314  (0.3403433747589588)\n",
      "\n",
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.0054903775453567505 \u001b[0m(-0.00032369792461395264)\n",
      "     | > avg_loss:\u001b[92m 0.21672796830534935 \u001b[0m(-0.015083696693181992)\n",
      "     | > avg_log_mle:\u001b[92m -0.12361540645360947 \u001b[0m(-0.0042199864983558655)\n",
      "     | > avg_loss_dur:\u001b[92m 0.3403433747589588 \u001b[0m(-0.010863710194826126)\n",
      "\n",
      " > BEST MODEL : train/run-February-22-2025_02+19AM-9b6e3e6/best_model_17045.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 26/40\u001b[0m\n",
      " --> train/run-February-22-2025_02+19AM-9b6e3e6\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-22 04:28:59) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:29:03 -- STEP: 5/406 -- GLOBAL_STEP: 17050\u001b[0m\n",
      "     | > loss: 0.22039303183555603  (0.24001067280769348)\n",
      "     | > log_mle: -0.0871894359588623  (-0.09405366182327271)\n",
      "     | > loss_dur: 0.30758246779441833  (0.3340643346309662)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(1.7307, device='cuda:0')  (tensor(2.2186, device='cuda:0'))\n",
      "     | > current_lr: 6.5e-06 \n",
      "     | > step_time: 0.3297  (0.4353060722351074)\n",
      "     | > loader_time: 0.0029  (0.012068414688110351)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:29:17 -- STEP: 30/406 -- GLOBAL_STEP: 17075\u001b[0m\n",
      "     | > loss: 0.2252574861049652  (0.2265662024418513)\n",
      "     | > log_mle: -0.09880435466766357  (-0.09896479646364847)\n",
      "     | > loss_dur: 0.3240618407726288  (0.3255309989054998)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(1.9236, device='cuda:0')  (tensor(2.4026, device='cuda:0'))\n",
      "     | > current_lr: 6.5e-06 \n",
      "     | > step_time: 0.7604  (0.5184140761693319)\n",
      "     | > loader_time: 0.0207  (0.010250393549601238)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:29:33 -- STEP: 55/406 -- GLOBAL_STEP: 17100\u001b[0m\n",
      "     | > loss: 0.1965063512325287  (0.22523189241235905)\n",
      "     | > log_mle: -0.11687004566192627  (-0.10083233551545577)\n",
      "     | > loss_dur: 0.31337639689445496  (0.32606422792781503)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(5.8682, device='cuda:0')  (tensor(3.1241, device='cuda:0'))\n",
      "     | > current_lr: 6.5e-06 \n",
      "     | > step_time: 0.3767  (0.5583210294896906)\n",
      "     | > loader_time: 0.0107  (0.010947392203591087)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:29:50 -- STEP: 80/406 -- GLOBAL_STEP: 17125\u001b[0m\n",
      "     | > loss: 0.22929838299751282  (0.22263391874730587)\n",
      "     | > log_mle: -0.10672974586486816  (-0.10365311279892922)\n",
      "     | > loss_dur: 0.336028128862381  (0.3262870315462353)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(2.1369, device='cuda:0')  (tensor(3.5088, device='cuda:0'))\n",
      "     | > current_lr: 6.5e-06 \n",
      "     | > step_time: 0.3992  (0.5948696523904801)\n",
      "     | > loader_time: 0.0465  (0.011064666509628297)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:30:06 -- STEP: 105/406 -- GLOBAL_STEP: 17150\u001b[0m\n",
      "     | > loss: 0.19329753518104553  (0.22082947435833158)\n",
      "     | > log_mle: -0.11417543888092041  (-0.1070290798232669)\n",
      "     | > loss_dur: 0.30747297406196594  (0.3278585541815986)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(7.4575, device='cuda:0')  (tensor(3.9343, device='cuda:0'))\n",
      "     | > current_lr: 6.5e-06 \n",
      "     | > step_time: 0.4255  (0.6055710111345565)\n",
      "     | > loader_time: 0.0184  (0.01146260897318522)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:30:24 -- STEP: 130/406 -- GLOBAL_STEP: 17175\u001b[0m\n",
      "     | > loss: 0.21214717626571655  (0.21870592832565308)\n",
      "     | > log_mle: -0.11223006248474121  (-0.10984256771894602)\n",
      "     | > loss_dur: 0.32437723875045776  (0.3285484960445992)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(6.5238, device='cuda:0')  (tensor(4.4482, device='cuda:0'))\n",
      "     | > current_lr: 6.5e-06 \n",
      "     | > step_time: 0.6978  (0.6190840647770809)\n",
      "     | > loader_time: 0.0071  (0.011426291098961464)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:30:42 -- STEP: 155/406 -- GLOBAL_STEP: 17200\u001b[0m\n",
      "     | > loss: 0.20211675763130188  (0.21753505968278455)\n",
      "     | > log_mle: -0.12076330184936523  (-0.11191396905529884)\n",
      "     | > loss_dur: 0.3228800594806671  (0.3294490287380834)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(2.7231, device='cuda:0')  (tensor(5.3001, device='cuda:0'))\n",
      "     | > current_lr: 6.5e-06 \n",
      "     | > step_time: 0.5786  (0.6350373575764319)\n",
      "     | > loader_time: 0.0078  (0.011591542151666459)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:31:01 -- STEP: 180/406 -- GLOBAL_STEP: 17225\u001b[0m\n",
      "     | > loss: 0.20475691556930542  (0.21671336938937505)\n",
      "     | > log_mle: -0.12534403800964355  (-0.11375889281431834)\n",
      "     | > loss_dur: 0.330100953578949  (0.3304722622036934)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(7.5324, device='cuda:0')  (tensor(5.4369, device='cuda:0'))\n",
      "     | > current_lr: 6.5e-06 \n",
      "     | > step_time: 0.6211  (0.6500557303428648)\n",
      "     | > loader_time: 0.0168  (0.012741875648498536)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:31:21 -- STEP: 205/406 -- GLOBAL_STEP: 17250\u001b[0m\n",
      "     | > loss: 0.2201480269432068  (0.21602609070335946)\n",
      "     | > log_mle: -0.13355183601379395  (-0.11546631935166149)\n",
      "     | > loss_dur: 0.35369986295700073  (0.331492410055021)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(7.8276, device='cuda:0')  (tensor(5.6302, device='cuda:0'))\n",
      "     | > current_lr: 6.5e-06 \n",
      "     | > step_time: 0.7891  (0.6628412107142007)\n",
      "     | > loader_time: 0.0122  (0.01288237106509325)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:31:41 -- STEP: 230/406 -- GLOBAL_STEP: 17275\u001b[0m\n",
      "     | > loss: 0.23261544108390808  (0.21527647142824918)\n",
      "     | > log_mle: -0.12556350231170654  (-0.11710356966308925)\n",
      "     | > loss_dur: 0.3581789433956146  (0.3323800410913385)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(8.7840, device='cuda:0')  (tensor(5.8180, device='cuda:0'))\n",
      "     | > current_lr: 6.5e-06 \n",
      "     | > step_time: 1.0561  (0.6752959044083305)\n",
      "     | > loader_time: 0.0399  (0.013267522272856339)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:32:01 -- STEP: 255/406 -- GLOBAL_STEP: 17300\u001b[0m\n",
      "     | > loss: 0.19968333840370178  (0.21459042546795865)\n",
      "     | > log_mle: -0.12708544731140137  (-0.11862106019375371)\n",
      "     | > loss_dur: 0.32676878571510315  (0.3332114856617124)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(5.2317, device='cuda:0')  (tensor(5.8863, device='cuda:0'))\n",
      "     | > current_lr: 6.5e-06 \n",
      "     | > step_time: 0.8925  (0.6851912610671099)\n",
      "     | > loader_time: 0.0196  (0.013579894047157438)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:32:21 -- STEP: 280/406 -- GLOBAL_STEP: 17325\u001b[0m\n",
      "     | > loss: 0.2049316167831421  (0.21363647867526328)\n",
      "     | > log_mle: -0.1410808563232422  (-0.11987286444221223)\n",
      "     | > loss_dur: 0.3460124731063843  (0.3335093431174756)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(2.9851, device='cuda:0')  (tensor(6.1365, device='cuda:0'))\n",
      "     | > current_lr: 6.5e-06 \n",
      "     | > step_time: 0.7714  (0.6945027027811324)\n",
      "     | > loader_time: 0.0068  (0.01355939677783421)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:32:42 -- STEP: 305/406 -- GLOBAL_STEP: 17350\u001b[0m\n",
      "     | > loss: 0.2162984013557434  (0.21307632317308525)\n",
      "     | > log_mle: -0.1357402801513672  (-0.1210053023744802)\n",
      "     | > loss_dur: 0.3520386815071106  (0.3340816255475655)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(9.7866, device='cuda:0')  (tensor(6.1054, device='cuda:0'))\n",
      "     | > current_lr: 6.5e-06 \n",
      "     | > step_time: 0.5208  (0.7043117460657341)\n",
      "     | > loader_time: 0.009  (0.01412104231412293)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:33:03 -- STEP: 330/406 -- GLOBAL_STEP: 17375\u001b[0m\n",
      "     | > loss: 0.20677942037582397  (0.21221652274782013)\n",
      "     | > log_mle: -0.1405402421951294  (-0.1219366602825396)\n",
      "     | > loss_dur: 0.34731966257095337  (0.33415318303035974)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(2.5025, device='cuda:0')  (tensor(5.9347, device='cuda:0'))\n",
      "     | > current_lr: 6.5e-06 \n",
      "     | > step_time: 0.6884  (0.7129011161399611)\n",
      "     | > loader_time: 0.0118  (0.014499496691154705)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:33:25 -- STEP: 355/406 -- GLOBAL_STEP: 17400\u001b[0m\n",
      "     | > loss: 0.18832829594612122  (0.2115990260956993)\n",
      "     | > log_mle: -0.14452850818634033  (-0.12301439483400801)\n",
      "     | > loss_dur: 0.33285680413246155  (0.33461342092970725)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(16.3502, device='cuda:0')  (tensor(6.3374, device='cuda:0'))\n",
      "     | > current_lr: 6.5e-06 \n",
      "     | > step_time: 1.1062  (0.7227730542841092)\n",
      "     | > loader_time: 0.0237  (0.014574954879116)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:33:47 -- STEP: 380/406 -- GLOBAL_STEP: 17425\u001b[0m\n",
      "     | > loss: 0.20558631420135498  (0.2108028164035396)\n",
      "     | > log_mle: -0.13502025604248047  (-0.12404339893868095)\n",
      "     | > loss_dur: 0.34060657024383545  (0.3348462153422204)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(11.0967, device='cuda:0')  (tensor(6.8730, device='cuda:0'))\n",
      "     | > current_lr: 6.5e-06 \n",
      "     | > step_time: 0.9137  (0.7310155931272004)\n",
      "     | > loader_time: 0.0204  (0.014932276073255032)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:34:05 -- STEP: 405/406 -- GLOBAL_STEP: 17450\u001b[0m\n",
      "     | > loss: 0.2309826910495758  (0.210039860525249)\n",
      "     | > log_mle: -0.13570010662078857  (-0.12500168438310977)\n",
      "     | > loss_dur: 0.3666827976703644  (0.3350415449083586)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(20.9422, device='cuda:0')  (tensor(7.3640, device='cuda:0'))\n",
      "     | > current_lr: 6.5e-06 \n",
      "     | > step_time: 0.3905  (0.7302711516250798)\n",
      "     | > loader_time: 0.0049  (0.014819995856579435)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: 0.18282446265220642  (0.18282446265220642)\n",
      "     | > log_mle: -0.10734128952026367  (-0.10734128952026367)\n",
      "     | > loss_dur: 0.2901657521724701  (0.2901657521724701)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: 0.17229872941970825  (0.17229872941970825)\n",
      "     | > log_mle: -0.14306342601776123  (-0.14306342601776123)\n",
      "     | > loss_dur: 0.3153621554374695  (0.3153621554374695)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: 0.2019517421722412  (0.18712523579597473)\n",
      "     | > log_mle: -0.10350918769836426  (-0.12328630685806274)\n",
      "     | > loss_dur: 0.30546092987060547  (0.3104115426540375)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: 0.164556086063385  (0.17960218588511148)\n",
      "     | > log_mle: -0.11935770511627197  (-0.12197677294413249)\n",
      "     | > loss_dur: 0.283913791179657  (0.30157895882924396)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: 0.19975128769874573  (0.18463946133852005)\n",
      "     | > log_mle: -0.1462571620941162  (-0.12804687023162842)\n",
      "     | > loss_dur: 0.34600844979286194  (0.31268633157014847)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: 0.1868574619293213  (0.1850830614566803)\n",
      "     | > log_mle: -0.14656460285186768  (-0.13175041675567628)\n",
      "     | > loss_dur: 0.33342206478118896  (0.3168334782123566)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: 0.2172011137008667  (0.1904360701640447)\n",
      "     | > log_mle: -0.15545940399169922  (-0.13570191462834677)\n",
      "     | > loss_dur: 0.3726605176925659  (0.3261379847923915)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: 0.18992620706558228  (0.19036323257855006)\n",
      "     | > log_mle: -0.12283611297607422  (-0.1338639429637364)\n",
      "     | > loss_dur: 0.3127623200416565  (0.32422717554228647)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: 0.19277778267860413  (0.19066505134105682)\n",
      "     | > log_mle: -0.12848079204559326  (-0.1331910490989685)\n",
      "     | > loss_dur: 0.3212585747241974  (0.32385610044002533)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: 0.23132073879241943  (0.19518234994676378)\n",
      "     | > log_mle: -0.13915443420410156  (-0.1338536474439833)\n",
      "     | > loss_dur: 0.370475172996521  (0.32903599739074707)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: 0.19866150617599487  (0.1955302655696869)\n",
      "     | > log_mle: -0.12849712371826172  (-0.13331799507141112)\n",
      "     | > loss_dur: 0.3271586298942566  (0.328848260641098)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: 0.17924532294273376  (0.19404981623996387)\n",
      "     | > log_mle: -0.14294147491455078  (-0.13419285687533292)\n",
      "     | > loss_dur: 0.32218679785728455  (0.3282426731152968)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: 0.16960865259170532  (0.192013052602609)\n",
      "     | > log_mle: -0.13200759887695312  (-0.1340107520421346)\n",
      "     | > loss_dur: 0.30161625146865845  (0.3260238046447436)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: 0.1433834433555603  (0.1882723134297591)\n",
      "     | > log_mle: -0.149436354637146  (-0.13519733685713547)\n",
      "     | > loss_dur: 0.2928197979927063  (0.32346965028689456)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: 0.21233299374580383  (0.18999093345233373)\n",
      "     | > log_mle: -0.14292550086975098  (-0.1357493485723223)\n",
      "     | > loss_dur: 0.3552584946155548  (0.32574028202465605)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: 0.162968248128891  (0.18818942109743755)\n",
      "     | > log_mle: -0.1374884843826294  (-0.13586529095967612)\n",
      "     | > loss_dur: 0.3004567325115204  (0.32405471205711367)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: 0.1667628288269043  (0.1868502590805292)\n",
      "     | > log_mle: -0.13130688667297363  (-0.1355803906917572)\n",
      "     | > loss_dur: 0.29806971549987793  (0.3224306497722864)\n",
      "\n",
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.005237504839897156 \u001b[0m(-0.0002528727054595947)\n",
      "     | > avg_loss:\u001b[92m 0.1868502590805292 \u001b[0m(-0.029877709224820137)\n",
      "     | > avg_log_mle:\u001b[92m -0.1355803906917572 \u001b[0m(-0.011964984238147736)\n",
      "     | > avg_loss_dur:\u001b[92m 0.3224306497722864 \u001b[0m(-0.0179127249866724)\n",
      "\n",
      " > BEST MODEL : train/run-February-22-2025_02+19AM-9b6e3e6/best_model_17451.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 27/40\u001b[0m\n",
      " --> train/run-February-22-2025_02+19AM-9b6e3e6\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-22 04:34:22) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:34:37 -- STEP: 24/406 -- GLOBAL_STEP: 17475\u001b[0m\n",
      "     | > loss: 0.1984967291355133  (0.20208043108383814)\n",
      "     | > log_mle: -0.10760641098022461  (-0.10660139222939809)\n",
      "     | > loss_dur: 0.3061031401157379  (0.3086818233132362)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(1.6523, device='cuda:0')  (tensor(2.5258, device='cuda:0'))\n",
      "     | > current_lr: 6.75e-06 \n",
      "     | > step_time: 0.6652  (0.49033061663309735)\n",
      "     | > loader_time: 0.0206  (0.00806566079457601)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:34:53 -- STEP: 49/406 -- GLOBAL_STEP: 17500\u001b[0m\n",
      "     | > loss: 0.21776732802391052  (0.2029274087779376)\n",
      "     | > log_mle: -0.11034774780273438  (-0.10765721846599968)\n",
      "     | > loss_dur: 0.3281150758266449  (0.31058462724393726)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(7.8976, device='cuda:0')  (tensor(3.4153, device='cuda:0'))\n",
      "     | > current_lr: 6.75e-06 \n",
      "     | > step_time: 0.3492  (0.5666993053591982)\n",
      "     | > loader_time: 0.0051  (0.010384087659874738)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:35:09 -- STEP: 74/406 -- GLOBAL_STEP: 17525\u001b[0m\n",
      "     | > loss: 0.18767154216766357  (0.2011093271745218)\n",
      "     | > log_mle: -0.14179682731628418  (-0.11148925890793672)\n",
      "     | > loss_dur: 0.32946836948394775  (0.3125985860824585)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.0328, device='cuda:0')  (tensor(4.1371, device='cuda:0'))\n",
      "     | > current_lr: 6.75e-06 \n",
      "     | > step_time: 0.566  (0.5786816107260216)\n",
      "     | > loader_time: 0.0049  (0.01201222393963788)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:35:26 -- STEP: 99/406 -- GLOBAL_STEP: 17550\u001b[0m\n",
      "     | > loss: 0.1986301839351654  (0.2000186949065237)\n",
      "     | > log_mle: -0.11909985542297363  (-0.11453140384019023)\n",
      "     | > loss_dur: 0.31773003935813904  (0.31455009874671397)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(1.7362, device='cuda:0')  (tensor(4.0262, device='cuda:0'))\n",
      "     | > current_lr: 6.75e-06 \n",
      "     | > step_time: 0.5012  (0.5963957044813367)\n",
      "     | > loader_time: 0.0156  (0.012299003023089785)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:35:44 -- STEP: 124/406 -- GLOBAL_STEP: 17575\u001b[0m\n",
      "     | > loss: 0.18891599774360657  (0.19785213855005077)\n",
      "     | > log_mle: -0.13207507133483887  (-0.11745687838523619)\n",
      "     | > loss_dur: 0.32099106907844543  (0.31530901693528696)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.6667, device='cuda:0')  (tensor(4.6679, device='cuda:0'))\n",
      "     | > current_lr: 6.75e-06 \n",
      "     | > step_time: 0.6959  (0.6209074143440492)\n",
      "     | > loader_time: 0.0077  (0.012836287098546182)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:36:03 -- STEP: 149/406 -- GLOBAL_STEP: 17600\u001b[0m\n",
      "     | > loss: 0.1833767592906952  (0.19649934268637792)\n",
      "     | > log_mle: -0.136712908744812  (-0.11979286702687308)\n",
      "     | > loss_dur: 0.3200896680355072  (0.316292209713251)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(2.9153, device='cuda:0')  (tensor(5.1162, device='cuda:0'))\n",
      "     | > current_lr: 6.75e-06 \n",
      "     | > step_time: 0.9978  (0.6395401186591027)\n",
      "     | > loader_time: 0.0092  (0.012736402101964759)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:36:22 -- STEP: 174/406 -- GLOBAL_STEP: 17625\u001b[0m\n",
      "     | > loss: 0.18867072463035583  (0.1959040017648675)\n",
      "     | > log_mle: -0.1326007843017578  (-0.1214814295713929)\n",
      "     | > loss_dur: 0.32127150893211365  (0.3173854313362604)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(13.4886, device='cuda:0')  (tensor(5.5485, device='cuda:0'))\n",
      "     | > current_lr: 6.75e-06 \n",
      "     | > step_time: 1.149  (0.6538380521467362)\n",
      "     | > loader_time: 0.0158  (0.013238116242419714)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:36:40 -- STEP: 199/406 -- GLOBAL_STEP: 17650\u001b[0m\n",
      "     | > loss: 0.1816488802433014  (0.19517891880255847)\n",
      "     | > log_mle: -0.1331084966659546  (-0.12322492455717307)\n",
      "     | > loss_dur: 0.314757376909256  (0.31840384335973143)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(6.5121, device='cuda:0')  (tensor(5.7310, device='cuda:0'))\n",
      "     | > current_lr: 6.75e-06 \n",
      "     | > step_time: 0.4549  (0.6627767709032375)\n",
      "     | > loader_time: 0.0063  (0.01345357703204131)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:37:00 -- STEP: 224/406 -- GLOBAL_STEP: 17675\u001b[0m\n",
      "     | > loss: 0.18288618326187134  (0.19441476903323615)\n",
      "     | > log_mle: -0.1297520399093628  (-0.1247720585337707)\n",
      "     | > loss_dur: 0.31263822317123413  (0.3191868275670067)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(14.1489, device='cuda:0')  (tensor(6.1842, device='cuda:0'))\n",
      "     | > current_lr: 6.75e-06 \n",
      "     | > step_time: 1.1899  (0.6757448017597198)\n",
      "     | > loader_time: 0.024  (0.013589238481862205)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:37:20 -- STEP: 249/406 -- GLOBAL_STEP: 17700\u001b[0m\n",
      "     | > loss: 0.19806012511253357  (0.19406174572117357)\n",
      "     | > log_mle: -0.13419091701507568  (-0.12621914765920986)\n",
      "     | > loss_dur: 0.33225104212760925  (0.3202808933803833)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(8.7440, device='cuda:0')  (tensor(6.2453, device='cuda:0'))\n",
      "     | > current_lr: 6.75e-06 \n",
      "     | > step_time: 0.7988  (0.6863559316918553)\n",
      "     | > loader_time: 0.0246  (0.013817651204794765)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:37:42 -- STEP: 274/406 -- GLOBAL_STEP: 17725\u001b[0m\n",
      "     | > loss: 0.19944047927856445  (0.19307263771982958)\n",
      "     | > log_mle: -0.14289593696594238  (-0.1276249989975978)\n",
      "     | > loss_dur: 0.34233641624450684  (0.32069763671742724)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.4846, device='cuda:0')  (tensor(6.5125, device='cuda:0'))\n",
      "     | > current_lr: 6.75e-06 \n",
      "     | > step_time: 0.9546  (0.6997727495040337)\n",
      "     | > loader_time: 0.0096  (0.014015227338693436)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:38:03 -- STEP: 299/406 -- GLOBAL_STEP: 17750\u001b[0m\n",
      "     | > loss: 0.17505300045013428  (0.19240138373247365)\n",
      "     | > log_mle: -0.15715301036834717  (-0.12865867622719956)\n",
      "     | > loss_dur: 0.33220601081848145  (0.32106005995967307)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(10.8096, device='cuda:0')  (tensor(6.7693, device='cuda:0'))\n",
      "     | > current_lr: 6.75e-06 \n",
      "     | > step_time: 0.7133  (0.7086550368114459)\n",
      "     | > loader_time: 0.0078  (0.014223868232905666)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:38:23 -- STEP: 324/406 -- GLOBAL_STEP: 17775\u001b[0m\n",
      "     | > loss: 0.1861867606639862  (0.1919525411025978)\n",
      "     | > log_mle: -0.14465737342834473  (-0.12964351383256323)\n",
      "     | > loss_dur: 0.33084413409233093  (0.32159605493516086)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(11.9570, device='cuda:0')  (tensor(6.9658, device='cuda:0'))\n",
      "     | > current_lr: 6.75e-06 \n",
      "     | > step_time: 0.7244  (0.7144621698944658)\n",
      "     | > loader_time: 0.0089  (0.014597340130511626)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:38:45 -- STEP: 349/406 -- GLOBAL_STEP: 17800\u001b[0m\n",
      "     | > loss: 0.2007296085357666  (0.19138023504896629)\n",
      "     | > log_mle: -0.1371556520462036  (-0.1305975022493597)\n",
      "     | > loss_dur: 0.3378852605819702  (0.3219777372983261)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(7.3728, device='cuda:0')  (tensor(7.0682, device='cuda:0'))\n",
      "     | > current_lr: 6.75e-06 \n",
      "     | > step_time: 0.7867  (0.7247321981413658)\n",
      "     | > loader_time: 0.0112  (0.01496867122486191)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:39:08 -- STEP: 374/406 -- GLOBAL_STEP: 17825\u001b[0m\n",
      "     | > loss: 0.18360605835914612  (0.1905832702622694)\n",
      "     | > log_mle: -0.14320313930511475  (-0.13161534931570448)\n",
      "     | > loss_dur: 0.32680919766426086  (0.322198619577974)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(5.9397, device='cuda:0')  (tensor(7.2797, device='cuda:0'))\n",
      "     | > current_lr: 6.75e-06 \n",
      "     | > step_time: 0.6606  (0.7360144381854623)\n",
      "     | > loader_time: 0.0079  (0.015086214172648873)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:39:28 -- STEP: 399/406 -- GLOBAL_STEP: 17850\u001b[0m\n",
      "     | > loss: 0.18329200148582458  (0.18991324313003616)\n",
      "     | > log_mle: -0.1470930576324463  (-0.1325291926998244)\n",
      "     | > loss_dur: 0.3303850591182709  (0.32244243582986065)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(13.1066, device='cuda:0')  (tensor(7.5332, device='cuda:0'))\n",
      "     | > current_lr: 6.75e-06 \n",
      "     | > step_time: 0.5741  (0.7386750637140489)\n",
      "     | > loader_time: 0.0074  (0.015150966500877439)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: 0.1652507781982422  (0.1652507781982422)\n",
      "     | > log_mle: -0.1157078742980957  (-0.1157078742980957)\n",
      "     | > loss_dur: 0.2809586524963379  (0.2809586524963379)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: 0.15268495678901672  (0.15268495678901672)\n",
      "     | > log_mle: -0.15252983570098877  (-0.15252983570098877)\n",
      "     | > loss_dur: 0.3052147924900055  (0.3052147924900055)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: 0.15472251176834106  (0.1537037342786789)\n",
      "     | > log_mle: -0.11213719844818115  (-0.13233351707458496)\n",
      "     | > loss_dur: 0.2668597102165222  (0.28603725135326385)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: 0.1534280776977539  (0.1536118487517039)\n",
      "     | > log_mle: -0.12899374961853027  (-0.13122026125590006)\n",
      "     | > loss_dur: 0.2824218273162842  (0.28483211000760394)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: 0.1686321198940277  (0.15736691653728485)\n",
      "     | > log_mle: -0.1558997631072998  (-0.13739013671875)\n",
      "     | > loss_dur: 0.3245318830013275  (0.29475705325603485)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: 0.1573004126548767  (0.15735361576080323)\n",
      "     | > log_mle: -0.15895342826843262  (-0.14170279502868652)\n",
      "     | > loss_dur: 0.3162538409233093  (0.29905641078948975)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: 0.19383639097213745  (0.1634340782960256)\n",
      "     | > log_mle: -0.16814053058624268  (-0.1461090842882792)\n",
      "     | > loss_dur: 0.3619769215583801  (0.3095431625843048)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: 0.15477019548416138  (0.16219638075147355)\n",
      "     | > log_mle: -0.1330089569091797  (-0.14423763751983643)\n",
      "     | > loss_dur: 0.28777915239334106  (0.30643401827131)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: 0.16357016563415527  (0.16236810386180878)\n",
      "     | > log_mle: -0.13772761821746826  (-0.1434238851070404)\n",
      "     | > loss_dur: 0.30129778385162354  (0.3057919889688492)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: 0.20534557104110718  (0.16714337799284193)\n",
      "     | > log_mle: -0.150199294090271  (-0.14417670832739937)\n",
      "     | > loss_dur: 0.3555448651313782  (0.3113200863202413)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: 0.16963404417037964  (0.16739244461059571)\n",
      "     | > log_mle: -0.13808059692382812  (-0.14356709718704225)\n",
      "     | > loss_dur: 0.30771464109420776  (0.31095954179763796)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: 0.1555313766002655  (0.16631416570056567)\n",
      "     | > log_mle: -0.15336716175079346  (-0.14445801214738327)\n",
      "     | > loss_dur: 0.30889853835105896  (0.3107721778479489)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: 0.13757124543190002  (0.16391892234484354)\n",
      "     | > log_mle: -0.14104390144348145  (-0.14417350292205813)\n",
      "     | > loss_dur: 0.27861514687538147  (0.3080924252669016)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: 0.11552152037620544  (0.16019604527033293)\n",
      "     | > log_mle: -0.16118621826171875  (-0.14548217333280128)\n",
      "     | > loss_dur: 0.2767077386379242  (0.3056782186031341)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: 0.18625116348266602  (0.16205712514264242)\n",
      "     | > log_mle: -0.1528719663619995  (-0.14601001569202973)\n",
      "     | > loss_dur: 0.3391231298446655  (0.30806714083467207)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: 0.13647395372390747  (0.16035158038139344)\n",
      "     | > log_mle: -0.1476154327392578  (-0.1461170434951783)\n",
      "     | > loss_dur: 0.2840893864631653  (0.3064686238765716)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: 0.1440275013446808  (0.1593313254415989)\n",
      "     | > log_mle: -0.14272356033325195  (-0.1459049507975579)\n",
      "     | > loss_dur: 0.28675106167793274  (0.30523627623915667)\n",
      "\n",
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.003999263048171997 \u001b[0m(-0.0012382417917251587)\n",
      "     | > avg_loss:\u001b[92m 0.1593313254415989 \u001b[0m(-0.02751893363893032)\n",
      "     | > avg_log_mle:\u001b[92m -0.1459049507975579 \u001b[0m(-0.010324560105800684)\n",
      "     | > avg_loss_dur:\u001b[92m 0.30523627623915667 \u001b[0m(-0.017194373533129748)\n",
      "\n",
      " > BEST MODEL : train/run-February-22-2025_02+19AM-9b6e3e6/best_model_17857.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 28/40\u001b[0m\n",
      " --> train/run-February-22-2025_02+19AM-9b6e3e6\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-22 04:39:48) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:39:59 -- STEP: 18/406 -- GLOBAL_STEP: 17875\u001b[0m\n",
      "     | > loss: 0.1793317198753357  (0.18435335159301758)\n",
      "     | > log_mle: -0.11058521270751953  (-0.11533493465847439)\n",
      "     | > loss_dur: 0.2899169325828552  (0.29968828625149196)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(5.9482, device='cuda:0')  (tensor(3.8042, device='cuda:0'))\n",
      "     | > current_lr: 7e-06 \n",
      "     | > step_time: 0.7347  (0.45720790492163765)\n",
      "     | > loader_time: 0.0057  (0.006421155399746365)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:40:15 -- STEP: 43/406 -- GLOBAL_STEP: 17900\u001b[0m\n",
      "     | > loss: 0.16317814588546753  (0.18428557210190352)\n",
      "     | > log_mle: -0.10860824584960938  (-0.11439638636833013)\n",
      "     | > loss_dur: 0.2717863917350769  (0.2986819584702336)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(2.0094, device='cuda:0')  (tensor(4.5811, device='cuda:0'))\n",
      "     | > current_lr: 7e-06 \n",
      "     | > step_time: 0.8216  (0.5612715732219605)\n",
      "     | > loader_time: 0.0363  (0.01070430666901344)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:40:32 -- STEP: 68/406 -- GLOBAL_STEP: 17925\u001b[0m\n",
      "     | > loss: 0.17129018902778625  (0.18377026784069397)\n",
      "     | > log_mle: -0.12937581539154053  (-0.11773553140023175)\n",
      "     | > loss_dur: 0.3006660044193268  (0.30150579924092574)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(7.3330, device='cuda:0')  (tensor(4.8379, device='cuda:0'))\n",
      "     | > current_lr: 7e-06 \n",
      "     | > step_time: 0.2989  (0.5907700166982762)\n",
      "     | > loader_time: 0.0041  (0.009839941473568184)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:40:48 -- STEP: 93/406 -- GLOBAL_STEP: 17950\u001b[0m\n",
      "     | > loss: 0.1680879294872284  (0.18162803752447962)\n",
      "     | > log_mle: -0.14643621444702148  (-0.12127091679521786)\n",
      "     | > loss_dur: 0.3145241439342499  (0.3028989543196975)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(12.2093, device='cuda:0')  (tensor(6.4730, device='cuda:0'))\n",
      "     | > current_lr: 7e-06 \n",
      "     | > step_time: 0.5416  (0.6068888325845041)\n",
      "     | > loader_time: 0.0067  (0.01058576696662492)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:41:05 -- STEP: 118/406 -- GLOBAL_STEP: 17975\u001b[0m\n",
      "     | > loss: 0.17300733923912048  (0.179991071001958)\n",
      "     | > log_mle: -0.1422804594039917  (-0.12401827513161352)\n",
      "     | > loss_dur: 0.3152877986431122  (0.30400934613357145)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(7.2870, device='cuda:0')  (tensor(7.4812, device='cuda:0'))\n",
      "     | > current_lr: 7e-06 \n",
      "     | > step_time: 0.6454  (0.6159541162393861)\n",
      "     | > loader_time: 0.0071  (0.011117163351026629)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:41:24 -- STEP: 143/406 -- GLOBAL_STEP: 18000\u001b[0m\n",
      "     | > loss: 0.15833133459091187  (0.179041004681087)\n",
      "     | > log_mle: -0.1419767141342163  (-0.12656680353871597)\n",
      "     | > loss_dur: 0.3003080487251282  (0.3056078082198029)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(6.2854, device='cuda:0')  (tensor(7.9108, device='cuda:0'))\n",
      "     | > current_lr: 7e-06 \n",
      "     | > step_time: 0.768  (0.6344247931367034)\n",
      "     | > loader_time: 0.0175  (0.011899042796421714)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:41:41 -- STEP: 168/406 -- GLOBAL_STEP: 18025\u001b[0m\n",
      "     | > loss: 0.18138790130615234  (0.17894453395690232)\n",
      "     | > log_mle: -0.12943601608276367  (-0.1282625439621154)\n",
      "     | > loss_dur: 0.310823917388916  (0.30720707791901763)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(10.6927, device='cuda:0')  (tensor(7.8745, device='cuda:0'))\n",
      "     | > current_lr: 7e-06 \n",
      "     | > step_time: 0.3938  (0.6411155178433373)\n",
      "     | > loader_time: 0.0069  (0.011941855862027118)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:42:00 -- STEP: 193/406 -- GLOBAL_STEP: 18050\u001b[0m\n",
      "     | > loss: 0.17136090993881226  (0.17826814802817106)\n",
      "     | > log_mle: -0.14239585399627686  (-0.13000865056724745)\n",
      "     | > loss_dur: 0.3137567639350891  (0.3082767985954185)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(7.4792, device='cuda:0')  (tensor(8.1544, device='cuda:0'))\n",
      "     | > current_lr: 7e-06 \n",
      "     | > step_time: 0.9048  (0.6550170856436299)\n",
      "     | > loader_time: 0.0097  (0.012531851239772653)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:42:20 -- STEP: 218/406 -- GLOBAL_STEP: 18075\u001b[0m\n",
      "     | > loss: 0.1922513246536255  (0.17757551331038862)\n",
      "     | > log_mle: -0.14156663417816162  (-0.13146867664582138)\n",
      "     | > loss_dur: 0.3338179588317871  (0.30904418995620997)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(8.0575, device='cuda:0')  (tensor(8.0933, device='cuda:0'))\n",
      "     | > current_lr: 7e-06 \n",
      "     | > step_time: 0.6187  (0.6674409120454701)\n",
      "     | > loader_time: 0.0078  (0.012586965473420026)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:42:39 -- STEP: 243/406 -- GLOBAL_STEP: 18100\u001b[0m\n",
      "     | > loss: 0.18059825897216797  (0.17732113673363198)\n",
      "     | > log_mle: -0.15945219993591309  (-0.1330469895782784)\n",
      "     | > loss_dur: 0.34005045890808105  (0.31036812631191035)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(5.1967, device='cuda:0')  (tensor(8.1574, device='cuda:0'))\n",
      "     | > current_lr: 7e-06 \n",
      "     | > step_time: 0.6479  (0.6770234569110007)\n",
      "     | > loader_time: 0.0083  (0.012829551971498336)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:43:00 -- STEP: 268/406 -- GLOBAL_STEP: 18125\u001b[0m\n",
      "     | > loss: 0.15999171137809753  (0.1762415832325593)\n",
      "     | > log_mle: -0.15451490879058838  (-0.1342230821723368)\n",
      "     | > loss_dur: 0.3145066201686859  (0.31046466540489615)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.6305, device='cuda:0')  (tensor(8.1262, device='cuda:0'))\n",
      "     | > current_lr: 7e-06 \n",
      "     | > step_time: 0.9238  (0.6901772475954313)\n",
      "     | > loader_time: 0.0407  (0.013238055492514991)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:43:21 -- STEP: 293/406 -- GLOBAL_STEP: 18150\u001b[0m\n",
      "     | > loss: 0.17291834950447083  (0.17551229207588948)\n",
      "     | > log_mle: -0.1510772705078125  (-0.13534769751512962)\n",
      "     | > loss_dur: 0.3239956200122833  (0.31085998959101907)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(11.9098, device='cuda:0')  (tensor(8.2714, device='cuda:0'))\n",
      "     | > current_lr: 7e-06 \n",
      "     | > step_time: 0.7784  (0.6998512354320228)\n",
      "     | > loader_time: 0.0162  (0.013137993145314497)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:43:43 -- STEP: 318/406 -- GLOBAL_STEP: 18175\u001b[0m\n",
      "     | > loss: 0.18974199891090393  (0.17494474248316305)\n",
      "     | > log_mle: -0.14137649536132812  (-0.13641168448910024)\n",
      "     | > loss_dur: 0.33111849427223206  (0.31135642697226323)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(6.4186, device='cuda:0')  (tensor(8.3799, device='cuda:0'))\n",
      "     | > current_lr: 7e-06 \n",
      "     | > step_time: 1.2366  (0.7131091138851717)\n",
      "     | > loader_time: 0.0084  (0.013175447781880697)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:44:06 -- STEP: 343/406 -- GLOBAL_STEP: 18200\u001b[0m\n",
      "     | > loss: 0.16422435641288757  (0.17448206145978878)\n",
      "     | > log_mle: -0.15952420234680176  (-0.13737027950954167)\n",
      "     | > loss_dur: 0.32374855875968933  (0.3118523409693304)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(12.3791, device='cuda:0')  (tensor(8.4756, device='cuda:0'))\n",
      "     | > current_lr: 7e-06 \n",
      "     | > step_time: 1.5945  (0.7247947325859404)\n",
      "     | > loader_time: 0.0255  (0.013533022243844525)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:44:28 -- STEP: 368/406 -- GLOBAL_STEP: 18225\u001b[0m\n",
      "     | > loss: 0.17861032485961914  (0.17394049214604113)\n",
      "     | > log_mle: -0.1483919620513916  (-0.13835041775651608)\n",
      "     | > loss_dur: 0.32700228691101074  (0.31229090990255715)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(15.7056, device='cuda:0')  (tensor(8.6633, device='cuda:0'))\n",
      "     | > current_lr: 7e-06 \n",
      "     | > step_time: 1.235  (0.7351512850626655)\n",
      "     | > loader_time: 0.0171  (0.013750961941221485)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:44:51 -- STEP: 393/406 -- GLOBAL_STEP: 18250\u001b[0m\n",
      "     | > loss: 0.16639775037765503  (0.1733811023732785)\n",
      "     | > log_mle: -0.1563882827758789  (-0.1392464637756349)\n",
      "     | > loss_dur: 0.32278603315353394  (0.3126275661489133)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(11.1127, device='cuda:0')  (tensor(8.9331, device='cuda:0'))\n",
      "     | > current_lr: 7e-06 \n",
      "     | > step_time: 0.584  (0.7445573521631061)\n",
      "     | > loader_time: 0.0091  (0.014015465898974858)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: 0.13959181308746338  (0.13959181308746338)\n",
      "     | > log_mle: -0.12270891666412354  (-0.12270891666412354)\n",
      "     | > loss_dur: 0.2623007297515869  (0.2623007297515869)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: 0.13340094685554504  (0.13340094685554504)\n",
      "     | > log_mle: -0.15969014167785645  (-0.15969014167785645)\n",
      "     | > loss_dur: 0.2930910885334015  (0.2930910885334015)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: 0.13841724395751953  (0.1359090954065323)\n",
      "     | > log_mle: -0.11931955814361572  (-0.13950484991073608)\n",
      "     | > loss_dur: 0.25773680210113525  (0.27541394531726837)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: 0.13756850361824036  (0.13646223147710165)\n",
      "     | > log_mle: -0.13628137111663818  (-0.13843035697937012)\n",
      "     | > loss_dur: 0.27384987473487854  (0.27489258845647174)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: 0.15418434143066406  (0.14089275896549225)\n",
      "     | > log_mle: -0.16298425197601318  (-0.14456883072853088)\n",
      "     | > loss_dur: 0.31716859340667725  (0.28546158969402313)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: 0.13848131895065308  (0.1404104709625244)\n",
      "     | > log_mle: -0.167344331741333  (-0.1491239309310913)\n",
      "     | > loss_dur: 0.3058256506919861  (0.28953440189361573)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: 0.17957475781440735  (0.1469378521045049)\n",
      "     | > log_mle: -0.17695844173431396  (-0.15376301606496176)\n",
      "     | > loss_dur: 0.3565331995487213  (0.3007008681694667)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: 0.13210174441337585  (0.1448184081486293)\n",
      "     | > log_mle: -0.1406099796295166  (-0.15188401085989817)\n",
      "     | > loss_dur: 0.27271172404289246  (0.2967024190085275)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: 0.13443875312805176  (0.14352095127105713)\n",
      "     | > log_mle: -0.14495384693145752  (-0.15101774036884308)\n",
      "     | > loss_dur: 0.2793926000595093  (0.2945386916399002)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: 0.19385302066802979  (0.14911340342627633)\n",
      "     | > log_mle: -0.15815317630767822  (-0.1518105665842692)\n",
      "     | > loss_dur: 0.352006196975708  (0.3009239700105455)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: 0.1579420268535614  (0.14999626576900482)\n",
      "     | > log_mle: -0.14549005031585693  (-0.15117851495742798)\n",
      "     | > loss_dur: 0.30343207716941833  (0.3011747807264328)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: 0.14016911387443542  (0.14910288832404398)\n",
      "     | > log_mle: -0.16089308261871338  (-0.1520616574720903)\n",
      "     | > loss_dur: 0.3010621964931488  (0.3011645457961343)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: 0.12500399351119995  (0.1470946470896403)\n",
      "     | > log_mle: -0.14833557605743408  (-0.1517511506875356)\n",
      "     | > loss_dur: 0.27333956956863403  (0.2988457977771759)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: 0.09825149178504944  (0.14333748129697946)\n",
      "     | > log_mle: -0.16922807693481445  (-0.15309552962963396)\n",
      "     | > loss_dur: 0.2674795687198639  (0.29643301092661345)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: 0.16768288612365723  (0.1450764387845993)\n",
      "     | > log_mle: -0.16056275367736816  (-0.15362890277590072)\n",
      "     | > loss_dur: 0.3282456398010254  (0.2987053415605)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: 0.13194909691810608  (0.14420128266016644)\n",
      "     | > log_mle: -0.1550443172454834  (-0.15372326374053955)\n",
      "     | > loss_dur: 0.2869934141635895  (0.297924546400706)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: 0.12193503975868225  (0.14280964247882366)\n",
      "     | > log_mle: -0.15088379383087158  (-0.1535457968711853)\n",
      "     | > loss_dur: 0.27281883358955383  (0.29635543935000896)\n",
      "\n",
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[91m 0.004221707582473755 \u001b[0m(+0.0002224445343017578)\n",
      "     | > avg_loss:\u001b[92m 0.14280964247882366 \u001b[0m(-0.01652168296277523)\n",
      "     | > avg_log_mle:\u001b[92m -0.1535457968711853 \u001b[0m(-0.007640846073627416)\n",
      "     | > avg_loss_dur:\u001b[92m 0.29635543935000896 \u001b[0m(-0.008880836889147703)\n",
      "\n",
      " > BEST MODEL : train/run-February-22-2025_02+19AM-9b6e3e6/best_model_18263.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 29/40\u001b[0m\n",
      " --> train/run-February-22-2025_02+19AM-9b6e3e6\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-22 04:45:14) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:45:22 -- STEP: 12/406 -- GLOBAL_STEP: 18275\u001b[0m\n",
      "     | > loss: 0.15638795495033264  (0.16411114980777106)\n",
      "     | > log_mle: -0.13284718990325928  (-0.1205934186776479)\n",
      "     | > loss_dur: 0.2892351448535919  (0.284704568485419)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.9890, device='cuda:0')  (tensor(3.9638, device='cuda:0'))\n",
      "     | > current_lr: 7.25e-06 \n",
      "     | > step_time: 0.3878  (0.37576814492543537)\n",
      "     | > loader_time: 0.0057  (0.005339701970418294)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:45:38 -- STEP: 37/406 -- GLOBAL_STEP: 18300\u001b[0m\n",
      "     | > loss: 0.16381904482841492  (0.16764404805930885)\n",
      "     | > log_mle: -0.11924099922180176  (-0.12147060278299693)\n",
      "     | > loss_dur: 0.2830600440502167  (0.28911465084230575)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(5.5090, device='cuda:0')  (tensor(3.8928, device='cuda:0'))\n",
      "     | > current_lr: 7.25e-06 \n",
      "     | > step_time: 0.4599  (0.5552731720176903)\n",
      "     | > loader_time: 0.0046  (0.008103834616171347)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:45:55 -- STEP: 62/406 -- GLOBAL_STEP: 18325\u001b[0m\n",
      "     | > loss: 0.1546536386013031  (0.1673167453658196)\n",
      "     | > log_mle: -0.1226423978805542  (-0.12389763709037535)\n",
      "     | > loss_dur: 0.2772960364818573  (0.29121438245619485)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(2.3557, device='cuda:0')  (tensor(3.7706, device='cuda:0'))\n",
      "     | > current_lr: 7.25e-06 \n",
      "     | > step_time: 0.769  (0.5975687888360793)\n",
      "     | > loader_time: 0.0337  (0.010576351996391047)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:46:12 -- STEP: 87/406 -- GLOBAL_STEP: 18350\u001b[0m\n",
      "     | > loss: 0.14604729413986206  (0.16567356490540777)\n",
      "     | > log_mle: -0.15131616592407227  (-0.12714888994721163)\n",
      "     | > loss_dur: 0.2973634600639343  (0.2928224548526192)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(17.5538, device='cuda:0')  (tensor(6.2379, device='cuda:0'))\n",
      "     | > current_lr: 7.25e-06 \n",
      "     | > step_time: 0.6947  (0.611126735292632)\n",
      "     | > loader_time: 0.0081  (0.012229560435503377)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:46:30 -- STEP: 112/406 -- GLOBAL_STEP: 18375\u001b[0m\n",
      "     | > loss: 0.1554623246192932  (0.1645592006721667)\n",
      "     | > log_mle: -0.14444077014923096  (-0.130111931690148)\n",
      "     | > loss_dur: 0.29990309476852417  (0.2946711323623145)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(5.0873, device='cuda:0')  (tensor(6.8722, device='cuda:0'))\n",
      "     | > current_lr: 7.25e-06 \n",
      "     | > step_time: 0.8633  (0.6264810647283282)\n",
      "     | > loader_time: 0.0086  (0.01260699757507869)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:46:48 -- STEP: 137/406 -- GLOBAL_STEP: 18400\u001b[0m\n",
      "     | > loss: 0.17069584131240845  (0.16351808335659276)\n",
      "     | > log_mle: -0.1422349214553833  (-0.13245278727399173)\n",
      "     | > loss_dur: 0.31293076276779175  (0.2959708706305844)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(6.2335, device='cuda:0')  (tensor(7.5897, device='cuda:0'))\n",
      "     | > current_lr: 7.25e-06 \n",
      "     | > step_time: 0.7478  (0.6410878017871049)\n",
      "     | > loader_time: 0.0058  (0.013021378621567775)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:47:07 -- STEP: 162/406 -- GLOBAL_STEP: 18425\u001b[0m\n",
      "     | > loss: 0.1613803207874298  (0.163306662145956)\n",
      "     | > log_mle: -0.14641594886779785  (-0.13417960684976465)\n",
      "     | > loss_dur: 0.30779626965522766  (0.29748626899572056)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(15.0470, device='cuda:0')  (tensor(8.2859, device='cuda:0'))\n",
      "     | > current_lr: 7.25e-06 \n",
      "     | > step_time: 0.6985  (0.6542014001328268)\n",
      "     | > loader_time: 0.0061  (0.013292455378873849)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:47:26 -- STEP: 187/406 -- GLOBAL_STEP: 18450\u001b[0m\n",
      "     | > loss: 0.15539830923080444  (0.16286335973178628)\n",
      "     | > log_mle: -0.15129518508911133  (-0.13593074854682474)\n",
      "     | > loss_dur: 0.30669349431991577  (0.298794108278611)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(9.0572, device='cuda:0')  (tensor(8.7619, device='cuda:0'))\n",
      "     | > current_lr: 7.25e-06 \n",
      "     | > step_time: 0.635  (0.6656326495389885)\n",
      "     | > loader_time: 0.0073  (0.013928484789190445)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:47:45 -- STEP: 212/406 -- GLOBAL_STEP: 18475\u001b[0m\n",
      "     | > loss: 0.16746851801872253  (0.16212024834920763)\n",
      "     | > log_mle: -0.16151440143585205  (-0.13746105556218136)\n",
      "     | > loss_dur: 0.3289829194545746  (0.299581303911389)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(9.7064, device='cuda:0')  (tensor(8.7132, device='cuda:0'))\n",
      "     | > current_lr: 7.25e-06 \n",
      "     | > step_time: 1.0488  (0.6771843163472299)\n",
      "     | > loader_time: 0.007  (0.013844114429545853)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:48:05 -- STEP: 237/406 -- GLOBAL_STEP: 18500\u001b[0m\n",
      "     | > loss: 0.1576956808567047  (0.16194926623553654)\n",
      "     | > log_mle: -0.16504454612731934  (-0.13902910550435385)\n",
      "     | > loss_dur: 0.32274022698402405  (0.3009783717398904)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(9.2097, device='cuda:0')  (tensor(8.8566, device='cuda:0'))\n",
      "     | > current_lr: 7.25e-06 \n",
      "     | > step_time: 0.5201  (0.6857511232673867)\n",
      "     | > loader_time: 0.0195  (0.013906318930130971)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:48:25 -- STEP: 262/406 -- GLOBAL_STEP: 18525\u001b[0m\n",
      "     | > loss: 0.16270437836647034  (0.16114178425028114)\n",
      "     | > log_mle: -0.13452041149139404  (-0.14036501727941383)\n",
      "     | > loss_dur: 0.2972247898578644  (0.30150680152969495)\n",
      "     | > amp_scaler: 32768.0  (17134.41221374046)\n",
      "     | > grad_norm: tensor(7.0615, device='cuda:0')  (tensor(8.8803, device='cuda:0'))\n",
      "     | > current_lr: 7.25e-06 \n",
      "     | > step_time: 0.8362  (0.6940301784122261)\n",
      "     | > loader_time: 0.0225  (0.014123250509946401)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:48:45 -- STEP: 287/406 -- GLOBAL_STEP: 18550\u001b[0m\n",
      "     | > loss: 0.16967108845710754  (0.16035559669604277)\n",
      "     | > log_mle: -0.15168237686157227  (-0.1415531294686454)\n",
      "     | > loss_dur: 0.3213534653186798  (0.30190872616468817)\n",
      "     | > amp_scaler: 32768.0  (18496.222996515684)\n",
      "     | > grad_norm: tensor(4.1207, device='cuda:0')  (tensor(8.7424, device='cuda:0'))\n",
      "     | > current_lr: 7.25e-06 \n",
      "     | > step_time: 1.3379  (0.7014617778698325)\n",
      "     | > loader_time: 0.0096  (0.01431401515256237)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:49:05 -- STEP: 312/406 -- GLOBAL_STEP: 18575\u001b[0m\n",
      "     | > loss: 0.14333978295326233  (0.1599495412829594)\n",
      "     | > log_mle: -0.15877509117126465  (-0.14255050588876766)\n",
      "     | > loss_dur: 0.302114874124527  (0.30250004717172707)\n",
      "     | > amp_scaler: 16384.0  (18747.076923076926)\n",
      "     | > grad_norm: tensor(9.6473, device='cuda:0')  (tensor(8.8341, device='cuda:0'))\n",
      "     | > current_lr: 7.25e-06 \n",
      "     | > step_time: 1.2484  (0.708675920963287)\n",
      "     | > loader_time: 0.0061  (0.014331748088200888)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:49:28 -- STEP: 337/406 -- GLOBAL_STEP: 18600\u001b[0m\n",
      "     | > loss: 0.1693696677684784  (0.15950550284866757)\n",
      "     | > log_mle: -0.15046632289886475  (-0.14346471030917285)\n",
      "     | > loss_dur: 0.31983599066734314  (0.3029702131578404)\n",
      "     | > amp_scaler: 16384.0  (18571.774480712156)\n",
      "     | > grad_norm: tensor(3.4766, device='cuda:0')  (tensor(8.9605, device='cuda:0'))\n",
      "     | > current_lr: 7.25e-06 \n",
      "     | > step_time: 1.314  (0.721115292710437)\n",
      "     | > loader_time: 0.0152  (0.014816867845348506)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:49:50 -- STEP: 362/406 -- GLOBAL_STEP: 18625\u001b[0m\n",
      "     | > loss: 0.14404696226119995  (0.1591274861802053)\n",
      "     | > log_mle: -0.16468989849090576  (-0.1444615794150209)\n",
      "     | > loss_dur: 0.3087368607521057  (0.30358906559522625)\n",
      "     | > amp_scaler: 16384.0  (18420.68508287291)\n",
      "     | > grad_norm: tensor(10.8044, device='cuda:0')  (tensor(9.3172, device='cuda:0'))\n",
      "     | > current_lr: 7.25e-06 \n",
      "     | > step_time: 0.858  (0.7313309907913204)\n",
      "     | > loader_time: 0.0431  (0.015236285509984137)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:50:13 -- STEP: 387/406 -- GLOBAL_STEP: 18650\u001b[0m\n",
      "     | > loss: 0.1371479630470276  (0.15863711127015045)\n",
      "     | > log_mle: -0.16079926490783691  (-0.14534648074660184)\n",
      "     | > loss_dur: 0.2979472279548645  (0.3039835920167523)\n",
      "     | > amp_scaler: 16384.0  (18289.116279069745)\n",
      "     | > grad_norm: tensor(7.6852, device='cuda:0')  (tensor(9.3558, device='cuda:0'))\n",
      "     | > current_lr: 7.25e-06 \n",
      "     | > step_time: 1.3336  (0.7411826100460315)\n",
      "     | > loader_time: 0.0078  (0.015401066427699048)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: 0.12894633412361145  (0.12894633412361145)\n",
      "     | > log_mle: -0.12894034385681152  (-0.12894034385681152)\n",
      "     | > loss_dur: 0.257886677980423  (0.257886677980423)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: 0.11872634291648865  (0.11872634291648865)\n",
      "     | > log_mle: -0.16481757164001465  (-0.16481757164001465)\n",
      "     | > loss_dur: 0.2835439145565033  (0.2835439145565033)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: 0.11359846591949463  (0.11616240441799164)\n",
      "     | > log_mle: -0.12490463256835938  (-0.144861102104187)\n",
      "     | > loss_dur: 0.238503098487854  (0.26102350652217865)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: 0.1167570948600769  (0.1163606345653534)\n",
      "     | > log_mle: -0.14092469215393066  (-0.14354896545410156)\n",
      "     | > loss_dur: 0.25768178701400757  (0.25990960001945496)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: 0.13971900939941406  (0.12220022827386856)\n",
      "     | > log_mle: -0.16713488101959229  (-0.14944544434547424)\n",
      "     | > loss_dur: 0.30685389041900635  (0.2716456726193428)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: 0.12471726536750793  (0.12270363569259643)\n",
      "     | > log_mle: -0.1673896312713623  (-0.15303428173065187)\n",
      "     | > loss_dur: 0.29210689663887024  (0.27573791742324827)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: 0.17680081725120544  (0.13171983261903128)\n",
      "     | > log_mle: -0.17734122276306152  (-0.1570854385693868)\n",
      "     | > loss_dur: 0.35414204001426697  (0.2888052711884181)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: 0.12344697117805481  (0.13053799527032034)\n",
      "     | > log_mle: -0.14421331882476807  (-0.15524656432015554)\n",
      "     | > loss_dur: 0.2676602900028229  (0.2857845595904759)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: 0.12249863147735596  (0.1295330747961998)\n",
      "     | > log_mle: -0.14960241317749023  (-0.1545410454273224)\n",
      "     | > loss_dur: 0.2721010446548462  (0.2840741202235222)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: 0.17932063341140747  (0.1350650257534451)\n",
      "     | > log_mle: -0.16092419624328613  (-0.1552502844068739)\n",
      "     | > loss_dur: 0.3402448296546936  (0.29031531016031903)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: 0.1505645513534546  (0.13661497831344604)\n",
      "     | > log_mle: -0.14913415908813477  (-0.154638671875)\n",
      "     | > loss_dur: 0.29969871044158936  (0.29125365018844607)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: 0.12878072261810303  (0.13590277325023303)\n",
      "     | > log_mle: -0.1643221378326416  (-0.15551898696205832)\n",
      "     | > loss_dur: 0.29310286045074463  (0.2914217602122914)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: 0.1140693724155426  (0.1340833231806755)\n",
      "     | > log_mle: -0.15263104438781738  (-0.15527832508087158)\n",
      "     | > loss_dur: 0.26670041680336  (0.2893616482615471)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: 0.08424133062362671  (0.13024932375321022)\n",
      "     | > log_mle: -0.17120468616485596  (-0.1565034297796396)\n",
      "     | > loss_dur: 0.25544601678848267  (0.28675275353284985)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: 0.15904712677001953  (0.13230630968298232)\n",
      "     | > log_mle: -0.16419804096221924  (-0.1570530448641096)\n",
      "     | > loss_dur: 0.32324516773223877  (0.2893593545470919)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: 0.12163248658180237  (0.131594721476237)\n",
      "     | > log_mle: -0.15878021717071533  (-0.15716818968454996)\n",
      "     | > loss_dur: 0.2804127037525177  (0.28876291116078695)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: 0.11384493112564087  (0.13048535957932472)\n",
      "     | > log_mle: -0.15350449085235596  (-0.15693920850753784)\n",
      "     | > loss_dur: 0.2673494219779968  (0.28742456808686256)\n",
      "\n",
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[91m 0.006157979369163513 \u001b[0m(+0.0019362717866897583)\n",
      "     | > avg_loss:\u001b[92m 0.13048535957932472 \u001b[0m(-0.01232428289949894)\n",
      "     | > avg_log_mle:\u001b[92m -0.15693920850753784 \u001b[0m(-0.003393411636352539)\n",
      "     | > avg_loss_dur:\u001b[92m 0.28742456808686256 \u001b[0m(-0.0089308712631464)\n",
      "\n",
      " > BEST MODEL : train/run-February-22-2025_02+19AM-9b6e3e6/best_model_18669.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 30/40\u001b[0m\n",
      " --> train/run-February-22-2025_02+19AM-9b6e3e6\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-22 04:50:41) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:50:46 -- STEP: 6/406 -- GLOBAL_STEP: 18675\u001b[0m\n",
      "     | > loss: 0.13001969456672668  (0.15719568729400635)\n",
      "     | > log_mle: -0.12682831287384033  (-0.12421315908432007)\n",
      "     | > loss_dur: 0.256848007440567  (0.2814088463783264)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(2.8717, device='cuda:0')  (tensor(3.8864, device='cuda:0'))\n",
      "     | > current_lr: 7.499999999999999e-06 \n",
      "     | > step_time: 0.3891  (0.38500014940897626)\n",
      "     | > loader_time: 0.0045  (0.008387168248494467)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:51:00 -- STEP: 31/406 -- GLOBAL_STEP: 18700\u001b[0m\n",
      "     | > loss: 0.14813798666000366  (0.1507345659117545)\n",
      "     | > log_mle: -0.1236867904663086  (-0.12787498966340097)\n",
      "     | > loss_dur: 0.27182477712631226  (0.2786095555751554)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(2.4847, device='cuda:0')  (tensor(3.7295, device='cuda:0'))\n",
      "     | > current_lr: 7.499999999999999e-06 \n",
      "     | > step_time: 0.7064  (0.511374496644543)\n",
      "     | > loader_time: 0.0286  (0.009399137189311365)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:51:15 -- STEP: 56/406 -- GLOBAL_STEP: 18725\u001b[0m\n",
      "     | > loss: 0.1498783826828003  (0.15249949480806085)\n",
      "     | > log_mle: -0.13647007942199707  (-0.12984208124024527)\n",
      "     | > loss_dur: 0.28634846210479736  (0.2823415760483059)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(2.9079, device='cuda:0')  (tensor(4.8458, device='cuda:0'))\n",
      "     | > current_lr: 7.499999999999999e-06 \n",
      "     | > step_time: 0.562  (0.5555064295019422)\n",
      "     | > loader_time: 0.0065  (0.010360028062547957)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:51:32 -- STEP: 81/406 -- GLOBAL_STEP: 18750\u001b[0m\n",
      "     | > loss: 0.13470911979675293  (0.1518533347565451)\n",
      "     | > log_mle: -0.1461395025253296  (-0.13260541874685405)\n",
      "     | > loss_dur: 0.2808486223220825  (0.28445875350339905)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(5.5368, device='cuda:0')  (tensor(4.5702, device='cuda:0'))\n",
      "     | > current_lr: 7.499999999999999e-06 \n",
      "     | > step_time: 0.3508  (0.5867891812030178)\n",
      "     | > loader_time: 0.018  (0.011434449089898003)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:51:49 -- STEP: 106/406 -- GLOBAL_STEP: 18775\u001b[0m\n",
      "     | > loss: 0.15741676092147827  (0.15066834497001938)\n",
      "     | > log_mle: -0.13632261753082275  (-0.13564118686712012)\n",
      "     | > loss_dur: 0.293739378452301  (0.2863095318371394)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(6.3033, device='cuda:0')  (tensor(5.7372, device='cuda:0'))\n",
      "     | > current_lr: 7.499999999999999e-06 \n",
      "     | > step_time: 0.3834  (0.6035582299502388)\n",
      "     | > loader_time: 0.0053  (0.012578966482630313)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:52:08 -- STEP: 131/406 -- GLOBAL_STEP: 18800\u001b[0m\n",
      "     | > loss: 0.12117302417755127  (0.1491411792412969)\n",
      "     | > log_mle: -0.14966166019439697  (-0.13843441464518771)\n",
      "     | > loss_dur: 0.27083468437194824  (0.2875755938864845)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.4929, device='cuda:0')  (tensor(6.2193, device='cuda:0'))\n",
      "     | > current_lr: 7.499999999999999e-06 \n",
      "     | > step_time: 0.6471  (0.6271256854515947)\n",
      "     | > loader_time: 0.0534  (0.013103590666792774)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:52:27 -- STEP: 156/406 -- GLOBAL_STEP: 18825\u001b[0m\n",
      "     | > loss: 0.15305325388908386  (0.14884021496161437)\n",
      "     | > log_mle: -0.15716183185577393  (-0.14043940641941163)\n",
      "     | > loss_dur: 0.3102150857448578  (0.289279621381026)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(11.0917, device='cuda:0')  (tensor(6.3631, device='cuda:0'))\n",
      "     | > current_lr: 7.499999999999999e-06 \n",
      "     | > step_time: 0.8979  (0.643954162414257)\n",
      "     | > loader_time: 0.0514  (0.01346216446314102)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:52:46 -- STEP: 181/406 -- GLOBAL_STEP: 18850\u001b[0m\n",
      "     | > loss: 0.1622733473777771  (0.14821504772697378)\n",
      "     | > log_mle: -0.15108191967010498  (-0.1420837535383951)\n",
      "     | > loss_dur: 0.3133552670478821  (0.2902988012653688)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(19.1320, device='cuda:0')  (tensor(6.7704, device='cuda:0'))\n",
      "     | > current_lr: 7.499999999999999e-06 \n",
      "     | > step_time: 0.54  (0.6556074092401323)\n",
      "     | > loader_time: 0.006  (0.013538031288273421)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:53:05 -- STEP: 206/406 -- GLOBAL_STEP: 18875\u001b[0m\n",
      "     | > loss: 0.1452210545539856  (0.14781011612091263)\n",
      "     | > log_mle: -0.1526881456375122  (-0.14365279616661444)\n",
      "     | > loss_dur: 0.2979092001914978  (0.2914629122875269)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(15.1683, device='cuda:0')  (tensor(7.2664, device='cuda:0'))\n",
      "     | > current_lr: 7.499999999999999e-06 \n",
      "     | > step_time: 0.5181  (0.6655311839094437)\n",
      "     | > loader_time: 0.0153  (0.013666133278781923)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:53:24 -- STEP: 231/406 -- GLOBAL_STEP: 18900\u001b[0m\n",
      "     | > loss: 0.14350572228431702  (0.14733863625175522)\n",
      "     | > log_mle: -0.16596639156341553  (-0.14524409987709738)\n",
      "     | > loss_dur: 0.30947211384773254  (0.29258273612885244)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(18.6817, device='cuda:0')  (tensor(7.5287, device='cuda:0'))\n",
      "     | > current_lr: 7.499999999999999e-06 \n",
      "     | > step_time: 0.6379  (0.6752385824789731)\n",
      "     | > loader_time: 0.0271  (0.013768391175703566)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:53:44 -- STEP: 256/406 -- GLOBAL_STEP: 18925\u001b[0m\n",
      "     | > loss: 0.1473408341407776  (0.1467850668122993)\n",
      "     | > log_mle: -0.15895092487335205  (-0.14655759604647756)\n",
      "     | > loss_dur: 0.30629175901412964  (0.2933426628587767)\n",
      "     | > amp_scaler: 8192.0  (15904.0)\n",
      "     | > grad_norm: tensor(12.5880, device='cuda:0')  (tensor(8.2265, device='cuda:0'))\n",
      "     | > current_lr: 7.499999999999999e-06 \n",
      "     | > step_time: 0.7687  (0.6859715441241858)\n",
      "     | > loader_time: 0.015  (0.013993083499372002)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:54:05 -- STEP: 281/406 -- GLOBAL_STEP: 18950\u001b[0m\n",
      "     | > loss: 0.12589168548583984  (0.14591744446669622)\n",
      "     | > log_mle: -0.16023683547973633  (-0.14769932044358436)\n",
      "     | > loss_dur: 0.28612852096557617  (0.2936167649102805)\n",
      "     | > amp_scaler: 8192.0  (15217.879003558719)\n",
      "     | > grad_norm: tensor(12.8199, device='cuda:0')  (tensor(8.5063, device='cuda:0'))\n",
      "     | > current_lr: 7.499999999999999e-06 \n",
      "     | > step_time: 0.6854  (0.6971038940538287)\n",
      "     | > loader_time: 0.0102  (0.014462398888801761)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:54:26 -- STEP: 306/406 -- GLOBAL_STEP: 18975\u001b[0m\n",
      "     | > loss: 0.15329697728157043  (0.14558333168232374)\n",
      "     | > log_mle: -0.153222918510437  (-0.14871693592445523)\n",
      "     | > loss_dur: 0.30651989579200745  (0.2943002676067789)\n",
      "     | > amp_scaler: 8192.0  (14643.869281045752)\n",
      "     | > grad_norm: tensor(9.7151, device='cuda:0')  (tensor(8.7414, device='cuda:0'))\n",
      "     | > current_lr: 7.499999999999999e-06 \n",
      "     | > step_time: 0.5871  (0.7058765046736772)\n",
      "     | > loader_time: 0.0143  (0.014480247996211828)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:54:47 -- STEP: 331/406 -- GLOBAL_STEP: 19000\u001b[0m\n",
      "     | > loss: 0.14724165201187134  (0.14513881229922135)\n",
      "     | > log_mle: -0.15752148628234863  (-0.14957260833406014)\n",
      "     | > loss_dur: 0.30476313829421997  (0.2947114206332817)\n",
      "     | > amp_scaler: 8192.0  (14156.567975830816)\n",
      "     | > grad_norm: tensor(22.1171, device='cuda:0')  (tensor(8.9313, device='cuda:0'))\n",
      "     | > current_lr: 7.499999999999999e-06 \n",
      "     | > step_time: 0.9443  (0.7148215259309982)\n",
      "     | > loader_time: 0.0124  (0.014701359941880146)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:55:09 -- STEP: 356/406 -- GLOBAL_STEP: 19025\u001b[0m\n",
      "     | > loss: 0.13529381155967712  (0.14474360636445927)\n",
      "     | > log_mle: -0.1669309139251709  (-0.15052681558587575)\n",
      "     | > loss_dur: 0.302224725484848  (0.29527042195033526)\n",
      "     | > amp_scaler: 8192.0  (13737.707865168539)\n",
      "     | > grad_norm: tensor(11.8210, device='cuda:0')  (tensor(9.4883, device='cuda:0'))\n",
      "     | > current_lr: 7.499999999999999e-06 \n",
      "     | > step_time: 0.731  (0.7241525094160873)\n",
      "     | > loader_time: 0.0166  (0.014992796972896273)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:55:31 -- STEP: 381/406 -- GLOBAL_STEP: 19050\u001b[0m\n",
      "     | > loss: 0.14836961030960083  (0.14419752860006715)\n",
      "     | > log_mle: -0.15203797817230225  (-0.15141616061603613)\n",
      "     | > loss_dur: 0.3004075884819031  (0.2956136892161035)\n",
      "     | > amp_scaler: 8192.0  (13373.81627296588)\n",
      "     | > grad_norm: tensor(14.0330, device='cuda:0')  (tensor(9.6095, device='cuda:0'))\n",
      "     | > current_lr: 7.499999999999999e-06 \n",
      "     | > step_time: 0.6732  (0.7345074343243296)\n",
      "     | > loader_time: 0.0093  (0.015107038452869323)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: 0.12515828013420105  (0.12515828013420105)\n",
      "     | > log_mle: -0.1354588270187378  (-0.1354588270187378)\n",
      "     | > loss_dur: 0.26061710715293884  (0.26061710715293884)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: 0.08558133244514465  (0.08558133244514465)\n",
      "     | > log_mle: -0.17196834087371826  (-0.17196834087371826)\n",
      "     | > loss_dur: 0.2575496733188629  (0.2575496733188629)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: 0.10467687249183655  (0.0951291024684906)\n",
      "     | > log_mle: -0.13166964054107666  (-0.15181899070739746)\n",
      "     | > loss_dur: 0.2363465130329132  (0.24694809317588806)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: 0.10771837830543518  (0.09932552774747212)\n",
      "     | > log_mle: -0.14820921421051025  (-0.15061573187510172)\n",
      "     | > loss_dur: 0.25592759251594543  (0.24994125962257385)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: 0.11676329374313354  (0.10368496924638748)\n",
      "     | > log_mle: -0.1744232177734375  (-0.15656760334968567)\n",
      "     | > loss_dur: 0.29118651151657104  (0.26025257259607315)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: 0.11030134558677673  (0.10500824451446533)\n",
      "     | > log_mle: -0.17665231227874756  (-0.16058454513549805)\n",
      "     | > loss_dur: 0.2869536578655243  (0.26559278964996336)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: 0.1559382975101471  (0.11349658668041229)\n",
      "     | > log_mle: -0.18696129322052002  (-0.16498066981633505)\n",
      "     | > loss_dur: 0.3428995907306671  (0.2784772564967473)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: 0.11212396621704102  (0.11330049804278783)\n",
      "     | > log_mle: -0.15191590785980225  (-0.16311427525111608)\n",
      "     | > loss_dur: 0.26403987407684326  (0.2764147732939039)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: 0.11045488715171814  (0.11294479668140411)\n",
      "     | > log_mle: -0.15655457973480225  (-0.16229431331157684)\n",
      "     | > loss_dur: 0.2670094668865204  (0.27523910999298096)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: 0.15927597880363464  (0.11809270580609639)\n",
      "     | > log_mle: -0.16915607452392578  (-0.16305673122406006)\n",
      "     | > loss_dur: 0.3284320533275604  (0.28114943703015643)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: 0.14189916849136353  (0.1204733520746231)\n",
      "     | > log_mle: -0.15671932697296143  (-0.1624229907989502)\n",
      "     | > loss_dur: 0.29861849546432495  (0.2828963428735733)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: 0.11090585589408875  (0.11960357969457452)\n",
      "     | > log_mle: -0.17208027839660645  (-0.16330092603510077)\n",
      "     | > loss_dur: 0.2829861342906952  (0.2829045057296753)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: 0.09296420216560364  (0.1173836315671603)\n",
      "     | > log_mle: -0.1596604585647583  (-0.16299755374590555)\n",
      "     | > loss_dur: 0.25262466073036194  (0.28038118531306583)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: 0.07757556438446045  (0.11432147255310646)\n",
      "     | > log_mle: -0.18003427982330322  (-0.1643080711364746)\n",
      "     | > loss_dur: 0.25760984420776367  (0.27862954368958104)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: 0.14403876662254333  (0.11644413641520909)\n",
      "     | > log_mle: -0.17196249961853027  (-0.16485481602805002)\n",
      "     | > loss_dur: 0.3160012662410736  (0.2812989524432591)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: 0.10855692625045776  (0.11591832240422567)\n",
      "     | > log_mle: -0.1662919521331787  (-0.16495062510172526)\n",
      "     | > loss_dur: 0.2748488783836365  (0.2808689475059509)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: 0.10201272368431091  (0.115049222484231)\n",
      "     | > log_mle: -0.16172587871551514  (-0.16474907845258713)\n",
      "     | > loss_dur: 0.26373860239982605  (0.2797983009368181)\n",
      "\n",
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.004631906747817993 \u001b[0m(-0.00152607262134552)\n",
      "     | > avg_loss:\u001b[92m 0.115049222484231 \u001b[0m(-0.015436137095093727)\n",
      "     | > avg_log_mle:\u001b[92m -0.16474907845258713 \u001b[0m(-0.007809869945049286)\n",
      "     | > avg_loss_dur:\u001b[92m 0.2797983009368181 \u001b[0m(-0.007626267150044441)\n",
      "\n",
      " > BEST MODEL : train/run-February-22-2025_02+19AM-9b6e3e6/best_model_19075.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 31/40\u001b[0m\n",
      " --> train/run-February-22-2025_02+19AM-9b6e3e6\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-22 04:56:06) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:56:09 -- STEP: 0/406 -- GLOBAL_STEP: 19075\u001b[0m\n",
      "     | > loss: 0.1593119502067566  (0.1593119502067566)\n",
      "     | > log_mle: -0.12153792381286621  (-0.12153792381286621)\n",
      "     | > loss_dur: 0.2808498740196228  (0.2808498740196228)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(2.2588, device='cuda:0')  (tensor(2.2588, device='cuda:0'))\n",
      "     | > current_lr: 7.75e-06 \n",
      "     | > step_time: 1.3866  (1.3866262435913086)\n",
      "     | > loader_time: 1.1589  (1.1588664054870605)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:56:22 -- STEP: 25/406 -- GLOBAL_STEP: 19100\u001b[0m\n",
      "     | > loss: 0.14021039009094238  (0.13697177708148955)\n",
      "     | > log_mle: -0.13958978652954102  (-0.13337790966033933)\n",
      "     | > loss_dur: 0.2798001766204834  (0.2703496867418289)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(11.1784, device='cuda:0')  (tensor(4.6331, device='cuda:0'))\n",
      "     | > current_lr: 7.75e-06 \n",
      "     | > step_time: 0.8706  (0.5054614067077636)\n",
      "     | > loader_time: 0.0054  (0.008673667907714844)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:56:38 -- STEP: 50/406 -- GLOBAL_STEP: 19125\u001b[0m\n",
      "     | > loss: 0.13859131932258606  (0.1394877952337265)\n",
      "     | > log_mle: -0.16189289093017578  (-0.13440779685974116)\n",
      "     | > loss_dur: 0.30048421025276184  (0.27389559209346775)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(8.6481, device='cuda:0')  (tensor(6.0454, device='cuda:0'))\n",
      "     | > current_lr: 7.75e-06 \n",
      "     | > step_time: 0.774  (0.571737127304077)\n",
      "     | > loader_time: 0.0054  (0.00807041645050049)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:56:55 -- STEP: 75/406 -- GLOBAL_STEP: 19150\u001b[0m\n",
      "     | > loss: 0.12517580389976501  (0.1378206984202067)\n",
      "     | > log_mle: -0.14919281005859375  (-0.13762219746907553)\n",
      "     | > loss_dur: 0.27436861395835876  (0.27544289588928234)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(18.0062, device='cuda:0')  (tensor(8.0472, device='cuda:0'))\n",
      "     | > current_lr: 7.75e-06 \n",
      "     | > step_time: 0.9664  (0.6062792269388831)\n",
      "     | > loader_time: 0.0049  (0.00984375)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:57:13 -- STEP: 100/406 -- GLOBAL_STEP: 19175\u001b[0m\n",
      "     | > loss: 0.1530531942844391  (0.13782961130142202)\n",
      "     | > log_mle: -0.15215957164764404  (-0.1403817737102508)\n",
      "     | > loss_dur: 0.30521276593208313  (0.278211385011673)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(4.1633, device='cuda:0')  (tensor(8.7971, device='cuda:0'))\n",
      "     | > current_lr: 7.75e-06 \n",
      "     | > step_time: 0.7097  (0.624072487354278)\n",
      "     | > loader_time: 0.0064  (0.010686614513397218)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:57:30 -- STEP: 125/406 -- GLOBAL_STEP: 19200\u001b[0m\n",
      "     | > loss: 0.14987829327583313  (0.13667799782752987)\n",
      "     | > log_mle: -0.16182172298431396  (-0.14315041637420647)\n",
      "     | > loss_dur: 0.3117000162601471  (0.2798284142017363)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(11.3060, device='cuda:0')  (tensor(9.7144, device='cuda:0'))\n",
      "     | > current_lr: 7.75e-06 \n",
      "     | > step_time: 0.59  (0.6332533512115474)\n",
      "     | > loader_time: 0.0195  (0.011056785583496093)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:57:48 -- STEP: 150/406 -- GLOBAL_STEP: 19225\u001b[0m\n",
      "     | > loss: 0.13672277331352234  (0.1359793253739675)\n",
      "     | > log_mle: -0.15462231636047363  (-0.14527657588322945)\n",
      "     | > loss_dur: 0.29134508967399597  (0.28125590125719696)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(11.0783, device='cuda:0')  (tensor(10.2565, device='cuda:0'))\n",
      "     | > current_lr: 7.75e-06 \n",
      "     | > step_time: 0.8599  (0.642234565416971)\n",
      "     | > loader_time: 0.0049  (0.01178414026896159)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:58:06 -- STEP: 175/406 -- GLOBAL_STEP: 19250\u001b[0m\n",
      "     | > loss: 0.12143898010253906  (0.13557256698608397)\n",
      "     | > log_mle: -0.16030144691467285  (-0.14687562125069745)\n",
      "     | > loss_dur: 0.2817404270172119  (0.28244818823678147)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(17.0034, device='cuda:0')  (tensor(10.6818, device='cuda:0'))\n",
      "     | > current_lr: 7.75e-06 \n",
      "     | > step_time: 0.6065  (0.6532649339948376)\n",
      "     | > loader_time: 0.0229  (0.01231722014290946)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:58:25 -- STEP: 200/406 -- GLOBAL_STEP: 19275\u001b[0m\n",
      "     | > loss: 0.13269710540771484  (0.13525530621409412)\n",
      "     | > log_mle: -0.1583254337310791  (-0.14845658957958213)\n",
      "     | > loss_dur: 0.29102253913879395  (0.28371189579367634)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(6.2448, device='cuda:0')  (tensor(10.7589, device='cuda:0'))\n",
      "     | > current_lr: 7.75e-06 \n",
      "     | > step_time: 0.7615  (0.6630887222290035)\n",
      "     | > loader_time: 0.0128  (0.012644381523132327)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:58:45 -- STEP: 225/406 -- GLOBAL_STEP: 19300\u001b[0m\n",
      "     | > loss: 0.14874982833862305  (0.13490477045377097)\n",
      "     | > log_mle: -0.1619199514389038  (-0.14990464475419774)\n",
      "     | > loss_dur: 0.31066977977752686  (0.28480941520796893)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(12.9747, device='cuda:0')  (tensor(10.5430, device='cuda:0'))\n",
      "     | > current_lr: 7.75e-06 \n",
      "     | > step_time: 0.7431  (0.674232705434163)\n",
      "     | > loader_time: 0.0217  (0.01307219399346246)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:59:05 -- STEP: 250/406 -- GLOBAL_STEP: 19325\u001b[0m\n",
      "     | > loss: 0.1181323230266571  (0.13451326370239255)\n",
      "     | > log_mle: -0.1722397804260254  (-0.1512863163948058)\n",
      "     | > loss_dur: 0.2903721034526825  (0.2857995800971986)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(38.0009, device='cuda:0')  (tensor(10.7549, device='cuda:0'))\n",
      "     | > current_lr: 7.75e-06 \n",
      "     | > step_time: 0.9499  (0.68503689956665)\n",
      "     | > loader_time: 0.0166  (0.013223647117614748)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:59:25 -- STEP: 275/406 -- GLOBAL_STEP: 19350\u001b[0m\n",
      "     | > loss: 0.12495666742324829  (0.13374142765998837)\n",
      "     | > log_mle: -0.1600896120071411  (-0.15252269744873037)\n",
      "     | > loss_dur: 0.2850462794303894  (0.28626412510871907)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(8.7424, device='cuda:0')  (tensor(11.4066, device='cuda:0'))\n",
      "     | > current_lr: 7.75e-06 \n",
      "     | > step_time: 0.8423  (0.6943389589136294)\n",
      "     | > loader_time: 0.01  (0.013411039005626334)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 04:59:46 -- STEP: 300/406 -- GLOBAL_STEP: 19375\u001b[0m\n",
      "     | > loss: 0.1269669234752655  (0.13354889601469033)\n",
      "     | > log_mle: -0.15228486061096191  (-0.15344103773434947)\n",
      "     | > loss_dur: 0.2792517840862274  (0.2869899337490402)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(14.2426, device='cuda:0')  (tensor(11.7784, device='cuda:0'))\n",
      "     | > current_lr: 7.75e-06 \n",
      "     | > step_time: 0.8352  (0.7046672590573625)\n",
      "     | > loader_time: 0.0089  (0.01367331663767497)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 05:00:07 -- STEP: 325/406 -- GLOBAL_STEP: 19400\u001b[0m\n",
      "     | > loss: 0.13362866640090942  (0.13322523942360504)\n",
      "     | > log_mle: -0.15643775463104248  (-0.15432936374957734)\n",
      "     | > loss_dur: 0.2900664210319519  (0.2875546031731828)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(15.1008, device='cuda:0')  (tensor(12.0792, device='cuda:0'))\n",
      "     | > current_lr: 7.75e-06 \n",
      "     | > step_time: 0.572  (0.7134946837792026)\n",
      "     | > loader_time: 0.0066  (0.014043136743398816)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 05:00:30 -- STEP: 350/406 -- GLOBAL_STEP: 19425\u001b[0m\n",
      "     | > loss: 0.12229400873184204  (0.13299340520586267)\n",
      "     | > log_mle: -0.1716991662979126  (-0.15521305492946066)\n",
      "     | > loss_dur: 0.29399317502975464  (0.2882064601353238)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(11.7742, device='cuda:0')  (tensor(12.3074, device='cuda:0'))\n",
      "     | > current_lr: 7.75e-06 \n",
      "     | > step_time: 1.1621  (0.7240870298658096)\n",
      "     | > loader_time: 0.0198  (0.01435976096561977)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 05:00:52 -- STEP: 375/406 -- GLOBAL_STEP: 19450\u001b[0m\n",
      "     | > loss: 0.12869930267333984  (0.13243309044837928)\n",
      "     | > log_mle: -0.17474234104156494  (-0.15615326499938953)\n",
      "     | > loss_dur: 0.3034416437149048  (0.28858635544776945)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(11.8278, device='cuda:0')  (tensor(12.3789, device='cuda:0'))\n",
      "     | > current_lr: 7.75e-06 \n",
      "     | > step_time: 0.945  (0.7347667331695553)\n",
      "     | > loader_time: 0.0574  (0.014780468622843428)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 05:01:13 -- STEP: 400/406 -- GLOBAL_STEP: 19475\u001b[0m\n",
      "     | > loss: 0.140792578458786  (0.13209769673645477)\n",
      "     | > log_mle: -0.17237865924835205  (-0.15697676211595515)\n",
      "     | > loss_dur: 0.31317123770713806  (0.28907445885241057)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(15.0743, device='cuda:0')  (tensor(12.2579, device='cuda:0'))\n",
      "     | > current_lr: 7.75e-06 \n",
      "     | > step_time: 0.6083  (0.7386025613546369)\n",
      "     | > loader_time: 0.0101  (0.014949758648872378)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: 0.12088754773139954  (0.12088754773139954)\n",
      "     | > log_mle: -0.1403716802597046  (-0.1403716802597046)\n",
      "     | > loss_dur: 0.2612592279911041  (0.2612592279911041)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: 0.08117720484733582  (0.08117720484733582)\n",
      "     | > log_mle: -0.17436981201171875  (-0.17436981201171875)\n",
      "     | > loss_dur: 0.25554701685905457  (0.25554701685905457)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: 0.08660182356834412  (0.08388951420783997)\n",
      "     | > log_mle: -0.13532984256744385  (-0.1548498272895813)\n",
      "     | > loss_dur: 0.22193166613578796  (0.23873934149742126)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: 0.09641711413860321  (0.08806538085142772)\n",
      "     | > log_mle: -0.15003538131713867  (-0.15324501196543375)\n",
      "     | > loss_dur: 0.24645249545574188  (0.24131039281686148)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: 0.09836232662200928  (0.0906396172940731)\n",
      "     | > log_mle: -0.1756148338317871  (-0.1588374674320221)\n",
      "     | > loss_dur: 0.2739771604537964  (0.2494770847260952)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: 0.11665153503417969  (0.09584200084209442)\n",
      "     | > log_mle: -0.1716829538345337  (-0.1614065647125244)\n",
      "     | > loss_dur: 0.2883344888687134  (0.25724856555461884)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: 0.1363562047481537  (0.10259436815977097)\n",
      "     | > log_mle: -0.18203389644622803  (-0.16484445333480835)\n",
      "     | > loss_dur: 0.3183901011943817  (0.2674388214945793)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: 0.1068984866142273  (0.1032092422246933)\n",
      "     | > log_mle: -0.1523113250732422  (-0.1630540064402989)\n",
      "     | > loss_dur: 0.2592098116874695  (0.2662632486649922)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: 0.09638041257858276  (0.10235563851892948)\n",
      "     | > log_mle: -0.15860211849212646  (-0.16249752044677734)\n",
      "     | > loss_dur: 0.25498253107070923  (0.2648531589657068)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: 0.15174591541290283  (0.1078434470627043)\n",
      "     | > log_mle: -0.1674281358718872  (-0.1630453666051229)\n",
      "     | > loss_dur: 0.31917405128479004  (0.2708888136678272)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: 0.12890374660491943  (0.10994947701692581)\n",
      "     | > log_mle: -0.1575000286102295  (-0.16249083280563353)\n",
      "     | > loss_dur: 0.2864037752151489  (0.27244030982255935)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: 0.10025790333747864  (0.1090684248642488)\n",
      "     | > log_mle: -0.17202222347259521  (-0.16335732286626642)\n",
      "     | > loss_dur: 0.27228012681007385  (0.2724257477305152)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: 0.0877559632062912  (0.10729238639275233)\n",
      "     | > log_mle: -0.16163253784179688  (-0.16321359078089395)\n",
      "     | > loss_dur: 0.24938850104808807  (0.2705059771736463)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: 0.07048968970775604  (0.10446140972467569)\n",
      "     | > log_mle: -0.17699861526489258  (-0.16427397727966309)\n",
      "     | > loss_dur: 0.24748830497264862  (0.2687353870043388)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: 0.1326005458831787  (0.10647134802171163)\n",
      "     | > log_mle: -0.17243003845214844  (-0.16485655307769775)\n",
      "     | > loss_dur: 0.30503058433532715  (0.2713279010994094)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: 0.1003405749797821  (0.10606262981891632)\n",
      "     | > log_mle: -0.16694366931915283  (-0.16499569416046142)\n",
      "     | > loss_dur: 0.26728424429893494  (0.27105832397937774)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: 0.10919639468193054  (0.10625849012285471)\n",
      "     | > log_mle: -0.16032516956329346  (-0.16470378637313843)\n",
      "     | > loss_dur: 0.269521564245224  (0.27096227649599314)\n",
      "\n",
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.004093095660209656 \u001b[0m(-0.0005388110876083374)\n",
      "     | > avg_loss:\u001b[92m 0.10625849012285471 \u001b[0m(-0.008790732361376286)\n",
      "     | > avg_log_mle:\u001b[91m -0.16470378637313843 \u001b[0m(+4.529207944869995e-05)\n",
      "     | > avg_loss_dur:\u001b[92m 0.27096227649599314 \u001b[0m(-0.008836024440824986)\n",
      "\n",
      " > BEST MODEL : train/run-February-22-2025_02+19AM-9b6e3e6/best_model_19481.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 32/40\u001b[0m\n",
      " --> train/run-February-22-2025_02+19AM-9b6e3e6\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-22 05:01:33) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 05:01:45 -- STEP: 19/406 -- GLOBAL_STEP: 19500\u001b[0m\n",
      "     | > loss: 0.13897210359573364  (0.12450099540384192)\n",
      "     | > log_mle: -0.12583136558532715  (-0.13849934778715434)\n",
      "     | > loss_dur: 0.2648034691810608  (0.26300034319099624)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(2.8210, device='cuda:0')  (tensor(3.3053, device='cuda:0'))\n",
      "     | > current_lr: 8e-06 \n",
      "     | > step_time: 0.4991  (0.46856545147142914)\n",
      "     | > loader_time: 0.006  (0.009477577711406508)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 05:02:01 -- STEP: 44/406 -- GLOBAL_STEP: 19525\u001b[0m\n",
      "     | > loss: 0.15362679958343506  (0.12861049717122852)\n",
      "     | > log_mle: -0.14337480068206787  (-0.13805993036790334)\n",
      "     | > loss_dur: 0.29700160026550293  (0.266670427539132)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(4.6747, device='cuda:0')  (tensor(5.5886, device='cuda:0'))\n",
      "     | > current_lr: 8e-06 \n",
      "     | > step_time: 0.4766  (0.5601412599736993)\n",
      "     | > loader_time: 0.0579  (0.012525981122797186)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 05:02:17 -- STEP: 69/406 -- GLOBAL_STEP: 19550\u001b[0m\n",
      "     | > loss: 0.1259739100933075  (0.12896634616713587)\n",
      "     | > log_mle: -0.1512376070022583  (-0.14129589606022488)\n",
      "     | > loss_dur: 0.2772115170955658  (0.27026224222736084)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(12.1499, device='cuda:0')  (tensor(6.5301, device='cuda:0'))\n",
      "     | > current_lr: 8e-06 \n",
      "     | > step_time: 0.7413  (0.5894781195599098)\n",
      "     | > loader_time: 0.0046  (0.012576987777931103)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 05:02:35 -- STEP: 94/406 -- GLOBAL_STEP: 19575\u001b[0m\n",
      "     | > loss: 0.10874316096305847  (0.1268585067480168)\n",
      "     | > log_mle: -0.15632283687591553  (-0.14482492208480827)\n",
      "     | > loss_dur: 0.265065997838974  (0.2716834288328251)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(14.1083, device='cuda:0')  (tensor(6.9906, device='cuda:0'))\n",
      "     | > current_lr: 8e-06 \n",
      "     | > step_time: 0.6254  (0.6101570002576135)\n",
      "     | > loader_time: 0.0192  (0.01228281538537208)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 05:02:52 -- STEP: 119/406 -- GLOBAL_STEP: 19600\u001b[0m\n",
      "     | > loss: 0.11532041430473328  (0.12602522343146694)\n",
      "     | > log_mle: -0.16810369491577148  (-0.14759713060715607)\n",
      "     | > loss_dur: 0.28342410922050476  (0.27362235403862295)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(9.1627, device='cuda:0')  (tensor(7.5688, device='cuda:0'))\n",
      "     | > current_lr: 8e-06 \n",
      "     | > step_time: 0.6981  (0.619710625720625)\n",
      "     | > loader_time: 0.0063  (0.012479120943726612)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 05:03:09 -- STEP: 144/406 -- GLOBAL_STEP: 19625\u001b[0m\n",
      "     | > loss: 0.12043741345405579  (0.12553736836545995)\n",
      "     | > log_mle: -0.16096758842468262  (-0.15001590632730047)\n",
      "     | > loss_dur: 0.2814050018787384  (0.27555327469276036)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(10.9058, device='cuda:0')  (tensor(7.9702, device='cuda:0'))\n",
      "     | > current_lr: 8e-06 \n",
      "     | > step_time: 0.4199  (0.6312870449490011)\n",
      "     | > loader_time: 0.0079  (0.012690736187828911)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 05:03:28 -- STEP: 169/406 -- GLOBAL_STEP: 19650\u001b[0m\n",
      "     | > loss: 0.11873525381088257  (0.12515948809815577)\n",
      "     | > log_mle: -0.16286230087280273  (-0.1516702400862111)\n",
      "     | > loss_dur: 0.2815975546836853  (0.27682972818436713)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(15.2205, device='cuda:0')  (tensor(8.3276, device='cuda:0'))\n",
      "     | > current_lr: 8e-06 \n",
      "     | > step_time: 1.0703  (0.6464404749447066)\n",
      "     | > loader_time: 0.0337  (0.013253989304311176)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 05:03:46 -- STEP: 194/406 -- GLOBAL_STEP: 19675\u001b[0m\n",
      "     | > loss: 0.11751735210418701  (0.12462910671824029)\n",
      "     | > log_mle: -0.16385424137115479  (-0.15337828569805492)\n",
      "     | > loss_dur: 0.2813715934753418  (0.2780073924162955)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(14.0536, device='cuda:0')  (tensor(8.8043, device='cuda:0'))\n",
      "     | > current_lr: 8e-06 \n",
      "     | > step_time: 0.6167  (0.6503467977661443)\n",
      "     | > loader_time: 0.04  (0.01352263234325291)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 05:04:05 -- STEP: 219/406 -- GLOBAL_STEP: 19700\u001b[0m\n",
      "     | > loss: 0.11089763045310974  (0.12399495423656617)\n",
      "     | > log_mle: -0.16397905349731445  (-0.15471064500068418)\n",
      "     | > loss_dur: 0.2748766839504242  (0.2787055992372506)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(6.4615, device='cuda:0')  (tensor(9.4074, device='cuda:0'))\n",
      "     | > current_lr: 8e-06 \n",
      "     | > step_time: 0.831  (0.6617975931733708)\n",
      "     | > loader_time: 0.017  (0.013778288070469687)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 05:04:24 -- STEP: 244/406 -- GLOBAL_STEP: 19725\u001b[0m\n",
      "     | > loss: 0.10595914721488953  (0.12368761943500547)\n",
      "     | > log_mle: -0.1686108112335205  (-0.15617510969521567)\n",
      "     | > loss_dur: 0.27456995844841003  (0.27986272913022137)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(8.5398, device='cuda:0')  (tensor(9.9186, device='cuda:0'))\n",
      "     | > current_lr: 8e-06 \n",
      "     | > step_time: 0.8416  (0.671950542535938)\n",
      "     | > loader_time: 0.0094  (0.013877204207123304)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 05:04:44 -- STEP: 269/406 -- GLOBAL_STEP: 19750\u001b[0m\n",
      "     | > loss: 0.10435155034065247  (0.1230181444533252)\n",
      "     | > log_mle: -0.17026770114898682  (-0.15728421636673598)\n",
      "     | > loss_dur: 0.2746192514896393  (0.28030236082006144)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(11.2325, device='cuda:0')  (tensor(10.0212, device='cuda:0'))\n",
      "     | > current_lr: 8e-06 \n",
      "     | > step_time: 0.4458  (0.6816960878974884)\n",
      "     | > loader_time: 0.0059  (0.014192581176757814)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 05:05:06 -- STEP: 294/406 -- GLOBAL_STEP: 19775\u001b[0m\n",
      "     | > loss: 0.12109920382499695  (0.12243937016749866)\n",
      "     | > log_mle: -0.17446041107177734  (-0.15836277948755798)\n",
      "     | > loss_dur: 0.2955596148967743  (0.28080214965505673)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(8.9808, device='cuda:0')  (tensor(10.1317, device='cuda:0'))\n",
      "     | > current_lr: 8e-06 \n",
      "     | > step_time: 0.9099  (0.6934484235283467)\n",
      "     | > loader_time: 0.0093  (0.01451808498019264)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 05:05:27 -- STEP: 319/406 -- GLOBAL_STEP: 19800\u001b[0m\n",
      "     | > loss: 0.11344337463378906  (0.12203822754393548)\n",
      "     | > log_mle: -0.17006909847259521  (-0.15934496912462962)\n",
      "     | > loss_dur: 0.2835124731063843  (0.28138319666856504)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(13.7198, device='cuda:0')  (tensor(10.2434, device='cuda:0'))\n",
      "     | > current_lr: 8e-06 \n",
      "     | > step_time: 0.7984  (0.704752358523282)\n",
      "     | > loader_time: 0.01  (0.014846008025740381)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 05:05:48 -- STEP: 344/406 -- GLOBAL_STEP: 19825\u001b[0m\n",
      "     | > loss: 0.13135454058647156  (0.12184460487130075)\n",
      "     | > log_mle: -0.16383683681488037  (-0.16020650988401375)\n",
      "     | > loss_dur: 0.29519137740135193  (0.2820511147553143)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(5.0517, device='cuda:0')  (tensor(10.3394, device='cuda:0'))\n",
      "     | > current_lr: 8e-06 \n",
      "     | > step_time: 0.9145  (0.7137450291666871)\n",
      "     | > loader_time: 0.0096  (0.014831854160441908)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 05:06:11 -- STEP: 369/406 -- GLOBAL_STEP: 19850\u001b[0m\n",
      "     | > loss: 0.11354440450668335  (0.12137507948125925)\n",
      "     | > log_mle: -0.16941452026367188  (-0.16110207394855786)\n",
      "     | > loss_dur: 0.2829589247703552  (0.2824771534298169)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(13.0833, device='cuda:0')  (tensor(10.7479, device='cuda:0'))\n",
      "     | > current_lr: 8e-06 \n",
      "     | > step_time: 0.9914  (0.7244024457647223)\n",
      "     | > loader_time: 0.0088  (0.015229915215717099)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 05:06:33 -- STEP: 394/406 -- GLOBAL_STEP: 19875\u001b[0m\n",
      "     | > loss: 0.11702600121498108  (0.1209420853762457)\n",
      "     | > log_mle: -0.17593204975128174  (-0.16197712560595598)\n",
      "     | > loss_dur: 0.2929580509662628  (0.2829192109822017)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(6.7531, device='cuda:0')  (tensor(10.6390, device='cuda:0'))\n",
      "     | > current_lr: 8e-06 \n",
      "     | > step_time: 0.5446  (0.7329844538935548)\n",
      "     | > loader_time: 0.0073  (0.01533681305531923)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: 0.10011476278305054  (0.10011476278305054)\n",
      "     | > log_mle: -0.14706861972808838  (-0.14706861972808838)\n",
      "     | > loss_dur: 0.24718338251113892  (0.24718338251113892)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: 0.06002940237522125  (0.06002940237522125)\n",
      "     | > log_mle: -0.18257451057434082  (-0.18257451057434082)\n",
      "     | > loss_dur: 0.24260391294956207  (0.24260391294956207)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: 0.06838791072368622  (0.06420865654945374)\n",
      "     | > log_mle: -0.1426459550857544  (-0.1626102328300476)\n",
      "     | > loss_dur: 0.2110338658094406  (0.22681888937950134)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: 0.09556490182876587  (0.07466073830922444)\n",
      "     | > log_mle: -0.15851831436157227  (-0.1612462600072225)\n",
      "     | > loss_dur: 0.25408321619033813  (0.23590699831644693)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: 0.08363604545593262  (0.07690456509590149)\n",
      "     | > log_mle: -0.1842358112335205  (-0.166993647813797)\n",
      "     | > loss_dur: 0.2678718566894531  (0.2438982129096985)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: 0.09193587303161621  (0.07991082668304443)\n",
      "     | > log_mle: -0.18433880805969238  (-0.17046267986297609)\n",
      "     | > loss_dur: 0.2762746810913086  (0.25037350654602053)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: 0.1226595938205719  (0.08703562120596568)\n",
      "     | > log_mle: -0.19503390789031982  (-0.17455788453420004)\n",
      "     | > loss_dur: 0.3176935017108917  (0.2615935057401657)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: 0.08671873807907104  (0.08699035218783788)\n",
      "     | > log_mle: -0.16143405437469482  (-0.17268305165427073)\n",
      "     | > loss_dur: 0.24815279245376587  (0.2596734038421086)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: 0.08102773129940033  (0.08624502457678318)\n",
      "     | > log_mle: -0.16705262660980225  (-0.17197924852371216)\n",
      "     | > loss_dur: 0.24808035790920258  (0.25822427310049534)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: 0.11428800225257874  (0.0893609109852049)\n",
      "     | > log_mle: -0.17843520641326904  (-0.17269657717810738)\n",
      "     | > loss_dur: 0.2927232086658478  (0.26205748816331226)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: 0.10311847925186157  (0.09073666781187058)\n",
      "     | > log_mle: -0.16634142398834229  (-0.17206106185913086)\n",
      "     | > loss_dur: 0.26945990324020386  (0.26279772967100146)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: 0.09405022859573364  (0.09103790061040358)\n",
      "     | > log_mle: -0.18149971961975098  (-0.17291912165555087)\n",
      "     | > loss_dur: 0.2755499482154846  (0.26395702226595447)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: 0.07398167252540588  (0.0896165482699871)\n",
      "     | > log_mle: -0.16981291770935059  (-0.17266027132670084)\n",
      "     | > loss_dur: 0.24379459023475647  (0.26227681959668797)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: 0.05716533958911896  (0.08712030144838187)\n",
      "     | > log_mle: -0.18872332572937012  (-0.17389589089613694)\n",
      "     | > loss_dur: 0.24588866531848907  (0.2610161923445188)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: 0.11614099144935608  (0.08919320787702288)\n",
      "     | > log_mle: -0.18180334568023682  (-0.17446070909500122)\n",
      "     | > loss_dur: 0.2979443371295929  (0.26365391697202406)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: 0.09188985824584961  (0.089372984568278)\n",
      "     | > log_mle: -0.17610383033752441  (-0.17457025051116942)\n",
      "     | > loss_dur: 0.267993688583374  (0.2639432350794474)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: 0.1037951111793518  (0.09027436748147011)\n",
      "     | > log_mle: -0.17099618911743164  (-0.17434687167406082)\n",
      "     | > loss_dur: 0.27479130029678345  (0.26462123915553093)\n",
      "\n",
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[91m 0.004875555634498596 \u001b[0m(+0.0007824599742889404)\n",
      "     | > avg_loss:\u001b[92m 0.09027436748147011 \u001b[0m(-0.0159841226413846)\n",
      "     | > avg_log_mle:\u001b[92m -0.17434687167406082 \u001b[0m(-0.009643085300922394)\n",
      "     | > avg_loss_dur:\u001b[92m 0.26462123915553093 \u001b[0m(-0.006341037340462208)\n",
      "\n",
      " > BEST MODEL : train/run-February-22-2025_02+19AM-9b6e3e6/best_model_19887.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 33/40\u001b[0m\n",
      " --> train/run-February-22-2025_02+19AM-9b6e3e6\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-22 05:06:55) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 05:07:04 -- STEP: 13/406 -- GLOBAL_STEP: 19900\u001b[0m\n",
      "     | > loss: 0.10343360900878906  (0.10747095369375669)\n",
      "     | > log_mle: -0.15046226978302002  (-0.1438217438184298)\n",
      "     | > loss_dur: 0.2538958787918091  (0.25129269751218647)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(5.5255, device='cuda:0')  (tensor(4.1421, device='cuda:0'))\n",
      "     | > current_lr: 8.25e-06 \n",
      "     | > step_time: 0.4221  (0.4018879670363206)\n",
      "     | > loader_time: 0.0041  (0.0076359968919020435)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 05:07:20 -- STEP: 38/406 -- GLOBAL_STEP: 19925\u001b[0m\n",
      "     | > loss: 0.13891282677650452  (0.11472295656015999)\n",
      "     | > log_mle: -0.15318679809570312  (-0.14386753345790662)\n",
      "     | > loss_dur: 0.29209962487220764  (0.25859049001806667)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(4.5133, device='cuda:0')  (tensor(4.5911, device='cuda:0'))\n",
      "     | > current_lr: 8.25e-06 \n",
      "     | > step_time: 0.322  (0.5569834771909211)\n",
      "     | > loader_time: 0.0043  (0.007312962883397152)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 05:07:37 -- STEP: 63/406 -- GLOBAL_STEP: 19950\u001b[0m\n",
      "     | > loss: 0.12804117798805237  (0.1150128874513838)\n",
      "     | > log_mle: -0.15017318725585938  (-0.1460392626505049)\n",
      "     | > loss_dur: 0.27821436524391174  (0.2610521501018886)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(8.3043, device='cuda:0')  (tensor(4.7881, device='cuda:0'))\n",
      "     | > current_lr: 8.25e-06 \n",
      "     | > step_time: 0.7337  (0.589180140268235)\n",
      "     | > loader_time: 0.0084  (0.00920330153571235)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 05:07:54 -- STEP: 88/406 -- GLOBAL_STEP: 19975\u001b[0m\n",
      "     | > loss: 0.11892080307006836  (0.11423895169388164)\n",
      "     | > log_mle: -0.14361464977264404  (-0.14920504391193387)\n",
      "     | > loss_dur: 0.2625354528427124  (0.26344399560581544)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(5.0331, device='cuda:0')  (tensor(5.5589, device='cuda:0'))\n",
      "     | > current_lr: 8.25e-06 \n",
      "     | > step_time: 0.6587  (0.612190848047083)\n",
      "     | > loader_time: 0.0147  (0.010450376705689867)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 05:08:10 -- STEP: 113/406 -- GLOBAL_STEP: 20000\u001b[0m\n",
      "     | > loss: 0.12450209259986877  (0.11284423111814314)\n",
      "     | > log_mle: -0.1583031415939331  (-0.15236367588549588)\n",
      "     | > loss_dur: 0.2828052341938019  (0.26520790700363905)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(16.9146, device='cuda:0')  (tensor(7.0550, device='cuda:0'))\n",
      "     | > current_lr: 8.25e-06 \n",
      "     | > step_time: 1.0167  (0.617597202284146)\n",
      "     | > loader_time: 0.0149  (0.010965513972054542)\n",
      "\n",
      "\n",
      " > CHECKPOINT : train/run-February-22-2025_02+19AM-9b6e3e6/checkpoint_20000.pth\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 05:08:33 -- STEP: 138/406 -- GLOBAL_STEP: 20025\u001b[0m\n",
      "     | > loss: 0.14727279543876648  (0.11245230704114056)\n",
      "     | > log_mle: -0.1688598394393921  (-0.15485808037329413)\n",
      "     | > loss_dur: 0.31613263487815857  (0.2673103874144347)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(8.9843, device='cuda:0')  (tensor(8.2946, device='cuda:0'))\n",
      "     | > current_lr: 8.25e-06 \n",
      "     | > step_time: 0.972  (0.628719094870747)\n",
      "     | > loader_time: 0.0424  (0.012097664501356045)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 05:08:51 -- STEP: 163/406 -- GLOBAL_STEP: 20050\u001b[0m\n",
      "     | > loss: 0.10836869478225708  (0.11196776109239075)\n",
      "     | > log_mle: -0.18038809299468994  (-0.15670965858763716)\n",
      "     | > loss_dur: 0.288756787776947  (0.2686774196800277)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(13.8137, device='cuda:0')  (tensor(8.7653, device='cuda:0'))\n",
      "     | > current_lr: 8.25e-06 \n",
      "     | > step_time: 0.5376  (0.6409406647360398)\n",
      "     | > loader_time: 0.0061  (0.012891134601429198)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 05:09:10 -- STEP: 188/406 -- GLOBAL_STEP: 20075\u001b[0m\n",
      "     | > loss: 0.11608731746673584  (0.11157551819973803)\n",
      "     | > log_mle: -0.17913591861724854  (-0.15842522205190462)\n",
      "     | > loss_dur: 0.2952232360839844  (0.27000074025164233)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(19.6283, device='cuda:0')  (tensor(9.0679, device='cuda:0'))\n",
      "     | > current_lr: 8.25e-06 \n",
      "     | > step_time: 0.4963  (0.6537617089900566)\n",
      "     | > loader_time: 0.0168  (0.013018984743889345)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 05:09:29 -- STEP: 213/406 -- GLOBAL_STEP: 20100\u001b[0m\n",
      "     | > loss: 0.09824883937835693  (0.11087032005260808)\n",
      "     | > log_mle: -0.17765414714813232  (-0.15990581143070282)\n",
      "     | > loss_dur: 0.27590298652648926  (0.2707761314833107)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(8.4447, device='cuda:0')  (tensor(9.4078, device='cuda:0'))\n",
      "     | > current_lr: 8.25e-06 \n",
      "     | > step_time: 0.4223  (0.6638399636801421)\n",
      "     | > loader_time: 0.0423  (0.013574074131782068)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 05:09:49 -- STEP: 238/406 -- GLOBAL_STEP: 20125\u001b[0m\n",
      "     | > loss: 0.10697054862976074  (0.1108993109033889)\n",
      "     | > log_mle: -0.18080103397369385  (-0.1614237187289391)\n",
      "     | > loss_dur: 0.2877715826034546  (0.2723230296323277)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(8.7281, device='cuda:0')  (tensor(9.8836, device='cuda:0'))\n",
      "     | > current_lr: 8.25e-06 \n",
      "     | > step_time: 0.5096  (0.6767159750481615)\n",
      "     | > loader_time: 0.0277  (0.01397618726521981)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 05:10:10 -- STEP: 263/406 -- GLOBAL_STEP: 20150\u001b[0m\n",
      "     | > loss: 0.1052166223526001  (0.11028459396199128)\n",
      "     | > log_mle: -0.18144619464874268  (-0.16265358535055885)\n",
      "     | > loss_dur: 0.2866628170013428  (0.2729381793125499)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(12.1169, device='cuda:0')  (tensor(10.1564, device='cuda:0'))\n",
      "     | > current_lr: 8.25e-06 \n",
      "     | > step_time: 0.8261  (0.6895868587856512)\n",
      "     | > loader_time: 0.0092  (0.01433910616450437)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 05:10:31 -- STEP: 288/406 -- GLOBAL_STEP: 20175\u001b[0m\n",
      "     | > loss: 0.08924156427383423  (0.1097092774386207)\n",
      "     | > log_mle: -0.1722325086593628  (-0.16373288755615556)\n",
      "     | > loss_dur: 0.261474072933197  (0.273442164994776)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(8.8131, device='cuda:0')  (tensor(10.4047, device='cuda:0'))\n",
      "     | > current_lr: 8.25e-06 \n",
      "     | > step_time: 0.7962  (0.6983004262049991)\n",
      "     | > loader_time: 0.0093  (0.014521910084618462)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 05:10:53 -- STEP: 313/406 -- GLOBAL_STEP: 20200\u001b[0m\n",
      "     | > loss: 0.10717406868934631  (0.10938569208303578)\n",
      "     | > log_mle: -0.17149567604064941  (-0.1646631666646598)\n",
      "     | > loss_dur: 0.2786697447299957  (0.27404885874769536)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(13.3094, device='cuda:0')  (tensor(10.6511, device='cuda:0'))\n",
      "     | > current_lr: 8.25e-06 \n",
      "     | > step_time: 0.7949  (0.7119047992145673)\n",
      "     | > loader_time: 0.0086  (0.01439045260127741)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 05:11:14 -- STEP: 338/406 -- GLOBAL_STEP: 20225\u001b[0m\n",
      "     | > loss: 0.10539570450782776  (0.10915177002460996)\n",
      "     | > log_mle: -0.17843341827392578  (-0.16550734938954456)\n",
      "     | > loss_dur: 0.28382912278175354  (0.27465911941415444)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(17.3298, device='cuda:0')  (tensor(10.8179, device='cuda:0'))\n",
      "     | > current_lr: 8.25e-06 \n",
      "     | > step_time: 0.6012  (0.7200330439403919)\n",
      "     | > loader_time: 0.0083  (0.014528376816292486)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 05:11:36 -- STEP: 363/406 -- GLOBAL_STEP: 20250\u001b[0m\n",
      "     | > loss: 0.09902212023735046  (0.10880303202253397)\n",
      "     | > log_mle: -0.18175363540649414  (-0.16647053520213143)\n",
      "     | > loss_dur: 0.2807757556438446  (0.27527356722466545)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(14.9144, device='cuda:0')  (tensor(11.0111, device='cuda:0'))\n",
      "     | > current_lr: 8.25e-06 \n",
      "     | > step_time: 0.8439  (0.7296712451073092)\n",
      "     | > loader_time: 0.0163  (0.014836958945618517)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 05:11:59 -- STEP: 388/406 -- GLOBAL_STEP: 20275\u001b[0m\n",
      "     | > loss: 0.1071893572807312  (0.10844652393122307)\n",
      "     | > log_mle: -0.18373024463653564  (-0.1672919386440945)\n",
      "     | > loss_dur: 0.29091960191726685  (0.27573846257531764)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(16.1036, device='cuda:0')  (tensor(11.2392, device='cuda:0'))\n",
      "     | > current_lr: 8.25e-06 \n",
      "     | > step_time: 1.1811  (0.740372179709759)\n",
      "     | > loader_time: 0.0104  (0.01528848385073475)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: 0.09939321875572205  (0.09939321875572205)\n",
      "     | > log_mle: -0.15132713317871094  (-0.15132713317871094)\n",
      "     | > loss_dur: 0.250720351934433  (0.250720351934433)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: 0.06158791482448578  (0.06158791482448578)\n",
      "     | > log_mle: -0.18548929691314697  (-0.18548929691314697)\n",
      "     | > loss_dur: 0.24707721173763275  (0.24707721173763275)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: 0.05941089987754822  (0.060499407351017)\n",
      "     | > log_mle: -0.14615392684936523  (-0.1658216118812561)\n",
      "     | > loss_dur: 0.20556482672691345  (0.2263210192322731)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: 0.09016925096511841  (0.07038935522238414)\n",
      "     | > log_mle: -0.1601477861404419  (-0.16393033663431802)\n",
      "     | > loss_dur: 0.2503170371055603  (0.23431969185670218)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: 0.07408124208450317  (0.0713123269379139)\n",
      "     | > log_mle: -0.18584275245666504  (-0.16940844058990479)\n",
      "     | > loss_dur: 0.2599239945411682  (0.24072076752781868)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: 0.082955002784729  (0.07364086210727691)\n",
      "     | > log_mle: -0.17954182624816895  (-0.17143511772155762)\n",
      "     | > loss_dur: 0.26249682903289795  (0.24507597982883453)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: 0.1274072527885437  (0.08260192722082138)\n",
      "     | > log_mle: -0.19054186344146729  (-0.17461957534154257)\n",
      "     | > loss_dur: 0.317949116230011  (0.2572215025623639)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: 0.08104220032691956  (0.08237910909312111)\n",
      "     | > log_mle: -0.16174685955047607  (-0.17278061594281877)\n",
      "     | > loss_dur: 0.24278905987739563  (0.2551597250359399)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: 0.07627493143081665  (0.08161608688533306)\n",
      "     | > log_mle: -0.1689441204071045  (-0.1723010540008545)\n",
      "     | > loss_dur: 0.24521905183792114  (0.25391714088618755)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: 0.10522618889808655  (0.08423943155341679)\n",
      "     | > log_mle: -0.17706120014190674  (-0.17282995912763807)\n",
      "     | > loss_dur: 0.2822873890399933  (0.25706939068105483)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: 0.10158190131187439  (0.08597367852926255)\n",
      "     | > log_mle: -0.16708815097808838  (-0.1722557783126831)\n",
      "     | > loss_dur: 0.26867005228996277  (0.25822945684194565)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: 0.08985373377799988  (0.0863264108246023)\n",
      "     | > log_mle: -0.18181169033050537  (-0.17312449758703058)\n",
      "     | > loss_dur: 0.27166542410850525  (0.2594509084116329)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: 0.06673334538936615  (0.08469365537166595)\n",
      "     | > log_mle: -0.17178082466125488  (-0.17301252484321594)\n",
      "     | > loss_dur: 0.23851417005062103  (0.2577061802148819)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: 0.04696819186210632  (0.08179169664016137)\n",
      "     | > log_mle: -0.1868191957473755  (-0.1740745764512282)\n",
      "     | > loss_dur: 0.2337873876094818  (0.2558662730913896)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: 0.11004412174224854  (0.08380972700459617)\n",
      "     | > log_mle: -0.18205082416534424  (-0.17464430843080794)\n",
      "     | > loss_dur: 0.2920949459075928  (0.2584540354354041)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: 0.08523297309875488  (0.08390461007754008)\n",
      "     | > log_mle: -0.17667675018310547  (-0.17477980454762776)\n",
      "     | > loss_dur: 0.26190972328186035  (0.25868441462516784)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: 0.0912003219127655  (0.08436059206724167)\n",
      "     | > log_mle: -0.17041587829589844  (-0.17450705915689468)\n",
      "     | > loss_dur: 0.26161620020866394  (0.25886765122413635)\n",
      "\n",
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[91m 0.005418434739112854 \u001b[0m(+0.0005428791046142578)\n",
      "     | > avg_loss:\u001b[92m 0.08436059206724167 \u001b[0m(-0.005913775414228439)\n",
      "     | > avg_log_mle:\u001b[92m -0.17450705915689468 \u001b[0m(-0.0001601874828338623)\n",
      "     | > avg_loss_dur:\u001b[92m 0.25886765122413635 \u001b[0m(-0.005753587931394577)\n",
      "\n",
      " > BEST MODEL : train/run-February-22-2025_02+19AM-9b6e3e6/best_model_20293.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 34/40\u001b[0m\n",
      " --> train/run-February-22-2025_02+19AM-9b6e3e6\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-22 05:12:27) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 05:12:32 -- STEP: 7/406 -- GLOBAL_STEP: 20300\u001b[0m\n",
      "     | > loss: 0.09828171133995056  (0.09963794478348323)\n",
      "     | > log_mle: -0.14155614376068115  (-0.1453820296696254)\n",
      "     | > loss_dur: 0.2398378551006317  (0.24501997445310866)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(4.4980, device='cuda:0')  (tensor(3.7976, device='cuda:0'))\n",
      "     | > current_lr: 8.5e-06 \n",
      "     | > step_time: 0.4055  (0.4329336370740618)\n",
      "     | > loader_time: 0.0052  (0.010440383638654436)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 05:12:47 -- STEP: 32/406 -- GLOBAL_STEP: 20325\u001b[0m\n",
      "     | > loss: 0.09976926445960999  (0.10308467270806432)\n",
      "     | > log_mle: -0.15061354637145996  (-0.14886491745710376)\n",
      "     | > loss_dur: 0.25038281083106995  (0.25194959016516805)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(2.5492, device='cuda:0')  (tensor(4.4319, device='cuda:0'))\n",
      "     | > current_lr: 8.5e-06 \n",
      "     | > step_time: 0.8773  (0.5435505956411362)\n",
      "     | > loader_time: 0.0053  (0.009238906204700467)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 05:13:03 -- STEP: 57/406 -- GLOBAL_STEP: 20350\u001b[0m\n",
      "     | > loss: 0.09785662591457367  (0.10520938169537929)\n",
      "     | > log_mle: -0.1489715576171875  (-0.15050457653246424)\n",
      "     | > loss_dur: 0.24682818353176117  (0.2557139582278437)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(4.6682, device='cuda:0')  (tensor(5.0110, device='cuda:0'))\n",
      "     | > current_lr: 8.5e-06 \n",
      "     | > step_time: 0.7161  (0.5768072897927801)\n",
      "     | > loader_time: 0.085  (0.011185420186896071)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 05:13:19 -- STEP: 82/406 -- GLOBAL_STEP: 20375\u001b[0m\n",
      "     | > loss: 0.09674730896949768  (0.104584866362374)\n",
      "     | > log_mle: -0.16430699825286865  (-0.15324125784199416)\n",
      "     | > loss_dur: 0.26105430722236633  (0.25782612420436823)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(9.8200, device='cuda:0')  (tensor(7.3068, device='cuda:0'))\n",
      "     | > current_lr: 8.5e-06 \n",
      "     | > step_time: 0.5317  (0.5902720224566574)\n",
      "     | > loader_time: 0.0172  (0.011245233256642409)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 05:13:36 -- STEP: 107/406 -- GLOBAL_STEP: 20400\u001b[0m\n",
      "     | > loss: 0.08650544285774231  (0.10308777464327411)\n",
      "     | > log_mle: -0.17069220542907715  (-0.15623143454578442)\n",
      "     | > loss_dur: 0.25719764828681946  (0.2593192091890585)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(6.5016, device='cuda:0')  (tensor(8.1109, device='cuda:0'))\n",
      "     | > current_lr: 8.5e-06 \n",
      "     | > step_time: 0.6409  (0.6040557455793717)\n",
      "     | > loader_time: 0.0189  (0.011668682098388668)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 05:13:54 -- STEP: 132/406 -- GLOBAL_STEP: 20425\u001b[0m\n",
      "     | > loss: 0.07671880722045898  (0.1021027062652689)\n",
      "     | > log_mle: -0.1840745210647583  (-0.15898786169109927)\n",
      "     | > loss_dur: 0.2607933282852173  (0.26109056795636815)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(9.9178, device='cuda:0')  (tensor(8.7275, device='cuda:0'))\n",
      "     | > current_lr: 8.5e-06 \n",
      "     | > step_time: 0.9954  (0.621598220232761)\n",
      "     | > loader_time: 0.0196  (0.012034483028180668)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 05:14:11 -- STEP: 157/406 -- GLOBAL_STEP: 20450\u001b[0m\n",
      "     | > loss: 0.09265792369842529  (0.10250780489414363)\n",
      "     | > log_mle: -0.16365468502044678  (-0.16079544717339203)\n",
      "     | > loss_dur: 0.25631260871887207  (0.26330325206753546)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(7.2061, device='cuda:0')  (tensor(8.8088, device='cuda:0'))\n",
      "     | > current_lr: 8.5e-06 \n",
      "     | > step_time: 0.7579  (0.6313139025572758)\n",
      "     | > loader_time: 0.0408  (0.012375011565578967)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 05:14:30 -- STEP: 182/406 -- GLOBAL_STEP: 20475\u001b[0m\n",
      "     | > loss: 0.10103324055671692  (0.10196862910147554)\n",
      "     | > log_mle: -0.17436599731445312  (-0.16250011619630755)\n",
      "     | > loss_dur: 0.27539923787117004  (0.26446874529778297)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(9.6619, device='cuda:0')  (tensor(9.2357, device='cuda:0'))\n",
      "     | > current_lr: 8.5e-06 \n",
      "     | > step_time: 0.4796  (0.6414548433743991)\n",
      "     | > loader_time: 0.0087  (0.01287435175298334)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 05:14:50 -- STEP: 207/406 -- GLOBAL_STEP: 20500\u001b[0m\n",
      "     | > loss: 0.09310603141784668  (0.10171061703836286)\n",
      "     | > log_mle: -0.17020893096923828  (-0.16398517175573082)\n",
      "     | > loss_dur: 0.26331496238708496  (0.2656957887940936)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(11.3636, device='cuda:0')  (tensor(9.8092, device='cuda:0'))\n",
      "     | > current_lr: 8.5e-06 \n",
      "     | > step_time: 1.2257  (0.6602457802076844)\n",
      "     | > loader_time: 0.0061  (0.013337138770283127)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 05:15:10 -- STEP: 232/406 -- GLOBAL_STEP: 20525\u001b[0m\n",
      "     | > loss: 0.10922369360923767  (0.10118545765249895)\n",
      "     | > log_mle: -0.17939555644989014  (-0.16560180382481937)\n",
      "     | > loss_dur: 0.2886192500591278  (0.26678726147731835)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(16.8872, device='cuda:0')  (tensor(10.2189, device='cuda:0'))\n",
      "     | > current_lr: 8.5e-06 \n",
      "     | > step_time: 0.5567  (0.671036291739036)\n",
      "     | > loader_time: 0.0072  (0.013310866109256083)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 05:15:31 -- STEP: 257/406 -- GLOBAL_STEP: 20550\u001b[0m\n",
      "     | > loss: 0.08782055974006653  (0.10059180780375515)\n",
      "     | > log_mle: -0.18184328079223633  (-0.16699351782000946)\n",
      "     | > loss_dur: 0.26966384053230286  (0.2675853256237646)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(13.3933, device='cuda:0')  (tensor(10.5198, device='cuda:0'))\n",
      "     | > current_lr: 8.5e-06 \n",
      "     | > step_time: 1.132  (0.6865601567442777)\n",
      "     | > loader_time: 0.0212  (0.013331627567454532)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 05:15:51 -- STEP: 282/406 -- GLOBAL_STEP: 20575\u001b[0m\n",
      "     | > loss: 0.0854220986366272  (0.09990218551235)\n",
      "     | > log_mle: -0.19249606132507324  (-0.1681460421136085)\n",
      "     | > loss_dur: 0.27791815996170044  (0.2680482276259585)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(6.0268, device='cuda:0')  (tensor(10.6729, device='cuda:0'))\n",
      "     | > current_lr: 8.5e-06 \n",
      "     | > step_time: 0.8456  (0.6949093840646402)\n",
      "     | > loader_time: 0.008  (0.013556991908567167)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 05:16:12 -- STEP: 307/406 -- GLOBAL_STEP: 20600\u001b[0m\n",
      "     | > loss: 0.08847597241401672  (0.09964196733426584)\n",
      "     | > log_mle: -0.17741799354553223  (-0.1690871599054492)\n",
      "     | > loss_dur: 0.26589396595954895  (0.268729127239715)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(8.8430, device='cuda:0')  (tensor(10.5584, device='cuda:0'))\n",
      "     | > current_lr: 8.5e-06 \n",
      "     | > step_time: 0.707  (0.7062740745295915)\n",
      "     | > loader_time: 0.0097  (0.013918160615604162)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 05:16:35 -- STEP: 332/406 -- GLOBAL_STEP: 20625\u001b[0m\n",
      "     | > loss: 0.10059714317321777  (0.09934228923485942)\n",
      "     | > log_mle: -0.17641139030456543  (-0.16992248971778232)\n",
      "     | > loss_dur: 0.2770085334777832  (0.2692647789526417)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(15.1187, device='cuda:0')  (tensor(10.8377, device='cuda:0'))\n",
      "     | > current_lr: 8.5e-06 \n",
      "     | > step_time: 1.0383  (0.7192389886063264)\n",
      "     | > loader_time: 0.0367  (0.014328169535441568)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 05:16:57 -- STEP: 357/406 -- GLOBAL_STEP: 20650\u001b[0m\n",
      "     | > loss: 0.09288525581359863  (0.09899045226453736)\n",
      "     | > log_mle: -0.1788926124572754  (-0.17094246279291747)\n",
      "     | > loss_dur: 0.271777868270874  (0.2699329150574551)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(14.0864, device='cuda:0')  (tensor(11.1334, device='cuda:0'))\n",
      "     | > current_lr: 8.5e-06 \n",
      "     | > step_time: 1.0872  (0.7296149316622096)\n",
      "     | > loader_time: 0.0316  (0.01473318896039861)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 05:17:21 -- STEP: 382/406 -- GLOBAL_STEP: 20675\u001b[0m\n",
      "     | > loss: 0.09850582480430603  (0.09850402063256161)\n",
      "     | > log_mle: -0.18779480457305908  (-0.1718744888355595)\n",
      "     | > loss_dur: 0.2863006293773651  (0.2703785094681214)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(9.3789, device='cuda:0')  (tensor(11.3626, device='cuda:0'))\n",
      "     | > current_lr: 8.5e-06 \n",
      "     | > step_time: 1.0217  (0.7412047885475358)\n",
      "     | > loader_time: 0.009  (0.014737380112653001)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: 0.08789028227329254  (0.08789028227329254)\n",
      "     | > log_mle: -0.15690922737121582  (-0.15690922737121582)\n",
      "     | > loss_dur: 0.24479950964450836  (0.24479950964450836)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: 0.03910401463508606  (0.03910401463508606)\n",
      "     | > log_mle: -0.19307661056518555  (-0.19307661056518555)\n",
      "     | > loss_dur: 0.2321806252002716  (0.2321806252002716)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: 0.0564177930355072  (0.04776090383529663)\n",
      "     | > log_mle: -0.152549147605896  (-0.17281287908554077)\n",
      "     | > loss_dur: 0.2089669406414032  (0.2205737829208374)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: 0.07731181383132935  (0.057611207167307533)\n",
      "     | > log_mle: -0.168379545211792  (-0.1713351011276245)\n",
      "     | > loss_dur: 0.24569135904312134  (0.22894630829493204)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: 0.06201577186584473  (0.058712348341941833)\n",
      "     | > log_mle: -0.19458913803100586  (-0.17714861035346985)\n",
      "     | > loss_dur: 0.2566049098968506  (0.23586095869541168)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: 0.06506481766700745  (0.059982842206954955)\n",
      "     | > log_mle: -0.19293558597564697  (-0.18030600547790526)\n",
      "     | > loss_dur: 0.2580004036426544  (0.24028884768486022)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: 0.10126286745071411  (0.06686284641424815)\n",
      "     | > log_mle: -0.20500695705413818  (-0.18442283074061075)\n",
      "     | > loss_dur: 0.3062698245048523  (0.2512856771548589)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: 0.07056222856044769  (0.06739132957799095)\n",
      "     | > log_mle: -0.171303391456604  (-0.18254862512860978)\n",
      "     | > loss_dur: 0.2418656200170517  (0.24993995470660074)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: 0.05160234868526459  (0.06541770696640015)\n",
      "     | > log_mle: -0.17666685581207275  (-0.18181340396404266)\n",
      "     | > loss_dur: 0.22826920449733734  (0.2472311109304428)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: 0.08795469999313354  (0.06792181730270386)\n",
      "     | > log_mle: -0.18841171264648438  (-0.18254654937320286)\n",
      "     | > loss_dur: 0.2763664126396179  (0.2504683666759067)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: 0.09482640027999878  (0.07061227560043334)\n",
      "     | > log_mle: -0.17587006092071533  (-0.1818789005279541)\n",
      "     | > loss_dur: 0.2706964612007141  (0.25249117612838745)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: 0.07082298398017883  (0.07063143090768294)\n",
      "     | > log_mle: -0.19164955615997314  (-0.18276714194904675)\n",
      "     | > loss_dur: 0.262472540140152  (0.2533985728567297)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: 0.04949033260345459  (0.06886967271566391)\n",
      "     | > log_mle: -0.17944657802581787  (-0.18249042828877768)\n",
      "     | > loss_dur: 0.22893691062927246  (0.25136010100444156)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: 0.02936495840549469  (0.06583084853795859)\n",
      "     | > log_mle: -0.19897449016571045  (-0.18375843304854172)\n",
      "     | > loss_dur: 0.22833944857120514  (0.24958928158650032)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: 0.09763523936271667  (0.06810259073972703)\n",
      "     | > log_mle: -0.19156265258789062  (-0.18431587730135238)\n",
      "     | > loss_dur: 0.2891978919506073  (0.25241846804107937)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: 0.07153001427650452  (0.06833108564217887)\n",
      "     | > log_mle: -0.18602240085601807  (-0.18442964553833008)\n",
      "     | > loss_dur: 0.2575524151325226  (0.25276073118050896)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: 0.08271375298500061  (0.06923000235110523)\n",
      "     | > log_mle: -0.181687593460083  (-0.18425826728343964)\n",
      "     | > loss_dur: 0.2644013464450836  (0.25348826963454485)\n",
      "\n",
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.0036513209342956543 \u001b[0m(-0.0017671138048171997)\n",
      "     | > avg_loss:\u001b[92m 0.06923000235110523 \u001b[0m(-0.015130589716136442)\n",
      "     | > avg_log_mle:\u001b[92m -0.18425826728343964 \u001b[0m(-0.009751208126544952)\n",
      "     | > avg_loss_dur:\u001b[92m 0.25348826963454485 \u001b[0m(-0.005379381589591503)\n",
      "\n",
      " > BEST MODEL : train/run-February-22-2025_02+19AM-9b6e3e6/best_model_20699.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 35/40\u001b[0m\n",
      " --> train/run-February-22-2025_02+19AM-9b6e3e6\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-22 05:17:54) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 05:17:57 -- STEP: 1/406 -- GLOBAL_STEP: 20700\u001b[0m\n",
      "     | > loss: 0.07522518932819366  (0.07522518932819366)\n",
      "     | > log_mle: -0.15153443813323975  (-0.15153443813323975)\n",
      "     | > loss_dur: 0.2267596274614334  (0.2267596274614334)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(4.8337, device='cuda:0')  (tensor(4.8337, device='cuda:0'))\n",
      "     | > current_lr: 8.750000000000001e-06 \n",
      "     | > step_time: 0.5571  (0.5570626258850098)\n",
      "     | > loader_time: 0.0062  (0.0061914920806884766)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 05:18:09 -- STEP: 26/406 -- GLOBAL_STEP: 20725\u001b[0m\n",
      "     | > loss: 0.08253781497478485  (0.0898907992702264)\n",
      "     | > log_mle: -0.15621662139892578  (-0.15433809390434852)\n",
      "     | > loss_dur: 0.23875443637371063  (0.2442288931745749)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(1.6991, device='cuda:0')  (tensor(3.9073, device='cuda:0'))\n",
      "     | > current_lr: 8.750000000000001e-06 \n",
      "     | > step_time: 0.382  (0.49262832678281343)\n",
      "     | > loader_time: 0.0039  (0.008064911915705755)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 05:18:25 -- STEP: 51/406 -- GLOBAL_STEP: 20750\u001b[0m\n",
      "     | > loss: 0.0812751054763794  (0.09392643909828335)\n",
      "     | > log_mle: -0.17209839820861816  (-0.15538808878730329)\n",
      "     | > loss_dur: 0.25337350368499756  (0.2493145278855866)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(14.1793, device='cuda:0')  (tensor(6.7649, device='cuda:0'))\n",
      "     | > current_lr: 8.750000000000001e-06 \n",
      "     | > step_time: 0.6447  (0.5545587679919075)\n",
      "     | > loader_time: 0.0048  (0.010496672462014594)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 05:18:43 -- STEP: 76/406 -- GLOBAL_STEP: 20775\u001b[0m\n",
      "     | > loss: 0.10424679517745972  (0.09325702527635976)\n",
      "     | > log_mle: -0.1601043939590454  (-0.15816494979356469)\n",
      "     | > loss_dur: 0.2643511891365051  (0.2514219750699244)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(13.1129, device='cuda:0')  (tensor(9.0716, device='cuda:0'))\n",
      "     | > current_lr: 8.750000000000001e-06 \n",
      "     | > step_time: 0.3647  (0.5951249568085921)\n",
      "     | > loader_time: 0.0062  (0.011235660628268597)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 05:18:59 -- STEP: 101/406 -- GLOBAL_STEP: 20800\u001b[0m\n",
      "     | > loss: 0.09675467014312744  (0.09304863981681295)\n",
      "     | > log_mle: -0.1676849126815796  (-0.1609087722136243)\n",
      "     | > loss_dur: 0.26443958282470703  (0.2539574120304371)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(2.0295, device='cuda:0')  (tensor(9.4935, device='cuda:0'))\n",
      "     | > current_lr: 8.750000000000001e-06 \n",
      "     | > step_time: 0.4348  (0.6054262099879801)\n",
      "     | > loader_time: 0.0171  (0.01206952746551816)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 05:19:17 -- STEP: 126/406 -- GLOBAL_STEP: 20825\u001b[0m\n",
      "     | > loss: 0.08309584856033325  (0.09230492725258782)\n",
      "     | > log_mle: -0.17060565948486328  (-0.16354037561113874)\n",
      "     | > loss_dur: 0.25370150804519653  (0.2558453028637264)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(17.8329, device='cuda:0')  (tensor(9.9489, device='cuda:0'))\n",
      "     | > current_lr: 8.750000000000001e-06 \n",
      "     | > step_time: 0.4704  (0.6222058856298051)\n",
      "     | > loader_time: 0.0077  (0.012268036130874878)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 05:19:35 -- STEP: 151/406 -- GLOBAL_STEP: 20850\u001b[0m\n",
      "     | > loss: 0.10510015487670898  (0.09242228630757493)\n",
      "     | > log_mle: -0.16727221012115479  (-0.16549514697876994)\n",
      "     | > loss_dur: 0.27237236499786377  (0.25791743328634453)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(18.6310, device='cuda:0')  (tensor(10.8913, device='cuda:0'))\n",
      "     | > current_lr: 8.750000000000001e-06 \n",
      "     | > step_time: 0.3847  (0.6338855778144683)\n",
      "     | > loader_time: 0.005  (0.012777214808179848)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 05:19:53 -- STEP: 176/406 -- GLOBAL_STEP: 20875\u001b[0m\n",
      "     | > loss: 0.09352108836174011  (0.09217222001064912)\n",
      "     | > log_mle: -0.1723402738571167  (-0.16703972626816144)\n",
      "     | > loss_dur: 0.2658613622188568  (0.25921194627881033)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(19.2964, device='cuda:0')  (tensor(11.8538, device='cuda:0'))\n",
      "     | > current_lr: 8.750000000000001e-06 \n",
      "     | > step_time: 1.0084  (0.642865260893648)\n",
      "     | > loader_time: 0.0313  (0.013543776490471586)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 05:20:12 -- STEP: 201/406 -- GLOBAL_STEP: 20900\u001b[0m\n",
      "     | > loss: 0.07937794923782349  (0.09192368714370541)\n",
      "     | > log_mle: -0.1717541217803955  (-0.16864043148002822)\n",
      "     | > loss_dur: 0.251132071018219  (0.26056411862373335)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(6.8452, device='cuda:0')  (tensor(11.9204, device='cuda:0'))\n",
      "     | > current_lr: 8.750000000000001e-06 \n",
      "     | > step_time: 1.0508  (0.6538870666750622)\n",
      "     | > loader_time: 0.02  (0.013839632717531124)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 05:20:30 -- STEP: 226/406 -- GLOBAL_STEP: 20925\u001b[0m\n",
      "     | > loss: 0.08241552114486694  (0.09167391088156576)\n",
      "     | > log_mle: -0.18639886379241943  (-0.17008672931552996)\n",
      "     | > loss_dur: 0.2688143849372864  (0.26176064019709544)\n",
      "     | > amp_scaler: 16384.0  (8735.716814159294)\n",
      "     | > grad_norm: tensor(6.8164, device='cuda:0')  (tensor(11.9334, device='cuda:0'))\n",
      "     | > current_lr: 8.750000000000001e-06 \n",
      "     | > step_time: 0.5686  (0.6624736300611913)\n",
      "     | > loader_time: 0.0104  (0.013675168552229893)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 05:20:50 -- STEP: 251/406 -- GLOBAL_STEP: 20950\u001b[0m\n",
      "     | > loss: 0.0903574526309967  (0.09142364709975713)\n",
      "     | > log_mle: -0.1850593090057373  (-0.17138642903818083)\n",
      "     | > loss_dur: 0.275416761636734  (0.2628100761379379)\n",
      "     | > amp_scaler: 16384.0  (9497.498007968132)\n",
      "     | > grad_norm: tensor(14.4114, device='cuda:0')  (tensor(12.0951, device='cuda:0'))\n",
      "     | > current_lr: 8.750000000000001e-06 \n",
      "     | > step_time: 0.8956  (0.6704257807408667)\n",
      "     | > loader_time: 0.0084  (0.014301165166604094)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 05:21:10 -- STEP: 276/406 -- GLOBAL_STEP: 20975\u001b[0m\n",
      "     | > loss: 0.09912499785423279  (0.09084156706281332)\n",
      "     | > log_mle: -0.17984604835510254  (-0.17259294399316766)\n",
      "     | > loss_dur: 0.2789710462093353  (0.26343451105598087)\n",
      "     | > amp_scaler: 8192.0  (9408.927536231888)\n",
      "     | > grad_norm: tensor(15.7500, device='cuda:0')  (tensor(12.1349, device='cuda:0'))\n",
      "     | > current_lr: 8.750000000000001e-06 \n",
      "     | > step_time: 0.5862  (0.6802937353866683)\n",
      "     | > loader_time: 0.0107  (0.014172542786252674)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 05:21:31 -- STEP: 301/406 -- GLOBAL_STEP: 21000\u001b[0m\n",
      "     | > loss: 0.09749463200569153  (0.0907334780376219)\n",
      "     | > log_mle: -0.19795012474060059  (-0.17356237264170604)\n",
      "     | > loss_dur: 0.2954447567462921  (0.26429585067932787)\n",
      "     | > amp_scaler: 8192.0  (9307.853820598008)\n",
      "     | > grad_norm: tensor(15.5555, device='cuda:0')  (tensor(11.8721, device='cuda:0'))\n",
      "     | > current_lr: 8.750000000000001e-06 \n",
      "     | > step_time: 0.9261  (0.6923264704669428)\n",
      "     | > loader_time: 0.0065  (0.0143565862281774)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 05:21:53 -- STEP: 326/406 -- GLOBAL_STEP: 21025\u001b[0m\n",
      "     | > loss: 0.08467882871627808  (0.09048562071806088)\n",
      "     | > log_mle: -0.1770397424697876  (-0.17438547560042403)\n",
      "     | > loss_dur: 0.2617185711860657  (0.2648710963184849)\n",
      "     | > amp_scaler: 8192.0  (9222.282208588964)\n",
      "     | > grad_norm: tensor(11.4928, device='cuda:0')  (tensor(11.9034, device='cuda:0'))\n",
      "     | > current_lr: 8.750000000000001e-06 \n",
      "     | > step_time: 0.5963  (0.7049484048152992)\n",
      "     | > loader_time: 0.0061  (0.01452052373827601)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 05:22:16 -- STEP: 351/406 -- GLOBAL_STEP: 21050\u001b[0m\n",
      "     | > loss: 0.09751877188682556  (0.09038883558026073)\n",
      "     | > log_mle: -0.17870914936065674  (-0.1752558800569627)\n",
      "     | > loss_dur: 0.2762279212474823  (0.26564471563722347)\n",
      "     | > amp_scaler: 8192.0  (9148.900284900288)\n",
      "     | > grad_norm: tensor(23.9740, device='cuda:0')  (tensor(12.1575, device='cuda:0'))\n",
      "     | > current_lr: 8.750000000000001e-06 \n",
      "     | > step_time: 1.357  (0.7188333942000341)\n",
      "     | > loader_time: 0.0241  (0.014984497657189006)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 05:22:38 -- STEP: 376/406 -- GLOBAL_STEP: 21075\u001b[0m\n",
      "     | > loss: 0.09122598171234131  (0.08993192223158292)\n",
      "     | > log_mle: -0.1892688274383545  (-0.17619788646698006)\n",
      "     | > loss_dur: 0.2804948091506958  (0.26612980869856295)\n",
      "     | > amp_scaler: 8192.0  (9085.276595744679)\n",
      "     | > grad_norm: tensor(13.7321, device='cuda:0')  (tensor(12.7787, device='cuda:0'))\n",
      "     | > current_lr: 8.750000000000001e-06 \n",
      "     | > step_time: 0.9121  (0.7284707002183223)\n",
      "     | > loader_time: 0.0256  (0.015130789356028783)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 05:22:58 -- STEP: 401/406 -- GLOBAL_STEP: 21100\u001b[0m\n",
      "     | > loss: 0.06784433126449585  (0.0896694598501163)\n",
      "     | > log_mle: -0.19195473194122314  (-0.1770196050182543)\n",
      "     | > loss_dur: 0.259799063205719  (0.2666890648683705)\n",
      "     | > amp_scaler: 8192.0  (9029.586034912718)\n",
      "     | > grad_norm: tensor(18.7324, device='cuda:0')  (tensor(13.2102, device='cuda:0'))\n",
      "     | > current_lr: 8.750000000000001e-06 \n",
      "     | > step_time: 0.6113  (0.7297405376101371)\n",
      "     | > loader_time: 0.0083  (0.015220055853636784)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: 0.08326813578605652  (0.08326813578605652)\n",
      "     | > log_mle: -0.16219747066497803  (-0.16219747066497803)\n",
      "     | > loss_dur: 0.24546560645103455  (0.24546560645103455)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: 0.030578479170799255  (0.030578479170799255)\n",
      "     | > log_mle: -0.1985619068145752  (-0.1985619068145752)\n",
      "     | > loss_dur: 0.22914038598537445  (0.22914038598537445)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: 0.04464997351169586  (0.03761422634124756)\n",
      "     | > log_mle: -0.15783703327178955  (-0.17819947004318237)\n",
      "     | > loss_dur: 0.2024870067834854  (0.21581369638442993)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: 0.06301417946815491  (0.04608087738355001)\n",
      "     | > log_mle: -0.17440927028656006  (-0.17693607012430826)\n",
      "     | > loss_dur: 0.23742344975471497  (0.22301694750785828)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: 0.051173776388168335  (0.04735410213470459)\n",
      "     | > log_mle: -0.20063793659210205  (-0.1828615367412567)\n",
      "     | > loss_dur: 0.2518117129802704  (0.2302156388759613)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: 0.05622848868370056  (0.049128979444503784)\n",
      "     | > log_mle: -0.20198404788970947  (-0.18668603897094727)\n",
      "     | > loss_dur: 0.25821253657341003  (0.23581501841545105)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: 0.09654709696769714  (0.057031999031702675)\n",
      "     | > log_mle: -0.2138274908065796  (-0.191209614276886)\n",
      "     | > loss_dur: 0.31037458777427673  (0.24824161330858865)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: 0.05423639714717865  (0.056632627333913534)\n",
      "     | > log_mle: -0.1775524616241455  (-0.18925859246935164)\n",
      "     | > loss_dur: 0.23178885877132416  (0.24589121980326517)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: 0.0466805100440979  (0.05538861267268658)\n",
      "     | > log_mle: -0.182855486869812  (-0.18845820426940918)\n",
      "     | > loss_dur: 0.2295359969139099  (0.24384681694209576)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: 0.07402053475379944  (0.05745882623725467)\n",
      "     | > log_mle: -0.19564080238342285  (-0.18925627072652182)\n",
      "     | > loss_dur: 0.2696613371372223  (0.24671509696377647)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: 0.07928621768951416  (0.059641565382480624)\n",
      "     | > log_mle: -0.18202710151672363  (-0.18853335380554198)\n",
      "     | > loss_dur: 0.2613133192062378  (0.24817491918802262)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: 0.06245043873786926  (0.05989691750569777)\n",
      "     | > log_mle: -0.19832205772399902  (-0.18942323597994717)\n",
      "     | > loss_dur: 0.2607724964618683  (0.24932015348564496)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: 0.04183533787727356  (0.05839178586999575)\n",
      "     | > log_mle: -0.18531107902526855  (-0.18908055623372397)\n",
      "     | > loss_dur: 0.22714641690254211  (0.2474723421037197)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: 0.01313696801662445  (0.05491064603512104)\n",
      "     | > log_mle: -0.20641982555389404  (-0.19041434618142936)\n",
      "     | > loss_dur: 0.2195567935705185  (0.24532499221655038)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: 0.08012360334396362  (0.05671157155718122)\n",
      "     | > log_mle: -0.19799506664276123  (-0.19095582621438162)\n",
      "     | > loss_dur: 0.27811866998672485  (0.24766739777156285)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: 0.053072452545166016  (0.056468963623046875)\n",
      "     | > log_mle: -0.19242775440216064  (-0.19105395476023357)\n",
      "     | > loss_dur: 0.24550020694732666  (0.24752291838328044)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: 0.08458772301673889  (0.058226386085152626)\n",
      "     | > log_mle: -0.18821847438812256  (-0.19087673723697662)\n",
      "     | > loss_dur: 0.27280619740486145  (0.24910312332212925)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: audio amplitude out of range, auto clipped.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[91m 0.00377635657787323 \u001b[0m(+0.00012503564357757568)\n",
      "     | > avg_loss:\u001b[92m 0.058226386085152626 \u001b[0m(-0.011003616265952601)\n",
      "     | > avg_log_mle:\u001b[92m -0.19087673723697662 \u001b[0m(-0.006618469953536987)\n",
      "     | > avg_loss_dur:\u001b[92m 0.24910312332212925 \u001b[0m(-0.0043851463124156)\n",
      "\n",
      " > BEST MODEL : train/run-February-22-2025_02+19AM-9b6e3e6/best_model_21105.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 36/40\u001b[0m\n",
      " --> train/run-February-22-2025_02+19AM-9b6e3e6\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-22 05:23:18) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 05:23:31 -- STEP: 20/406 -- GLOBAL_STEP: 21125\u001b[0m\n",
      "     | > loss: 0.09701956808567047  (0.08118630349636077)\n",
      "     | > log_mle: -0.1416633129119873  (-0.15810806751251222)\n",
      "     | > loss_dur: 0.23868288099765778  (0.239294371008873)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(7.9840, device='cuda:0')  (tensor(6.2664, device='cuda:0'))\n",
      "     | > current_lr: 9e-06 \n",
      "     | > step_time: 0.4227  (0.49135193824768064)\n",
      "     | > loader_time: 0.0051  (0.009206128120422364)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 05:23:48 -- STEP: 45/406 -- GLOBAL_STEP: 21150\u001b[0m\n",
      "     | > loss: 0.08591219782829285  (0.08525484469201831)\n",
      "     | > log_mle: -0.16096889972686768  (-0.15827582942114934)\n",
      "     | > loss_dur: 0.24688109755516052  (0.24353067411316764)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(14.1078, device='cuda:0')  (tensor(6.8989, device='cuda:0'))\n",
      "     | > current_lr: 9e-06 \n",
      "     | > step_time: 0.5832  (0.5788293732537165)\n",
      "     | > loader_time: 0.0278  (0.009887048933241103)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 05:24:04 -- STEP: 70/406 -- GLOBAL_STEP: 21175\u001b[0m\n",
      "     | > loss: 0.045936986804008484  (0.08536051043442319)\n",
      "     | > log_mle: -0.17349910736083984  (-0.161365282535553)\n",
      "     | > loss_dur: 0.21943609416484833  (0.24672579296997615)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(6.2867, device='cuda:0')  (tensor(8.7706, device='cuda:0'))\n",
      "     | > current_lr: 9e-06 \n",
      "     | > step_time: 0.6055  (0.6030189173562186)\n",
      "     | > loader_time: 0.0226  (0.011691992623465403)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 05:24:21 -- STEP: 95/406 -- GLOBAL_STEP: 21200\u001b[0m\n",
      "     | > loss: 0.08896076679229736  (0.08472478860302979)\n",
      "     | > log_mle: -0.17209291458129883  (-0.16470785642925065)\n",
      "     | > loss_dur: 0.2610536813735962  (0.24943264503228038)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(20.6177, device='cuda:0')  (tensor(8.4188, device='cuda:0'))\n",
      "     | > current_lr: 9e-06 \n",
      "     | > step_time: 0.7146  (0.615916432832417)\n",
      "     | > loader_time: 0.0185  (0.012182185524388364)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 05:24:38 -- STEP: 120/406 -- GLOBAL_STEP: 21225\u001b[0m\n",
      "     | > loss: 0.0885973870754242  (0.08416108104089899)\n",
      "     | > log_mle: -0.1765584945678711  (-0.1672825674215953)\n",
      "     | > loss_dur: 0.2651558816432953  (0.25144364846249406)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(10.8614, device='cuda:0')  (tensor(8.8639, device='cuda:0'))\n",
      "     | > current_lr: 9e-06 \n",
      "     | > step_time: 0.6288  (0.6231633285681409)\n",
      "     | > loader_time: 0.0199  (0.01277109185854594)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 05:24:56 -- STEP: 145/406 -- GLOBAL_STEP: 21250\u001b[0m\n",
      "     | > loss: 0.08849388360977173  (0.08401132267096949)\n",
      "     | > log_mle: -0.16460704803466797  (-0.1695112951870623)\n",
      "     | > loss_dur: 0.2531009316444397  (0.2535226178580316)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(12.4002, device='cuda:0')  (tensor(9.5655, device='cuda:0'))\n",
      "     | > current_lr: 9e-06 \n",
      "     | > step_time: 0.7767  (0.6364931155895367)\n",
      "     | > loader_time: 0.0079  (0.0132483564574143)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 05:25:14 -- STEP: 170/406 -- GLOBAL_STEP: 21275\u001b[0m\n",
      "     | > loss: 0.0660296231508255  (0.0837165828136837)\n",
      "     | > log_mle: -0.17838215827941895  (-0.17114713402355414)\n",
      "     | > loss_dur: 0.24441178143024445  (0.2548637168372378)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(18.9183, device='cuda:0')  (tensor(11.0520, device='cuda:0'))\n",
      "     | > current_lr: 9e-06 \n",
      "     | > step_time: 0.5482  (0.6457483978832472)\n",
      "     | > loader_time: 0.0081  (0.01363767736098346)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 05:25:33 -- STEP: 195/406 -- GLOBAL_STEP: 21300\u001b[0m\n",
      "     | > loss: 0.09426680207252502  (0.08315687852028085)\n",
      "     | > log_mle: -0.17282462120056152  (-0.1728275237939296)\n",
      "     | > loss_dur: 0.26709142327308655  (0.2559844023142104)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(8.2984, device='cuda:0')  (tensor(11.7545, device='cuda:0'))\n",
      "     | > current_lr: 9e-06 \n",
      "     | > step_time: 0.6147  (0.6551058830359044)\n",
      "     | > loader_time: 0.0243  (0.013848711894108702)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 05:25:52 -- STEP: 220/406 -- GLOBAL_STEP: 21325\u001b[0m\n",
      "     | > loss: 0.07613900303840637  (0.08277157301252536)\n",
      "     | > log_mle: -0.20526611804962158  (-0.17434923269531938)\n",
      "     | > loss_dur: 0.28140512108802795  (0.2571208057078447)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(19.6649, device='cuda:0')  (tensor(11.9044, device='cuda:0'))\n",
      "     | > current_lr: 9e-06 \n",
      "     | > step_time: 0.9111  (0.6650885982946917)\n",
      "     | > loader_time: 0.0061  (0.01462264494462447)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 05:26:11 -- STEP: 245/406 -- GLOBAL_STEP: 21350\u001b[0m\n",
      "     | > loss: 0.088711678981781  (0.08280910630615387)\n",
      "     | > log_mle: -0.18394708633422852  (-0.1756559143261033)\n",
      "     | > loss_dur: 0.2726587653160095  (0.2584650206322571)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(7.1902, device='cuda:0')  (tensor(11.9832, device='cuda:0'))\n",
      "     | > current_lr: 9e-06 \n",
      "     | > step_time: 0.681  (0.6747285667730839)\n",
      "     | > loader_time: 0.0122  (0.01473909008259676)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 05:26:31 -- STEP: 270/406 -- GLOBAL_STEP: 21375\u001b[0m\n",
      "     | > loss: 0.07012039422988892  (0.08225571744971802)\n",
      "     | > log_mle: -0.1936429738998413  (-0.17675769593980573)\n",
      "     | > loss_dur: 0.2637633681297302  (0.2590134133895237)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(20.0119, device='cuda:0')  (tensor(11.9348, device='cuda:0'))\n",
      "     | > current_lr: 9e-06 \n",
      "     | > step_time: 0.6222  (0.6838531714898569)\n",
      "     | > loader_time: 0.0081  (0.014616465568542483)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 05:26:52 -- STEP: 295/406 -- GLOBAL_STEP: 21400\u001b[0m\n",
      "     | > loss: 0.07247287034988403  (0.08184068990966016)\n",
      "     | > log_mle: -0.18725800514221191  (-0.1777937416302956)\n",
      "     | > loss_dur: 0.25973087549209595  (0.25963443153995563)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(14.7781, device='cuda:0')  (tensor(12.2153, device='cuda:0'))\n",
      "     | > current_lr: 9e-06 \n",
      "     | > step_time: 0.9292  (0.6954858884973041)\n",
      "     | > loader_time: 0.0082  (0.014725005424628823)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 05:27:14 -- STEP: 320/406 -- GLOBAL_STEP: 21425\u001b[0m\n",
      "     | > loss: 0.09306436777114868  (0.08145574568770822)\n",
      "     | > log_mle: -0.18218660354614258  (-0.1787657793611288)\n",
      "     | > loss_dur: 0.27525097131729126  (0.2602215250488368)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(18.7556, device='cuda:0')  (tensor(12.4346, device='cuda:0'))\n",
      "     | > current_lr: 9e-06 \n",
      "     | > step_time: 0.9571  (0.7076000049710274)\n",
      "     | > loader_time: 0.0187  (0.014979936927556992)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 05:27:35 -- STEP: 345/406 -- GLOBAL_STEP: 21450\u001b[0m\n",
      "     | > loss: 0.07882905006408691  (0.08118347110955608)\n",
      "     | > log_mle: -0.19482636451721191  (-0.17965806187063024)\n",
      "     | > loss_dur: 0.27365541458129883  (0.260841532980186)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(12.9863, device='cuda:0')  (tensor(12.6309, device='cuda:0'))\n",
      "     | > current_lr: 9e-06 \n",
      "     | > step_time: 0.9549  (0.7156522730122442)\n",
      "     | > loader_time: 0.043  (0.015443689235742542)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 05:27:59 -- STEP: 370/406 -- GLOBAL_STEP: 21475\u001b[0m\n",
      "     | > loss: 0.07327857613563538  (0.08079974611063258)\n",
      "     | > log_mle: -0.21297597885131836  (-0.180626841493555)\n",
      "     | > loss_dur: 0.28625455498695374  (0.26142658760418724)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(21.1293, device='cuda:0')  (tensor(12.9055, device='cuda:0'))\n",
      "     | > current_lr: 9e-06 \n",
      "     | > step_time: 1.0058  (0.7290064334869385)\n",
      "     | > loader_time: 0.0337  (0.015795509235278976)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 05:28:20 -- STEP: 395/406 -- GLOBAL_STEP: 21500\u001b[0m\n",
      "     | > loss: 0.07635730504989624  (0.08049024645286264)\n",
      "     | > log_mle: -0.1994701623916626  (-0.18145767284345024)\n",
      "     | > loss_dur: 0.27582746744155884  (0.2619479192963124)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(14.7668, device='cuda:0')  (tensor(13.0878, device='cuda:0'))\n",
      "     | > current_lr: 9e-06 \n",
      "     | > step_time: 0.568  (0.733860580227043)\n",
      "     | > loader_time: 0.0083  (0.01603150065941146)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: 0.0760599672794342  (0.0760599672794342)\n",
      "     | > log_mle: -0.16594016551971436  (-0.16594016551971436)\n",
      "     | > loss_dur: 0.24200013279914856  (0.24200013279914856)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: 0.011031880974769592  (0.011031880974769592)\n",
      "     | > log_mle: -0.20169281959533691  (-0.20169281959533691)\n",
      "     | > loss_dur: 0.2127247005701065  (0.2127247005701065)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: 0.03900691866874695  (0.02501939982175827)\n",
      "     | > log_mle: -0.16132771968841553  (-0.18151026964187622)\n",
      "     | > loss_dur: 0.20033463835716248  (0.2065296694636345)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: 0.05193084478378296  (0.0339898814757665)\n",
      "     | > log_mle: -0.17699038982391357  (-0.18000364303588867)\n",
      "     | > loss_dur: 0.22892123460769653  (0.21399352451165518)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: 0.0504571795463562  (0.038106705993413925)\n",
      "     | > log_mle: -0.20298945903778076  (-0.1857500970363617)\n",
      "     | > loss_dur: 0.25344663858413696  (0.22385680302977562)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: 0.046852707862854004  (0.03985590636730194)\n",
      "     | > log_mle: -0.19931209087371826  (-0.188462495803833)\n",
      "     | > loss_dur: 0.24616479873657227  (0.22831840217113494)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: 0.08382195234298706  (0.047183580696582794)\n",
      "     | > log_mle: -0.21177458763122559  (-0.19234784444173178)\n",
      "     | > loss_dur: 0.29559653997421265  (0.23953142513831457)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: 0.05442385375499725  (0.04821790541921343)\n",
      "     | > log_mle: -0.1792445182800293  (-0.1904759407043457)\n",
      "     | > loss_dur: 0.23366837203502655  (0.23869384612355912)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: 0.03656323254108429  (0.04676107130944729)\n",
      "     | > log_mle: -0.18499457836151123  (-0.1897907704114914)\n",
      "     | > loss_dur: 0.22155781090259552  (0.23655184172093868)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: 0.07688447833061218  (0.05010811653402117)\n",
      "     | > log_mle: -0.19617044925689697  (-0.19049962361653647)\n",
      "     | > loss_dur: 0.27305492758750916  (0.24060774015055764)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: 0.07582810521125793  (0.052680115401744845)\n",
      "     | > log_mle: -0.18399560451507568  (-0.18984922170639038)\n",
      "     | > loss_dur: 0.2598237097263336  (0.24252933710813523)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: 0.05409151315689087  (0.0528084242885763)\n",
      "     | > log_mle: -0.19974911212921143  (-0.19074921174482865)\n",
      "     | > loss_dur: 0.2538406252861023  (0.24355763603340497)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: 0.03579571843147278  (0.05139069880048434)\n",
      "     | > log_mle: -0.1877601146697998  (-0.19050012032190958)\n",
      "     | > loss_dur: 0.22355583310127258  (0.24189081912239394)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: 0.011391595005989075  (0.048313844662446245)\n",
      "     | > log_mle: -0.20647907257080078  (-0.1917292704949012)\n",
      "     | > loss_dur: 0.21787066757678986  (0.24004311515734747)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: 0.07048177719116211  (0.049897268414497375)\n",
      "     | > log_mle: -0.19949805736541748  (-0.19228418384279525)\n",
      "     | > loss_dur: 0.2699798345565796  (0.24218145225729262)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: 0.050895482301712036  (0.04996381600697835)\n",
      "     | > log_mle: -0.1940685510635376  (-0.1924031416575114)\n",
      "     | > loss_dur: 0.24496403336524963  (0.24236695766448973)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: 0.06505262851715088  (0.050906866788864136)\n",
      "     | > log_mle: -0.18988943099975586  (-0.19224603474140167)\n",
      "     | > loss_dur: 0.25494205951690674  (0.2431529015302658)\n",
      "\n",
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[91m 0.00451284646987915 \u001b[0m(+0.0007364898920059204)\n",
      "     | > avg_loss:\u001b[92m 0.050906866788864136 \u001b[0m(-0.00731951929628849)\n",
      "     | > avg_log_mle:\u001b[92m -0.19224603474140167 \u001b[0m(-0.0013692975044250488)\n",
      "     | > avg_loss_dur:\u001b[92m 0.2431529015302658 \u001b[0m(-0.0059502217918634415)\n",
      "\n",
      " > BEST MODEL : train/run-February-22-2025_02+19AM-9b6e3e6/best_model_21511.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 37/40\u001b[0m\n",
      " --> train/run-February-22-2025_02+19AM-9b6e3e6\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-22 05:28:43) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 05:28:52 -- STEP: 14/406 -- GLOBAL_STEP: 21525\u001b[0m\n",
      "     | > loss: 0.0761970579624176  (0.07189865303891045)\n",
      "     | > log_mle: -0.17486989498138428  (-0.16478633880615234)\n",
      "     | > loss_dur: 0.2510669529438019  (0.2366849918450628)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(23.9433, device='cuda:0')  (tensor(7.9337, device='cuda:0'))\n",
      "     | > current_lr: 9.250000000000001e-06 \n",
      "     | > step_time: 0.7994  (0.4301129068647112)\n",
      "     | > loader_time: 0.005  (0.00891869408743722)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 05:29:07 -- STEP: 39/406 -- GLOBAL_STEP: 21550\u001b[0m\n",
      "     | > loss: 0.10094892978668213  (0.07792134735828792)\n",
      "     | > log_mle: -0.15981900691986084  (-0.16339690563006282)\n",
      "     | > loss_dur: 0.26076793670654297  (0.2413182529883507)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(4.6120, device='cuda:0')  (tensor(6.9561, device='cuda:0'))\n",
      "     | > current_lr: 9.250000000000001e-06 \n",
      "     | > step_time: 0.4142  (0.5307034834837303)\n",
      "     | > loader_time: 0.0079  (0.009499299220549755)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 05:29:23 -- STEP: 64/406 -- GLOBAL_STEP: 21575\u001b[0m\n",
      "     | > loss: 0.06511799991130829  (0.07843549130484463)\n",
      "     | > log_mle: -0.17550349235534668  (-0.16549518890678883)\n",
      "     | > loss_dur: 0.24062149226665497  (0.24393068021163344)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(8.8697, device='cuda:0')  (tensor(6.9646, device='cuda:0'))\n",
      "     | > current_lr: 9.250000000000001e-06 \n",
      "     | > step_time: 0.7617  (0.5758977122604847)\n",
      "     | > loader_time: 0.006  (0.009716901928186417)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 05:29:40 -- STEP: 89/406 -- GLOBAL_STEP: 21600\u001b[0m\n",
      "     | > loss: 0.07576927542686462  (0.07796159118748781)\n",
      "     | > log_mle: -0.17321109771728516  (-0.16841329885332773)\n",
      "     | > loss_dur: 0.24898037314414978  (0.24637489004081556)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(13.9487, device='cuda:0')  (tensor(7.6283, device='cuda:0'))\n",
      "     | > current_lr: 9.250000000000001e-06 \n",
      "     | > step_time: 0.7122  (0.5909749631131631)\n",
      "     | > loader_time: 0.0284  (0.009938781181078282)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 05:29:57 -- STEP: 114/406 -- GLOBAL_STEP: 21625\u001b[0m\n",
      "     | > loss: 0.05767035484313965  (0.07632820661130704)\n",
      "     | > log_mle: -0.20626747608184814  (-0.1716717847606592)\n",
      "     | > loss_dur: 0.2639378309249878  (0.24799999137196624)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(17.2781, device='cuda:0')  (tensor(9.0279, device='cuda:0'))\n",
      "     | > current_lr: 9.250000000000001e-06 \n",
      "     | > step_time: 0.8317  (0.6068894256625255)\n",
      "     | > loader_time: 0.0247  (0.010587294896443689)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 05:30:15 -- STEP: 139/406 -- GLOBAL_STEP: 21650\u001b[0m\n",
      "     | > loss: 0.0872446596622467  (0.07622094313017756)\n",
      "     | > log_mle: -0.1815727949142456  (-0.1737890629459628)\n",
      "     | > loss_dur: 0.2688174545764923  (0.2500100060761404)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(12.6550, device='cuda:0')  (tensor(9.8211, device='cuda:0'))\n",
      "     | > current_lr: 9.250000000000001e-06 \n",
      "     | > step_time: 0.8214  (0.6246961895510443)\n",
      "     | > loader_time: 0.0054  (0.011074831159852395)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 05:30:33 -- STEP: 164/406 -- GLOBAL_STEP: 21675\u001b[0m\n",
      "     | > loss: 0.0788818895816803  (0.07616567566263964)\n",
      "     | > log_mle: -0.17440807819366455  (-0.17548069139806238)\n",
      "     | > loss_dur: 0.25328996777534485  (0.25164636706070204)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(12.7766, device='cuda:0')  (tensor(10.4119, device='cuda:0'))\n",
      "     | > current_lr: 9.250000000000001e-06 \n",
      "     | > step_time: 0.7675  (0.6376199315233924)\n",
      "     | > loader_time: 0.0332  (0.01192956581348327)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 05:30:51 -- STEP: 189/406 -- GLOBAL_STEP: 21700\u001b[0m\n",
      "     | > loss: 0.06565171480178833  (0.07552997184493551)\n",
      "     | > log_mle: -0.1905425786972046  (-0.17717562024555508)\n",
      "     | > loss_dur: 0.2561942934989929  (0.2527055920904904)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(14.0906, device='cuda:0')  (tensor(10.8932, device='cuda:0'))\n",
      "     | > current_lr: 9.250000000000001e-06 \n",
      "     | > step_time: 0.6256  (0.6430008436636948)\n",
      "     | > loader_time: 0.0071  (0.012860754810313076)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 05:31:11 -- STEP: 214/406 -- GLOBAL_STEP: 21725\u001b[0m\n",
      "     | > loss: 0.07390037178993225  (0.07487055714999401)\n",
      "     | > log_mle: -0.19389641284942627  (-0.1785538575359594)\n",
      "     | > loss_dur: 0.2677967846393585  (0.2534244146859532)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(14.0822, device='cuda:0')  (tensor(11.3575, device='cuda:0'))\n",
      "     | > current_lr: 9.250000000000001e-06 \n",
      "     | > step_time: 0.9479  (0.6583152329810312)\n",
      "     | > loader_time: 0.0133  (0.013337440579851104)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 05:31:30 -- STEP: 239/406 -- GLOBAL_STEP: 21750\u001b[0m\n",
      "     | > loss: 0.07830646634101868  (0.07474803656464338)\n",
      "     | > log_mle: -0.18862950801849365  (-0.179967606416806)\n",
      "     | > loss_dur: 0.26693597435951233  (0.25471564298144905)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(6.4701, device='cuda:0')  (tensor(11.8531, device='cuda:0'))\n",
      "     | > current_lr: 9.250000000000001e-06 \n",
      "     | > step_time: 0.7309  (0.6656717665524662)\n",
      "     | > loader_time: 0.0089  (0.013914943240177688)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 05:31:51 -- STEP: 264/406 -- GLOBAL_STEP: 21775\u001b[0m\n",
      "     | > loss: 0.07668781280517578  (0.07421310279857025)\n",
      "     | > log_mle: -0.18643569946289062  (-0.18116521790172113)\n",
      "     | > loss_dur: 0.2631235122680664  (0.2553783207002912)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(9.2598, device='cuda:0')  (tensor(12.1055, device='cuda:0'))\n",
      "     | > current_lr: 9.250000000000001e-06 \n",
      "     | > step_time: 1.0982  (0.6817459247329019)\n",
      "     | > loader_time: 0.0163  (0.013998362151059242)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 05:32:11 -- STEP: 289/406 -- GLOBAL_STEP: 21800\u001b[0m\n",
      "     | > loss: 0.0695061981678009  (0.07364972209022942)\n",
      "     | > log_mle: -0.18140733242034912  (-0.18220248230600847)\n",
      "     | > loss_dur: 0.25091353058815  (0.25585220439623774)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(12.3791, device='cuda:0')  (tensor(12.3495, device='cuda:0'))\n",
      "     | > current_lr: 9.250000000000001e-06 \n",
      "     | > step_time: 0.9056  (0.691599647066585)\n",
      "     | > loader_time: 0.027  (0.014168536374313203)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 05:32:33 -- STEP: 314/406 -- GLOBAL_STEP: 21825\u001b[0m\n",
      "     | > loss: 0.05516114830970764  (0.07338157557188324)\n",
      "     | > log_mle: -0.20056474208831787  (-0.18313941720184992)\n",
      "     | > loss_dur: 0.2557258903980255  (0.256520992773733)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(13.6048, device='cuda:0')  (tensor(12.6908, device='cuda:0'))\n",
      "     | > current_lr: 9.250000000000001e-06 \n",
      "     | > step_time: 0.8151  (0.7032878672241406)\n",
      "     | > loader_time: 0.0333  (0.01422667199638999)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 05:32:56 -- STEP: 339/406 -- GLOBAL_STEP: 21850\u001b[0m\n",
      "     | > loss: 0.0677986741065979  (0.073398450790605)\n",
      "     | > log_mle: -0.1969904899597168  (-0.18385486968499)\n",
      "     | > loss_dur: 0.2647891640663147  (0.2572533204755949)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(18.5184, device='cuda:0')  (tensor(12.8636, device='cuda:0'))\n",
      "     | > current_lr: 9.250000000000001e-06 \n",
      "     | > step_time: 0.9705  (0.7159427942427916)\n",
      "     | > loader_time: 0.0082  (0.01465404631465586)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 05:33:19 -- STEP: 364/406 -- GLOBAL_STEP: 21875\u001b[0m\n",
      "     | > loss: 0.06719714403152466  (0.07319978636863464)\n",
      "     | > log_mle: -0.19290971755981445  (-0.1847554199643186)\n",
      "     | > loss_dur: 0.2601068615913391  (0.2579552063329532)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(5.8157, device='cuda:0')  (tensor(12.9664, device='cuda:0'))\n",
      "     | > current_lr: 9.250000000000001e-06 \n",
      "     | > step_time: 0.8916  (0.7280160057675711)\n",
      "     | > loader_time: 0.0081  (0.014972155565743923)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 05:33:41 -- STEP: 389/406 -- GLOBAL_STEP: 21900\u001b[0m\n",
      "     | > loss: 0.07241332530975342  (0.07297614733939917)\n",
      "     | > log_mle: -0.19521081447601318  (-0.18554217312820145)\n",
      "     | > loss_dur: 0.2676241397857666  (0.25851832046760065)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(22.0149, device='cuda:0')  (tensor(13.0415, device='cuda:0'))\n",
      "     | > current_lr: 9.250000000000001e-06 \n",
      "     | > step_time: 1.101  (0.7373490112912688)\n",
      "     | > loader_time: 0.0082  (0.015184032273476417)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: 0.06744551658630371  (0.06744551658630371)\n",
      "     | > log_mle: -0.17087936401367188  (-0.17087936401367188)\n",
      "     | > loss_dur: 0.23832488059997559  (0.23832488059997559)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: 0.0002978295087814331  (0.0002978295087814331)\n",
      "     | > log_mle: -0.20660638809204102  (-0.20660638809204102)\n",
      "     | > loss_dur: 0.20690421760082245  (0.20690421760082245)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: 0.0363495796918869  (0.018323704600334167)\n",
      "     | > log_mle: -0.16673123836517334  (-0.18666881322860718)\n",
      "     | > loss_dur: 0.20308081805706024  (0.20499251782894135)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: 0.04466576874256134  (0.027104392647743225)\n",
      "     | > log_mle: -0.1823124885559082  (-0.18521670500437418)\n",
      "     | > loss_dur: 0.22697825729846954  (0.2123210976521174)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: 0.03996759653091431  (0.030320193618535995)\n",
      "     | > log_mle: -0.20836377143859863  (-0.1910034716129303)\n",
      "     | > loss_dur: 0.24833136796951294  (0.2213236652314663)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: 0.03327202796936035  (0.030910560488700868)\n",
      "     | > log_mle: -0.2076171636581421  (-0.19432621002197265)\n",
      "     | > loss_dur: 0.24088919162750244  (0.22523677051067353)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: 0.07818055152893066  (0.038788892328739166)\n",
      "     | > log_mle: -0.2188863754272461  (-0.19841957092285156)\n",
      "     | > loss_dur: 0.29706692695617676  (0.23720846325159073)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: 0.03718014061450958  (0.0385590706552778)\n",
      "     | > log_mle: -0.18487751483917236  (-0.19648499148232595)\n",
      "     | > loss_dur: 0.22205765545368195  (0.23504406213760376)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: 0.03199176490306854  (0.03773815743625164)\n",
      "     | > log_mle: -0.1905728578567505  (-0.19574597477912903)\n",
      "     | > loss_dur: 0.22256462275981903  (0.23348413221538067)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: 0.06271561980247498  (0.04051343103249868)\n",
      "     | > log_mle: -0.2020353078842163  (-0.19644478956858316)\n",
      "     | > loss_dur: 0.2647509276866913  (0.23695822060108185)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: 0.057534411549568176  (0.04221552908420563)\n",
      "     | > log_mle: -0.18997621536254883  (-0.19579793214797975)\n",
      "     | > loss_dur: 0.247510626912117  (0.23801346123218536)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: 0.04605349898338318  (0.042564435438676315)\n",
      "     | > log_mle: -0.20543646812438965  (-0.19667416269128973)\n",
      "     | > loss_dur: 0.2514899671077728  (0.23923859812996603)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: 0.025224953889846802  (0.04111947864294052)\n",
      "     | > log_mle: -0.1932063102722168  (-0.19638517498970032)\n",
      "     | > loss_dur: 0.2184312641620636  (0.23750465363264084)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: 0.0018915683031082153  (0.038101947078338035)\n",
      "     | > log_mle: -0.21314382553100586  (-0.19767430195441613)\n",
      "     | > loss_dur: 0.21503539383411407  (0.23577624903275415)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: 0.04717382788658142  (0.03874993856464114)\n",
      "     | > log_mle: -0.20513439178466797  (-0.19820716551371984)\n",
      "     | > loss_dur: 0.2523082196712494  (0.23695710407836096)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: 0.03418205678462982  (0.03844541311264038)\n",
      "     | > log_mle: -0.19923710823059082  (-0.19827582836151122)\n",
      "     | > loss_dur: 0.23341916501522064  (0.2367212414741516)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: 0.05937182903289795  (0.03975331410765648)\n",
      "     | > log_mle: -0.19604885578155518  (-0.19813664257526398)\n",
      "     | > loss_dur: 0.2554206848144531  (0.23788995668292046)\n",
      "\n",
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[91m 0.004697695374488831 \u001b[0m(+0.00018484890460968018)\n",
      "     | > avg_loss:\u001b[92m 0.03975331410765648 \u001b[0m(-0.011153552681207657)\n",
      "     | > avg_log_mle:\u001b[92m -0.19813664257526398 \u001b[0m(-0.005890607833862305)\n",
      "     | > avg_loss_dur:\u001b[92m 0.23788995668292046 \u001b[0m(-0.005262944847345352)\n",
      "\n",
      " > BEST MODEL : train/run-February-22-2025_02+19AM-9b6e3e6/best_model_21917.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 38/40\u001b[0m\n",
      " --> train/run-February-22-2025_02+19AM-9b6e3e6\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-22 05:34:08) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 05:34:13 -- STEP: 8/406 -- GLOBAL_STEP: 21925\u001b[0m\n",
      "     | > loss: 0.03466592729091644  (0.058740267530083656)\n",
      "     | > log_mle: -0.17376482486724854  (-0.1651337891817093)\n",
      "     | > loss_dur: 0.20843075215816498  (0.22387405671179295)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(5.1548, device='cuda:0')  (tensor(5.4663, device='cuda:0'))\n",
      "     | > current_lr: 9.499999999999999e-06 \n",
      "     | > step_time: 0.3802  (0.3918904662132263)\n",
      "     | > loader_time: 0.0041  (0.008581161499023438)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 05:34:29 -- STEP: 33/406 -- GLOBAL_STEP: 21950\u001b[0m\n",
      "     | > loss: 0.09151288866996765  (0.0669735367550994)\n",
      "     | > log_mle: -0.16313660144805908  (-0.16710442485231342)\n",
      "     | > loss_dur: 0.25464949011802673  (0.23407796160741287)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(11.8854, device='cuda:0')  (tensor(7.0001, device='cuda:0'))\n",
      "     | > current_lr: 9.499999999999999e-06 \n",
      "     | > step_time: 0.5367  (0.5416622017369124)\n",
      "     | > loader_time: 0.0295  (0.012253450624870531)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 05:34:45 -- STEP: 58/406 -- GLOBAL_STEP: 21975\u001b[0m\n",
      "     | > loss: 0.07957327365875244  (0.07037759469500901)\n",
      "     | > log_mle: -0.17559528350830078  (-0.1688933701350771)\n",
      "     | > loss_dur: 0.2551685571670532  (0.23927096483008614)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(14.7056, device='cuda:0')  (tensor(9.4135, device='cuda:0'))\n",
      "     | > current_lr: 9.499999999999999e-06 \n",
      "     | > step_time: 0.4698  (0.5902393234187159)\n",
      "     | > loader_time: 0.02  (0.012288089456229374)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 05:35:02 -- STEP: 83/406 -- GLOBAL_STEP: 22000\u001b[0m\n",
      "     | > loss: 0.06255875527858734  (0.0691588793892458)\n",
      "     | > log_mle: -0.18468940258026123  (-0.17176788542644086)\n",
      "     | > loss_dur: 0.24724815785884857  (0.2409267648156867)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(10.2576, device='cuda:0')  (tensor(11.3493, device='cuda:0'))\n",
      "     | > current_lr: 9.499999999999999e-06 \n",
      "     | > step_time: 0.6884  (0.6053462287029588)\n",
      "     | > loader_time: 0.0061  (0.012328779841043863)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 05:35:20 -- STEP: 108/406 -- GLOBAL_STEP: 22025\u001b[0m\n",
      "     | > loss: 0.07091084122657776  (0.06796566479735902)\n",
      "     | > log_mle: -0.17893767356872559  (-0.17460188821510036)\n",
      "     | > loss_dur: 0.24984851479530334  (0.24256755301245936)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(11.4088, device='cuda:0')  (tensor(12.4910, device='cuda:0'))\n",
      "     | > current_lr: 9.499999999999999e-06 \n",
      "     | > step_time: 0.425  (0.6241093322082802)\n",
      "     | > loader_time: 0.0109  (0.012202752961052788)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 05:35:37 -- STEP: 133/406 -- GLOBAL_STEP: 22050\u001b[0m\n",
      "     | > loss: 0.05870997905731201  (0.06727163370390583)\n",
      "     | > log_mle: -0.1915278434753418  (-0.1773648279950135)\n",
      "     | > loss_dur: 0.2502378225326538  (0.2446364616989193)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(12.1820, device='cuda:0')  (tensor(12.1940, device='cuda:0'))\n",
      "     | > current_lr: 9.499999999999999e-06 \n",
      "     | > step_time: 0.8223  (0.6334778760608873)\n",
      "     | > loader_time: 0.0067  (0.01220731806934328)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 05:35:55 -- STEP: 158/406 -- GLOBAL_STEP: 22075\u001b[0m\n",
      "     | > loss: 0.06503823399543762  (0.06807408312076255)\n",
      "     | > log_mle: -0.19559478759765625  (-0.17898248569874825)\n",
      "     | > loss_dur: 0.26063302159309387  (0.2470565688195108)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(17.5449, device='cuda:0')  (tensor(12.0183, device='cuda:0'))\n",
      "     | > current_lr: 9.499999999999999e-06 \n",
      "     | > step_time: 0.8041  (0.6440006162546859)\n",
      "     | > loader_time: 0.0051  (0.0125328739987144)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 05:36:14 -- STEP: 183/406 -- GLOBAL_STEP: 22100\u001b[0m\n",
      "     | > loss: 0.04919925332069397  (0.06771074015586101)\n",
      "     | > log_mle: -0.1951899528503418  (-0.18054375427016803)\n",
      "     | > loss_dur: 0.24438920617103577  (0.24825449442602898)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(16.9738, device='cuda:0')  (tensor(12.3565, device='cuda:0'))\n",
      "     | > current_lr: 9.499999999999999e-06 \n",
      "     | > step_time: 0.4891  (0.6558809853642366)\n",
      "     | > loader_time: 0.0048  (0.013276739850070307)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 05:36:34 -- STEP: 208/406 -- GLOBAL_STEP: 22125\u001b[0m\n",
      "     | > loss: 0.05000399053096771  (0.06754551441050491)\n",
      "     | > log_mle: -0.19856500625610352  (-0.1819775969936298)\n",
      "     | > loss_dur: 0.24856899678707123  (0.2495231114041347)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(17.6943, device='cuda:0')  (tensor(12.6824, device='cuda:0'))\n",
      "     | > current_lr: 9.499999999999999e-06 \n",
      "     | > step_time: 0.9353  (0.6696352924291907)\n",
      "     | > loader_time: 0.0058  (0.013607460718888503)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 05:36:54 -- STEP: 233/406 -- GLOBAL_STEP: 22150\u001b[0m\n",
      "     | > loss: 0.07655134797096252  (0.06714819435653768)\n",
      "     | > log_mle: -0.19824016094207764  (-0.18348801391830777)\n",
      "     | > loss_dur: 0.27479150891304016  (0.2506362082748454)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(13.0014, device='cuda:0')  (tensor(12.9559, device='cuda:0'))\n",
      "     | > current_lr: 9.499999999999999e-06 \n",
      "     | > step_time: 0.8769  (0.6816545893705968)\n",
      "     | > loader_time: 0.0073  (0.013930878414104937)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 05:37:14 -- STEP: 258/406 -- GLOBAL_STEP: 22175\u001b[0m\n",
      "     | > loss: 0.08089575171470642  (0.066810846675274)\n",
      "     | > log_mle: -0.18341052532196045  (-0.18470885448677601)\n",
      "     | > loss_dur: 0.26430627703666687  (0.2515197011620498)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(17.1194, device='cuda:0')  (tensor(13.0058, device='cuda:0'))\n",
      "     | > current_lr: 9.499999999999999e-06 \n",
      "     | > step_time: 1.2102  (0.6920024248980738)\n",
      "     | > loader_time: 0.0296  (0.013914168343063473)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 05:37:34 -- STEP: 283/406 -- GLOBAL_STEP: 22200\u001b[0m\n",
      "     | > loss: 0.06512045860290527  (0.06602505070581874)\n",
      "     | > log_mle: -0.19658100605010986  (-0.18587092544501757)\n",
      "     | > loss_dur: 0.26170146465301514  (0.2518959761508361)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(23.2536, device='cuda:0')  (tensor(13.1831, device='cuda:0'))\n",
      "     | > current_lr: 9.499999999999999e-06 \n",
      "     | > step_time: 0.9071  (0.6989517692121097)\n",
      "     | > loader_time: 0.042  (0.013998411569494239)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 05:37:55 -- STEP: 308/406 -- GLOBAL_STEP: 22225\u001b[0m\n",
      "     | > loss: 0.05527234077453613  (0.06578880432364224)\n",
      "     | > log_mle: -0.19945871829986572  (-0.18677942977323164)\n",
      "     | > loss_dur: 0.25473105907440186  (0.2525682340968738)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(21.6398, device='cuda:0')  (tensor(13.9285, device='cuda:0'))\n",
      "     | > current_lr: 9.499999999999999e-06 \n",
      "     | > step_time: 1.1134  (0.709504773090412)\n",
      "     | > loader_time: 0.0112  (0.013990896088736394)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 05:38:15 -- STEP: 333/406 -- GLOBAL_STEP: 22250\u001b[0m\n",
      "     | > loss: 0.052230387926101685  (0.06552909976906239)\n",
      "     | > log_mle: -0.20712733268737793  (-0.18758224009035585)\n",
      "     | > loss_dur: 0.2593577206134796  (0.2531113398594182)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(29.9376, device='cuda:0')  (tensor(14.5333, device='cuda:0'))\n",
      "     | > current_lr: 9.499999999999999e-06 \n",
      "     | > step_time: 0.8096  (0.7157604085790502)\n",
      "     | > loader_time: 0.0289  (0.014147474243118238)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 05:38:38 -- STEP: 358/406 -- GLOBAL_STEP: 22275\u001b[0m\n",
      "     | > loss: 0.03757169842720032  (0.06534889057361874)\n",
      "     | > log_mle: -0.21562373638153076  (-0.1885435184952933)\n",
      "     | > loss_dur: 0.2531954348087311  (0.25389240906891203)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(4.4888, device='cuda:0')  (tensor(14.7758, device='cuda:0'))\n",
      "     | > current_lr: 9.499999999999999e-06 \n",
      "     | > step_time: 0.8627  (0.728610955803088)\n",
      "     | > loader_time: 0.007  (0.014216467654904837)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 05:39:02 -- STEP: 383/406 -- GLOBAL_STEP: 22300\u001b[0m\n",
      "     | > loss: 0.056851983070373535  (0.065081683602719)\n",
      "     | > log_mle: -0.19399011135101318  (-0.1893045958277451)\n",
      "     | > loss_dur: 0.2508420944213867  (0.2543862794304641)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(8.1791, device='cuda:0')  (tensor(15.0590, device='cuda:0'))\n",
      "     | > current_lr: 9.499999999999999e-06 \n",
      "     | > step_time: 1.1712  (0.7402001136899306)\n",
      "     | > loader_time: 0.0163  (0.014302493386729266)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: 0.06420698761940002  (0.06420698761940002)\n",
      "     | > log_mle: -0.1737067699432373  (-0.1737067699432373)\n",
      "     | > loss_dur: 0.23791375756263733  (0.23791375756263733)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: -0.00041340291500091553  (-0.00041340291500091553)\n",
      "     | > log_mle: -0.20699524879455566  (-0.20699524879455566)\n",
      "     | > loss_dur: 0.20658184587955475  (0.20658184587955475)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: 0.02987232804298401  (0.014729462563991547)\n",
      "     | > log_mle: -0.16843926906585693  (-0.1877172589302063)\n",
      "     | > loss_dur: 0.19831159710884094  (0.20244672149419785)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: 0.03998267650604248  (0.02314720054467519)\n",
      "     | > log_mle: -0.18058335781097412  (-0.18533929189046225)\n",
      "     | > loss_dur: 0.2205660343170166  (0.20848649243513742)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: 0.0399899035692215  (0.027357876300811768)\n",
      "     | > log_mle: -0.20607435703277588  (-0.19052305817604065)\n",
      "     | > loss_dur: 0.24606426060199738  (0.21788093447685242)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: 0.04312629997730255  (0.030511561036109924)\n",
      "     | > log_mle: -0.19591736793518066  (-0.19160192012786864)\n",
      "     | > loss_dur: 0.23904366791248322  (0.22211348116397858)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: 0.07592809200286865  (0.038080982863903046)\n",
      "     | > log_mle: -0.20746839046478271  (-0.19424633185068765)\n",
      "     | > loss_dur: 0.28339648246765137  (0.2323273147145907)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: 0.03657682240009308  (0.03786610279764448)\n",
      "     | > log_mle: -0.1811542510986328  (-0.19237603460039412)\n",
      "     | > loss_dur: 0.2177310734987259  (0.2302421373980386)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: 0.0323442667722702  (0.037175873294472694)\n",
      "     | > log_mle: -0.1898822784423828  (-0.1920643150806427)\n",
      "     | > loss_dur: 0.22222654521465302  (0.2292401883751154)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: 0.06568780541419983  (0.040343865752220154)\n",
      "     | > log_mle: -0.19630086421966553  (-0.19253504276275635)\n",
      "     | > loss_dur: 0.26198866963386536  (0.2328789085149765)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: 0.06243319809436798  (0.042552798986434937)\n",
      "     | > log_mle: -0.1868504285812378  (-0.19196658134460448)\n",
      "     | > loss_dur: 0.24928362667560577  (0.23451938033103942)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: 0.04892778396606445  (0.043132343075492165)\n",
      "     | > log_mle: -0.20148324966430664  (-0.19283173301003195)\n",
      "     | > loss_dur: 0.2504110336303711  (0.23596407608552414)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: 0.022247135639190674  (0.04139190912246704)\n",
      "     | > log_mle: -0.19211101531982422  (-0.19277167320251465)\n",
      "     | > loss_dur: 0.2143581509590149  (0.2341635823249817)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: 0.0023386776447296143  (0.03838781439341032)\n",
      "     | > log_mle: -0.20554721355438232  (-0.19375440707573524)\n",
      "     | > loss_dur: 0.20788589119911194  (0.23214222146914557)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: 0.04947882890701294  (0.039180029715810506)\n",
      "     | > log_mle: -0.20149016380310059  (-0.19430696112768991)\n",
      "     | > loss_dur: 0.2509689927101135  (0.2334869908435004)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: 0.0342843234539032  (0.038853649298350015)\n",
      "     | > log_mle: -0.1961132287979126  (-0.19442737897237142)\n",
      "     | > loss_dur: 0.2303975522518158  (0.23328102827072145)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: 0.059838324785232544  (0.040165191516280174)\n",
      "     | > log_mle: -0.19062960147857666  (-0.19419001787900925)\n",
      "     | > loss_dur: 0.2504679262638092  (0.23435520939528942)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: audio amplitude out of range, auto clipped.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[91m 0.005947694182395935 \u001b[0m(+0.0012499988079071045)\n",
      "     | > avg_loss:\u001b[91m 0.040165191516280174 \u001b[0m(+0.0004118774086236954)\n",
      "     | > avg_log_mle:\u001b[91m -0.19419001787900925 \u001b[0m(+0.00394662469625473)\n",
      "     | > avg_loss_dur:\u001b[92m 0.23435520939528942 \u001b[0m(-0.003534747287631035)\n",
      "\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 39/40\u001b[0m\n",
      " --> train/run-February-22-2025_02+19AM-9b6e3e6\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-22 05:39:33) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 05:39:36 -- STEP: 2/406 -- GLOBAL_STEP: 22325\u001b[0m\n",
      "     | > loss: 0.03577302396297455  (0.044322676956653595)\n",
      "     | > log_mle: -0.18397462368011475  (-0.1769341230392456)\n",
      "     | > loss_dur: 0.2197476476430893  (0.2212567999958992)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(6.5903, device='cuda:0')  (tensor(5.0262, device='cuda:0'))\n",
      "     | > current_lr: 9.75e-06 \n",
      "     | > step_time: 0.3241  (0.527601957321167)\n",
      "     | > loader_time: 0.004  (0.025082826614379883)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 05:39:49 -- STEP: 27/406 -- GLOBAL_STEP: 22350\u001b[0m\n",
      "     | > loss: 0.050812721252441406  (0.055954301798785175)\n",
      "     | > log_mle: -0.16886913776397705  (-0.17172213395436606)\n",
      "     | > loss_dur: 0.21968185901641846  (0.22767643575315122)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(2.6884, device='cuda:0')  (tensor(6.2142, device='cuda:0'))\n",
      "     | > current_lr: 9.75e-06 \n",
      "     | > step_time: 0.5042  (0.49050046779491285)\n",
      "     | > loader_time: 0.0044  (0.009648305398446543)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 05:40:05 -- STEP: 52/406 -- GLOBAL_STEP: 22375\u001b[0m\n",
      "     | > loss: 0.09173479676246643  (0.06214483454823494)\n",
      "     | > log_mle: -0.17366814613342285  (-0.17285581735464242)\n",
      "     | > loss_dur: 0.2654029428958893  (0.23500065190287736)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(10.3145, device='cuda:0')  (tensor(6.1935, device='cuda:0'))\n",
      "     | > current_lr: 9.75e-06 \n",
      "     | > step_time: 0.5597  (0.567129020507519)\n",
      "     | > loader_time: 0.0079  (0.011230207406557523)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 05:40:23 -- STEP: 77/406 -- GLOBAL_STEP: 22400\u001b[0m\n",
      "     | > loss: 0.07992935180664062  (0.06160524100452274)\n",
      "     | > log_mle: -0.1735820770263672  (-0.17550625429525005)\n",
      "     | > loss_dur: 0.2535114288330078  (0.2371114952997728)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(6.7545, device='cuda:0')  (tensor(7.4444, device='cuda:0'))\n",
      "     | > current_lr: 9.75e-06 \n",
      "     | > step_time: 0.6407  (0.6056092962042078)\n",
      "     | > loader_time: 0.0053  (0.012038113234879131)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 05:40:40 -- STEP: 102/406 -- GLOBAL_STEP: 22425\u001b[0m\n",
      "     | > loss: 0.03137513995170593  (0.060816106696923576)\n",
      "     | > log_mle: -0.19780278205871582  (-0.17845745647654815)\n",
      "     | > loss_dur: 0.22917792201042175  (0.2392735631734717)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(23.3180, device='cuda:0')  (tensor(8.7339, device='cuda:0'))\n",
      "     | > current_lr: 9.75e-06 \n",
      "     | > step_time: 0.5372  (0.6150572136336685)\n",
      "     | > loader_time: 0.0058  (0.012638250986735022)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 05:40:57 -- STEP: 127/406 -- GLOBAL_STEP: 22450\u001b[0m\n",
      "     | > loss: 0.059554070234298706  (0.059955188843208974)\n",
      "     | > log_mle: -0.19350159168243408  (-0.18110257903421959)\n",
      "     | > loss_dur: 0.2530556619167328  (0.24105776787742855)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(15.4035, device='cuda:0')  (tensor(9.6791, device='cuda:0'))\n",
      "     | > current_lr: 9.75e-06 \n",
      "     | > step_time: 0.6998  (0.625862857488197)\n",
      "     | > loader_time: 0.0397  (0.012468948138980411)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 05:41:16 -- STEP: 152/406 -- GLOBAL_STEP: 22475\u001b[0m\n",
      "     | > loss: 0.07248392701148987  (0.059774056175037435)\n",
      "     | > log_mle: -0.19161856174468994  (-0.18315584330182327)\n",
      "     | > loss_dur: 0.2641024887561798  (0.2429298994768607)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(10.3149, device='cuda:0')  (tensor(10.2985, device='cuda:0'))\n",
      "     | > current_lr: 9.75e-06 \n",
      "     | > step_time: 0.7726  (0.6441737146754015)\n",
      "     | > loader_time: 0.0062  (0.012939506455471636)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 05:41:34 -- STEP: 177/406 -- GLOBAL_STEP: 22500\u001b[0m\n",
      "     | > loss: 0.05699089169502258  (0.059181905483121924)\n",
      "     | > log_mle: -0.1972740888595581  (-0.18476596188410518)\n",
      "     | > loss_dur: 0.2542649805545807  (0.2439478673672272)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(14.1711, device='cuda:0')  (tensor(10.8639, device='cuda:0'))\n",
      "     | > current_lr: 9.75e-06 \n",
      "     | > step_time: 0.7439  (0.6539126600922839)\n",
      "     | > loader_time: 0.005  (0.013472695808626159)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 05:41:52 -- STEP: 202/406 -- GLOBAL_STEP: 22525\u001b[0m\n",
      "     | > loss: 0.0699722170829773  (0.05883750267843209)\n",
      "     | > log_mle: -0.1867215633392334  (-0.18628795253168232)\n",
      "     | > loss_dur: 0.2566937804222107  (0.24512545521011447)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(13.6470, device='cuda:0')  (tensor(11.2581, device='cuda:0'))\n",
      "     | > current_lr: 9.75e-06 \n",
      "     | > step_time: 0.6128  (0.6592598858446177)\n",
      "     | > loader_time: 0.006  (0.013975901178794327)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 05:42:12 -- STEP: 227/406 -- GLOBAL_STEP: 22550\u001b[0m\n",
      "     | > loss: 0.06828168034553528  (0.058565474751237204)\n",
      "     | > log_mle: -0.19517886638641357  (-0.18781411437736203)\n",
      "     | > loss_dur: 0.26346054673194885  (0.24637958912859928)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(12.8139, device='cuda:0')  (tensor(11.6846, device='cuda:0'))\n",
      "     | > current_lr: 9.75e-06 \n",
      "     | > step_time: 1.1165  (0.6684456848362993)\n",
      "     | > loader_time: 0.0257  (0.014040837729029714)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 05:42:32 -- STEP: 252/406 -- GLOBAL_STEP: 22575\u001b[0m\n",
      "     | > loss: 0.05700847506523132  (0.05846872606447765)\n",
      "     | > log_mle: -0.19731593132019043  (-0.1890173937593187)\n",
      "     | > loss_dur: 0.25432440638542175  (0.2474861198237964)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(27.8832, device='cuda:0')  (tensor(12.8995, device='cuda:0'))\n",
      "     | > current_lr: 9.75e-06 \n",
      "     | > step_time: 0.9661  (0.6799277114489721)\n",
      "     | > loader_time: 0.0159  (0.014065337559533495)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 05:42:51 -- STEP: 277/406 -- GLOBAL_STEP: 22600\u001b[0m\n",
      "     | > loss: 0.045979976654052734  (0.0578881686667673)\n",
      "     | > log_mle: -0.19759249687194824  (-0.19010171864437278)\n",
      "     | > loss_dur: 0.24357247352600098  (0.24798988731114013)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(19.1758, device='cuda:0')  (tensor(13.2317, device='cuda:0'))\n",
      "     | > current_lr: 9.75e-06 \n",
      "     | > step_time: 0.9115  (0.6869729666933686)\n",
      "     | > loader_time: 0.0146  (0.014504282913483433)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 05:43:13 -- STEP: 302/406 -- GLOBAL_STEP: 22625\u001b[0m\n",
      "     | > loss: 0.058775097131729126  (0.057707323587888125)\n",
      "     | > log_mle: -0.20601582527160645  (-0.19100310944563498)\n",
      "     | > loss_dur: 0.26479092240333557  (0.2487104330335232)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(16.9697, device='cuda:0')  (tensor(13.4498, device='cuda:0'))\n",
      "     | > current_lr: 9.75e-06 \n",
      "     | > step_time: 0.7954  (0.6987098510691658)\n",
      "     | > loader_time: 0.012  (0.014655178745850818)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 05:43:34 -- STEP: 327/406 -- GLOBAL_STEP: 22650\u001b[0m\n",
      "     | > loss: 0.06162610650062561  (0.05730368069370223)\n",
      "     | > log_mle: -0.1985468864440918  (-0.19177347622151034)\n",
      "     | > loss_dur: 0.2601729929447174  (0.24907715691521262)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(6.0678, device='cuda:0')  (tensor(13.4927, device='cuda:0'))\n",
      "     | > current_lr: 9.75e-06 \n",
      "     | > step_time: 0.767  (0.7082820478200178)\n",
      "     | > loader_time: 0.0262  (0.014807747773803335)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 05:43:56 -- STEP: 352/406 -- GLOBAL_STEP: 22675\u001b[0m\n",
      "     | > loss: 0.053925275802612305  (0.05726048697463491)\n",
      "     | > log_mle: -0.19964933395385742  (-0.19263406267220315)\n",
      "     | > loss_dur: 0.2535746097564697  (0.24989454964683813)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(10.6985, device='cuda:0')  (tensor(13.2884, device='cuda:0'))\n",
      "     | > current_lr: 9.75e-06 \n",
      "     | > step_time: 1.1527  (0.7188022820786988)\n",
      "     | > loader_time: 0.01  (0.014946374026211823)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 05:44:18 -- STEP: 377/406 -- GLOBAL_STEP: 22700\u001b[0m\n",
      "     | > loss: 0.0672474205493927  (0.05701743726388845)\n",
      "     | > log_mle: -0.20254850387573242  (-0.19355936739741958)\n",
      "     | > loss_dur: 0.2697959244251251  (0.25057680466130816)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(23.4973, device='cuda:0')  (tensor(13.5374, device='cuda:0'))\n",
      "     | > current_lr: 9.75e-06 \n",
      "     | > step_time: 1.0076  (0.7295426696301763)\n",
      "     | > loader_time: 0.0277  (0.014978792686361214)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 05:44:38 -- STEP: 402/406 -- GLOBAL_STEP: 22725\u001b[0m\n",
      "     | > loss: 0.049361228942871094  (0.056896382785258603)\n",
      "     | > log_mle: -0.21205401420593262  (-0.19431000829336054)\n",
      "     | > loss_dur: 0.2614152431488037  (0.25120639107861914)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(18.0215, device='cuda:0')  (tensor(13.6812, device='cuda:0'))\n",
      "     | > current_lr: 9.75e-06 \n",
      "     | > step_time: 0.525  (0.7316495435154846)\n",
      "     | > loader_time: 0.0083  (0.014781917505596405)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: 0.057252079248428345  (0.057252079248428345)\n",
      "     | > log_mle: -0.17892169952392578  (-0.17892169952392578)\n",
      "     | > loss_dur: 0.23617377877235413  (0.23617377877235413)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: -0.018449291586875916  (-0.018449291586875916)\n",
      "     | > log_mle: -0.21538913249969482  (-0.21538913249969482)\n",
      "     | > loss_dur: 0.1969398409128189  (0.1969398409128189)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: 0.026969999074935913  (0.004260353744029999)\n",
      "     | > log_mle: -0.17502152919769287  (-0.19520533084869385)\n",
      "     | > loss_dur: 0.20199152827262878  (0.19946568459272385)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: 0.02920377254486084  (0.01257482667764028)\n",
      "     | > log_mle: -0.190252423286438  (-0.19355436166127524)\n",
      "     | > loss_dur: 0.21945619583129883  (0.2061291883389155)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: 0.03149294853210449  (0.017304357141256332)\n",
      "     | > log_mle: -0.2167595624923706  (-0.19935566186904907)\n",
      "     | > loss_dur: 0.2482525110244751  (0.2166600190103054)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: 0.01966319978237152  (0.01777612566947937)\n",
      "     | > log_mle: -0.21334588527679443  (-0.20215370655059814)\n",
      "     | > loss_dur: 0.23300908505916595  (0.2199298322200775)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: 0.05316275358200073  (0.02367389698823293)\n",
      "     | > log_mle: -0.22573280334472656  (-0.20608355601628622)\n",
      "     | > loss_dur: 0.2788955569267273  (0.22975745300451914)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: 0.023660898208618164  (0.023672040019716536)\n",
      "     | > log_mle: -0.19211792945861816  (-0.20408846650804793)\n",
      "     | > loss_dur: 0.21577882766723633  (0.22776050652776444)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: 0.022008970379829407  (0.023464156314730644)\n",
      "     | > log_mle: -0.19892454147338867  (-0.20344297587871552)\n",
      "     | > loss_dur: 0.22093351185321808  (0.22690713219344616)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: 0.056860893964767456  (0.027174904942512512)\n",
      "     | > log_mle: -0.21035873889923096  (-0.2042113939921061)\n",
      "     | > loss_dur: 0.2672196328639984  (0.23138629893461862)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: 0.04452723264694214  (0.028910137712955475)\n",
      "     | > log_mle: -0.19783437252044678  (-0.20357369184494017)\n",
      "     | > loss_dur: 0.24236160516738892  (0.23248382955789565)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: 0.03283742070198059  (0.029267163439230484)\n",
      "     | > log_mle: -0.21335959434509277  (-0.20446331934495407)\n",
      "     | > loss_dur: 0.24619701504707336  (0.23373048278418454)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: 0.005957171320915222  (0.027324664096037548)\n",
      "     | > log_mle: -0.20103752613067627  (-0.20417783657709757)\n",
      "     | > loss_dur: 0.2069946974515915  (0.23150250067313513)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: -0.011129394173622131  (0.024366659613756034)\n",
      "     | > log_mle: -0.22024643421173096  (-0.20541388254899245)\n",
      "     | > loss_dur: 0.20911704003810883  (0.22978054216274849)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: 0.031100183725357056  (0.024847625621727536)\n",
      "     | > log_mle: -0.21312987804412842  (-0.2059650250843593)\n",
      "     | > loss_dur: 0.24423006176948547  (0.23081265070608684)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: 0.01920020580291748  (0.0244711309671402)\n",
      "     | > log_mle: -0.20709228515625  (-0.20604017575581868)\n",
      "     | > loss_dur: 0.22629249095916748  (0.2305113067229589)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: 0.043975651264190674  (0.025690163485705853)\n",
      "     | > log_mle: -0.20412373542785645  (-0.20592039823532104)\n",
      "     | > loss_dur: 0.24809938669204712  (0.2316105617210269)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: audio amplitude out of range, auto clipped.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.004724264144897461 \u001b[0m(-0.0012234300374984741)\n",
      "     | > avg_loss:\u001b[92m 0.025690163485705853 \u001b[0m(-0.014475028030574322)\n",
      "     | > avg_log_mle:\u001b[92m -0.20592039823532104 \u001b[0m(-0.011730380356311798)\n",
      "     | > avg_loss_dur:\u001b[92m 0.2316105617210269 \u001b[0m(-0.0027446476742625237)\n",
      "\n",
      " > BEST MODEL : train/run-February-22-2025_02+19AM-9b6e3e6/best_model_22729.pth\n"
     ]
    }
   ],
   "source": [
    "trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
