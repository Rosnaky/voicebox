{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from trainer import Trainer, TrainerArgs\n",
    "\n",
    "from TTS.tts.configs.glow_tts_config import GlowTTSConfig\n",
    "\n",
    "from TTS.tts.configs.shared_configs import BaseDatasetConfig\n",
    "from TTS.tts.datasets import load_tts_samples\n",
    "from TTS.tts.models.glow_tts import GlowTTS\n",
    "from TTS.tts.utils.text.tokenizer import TTSTokenizer\n",
    "from TTS.utils.audio import AudioProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"train\"\n",
    "dataset_path = \"LJSpeech-1.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset_config = BaseDatasetConfig(\n",
    "    formatter=\"ljspeech\", meta_file_train=\"metadata.csv\", path=dataset_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = GlowTTSConfig(\n",
    "    batch_size=32,\n",
    "    eval_batch_size=8,\n",
    "    num_loader_workers=8,\n",
    "    num_eval_loader_workers=8,\n",
    "    run_eval=True,\n",
    "    test_delay_epochs=-1,\n",
    "    epochs=100,\n",
    "    text_cleaner=\"phoneme_cleaners\",\n",
    "    use_phonemes=True,\n",
    "    phoneme_language=\"en-us\",\n",
    "    phoneme_cache_path=os.path.join(output_path, \"phoneme_cache\"),\n",
    "    print_step=25,\n",
    "    print_eval=True,\n",
    "    mixed_precision=True,\n",
    "    output_path=output_path,\n",
    "    datasets=[dataset_config],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ap = AudioProcessor.init_from_config(config)\n",
    "\n",
    "tokenizer, config = TTSTokenizer.init_from_config(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples, eval_samples = load_tts_samples(\n",
    "    dataset_config,\n",
    "    eval_split=True,\n",
    "    eval_split_max_size=config.eval_split_max_size,\n",
    "    eval_split_size=config.eval_split_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GlowTTS(config, ap, tokenizer, speaker_manager=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " > Training Environment:\n",
      " | > Backend: Torch\n",
      " | > Mixed precision: True\n",
      " | > Precision: fp16\n",
      " | > Current device: 0\n",
      " | > Num. of GPUs: 1\n",
      " | > Num. of CPUs: 16\n",
      " | > Num. of Torch Threads: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " | > Torch seed: 54321\n",
      " | > Torch CUDNN: True\n",
      " | > Torch CUDNN deterministic: False\n",
      " | > Torch CUDNN benchmark: False\n",
      " | > Torch TF32 MatMul: False\n",
      " > Start Tensorboard: tensorboard --logdir=train/run-February-22-2025_01+01AM-9b6e3e6\n",
      "\n",
      " > Model has 28610449 parameters\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    TrainerArgs(), config, output_path, model=model, train_samples=train_samples, eval_samples=eval_samples\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 0/10\u001b[0m\n",
      " --> train/run-February-22-2025_01+01AM-9b6e3e6\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-22 01:01:20) \u001b[0m\n",
      "d͡ʒoʊsɪf di. nɪkɔl,\n",
      "Character '͡' not found in the vocabulary. Discarding it.\n",
      "ðə ɪŋkaʊntɚ ɪn ðə lʌnt͡ʃɹum.\n",
      "Character '͡' not found in the vocabulary. Discarding it.\n",
      "noʊ soʊld͡ʒɚz iðɚ.\n",
      "Character '͡' not found in the vocabulary. Discarding it.\n",
      "æftɚ fɚðɚ kwɛst͡ʃənɪŋ\n",
      "Character '͡' not found in the vocabulary. Discarding it.\n",
      "ðə soʊld͡ʒɚz ðɛn?\n",
      "Character '͡' not found in the vocabulary. Discarding it.\n",
      "ɪn kwɪɡliz d͡ʒʌd͡ʒmənt,\n",
      "Character '͡' not found in the vocabulary. Discarding it.\n",
      "ðə dʌt͡ʃəs əv kɛnt.\n",
      "Character '͡' not found in the vocabulary. Discarding it.\n",
      "hɚ kæptən wəz d͡ʒɑn smɪθ,\n",
      "Character '͡' not found in the vocabulary. Discarding it.\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:01:28 -- STEP: 0/811 -- GLOBAL_STEP: 0\u001b[0m\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 4.5945  (4.594481706619263)\n",
      "     | > loader_time: 3.4383  (3.438286781311035)\n",
      "\n",
      " [!] `train_step()` retuned `None` outputs. Skipping training step.\n",
      " [!] `train_step()` retuned `None` outputs. Skipping training step.\n",
      " [!] `train_step()` retuned `None` outputs. Skipping training step.\n",
      " [!] `train_step()` retuned `None` outputs. Skipping training step.\n",
      " [!] `train_step()` retuned `None` outputs. Skipping training step.\n",
      " [!] `train_step()` retuned `None` outputs. Skipping training step.\n",
      " [!] `train_step()` retuned `None` outputs. Skipping training step.\n",
      " [!] `train_step()` retuned `None` outputs. Skipping training step.\n",
      " [!] `train_step()` retuned `None` outputs. Skipping training step.\n",
      " [!] `train_step()` retuned `None` outputs. Skipping training step.\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:01:41 -- STEP: 25/811 -- GLOBAL_STEP: 25\u001b[0m\n",
      "     | > loss: 3.9555912017822266  (4.052179463704427)\n",
      "     | > log_mle: 0.8365178108215332  (0.8260264197985331)\n",
      "     | > loss_dur: 3.1190733909606934  (3.226153008143107)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(10.6877, device='cuda:0')  (tensor(10.1719, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.5192  (0.5051443481445312)\n",
      "     | > loader_time: 0.0046  (3.7345070838928227)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:01:58 -- STEP: 50/811 -- GLOBAL_STEP: 50\u001b[0m\n",
      "     | > loss: 4.125707149505615  (4.042190110683442)\n",
      "     | > log_mle: 0.8257442116737366  (0.8278882563114166)\n",
      "     | > loss_dur: 3.2999627590179443  (3.214301860332489)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(11.0949, device='cuda:0')  (tensor(10.6673, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.7999  (0.5933951807022094)\n",
      "     | > loader_time: 0.0058  (1.8701472473144536)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:02:17 -- STEP: 75/811 -- GLOBAL_STEP: 75\u001b[0m\n",
      "     | > loss: 4.013096332550049  (4.031085678247307)\n",
      "     | > log_mle: 0.8271570801734924  (0.8288087872358468)\n",
      "     | > loss_dur: 3.185939073562622  (3.202276879090529)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(10.7993, device='cuda:0')  (tensor(10.7664, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.5543  (0.6449004618326822)\n",
      "     | > loader_time: 0.0034  (1.24901268641154)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:02:37 -- STEP: 100/811 -- GLOBAL_STEP: 100\u001b[0m\n",
      "     | > loss: 4.053307056427002  (4.0222837050755835)\n",
      "     | > log_mle: 0.820000171661377  (0.8294922716087765)\n",
      "     | > loss_dur: 3.233306884765625  (3.1927914301554363)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(10.9502, device='cuda:0')  (tensor(10.8056, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 1.1664  (0.6803517603874208)\n",
      "     | > loader_time: 0.0176  (0.9383572316169745)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:02:59 -- STEP: 125/811 -- GLOBAL_STEP: 125\u001b[0m\n",
      "     | > loss: 3.907080888748169  (4.019252764660378)\n",
      "     | > log_mle: 0.8318209648132324  (0.8297700182251309)\n",
      "     | > loss_dur: 3.0752599239349365  (3.1894827407339346)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(10.7684, device='cuda:0')  (tensor(10.8389, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.4436  (0.7156081771850588)\n",
      "     | > loader_time: 0.0038  (0.7530546894073491)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:03:18 -- STEP: 150/811 -- GLOBAL_STEP: 150\u001b[0m\n",
      "     | > loss: 4.101287841796875  (4.015740624495914)\n",
      "     | > log_mle: 0.8339043259620667  (0.8300950178078241)\n",
      "     | > loss_dur: 3.267383337020874  (3.185645602430616)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(11.1057, device='cuda:0')  (tensor(10.8582, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.4914  (0.718474143346151)\n",
      "     | > loader_time: 0.0077  (0.6292549324035648)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:03:39 -- STEP: 175/811 -- GLOBAL_STEP: 175\u001b[0m\n",
      "     | > loss: 3.9633162021636963  (4.012083926345361)\n",
      "     | > log_mle: 0.8337584137916565  (0.8300689993482647)\n",
      "     | > loss_dur: 3.1295578479766846  (3.182014917604852)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(11.0064, device='cuda:0')  (tensor(10.8714, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 1.0995  (0.733154433114188)\n",
      "     | > loader_time: 0.0068  (0.540730314254761)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:04:00 -- STEP: 200/811 -- GLOBAL_STEP: 200\u001b[0m\n",
      "     | > loss: 3.896812677383423  (4.006369464020977)\n",
      "     | > log_mle: 0.8324115872383118  (0.830267996537058)\n",
      "     | > loss_dur: 3.064401149749756  (3.1761014612097496)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(10.6908, device='cuda:0')  (tensor(10.8752, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.5617  (0.7430115258693695)\n",
      "     | > loader_time: 0.0111  (0.4746846997737886)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:04:20 -- STEP: 225/811 -- GLOBAL_STEP: 225\u001b[0m\n",
      "     | > loss: 3.952315330505371  (4.000636084135185)\n",
      "     | > log_mle: 0.8304363489151001  (0.8302802302116572)\n",
      "     | > loss_dur: 3.1218791007995605  (3.1703558500422995)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(10.7780, device='cuda:0')  (tensor(10.8740, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.6059  (0.7478994072808159)\n",
      "     | > loader_time: 0.0045  (0.42349112086825913)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:04:39 -- STEP: 250/811 -- GLOBAL_STEP: 250\u001b[0m\n",
      "     | > loss: 4.050116062164307  (3.9975414901971784)\n",
      "     | > log_mle: 0.8344279527664185  (0.830237249781688)\n",
      "     | > loss_dur: 3.2156879901885986  (3.1673042406638467)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(11.0077, device='cuda:0')  (tensor(10.8763, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.7687  (0.7481365642547607)\n",
      "     | > loader_time: 0.0047  (0.3823601293563844)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:04:58 -- STEP: 275/811 -- GLOBAL_STEP: 275\u001b[0m\n",
      "     | > loss: 3.9446630477905273  (3.994902810510596)\n",
      "     | > log_mle: 0.8275009393692017  (0.8301484197940466)\n",
      "     | > loss_dur: 3.1171622276306152  (3.1647543925159387)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(10.8506, device='cuda:0')  (tensor(10.8767, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.8721  (0.7485688148845325)\n",
      "     | > loader_time: 0.005  (0.3483307014812123)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:05:17 -- STEP: 300/811 -- GLOBAL_STEP: 300\u001b[0m\n",
      "     | > loss: 3.965703010559082  (3.993788091067607)\n",
      "     | > log_mle: 0.8350074291229248  (0.8301562981358888)\n",
      "     | > loss_dur: 3.1306955814361572  (3.163631792726188)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(10.8272, device='cuda:0')  (tensor(10.8777, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.4439  (0.7467893195152283)\n",
      "     | > loader_time: 0.0049  (0.32026932001113906)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:05:36 -- STEP: 325/811 -- GLOBAL_STEP: 325\u001b[0m\n",
      "     | > loss: 3.905095100402832  (3.9904213806939475)\n",
      "     | > log_mle: 0.8265878558158875  (0.8301304813415283)\n",
      "     | > loss_dur: 3.0785071849823  (3.1602908982170947)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(10.8416, device='cuda:0')  (tensor(10.8734, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.5052  (0.748287818615253)\n",
      "     | > loader_time: 0.007  (0.29638983799861046)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:05:56 -- STEP: 350/811 -- GLOBAL_STEP: 350\u001b[0m\n",
      "     | > loss: 4.052164077758789  (3.9870640102554744)\n",
      "     | > log_mle: 0.8253610134124756  (0.8300542761297786)\n",
      "     | > loss_dur: 3.2268030643463135  (3.157009732723235)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(11.0654, device='cuda:0')  (tensor(10.8674, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.6245  (0.7498236649377004)\n",
      "     | > loader_time: 0.0138  (0.2761061007635935)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:06:14 -- STEP: 375/811 -- GLOBAL_STEP: 375\u001b[0m\n",
      "     | > loss: 3.9458484649658203  (3.983925097609217)\n",
      "     | > log_mle: 0.8301047682762146  (0.8299301077241765)\n",
      "     | > loss_dur: 3.115743637084961  (3.153994988088737)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(10.7030, device='cuda:0')  (tensor(10.8609, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.4715  (0.7488325684865315)\n",
      "     | > loader_time: 0.0058  (0.25816002146403)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:06:35 -- STEP: 400/811 -- GLOBAL_STEP: 400\u001b[0m\n",
      "     | > loss: 3.8830254077911377  (3.980586441969258)\n",
      "     | > log_mle: 0.8310415148735046  (0.8298543636615459)\n",
      "     | > loss_dur: 3.0519838333129883  (3.1507320752510646)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(10.6055, device='cuda:0')  (tensor(10.8522, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.8019  (0.7534034603834151)\n",
      "     | > loader_time: 0.0047  (0.2427332186698914)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:06:55 -- STEP: 425/811 -- GLOBAL_STEP: 425\u001b[0m\n",
      "     | > loss: 3.940486192703247  (3.9762353196201534)\n",
      "     | > log_mle: 0.82253497838974  (0.8297541546534342)\n",
      "     | > loss_dur: 3.1179511547088623  (3.146481162381458)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(10.7450, device='cuda:0')  (tensor(10.8407, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 1.5009  (0.7552029177721807)\n",
      "     | > loader_time: 0.0052  (0.2289486391404096)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:07:15 -- STEP: 450/811 -- GLOBAL_STEP: 450\u001b[0m\n",
      "     | > loss: 3.8866994380950928  (3.9711870458993026)\n",
      "     | > log_mle: 0.8129057288169861  (0.8296877461400898)\n",
      "     | > loss_dur: 3.073793649673462  (3.1414992982690975)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(10.6869, device='cuda:0')  (tensor(10.8272, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.6158  (0.7570833677715724)\n",
      "     | > loader_time: 0.006  (0.21673614713880754)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:07:36 -- STEP: 475/811 -- GLOBAL_STEP: 475\u001b[0m\n",
      "     | > loss: 3.908291816711426  (3.967812633514402)\n",
      "     | > log_mle: 0.8250256776809692  (0.8296489746339858)\n",
      "     | > loss_dur: 3.083266019821167  (3.138163656829505)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(10.6610, device='cuda:0')  (tensor(10.8148, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.8549  (0.7602981928775184)\n",
      "     | > loader_time: 0.0077  (0.2058639034472014)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:07:58 -- STEP: 500/811 -- GLOBAL_STEP: 500\u001b[0m\n",
      "     | > loss: 3.96956729888916  (3.9639398117454667)\n",
      "     | > log_mle: 0.8292227387428284  (0.8294674711568014)\n",
      "     | > loss_dur: 3.1403446197509766  (3.1344723409535926)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(10.6265, device='cuda:0')  (tensor(10.8017, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.907  (0.7648301973342895)\n",
      "     | > loader_time: 0.0066  (0.19620894050598148)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:08:17 -- STEP: 525/811 -- GLOBAL_STEP: 525\u001b[0m\n",
      "     | > loss: 3.8031563758850098  (3.9596619624535996)\n",
      "     | > log_mle: 0.8212277293205261  (0.8292009619833195)\n",
      "     | > loss_dur: 2.981928586959839  (3.130460999775858)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(10.4142, device='cuda:0')  (tensor(10.7874, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.4751  (0.7648658075786771)\n",
      "     | > loader_time: 0.0063  (0.18729629970732192)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:08:38 -- STEP: 550/811 -- GLOBAL_STEP: 550\u001b[0m\n",
      "     | > loss: 3.8797483444213867  (3.9553974186932583)\n",
      "     | > log_mle: 0.8258774280548096  (0.828978360582281)\n",
      "     | > loss_dur: 3.053870916366577  (3.1264190563449143)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(10.4033, device='cuda:0')  (tensor(10.7719, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.9014  (0.7669858936829999)\n",
      "     | > loader_time: 0.0058  (0.17922015883705836)\n",
      "\n",
      "ðə fɑsfeɪts wɪt͡ʃ ðə pɹɑsɛs əv “boʊltɪŋ” ɹimuvz tə ə lɑɹd͡ʒ ɪkstɛnt fɹʌm waɪt flaʊɚ, ɡoʊ dɪɹɛktli tə ðə mænjəfækt͡ʃɚ əv boʊn,\n",
      "Character '“' not found in the vocabulary. Discarding it.\n",
      "ðə fɑsfeɪts wɪt͡ʃ ðə pɹɑsɛs əv “boʊltɪŋ” ɹimuvz tə ə lɑɹd͡ʒ ɪkstɛnt fɹʌm waɪt flaʊɚ, ɡoʊ dɪɹɛktli tə ðə mænjəfækt͡ʃɚ əv boʊn,\n",
      "Character '”' not found in the vocabulary. Discarding it.\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:08:59 -- STEP: 575/811 -- GLOBAL_STEP: 575\u001b[0m\n",
      "     | > loss: 3.823526620864868  (3.9508384392324785)\n",
      "     | > log_mle: 0.8238480091094971  (0.8287756773222867)\n",
      "     | > loss_dur: 2.999678611755371  (3.1220627607497486)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(10.2766, device='cuda:0')  (tensor(10.7554, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.975  (0.7694902374433431)\n",
      "     | > loader_time: 0.0072  (0.17188126107920765)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:09:22 -- STEP: 600/811 -- GLOBAL_STEP: 600\u001b[0m\n",
      "     | > loss: 3.7834296226501465  (3.945821181798384)\n",
      "     | > log_mle: 0.8185145854949951  (0.8285280869168752)\n",
      "     | > loss_dur: 2.9649150371551514  (3.1172930931640876)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(10.1402, device='cuda:0')  (tensor(10.7369, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 1.4721  (0.7743994128704066)\n",
      "     | > loader_time: 0.0064  (0.16531778494517002)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:09:44 -- STEP: 625/811 -- GLOBAL_STEP: 625\u001b[0m\n",
      "     | > loss: 4.010653018951416  (3.941230276929652)\n",
      "     | > log_mle: 0.8223215341567993  (0.8282963003569501)\n",
      "     | > loss_dur: 3.1883316040039062  (3.1129339753127683)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(10.6028, device='cuda:0')  (tensor(10.7189, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.9373  (0.7783945621490473)\n",
      "     | > loader_time: 0.0221  (0.15916852836608877)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:10:05 -- STEP: 650/811 -- GLOBAL_STEP: 650\u001b[0m\n",
      "     | > loss: 3.831927537918091  (3.9355652604252085)\n",
      "     | > log_mle: 0.8260261416435242  (0.8280136958695948)\n",
      "     | > loss_dur: 3.005901336669922  (3.1075515631586312)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(10.2743, device='cuda:0')  (tensor(10.6986, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.7034  (0.7800310263266925)\n",
      "     | > loader_time: 0.0075  (0.15352805944589462)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:10:25 -- STEP: 675/811 -- GLOBAL_STEP: 675\u001b[0m\n",
      "     | > loss: 3.8612358570098877  (3.9314556792266373)\n",
      "     | > log_mle: 0.8250312209129333  (0.8277965937341962)\n",
      "     | > loss_dur: 3.0362045764923096  (3.1036590837894518)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(10.2863, device='cuda:0')  (tensor(10.6794, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.825  (0.7804246199572521)\n",
      "     | > loader_time: 0.0058  (0.14816338185910827)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:10:46 -- STEP: 700/811 -- GLOBAL_STEP: 700\u001b[0m\n",
      "     | > loss: 3.705026626586914  (3.9264812300170666)\n",
      "     | > log_mle: 0.8243380188941956  (0.8275554488534512)\n",
      "     | > loss_dur: 2.8806886672973633  (3.098925780558931)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(9.8779, device='cuda:0')  (tensor(10.6574, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.4083  (0.7815533798081528)\n",
      "     | > loader_time: 0.0051  (0.14322634424482078)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:11:05 -- STEP: 725/811 -- GLOBAL_STEP: 725\u001b[0m\n",
      "     | > loss: 3.6955642700195312  (3.920680088096564)\n",
      "     | > log_mle: 0.8244917392730713  (0.8272656837543407)\n",
      "     | > loss_dur: 2.87107253074646  (3.0934144040087714)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(9.8306, device='cuda:0')  (tensor(10.6343, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.5815  (0.7796009076874826)\n",
      "     | > loader_time: 0.0066  (0.13863649598483385)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:11:24 -- STEP: 750/811 -- GLOBAL_STEP: 750\u001b[0m\n",
      "     | > loss: 3.6260368824005127  (3.9139965659863227)\n",
      "     | > log_mle: 0.8149606585502625  (0.8269757749261083)\n",
      "     | > loss_dur: 2.8110761642456055  (3.087020791221309)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(9.6363, device='cuda:0')  (tensor(10.6086, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.486  (0.7793238255182896)\n",
      "     | > loader_time: 0.0044  (0.13438874244689952)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:11:47 -- STEP: 775/811 -- GLOBAL_STEP: 775\u001b[0m\n",
      "     | > loss: 3.694925308227539  (3.907689000110999)\n",
      "     | > log_mle: 0.8210809826850891  (0.8267191445126253)\n",
      "     | > loss_dur: 2.8738443851470947  (3.0809698562996055)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(9.7657, device='cuda:0')  (tensor(10.5833, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 1.2422  (0.7830525302886957)\n",
      "     | > loader_time: 0.0078  (0.13044555971699384)\n",
      "\n",
      "bɹɛd ɹeɪzd wɪθ wʌt ɪz noʊn tə beɪkɚz æz ə “spʌnd͡ʒ,” ɹikwaɪɚz mɔɹ taɪm ænd ə tɹaɪfəl mɔɹ wɚk ðən ðə sɪmplɚ fɔɹm fɚ wɪt͡ʃ aɪ hæv d͡ʒʌst ɔlɹɛdi ɡɪvən dɪɹɛkʃənz.\n",
      "Character '“' not found in the vocabulary. Discarding it.\n",
      "bɹɛd ɹeɪzd wɪθ wʌt ɪz noʊn tə beɪkɚz æz ə “spʌnd͡ʒ,” ɹikwaɪɚz mɔɹ taɪm ænd ə tɹaɪfəl mɔɹ wɚk ðən ðə sɪmplɚ fɔɹm fɚ wɪt͡ʃ aɪ hæv d͡ʒʌst ɔlɹɛdi ɡɪvən dɪɹɛkʃənz.\n",
      "Character '”' not found in the vocabulary. Discarding it.\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:12:08 -- STEP: 800/811 -- GLOBAL_STEP: 800\u001b[0m\n",
      "     | > loss: 3.7254319190979004  (3.9017020065573185)\n",
      "     | > log_mle: 0.8201586008071899  (0.8264663034602057)\n",
      "     | > loss_dur: 2.9052734375  (3.075235704530643)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(9.7588, device='cuda:0')  (tensor(10.5580, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.4785  (0.7844527456164354)\n",
      "     | > loader_time: 0.0079  (0.12675419449806216)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "kɚvwisiɚ maɪt hæv lɪvd ə sɛnt͡ʃɚi ɚliɚ.\n",
      "Character '͡' not found in the vocabulary. Discarding it.\n",
      "bʌt əkɔɹdɪŋ tə ðə ɑpəzɪt vju noʊ ɹizən kən bi əsaɪnd waɪ sʌt͡ʃ ʃʊd bi ðə keɪs.\n",
      "ðɪs d͡ʒeɪl wəz nɑmənəli tə ɹipleɪs ðə ɡɪltspɚ stɹit kəmptɚ,\n",
      "Character '͡' not found in the vocabulary. Discarding it.\n",
      "Character '͡' not found in the vocabulary. Discarding it.\n",
      "ʌndɚ ðə eɪbəl ænd ɛnɚd͡ʒɛtɪk lidɚʃɪp əv d͡ʒɛnɚəl d͡ʒɑnsən.\n",
      "Character '͡' not found in the vocabulary. Discarding it.\n",
      "kəntɪnjud dænsɪŋ ænd ɹɛvəlɪŋ ʌntɪl ðeɪ lɚnd ðə kæpt͡ʃɚ bʌt tu sɚtənli.\n",
      "Character '͡' not found in the vocabulary. Discarding it.\n",
      "dɪskʌst ɪn t͡ʃæptɚ sɪks əv ðɪs ɹɪpɔɹt.\n",
      "Character '͡' not found in the vocabulary. Discarding it.\n",
      "ðə pɛnʌltəmɪt əv sʌt͡ʃ ɪnæktmənts, mɛni əv ðə pɹəvɪʒənz əv wɪt͡ʃ stɪl ɹɪmeɪn ɪn fɔɹs.\n",
      "Character '͡' not found in the vocabulary. Discarding it.\n",
      "t͡ʃæptɚ sɛvən. li hɑɹvi ɔzwɔld, bækɡɹaʊnd ænd pɑsəbəl moʊtɪvz, pɑɹt tu.\n",
      "Character '͡' not found in the vocabulary. Discarding it.\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: 3.559353828430176  (3.559353828430176)\n",
      "     | > log_mle: 0.8156291246414185  (0.8156291246414185)\n",
      "     | > loss_dur: 2.743724822998047  (2.743724822998047)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: 3.6279280185699463  (3.6279280185699463)\n",
      "     | > log_mle: 0.7998151779174805  (0.7998151779174805)\n",
      "     | > loss_dur: 2.828112840652466  (2.828112840652466)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: 3.5893280506134033  (3.608628034591675)\n",
      "     | > log_mle: 0.8256784081459045  (0.8127467930316925)\n",
      "     | > loss_dur: 2.7636497020721436  (2.7958812713623047)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: 3.74767804145813  (3.654978036880493)\n",
      "     | > log_mle: 0.8232160210609436  (0.8162365357081095)\n",
      "     | > loss_dur: 2.924462080001831  (2.8387415409088135)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: 3.760734796524048  (3.681417226791382)\n",
      "     | > log_mle: 0.8096796870231628  (0.8145973235368729)\n",
      "     | > loss_dur: 2.9510550498962402  (2.86681991815567)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: 3.636920928955078  (3.6725179672241213)\n",
      "     | > log_mle: 0.8166065216064453  (0.8149991631507874)\n",
      "     | > loss_dur: 2.820314407348633  (2.8575188159942626)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: 3.862544298171997  (3.7041890223821006)\n",
      "     | > log_mle: 0.8118694424629211  (0.814477543036143)\n",
      "     | > loss_dur: 3.0506749153137207  (2.8897114992141724)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: 3.569467306137085  (3.684943062918527)\n",
      "     | > log_mle: 0.8143282532691956  (0.814456215926579)\n",
      "     | > loss_dur: 2.755139112472534  (2.8704868725367954)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: 3.6181774139404297  (3.6765973567962646)\n",
      "     | > log_mle: 0.8063405752182007  (0.8134417608380318)\n",
      "     | > loss_dur: 2.8118367195129395  (2.8631556034088135)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: 3.6641287803649902  (3.675211959415012)\n",
      "     | > log_mle: 0.8231649398803711  (0.8145221140649583)\n",
      "     | > loss_dur: 2.840963840484619  (2.8606898519727917)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: 3.741518974304199  (3.6818426609039308)\n",
      "     | > log_mle: 0.8276913166046143  (0.8158390343189239)\n",
      "     | > loss_dur: 2.913827657699585  (2.866003632545471)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: 3.6682395935058594  (3.680606018413197)\n",
      "     | > log_mle: 0.8238099217414856  (0.8165636604482477)\n",
      "     | > loss_dur: 2.8444297313690186  (2.8640423688021572)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: 3.5892529487609863  (3.672993262608846)\n",
      "     | > log_mle: 0.8122919797897339  (0.8162076870600382)\n",
      "     | > loss_dur: 2.776960849761963  (2.8567855755488076)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: 3.813556671142578  (3.683805832496056)\n",
      "     | > log_mle: 0.8218838572502136  (0.8166443155362055)\n",
      "     | > loss_dur: 2.9916727542877197  (2.867161512374878)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: 3.617410659790039  (3.679063320159912)\n",
      "     | > log_mle: 0.8019490838050842  (0.8155946561268398)\n",
      "     | > loss_dur: 2.8154616355895996  (2.863468664033072)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: 3.6063733100891113  (3.6742173194885255)\n",
      "     | > log_mle: 0.8180018663406372  (0.8157551368077596)\n",
      "     | > loss_dur: 2.7883713245391846  (2.85846217473348)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: 3.812605142593384  (3.682866558432579)\n",
      "     | > log_mle: 0.8096745014190674  (0.8153750970959663)\n",
      "     | > loss_dur: 3.0029306411743164  (2.867491453886032)\n",
      "\n",
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time: 0.21255211532115936 \u001b[0m(+0.0)\n",
      "     | > avg_loss: 3.682866558432579 \u001b[0m(+0.0)\n",
      "     | > avg_log_mle: 0.8153750970959663 \u001b[0m(+0.0)\n",
      "     | > avg_loss_dur: 2.867491453886032 \u001b[0m(+0.0)\n",
      "\n",
      " > BEST MODEL : train/run-February-22-2025_01+01AM-9b6e3e6/best_model_811.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 1/10\u001b[0m\n",
      " --> train/run-February-22-2025_01+01AM-9b6e3e6\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-22 01:12:41) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:12:50 -- STEP: 14/811 -- GLOBAL_STEP: 825\u001b[0m\n",
      "     | > loss: 3.7178211212158203  (3.797896010535104)\n",
      "     | > log_mle: 0.8050602674484253  (0.8076506938253131)\n",
      "     | > loss_dur: 2.9127609729766846  (2.9902453252247403)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(9.7169, device='cuda:0')  (tensor(9.5589, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.4846  (0.47057758058820454)\n",
      "     | > loader_time: 0.0093  (0.0046117305755615234)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:13:01 -- STEP: 39/811 -- GLOBAL_STEP: 850\u001b[0m\n",
      "     | > loss: 3.7333667278289795  (3.7585417796403933)\n",
      "     | > log_mle: 0.8201798796653748  (0.8114267175014203)\n",
      "     | > loss_dur: 2.91318678855896  (2.947115054497352)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(9.5846, device='cuda:0')  (tensor(9.5757, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.5409  (0.4531885477212759)\n",
      "     | > loader_time: 0.0054  (0.005021975590632513)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:13:20 -- STEP: 64/811 -- GLOBAL_STEP: 875\u001b[0m\n",
      "     | > loss: 3.6660072803497314  (3.702665839344263)\n",
      "     | > log_mle: 0.8174457550048828  (0.8123985882848501)\n",
      "     | > loss_dur: 2.8485615253448486  (2.890267252922058)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(9.5469, device='cuda:0')  (tensor(9.4872, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.8325  (0.5603388510644438)\n",
      "     | > loader_time: 0.0211  (0.008497610688209537)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:13:37 -- STEP: 89/811 -- GLOBAL_STEP: 900\u001b[0m\n",
      "     | > loss: 3.538466453552246  (3.6776554450560153)\n",
      "     | > log_mle: 0.8181048631668091  (0.8127076666006882)\n",
      "     | > loss_dur: 2.7203614711761475  (2.8649477824736183)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(9.1800, device='cuda:0')  (tensor(9.4444, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.6519  (0.5901884014686842)\n",
      "     | > loader_time: 0.0512  (0.009440357765454925)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:13:54 -- STEP: 114/811 -- GLOBAL_STEP: 925\u001b[0m\n",
      "     | > loss: 3.6239962577819824  (3.663299332585251)\n",
      "     | > log_mle: 0.8230563402175903  (0.8127843528463129)\n",
      "     | > loss_dur: 2.8009400367736816  (2.8505149828760254)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(9.3446, device='cuda:0')  (tensor(9.4104, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.556  (0.6123883285020525)\n",
      "     | > loader_time: 0.0098  (0.009374603890536124)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:14:11 -- STEP: 139/811 -- GLOBAL_STEP: 950\u001b[0m\n",
      "     | > loss: 3.7119011878967285  (3.650915819963963)\n",
      "     | > log_mle: 0.8226979970932007  (0.8127584538871436)\n",
      "     | > loss_dur: 2.8892033100128174  (2.838157369078493)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(9.3637, device='cuda:0')  (tensor(9.3781, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.5504  (0.6161054038315367)\n",
      "     | > loader_time: 0.0637  (0.009524925149601998)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:14:28 -- STEP: 164/811 -- GLOBAL_STEP: 975\u001b[0m\n",
      "     | > loss: 3.4850776195526123  (3.63951788588268)\n",
      "     | > log_mle: 0.814526379108429  (0.812658048984481)\n",
      "     | > loss_dur: 2.670551300048828  (2.826859839078859)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(9.0827, device='cuda:0')  (tensor(9.3449, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.9469  (0.629266237340322)\n",
      "     | > loader_time: 0.0172  (0.009640447977112563)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:14:45 -- STEP: 189/811 -- GLOBAL_STEP: 1000\u001b[0m\n",
      "     | > loss: 3.4696452617645264  (3.6265424243987554)\n",
      "     | > log_mle: 0.801760733127594  (0.8122080315357794)\n",
      "     | > loss_dur: 2.667884588241577  (2.814334397593506)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(8.9492, device='cuda:0')  (tensor(9.3070, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 1.0533  (0.6295703517066107)\n",
      "     | > loader_time: 0.0047  (0.00928456821138897)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:15:00 -- STEP: 214/811 -- GLOBAL_STEP: 1025\u001b[0m\n",
      "     | > loss: 3.551232099533081  (3.6154535440641027)\n",
      "     | > log_mle: 0.8046988844871521  (0.8121086537280929)\n",
      "     | > loss_dur: 2.746533155441284  (2.803344894792434)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(8.9877, device='cuda:0')  (tensor(9.2656, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.6893  (0.6283663533558357)\n",
      "     | > loader_time: 0.0048  (0.008945297972064154)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:15:16 -- STEP: 239/811 -- GLOBAL_STEP: 1050\u001b[0m\n",
      "     | > loss: 3.476961851119995  (3.60436113209904)\n",
      "     | > log_mle: 0.7994897365570068  (0.8117015326871034)\n",
      "     | > loss_dur: 2.6774721145629883  (2.7926596048985584)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(8.6910, device='cuda:0')  (tensor(9.2223, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.7142  (0.6266831872852279)\n",
      "     | > loader_time: 0.0058  (0.00861186063439277)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:15:31 -- STEP: 264/811 -- GLOBAL_STEP: 1075\u001b[0m\n",
      "     | > loss: 3.4285495281219482  (3.5958831825039606)\n",
      "     | > log_mle: 0.7988383173942566  (0.811299612124761)\n",
      "     | > loss_dur: 2.629711151123047  (2.784583575797805)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(8.6132, device='cuda:0')  (tensor(9.1832, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.4822  (0.6250077133828943)\n",
      "     | > loader_time: 0.0046  (0.008462431755932892)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:15:49 -- STEP: 289/811 -- GLOBAL_STEP: 1100\u001b[0m\n",
      "     | > loss: 3.466526508331299  (3.588426048780395)\n",
      "     | > log_mle: 0.80558180809021  (0.8108865214466636)\n",
      "     | > loss_dur: 2.660944700241089  (2.777539532077356)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(8.5430, device='cuda:0')  (tensor(9.1426, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.5475  (0.6317335536323204)\n",
      "     | > loader_time: 0.0095  (0.00863316232357883)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:16:05 -- STEP: 314/811 -- GLOBAL_STEP: 1125\u001b[0m\n",
      "     | > loss: 3.520014524459839  (3.580415592831411)\n",
      "     | > log_mle: 0.8004279136657715  (0.810624921018151)\n",
      "     | > loss_dur: 2.7195866107940674  (2.7697906759893844)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(8.6693, device='cuda:0')  (tensor(9.1002, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.6792  (0.6292290771083465)\n",
      "     | > loader_time: 0.0068  (0.008537757928204383)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:16:22 -- STEP: 339/811 -- GLOBAL_STEP: 1150\u001b[0m\n",
      "     | > loss: 3.454435110092163  (3.573048158381189)\n",
      "     | > log_mle: 0.8143308758735657  (0.8102412981621284)\n",
      "     | > loss_dur: 2.640104293823242  (2.7628068635597365)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(8.2883, device='cuda:0')  (tensor(9.0566, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.5728  (0.6343437985333016)\n",
      "     | > loader_time: 0.0046  (0.008341066956871725)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:16:38 -- STEP: 364/811 -- GLOBAL_STEP: 1175\u001b[0m\n",
      "     | > loss: 3.5254905223846436  (3.564727615524124)\n",
      "     | > log_mle: 0.79988032579422  (0.8097536349362069)\n",
      "     | > loss_dur: 2.7256102561950684  (2.7549739846816443)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(8.5056, device='cuda:0')  (tensor(9.0107, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.8506  (0.6329042996679036)\n",
      "     | > loader_time: 0.0048  (0.008235998206086207)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:16:59 -- STEP: 389/811 -- GLOBAL_STEP: 1200\u001b[0m\n",
      "     | > loss: 3.415111541748047  (3.557909445774892)\n",
      "     | > log_mle: 0.8047589063644409  (0.8093132133042598)\n",
      "     | > loss_dur: 2.6103525161743164  (2.74859623553514)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(8.1002, device='cuda:0')  (tensor(8.9667, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.5871  (0.6455987075913537)\n",
      "     | > loader_time: 0.0064  (0.00860990779258904)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:17:18 -- STEP: 414/811 -- GLOBAL_STEP: 1225\u001b[0m\n",
      "     | > loss: 3.4883830547332764  (3.550270540702746)\n",
      "     | > log_mle: 0.7993581295013428  (0.8089050519581579)\n",
      "     | > loss_dur: 2.6890249252319336  (2.7413654914800683)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(8.2626, device='cuda:0')  (tensor(8.9208, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.7708  (0.6502630480245695)\n",
      "     | > loader_time: 0.0237  (0.008725246945441053)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:17:35 -- STEP: 439/811 -- GLOBAL_STEP: 1250\u001b[0m\n",
      "     | > loss: 3.390019416809082  (3.542216627907373)\n",
      "     | > log_mle: 0.8066321611404419  (0.8084657898253351)\n",
      "     | > loss_dur: 2.5833871364593506  (2.733750839711323)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(8.0527, device='cuda:0')  (tensor(8.8727, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.8864  (0.6518390026613903)\n",
      "     | > loader_time: 0.0118  (0.008695517694216925)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:17:54 -- STEP: 464/811 -- GLOBAL_STEP: 1275\u001b[0m\n",
      "     | > loss: 3.388632297515869  (3.5355646240300147)\n",
      "     | > log_mle: 0.8011202812194824  (0.8080740175370512)\n",
      "     | > loss_dur: 2.5875120162963867  (2.72749060906213)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(7.9378, device='cuda:0')  (tensor(8.8267, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.5823  (0.6572924626284634)\n",
      "     | > loader_time: 0.0041  (0.008704045209391368)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:18:11 -- STEP: 489/811 -- GLOBAL_STEP: 1300\u001b[0m\n",
      "     | > loss: 3.4265003204345703  (3.5295594235870738)\n",
      "     | > log_mle: 0.7912436723709106  (0.8076073270146344)\n",
      "     | > loss_dur: 2.635256767272949  (2.7219520985226944)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(8.0007, device='cuda:0')  (tensor(8.7803, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.6194  (0.6582568705935178)\n",
      "     | > loader_time: 0.0051  (0.00870703090675526)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:18:30 -- STEP: 514/811 -- GLOBAL_STEP: 1325\u001b[0m\n",
      "     | > loss: 3.345252275466919  (3.5233794353351517)\n",
      "     | > log_mle: 0.7969561219215393  (0.807114919451888)\n",
      "     | > loss_dur: 2.5482962131500244  (2.716264518318474)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(7.7528, device='cuda:0')  (tensor(8.7345, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.7282  (0.6621986511616393)\n",
      "     | > loader_time: 0.0334  (0.008938414577380233)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:18:46 -- STEP: 539/811 -- GLOBAL_STEP: 1350\u001b[0m\n",
      "     | > loss: 3.3504390716552734  (3.516991761265969)\n",
      "     | > log_mle: 0.7983445525169373  (0.8065243175388047)\n",
      "     | > loss_dur: 2.5520944595336914  (2.7104674456070894)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(7.5212, device='cuda:0')  (tensor(8.6876, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.3848  (0.6594951334158876)\n",
      "     | > loader_time: 0.0231  (0.00892419850450279)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:19:02 -- STEP: 564/811 -- GLOBAL_STEP: 1375\u001b[0m\n",
      "     | > loss: 3.28944730758667  (3.510916120617102)\n",
      "     | > log_mle: 0.7866514325141907  (0.8060320461472723)\n",
      "     | > loss_dur: 2.502795934677124  (2.704884075949379)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(7.4019, device='cuda:0')  (tensor(8.6409, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.3331  (0.6592728516734241)\n",
      "     | > loader_time: 0.0047  (0.00893622214067067)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:19:20 -- STEP: 589/811 -- GLOBAL_STEP: 1400\u001b[0m\n",
      "     | > loss: 3.4097442626953125  (3.50562927111705)\n",
      "     | > log_mle: 0.7945187091827393  (0.805469008779283)\n",
      "     | > loss_dur: 2.6152255535125732  (2.700160263754517)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(7.5721, device='cuda:0')  (tensor(8.5958, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.4849  (0.6606376859247184)\n",
      "     | > loader_time: 0.0047  (0.00911688845105001)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:19:37 -- STEP: 614/811 -- GLOBAL_STEP: 1425\u001b[0m\n",
      "     | > loss: 3.3474645614624023  (3.500602167281732)\n",
      "     | > log_mle: 0.7948507070541382  (0.8049481364531316)\n",
      "     | > loss_dur: 2.5526139736175537  (2.695654030731525)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(7.3909, device='cuda:0')  (tensor(8.5511, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.6397  (0.6615000485597301)\n",
      "     | > loader_time: 0.007  (0.009090797908919639)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:19:56 -- STEP: 639/811 -- GLOBAL_STEP: 1450\u001b[0m\n",
      "     | > loss: 3.353905200958252  (3.495020181733491)\n",
      "     | > log_mle: 0.7914708852767944  (0.8043496445497627)\n",
      "     | > loss_dur: 2.562434196472168  (2.6906705376501203)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(7.3622, device='cuda:0')  (tensor(8.5061, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.6353  (0.6637524047368019)\n",
      "     | > loader_time: 0.0187  (0.009167507034325634)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:20:14 -- STEP: 664/811 -- GLOBAL_STEP: 1475\u001b[0m\n",
      "     | > loss: 3.3702757358551025  (3.4897189172635596)\n",
      "     | > log_mle: 0.7912595868110657  (0.8038080300552303)\n",
      "     | > loss_dur: 2.5790162086486816  (2.685910887028798)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(7.2965, device='cuda:0')  (tensor(8.4611, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 1.0575  (0.6661185902285296)\n",
      "     | > loader_time: 0.0067  (0.009241264986704635)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:20:32 -- STEP: 689/811 -- GLOBAL_STEP: 1500\u001b[0m\n",
      "     | > loss: 3.3731958866119385  (3.4855579222580864)\n",
      "     | > log_mle: 0.7871766090393066  (0.8032278529272373)\n",
      "     | > loss_dur: 2.586019277572632  (2.6823300695903773)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(7.2116, device='cuda:0')  (tensor(8.4177, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.7839  (0.6678064651516944)\n",
      "     | > loader_time: 0.0067  (0.009242128391570388)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:20:50 -- STEP: 714/811 -- GLOBAL_STEP: 1525\u001b[0m\n",
      "     | > loss: 3.3514819145202637  (3.4807781852593944)\n",
      "     | > log_mle: 0.7867164611816406  (0.8025965714821965)\n",
      "     | > loss_dur: 2.564765453338623  (2.678181613860679)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(7.1612, device='cuda:0')  (tensor(8.3737, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.6449  (0.6683089395865008)\n",
      "     | > loader_time: 0.0202  (0.00939624917273428)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:21:07 -- STEP: 739/811 -- GLOBAL_STEP: 1550\u001b[0m\n",
      "     | > loss: 3.2998037338256836  (3.4753265058236127)\n",
      "     | > log_mle: 0.781501293182373  (0.8020195824690216)\n",
      "     | > loss_dur: 2.5183024406433105  (2.6733069239191822)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(6.9433, device='cuda:0')  (tensor(8.3293, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.4218  (0.6683238049482626)\n",
      "     | > loader_time: 0.0059  (0.009469448471585531)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:21:24 -- STEP: 764/811 -- GLOBAL_STEP: 1575\u001b[0m\n",
      "     | > loss: 3.344886302947998  (3.470158595377238)\n",
      "     | > log_mle: 0.7929320931434631  (0.8013985615750261)\n",
      "     | > loss_dur: 2.5519542694091797  (2.668760034426345)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(7.0139, device='cuda:0')  (tensor(8.2858, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.4872  (0.6676328032428686)\n",
      "     | > loader_time: 0.0051  (0.009475710816408323)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:21:42 -- STEP: 789/811 -- GLOBAL_STEP: 1600\u001b[0m\n",
      "     | > loss: 3.3377647399902344  (3.465159424055363)\n",
      "     | > log_mle: 0.7821153402328491  (0.8008343504106744)\n",
      "     | > loss_dur: 2.555649518966675  (2.6643250744001343)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(6.9501, device='cuda:0')  (tensor(8.2429, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.6339  (0.6690383734056405)\n",
      "     | > loader_time: 0.0114  (0.009636327794296204)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: 3.261584758758545  (3.261584758758545)\n",
      "     | > log_mle: 0.7819939851760864  (0.7819939851760864)\n",
      "     | > loss_dur: 2.479590892791748  (2.479590892791748)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: 3.0760374069213867  (3.0760374069213867)\n",
      "     | > log_mle: 0.7649089694023132  (0.7649089694023132)\n",
      "     | > loss_dur: 2.3111283779144287  (2.3111283779144287)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: 3.268214225769043  (3.172125816345215)\n",
      "     | > log_mle: 0.7909544110298157  (0.7779316902160645)\n",
      "     | > loss_dur: 2.477259874343872  (2.3941941261291504)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: 3.24385666847229  (3.1960361003875732)\n",
      "     | > log_mle: 0.7845390439033508  (0.7801341414451599)\n",
      "     | > loss_dur: 2.459317684173584  (2.4159019788106284)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: 3.2963619232177734  (3.2211175560951233)\n",
      "     | > log_mle: 0.7721195220947266  (0.7781304866075516)\n",
      "     | > loss_dur: 2.524242401123047  (2.442987084388733)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: 3.1748604774475098  (3.2118661403656006)\n",
      "     | > log_mle: 0.7783346176147461  (0.7781713128089904)\n",
      "     | > loss_dur: 2.3965258598327637  (2.433694839477539)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: 3.324272871017456  (3.230600595474243)\n",
      "     | > log_mle: 0.7730469703674316  (0.7773172557353973)\n",
      "     | > loss_dur: 2.5512259006500244  (2.453283349672953)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: 3.2429070472717285  (3.232358660016741)\n",
      "     | > log_mle: 0.7774847745895386  (0.7773411870002747)\n",
      "     | > loss_dur: 2.4654221534729004  (2.455017464501517)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: 3.2142276763916016  (3.2300922870635986)\n",
      "     | > log_mle: 0.7699720859527588  (0.7764200493693352)\n",
      "     | > loss_dur: 2.4442555904388428  (2.453672230243683)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: 3.3068089485168457  (3.238616360558404)\n",
      "     | > log_mle: 0.7849819660186768  (0.7773713734414842)\n",
      "     | > loss_dur: 2.521826982498169  (2.461244980494181)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: 3.293063163757324  (3.2440610408782957)\n",
      "     | > log_mle: 0.7892519235610962  (0.7785594284534454)\n",
      "     | > loss_dur: 2.5038113594055176  (2.465501618385315)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: 3.306595802307129  (3.249746019190008)\n",
      "     | > log_mle: 0.7849779725074768  (0.7791429324583574)\n",
      "     | > loss_dur: 2.521617889404297  (2.470603097568859)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: 3.2181293964385986  (3.2471113006273904)\n",
      "     | > log_mle: 0.7763081192970276  (0.7789066980282465)\n",
      "     | > loss_dur: 2.441821336746216  (2.468204617500305)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: 3.3235650062561035  (3.2529923549065223)\n",
      "     | > log_mle: 0.7831684350967407  (0.7792345239565923)\n",
      "     | > loss_dur: 2.5403966903686523  (2.4737578538747935)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: 3.1669795513153076  (3.2468485832214355)\n",
      "     | > log_mle: 0.7662808895111084  (0.7783092643533435)\n",
      "     | > loss_dur: 2.400698661804199  (2.4685393401554654)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: 3.232445478439331  (3.245888376235962)\n",
      "     | > log_mle: 0.7810271382331848  (0.7784904559453328)\n",
      "     | > loss_dur: 2.451418399810791  (2.467397944132487)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: 3.384394407272339  (3.2545450031757355)\n",
      "     | > log_mle: 0.7724676728248596  (0.7781140320003033)\n",
      "     | > loss_dur: 2.611926794052124  (2.4764309972524643)\n",
      "\n",
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.004525527358055115 \u001b[0m(-0.20802658796310425)\n",
      "     | > avg_loss:\u001b[92m 3.2545450031757355 \u001b[0m(-0.42832155525684357)\n",
      "     | > avg_log_mle:\u001b[92m 0.7781140320003033 \u001b[0m(-0.03726106509566307)\n",
      "     | > avg_loss_dur:\u001b[92m 2.4764309972524643 \u001b[0m(-0.3910604566335678)\n",
      "\n",
      " > BEST MODEL : train/run-February-22-2025_01+01AM-9b6e3e6/best_model_1622.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 2/10\u001b[0m\n",
      " --> train/run-February-22-2025_01+01AM-9b6e3e6\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-22 01:22:06) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:22:09 -- STEP: 3/811 -- GLOBAL_STEP: 1625\u001b[0m\n",
      "     | > loss: 3.4649429321289062  (3.4907153447469077)\n",
      "     | > log_mle: 0.768803596496582  (0.7820117076237997)\n",
      "     | > loss_dur: 2.696139335632324  (2.7087036768595376)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(7.1169, device='cuda:0')  (tensor(7.0702, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.4296  (0.4148007233937581)\n",
      "     | > loader_time: 0.0021  (0.0031714439392089844)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:22:20 -- STEP: 28/811 -- GLOBAL_STEP: 1650\u001b[0m\n",
      "     | > loss: 3.441835403442383  (3.366990336350032)\n",
      "     | > log_mle: 0.7806257605552673  (0.7779004935707364)\n",
      "     | > loss_dur: 2.6612095832824707  (2.5890898278781345)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(6.9960, device='cuda:0')  (tensor(6.8626, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.3907  (0.4230292865208217)\n",
      "     | > loader_time: 0.0038  (0.004406613962990897)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:22:33 -- STEP: 53/811 -- GLOBAL_STEP: 1675\u001b[0m\n",
      "     | > loss: 3.213675022125244  (3.3222964079874866)\n",
      "     | > log_mle: 0.7833823561668396  (0.7779381376392437)\n",
      "     | > loss_dur: 2.4302926063537598  (2.5443582579774677)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(6.7176, device='cuda:0')  (tensor(6.7873, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.9034  (0.4663839160271411)\n",
      "     | > loader_time: 0.0031  (0.004933321251059478)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:22:48 -- STEP: 78/811 -- GLOBAL_STEP: 1700\u001b[0m\n",
      "     | > loss: 3.357527732849121  (3.2983883069111752)\n",
      "     | > log_mle: 0.7766716480255127  (0.7771226366360983)\n",
      "     | > loss_dur: 2.5808560848236084  (2.5212656565201588)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(6.8100, device='cuda:0')  (tensor(6.7338, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.606  (0.5052911929595165)\n",
      "     | > loader_time: 0.0045  (0.005429451282207782)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:23:04 -- STEP: 103/811 -- GLOBAL_STEP: 1725\u001b[0m\n",
      "     | > loss: 3.3400561809539795  (3.2818471737278316)\n",
      "     | > log_mle: 0.76178377866745  (0.776133674441032)\n",
      "     | > loss_dur: 2.5782723426818848  (2.5057134929212563)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(6.6224, device='cuda:0')  (tensor(6.6751, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.6255  (0.5301904307985768)\n",
      "     | > loader_time: 0.0054  (0.005627953890457893)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:23:20 -- STEP: 128/811 -- GLOBAL_STEP: 1750\u001b[0m\n",
      "     | > loss: 3.144169569015503  (3.26915205642581)\n",
      "     | > log_mle: 0.7658244967460632  (0.7750188829377294)\n",
      "     | > loss_dur: 2.378345012664795  (2.494133165106178)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(6.3575, device='cuda:0')  (tensor(6.6215, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.6592  (0.5484695397317407)\n",
      "     | > loader_time: 0.004  (0.005939284339547156)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:23:36 -- STEP: 153/811 -- GLOBAL_STEP: 1775\u001b[0m\n",
      "     | > loss: 3.2891151905059814  (3.2626124067244184)\n",
      "     | > log_mle: 0.7683854103088379  (0.7740675148621103)\n",
      "     | > loss_dur: 2.5207297801971436  (2.488544884849997)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(6.4714, device='cuda:0')  (tensor(6.5770, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.6326  (0.5604593753814695)\n",
      "     | > loader_time: 0.0058  (0.0062581495521894445)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:23:51 -- STEP: 178/811 -- GLOBAL_STEP: 1800\u001b[0m\n",
      "     | > loss: 3.2715389728546143  (3.2531814334097873)\n",
      "     | > log_mle: 0.7657226920127869  (0.7725907557466057)\n",
      "     | > loss_dur: 2.5058162212371826  (2.480590668956885)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(6.3719, device='cuda:0')  (tensor(6.5341, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.732  (0.5646664413173547)\n",
      "     | > loader_time: 0.0043  (0.006535824764980357)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:24:06 -- STEP: 203/811 -- GLOBAL_STEP: 1825\u001b[0m\n",
      "     | > loss: 3.2111988067626953  (3.2445025526244065)\n",
      "     | > log_mle: 0.7555081844329834  (0.7712808280742814)\n",
      "     | > loss_dur: 2.455690622329712  (2.473221716622412)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(6.1589, device='cuda:0')  (tensor(6.4903, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.6597  (0.5694183469405901)\n",
      "     | > loader_time: 0.0041  (0.006650841294838288)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:24:22 -- STEP: 228/811 -- GLOBAL_STEP: 1850\u001b[0m\n",
      "     | > loss: 3.1515636444091797  (3.235659525059817)\n",
      "     | > log_mle: 0.7541820406913757  (0.7698932491373598)\n",
      "     | > loss_dur: 2.397381544113159  (2.4657662699097065)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(6.0516, device='cuda:0')  (tensor(6.4494, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.8003  (0.5757249185913488)\n",
      "     | > loader_time: 0.0048  (0.0067892555604901214)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:24:38 -- STEP: 253/811 -- GLOBAL_STEP: 1875\u001b[0m\n",
      "     | > loss: 3.0488381385803223  (3.228130113465984)\n",
      "     | > log_mle: 0.7552531957626343  (0.7684692811117813)\n",
      "     | > loss_dur: 2.2935848236083984  (2.459660825993231)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(5.8929, device='cuda:0')  (tensor(6.4111, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.52  (0.580904824931631)\n",
      "     | > loader_time: 0.0043  (0.006662202918011208)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:24:54 -- STEP: 278/811 -- GLOBAL_STEP: 1900\u001b[0m\n",
      "     | > loss: 3.1403653621673584  (3.2229691769579336)\n",
      "     | > log_mle: 0.7555834650993347  (0.7669522826620145)\n",
      "     | > loss_dur: 2.384781837463379  (2.4560168878637616)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(6.0009, device='cuda:0')  (tensor(6.3769, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.8215  (0.5847165987645979)\n",
      "     | > loader_time: 0.0059  (0.006669118250016684)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:25:11 -- STEP: 303/811 -- GLOBAL_STEP: 1925\u001b[0m\n",
      "     | > loss: 3.1568539142608643  (3.2184484233163766)\n",
      "     | > log_mle: 0.746340811252594  (0.7655670160901038)\n",
      "     | > loss_dur: 2.410513162612915  (2.452881400734678)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(6.0143, device='cuda:0')  (tensor(6.3469, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.8884  (0.5928760157166533)\n",
      "     | > loader_time: 0.0076  (0.006763217472794032)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:25:28 -- STEP: 328/811 -- GLOBAL_STEP: 1950\u001b[0m\n",
      "     | > loss: 3.109062433242798  (3.212962534369492)\n",
      "     | > log_mle: 0.7428710460662842  (0.7641058293421097)\n",
      "     | > loss_dur: 2.3661913871765137  (2.4488566975768022)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(5.8374, device='cuda:0')  (tensor(6.3167, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.6992  (0.5986177041763209)\n",
      "     | > loader_time: 0.0053  (0.006900217474960699)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:25:45 -- STEP: 353/811 -- GLOBAL_STEP: 1975\u001b[0m\n",
      "     | > loss: 3.1120052337646484  (3.2066007342622234)\n",
      "     | > log_mle: 0.7406935691833496  (0.762694575800099)\n",
      "     | > loss_dur: 2.371311664581299  (2.443906151876908)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(5.7935, device='cuda:0')  (tensor(6.2847, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.8415  (0.602375414148606)\n",
      "     | > loader_time: 0.0048  (0.006936617005648086)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:26:04 -- STEP: 378/811 -- GLOBAL_STEP: 2000\u001b[0m\n",
      "     | > loss: 3.2069106101989746  (3.202031235215525)\n",
      "     | > log_mle: 0.7412325143814087  (0.7612189033990187)\n",
      "     | > loss_dur: 2.4656782150268555  (2.440812325982189)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(5.9721, device='cuda:0')  (tensor(6.2575, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.728  (0.6114948584289148)\n",
      "     | > loader_time: 0.0072  (0.007161693598227526)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:26:19 -- STEP: 403/811 -- GLOBAL_STEP: 2025\u001b[0m\n",
      "     | > loss: 3.0247883796691895  (3.194992368925298)\n",
      "     | > log_mle: 0.7451590299606323  (0.7598142586925783)\n",
      "     | > loss_dur: 2.2796294689178467  (2.435178105943551)\n",
      "     | > amp_scaler: 16384.0  (16424.655086848627)\n",
      "     | > grad_norm: tensor(5.6888, device='cuda:0')  (tensor(6.2138, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.5338  (0.6110219482156832)\n",
      "     | > loader_time: 0.0058  (0.007269384251634773)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:26:35 -- STEP: 428/811 -- GLOBAL_STEP: 2050\u001b[0m\n",
      "     | > loss: 3.0997612476348877  (3.1891905392441795)\n",
      "     | > log_mle: 0.7362549901008606  (0.7583530992269518)\n",
      "     | > loss_dur: 2.363506317138672  (2.430837436257121)\n",
      "     | > amp_scaler: 16384.0  (16422.28037383177)\n",
      "     | > grad_norm: tensor(5.7566, device='cuda:0')  (tensor(6.1881, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.6773  (0.6121286493595518)\n",
      "     | > loader_time: 0.0076  (0.007344369576356122)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:26:52 -- STEP: 453/811 -- GLOBAL_STEP: 2075\u001b[0m\n",
      "     | > loss: 3.051913261413574  (3.18298662840399)\n",
      "     | > log_mle: 0.7373062372207642  (0.7569469834531909)\n",
      "     | > loss_dur: 2.3146071434020996  (2.4260396415297816)\n",
      "     | > amp_scaler: 16384.0  (16420.167770419426)\n",
      "     | > grad_norm: tensor(5.7532, device='cuda:0')  (tensor(6.1630, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.3262  (0.6147354791232821)\n",
      "     | > loader_time: 0.0051  (0.007558505793017794)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:27:08 -- STEP: 478/811 -- GLOBAL_STEP: 2100\u001b[0m\n",
      "     | > loss: 3.117617607116699  (3.1778883450200865)\n",
      "     | > log_mle: 0.7253459692001343  (0.7555109079163446)\n",
      "     | > loss_dur: 2.3922715187072754  (2.4223774332381685)\n",
      "     | > amp_scaler: 16384.0  (16418.276150627607)\n",
      "     | > grad_norm: tensor(5.6650, device='cuda:0')  (tensor(6.1395, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.4543  (0.6160219064816274)\n",
      "     | > loader_time: 0.0044  (0.0076661474036372355)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:27:24 -- STEP: 503/811 -- GLOBAL_STEP: 2125\u001b[0m\n",
      "     | > loss: 3.0707907676696777  (3.1726523915057627)\n",
      "     | > log_mle: 0.7225219011306763  (0.7540388315856814)\n",
      "     | > loss_dur: 2.348268747329712  (2.4186135561281357)\n",
      "     | > amp_scaler: 16384.0  (16416.57256461231)\n",
      "     | > grad_norm: tensor(5.6386, device='cuda:0')  (tensor(6.1176, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.4628  (0.6161379273795705)\n",
      "     | > loader_time: 0.0066  (0.007866425258264862)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:27:40 -- STEP: 528/811 -- GLOBAL_STEP: 2150\u001b[0m\n",
      "     | > loss: 3.096560001373291  (3.166973826560107)\n",
      "     | > log_mle: 0.7168155908584595  (0.7524923807518051)\n",
      "     | > loss_dur: 2.379744529724121  (2.4144814425345618)\n",
      "     | > amp_scaler: 16384.0  (16415.030303030286)\n",
      "     | > grad_norm: tensor(5.7035, device='cuda:0')  (tensor(6.0959, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.7076  (0.6165892233451211)\n",
      "     | > loader_time: 0.0056  (0.007969973213744885)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:27:56 -- STEP: 553/811 -- GLOBAL_STEP: 2175\u001b[0m\n",
      "     | > loss: 3.015721082687378  (3.161165773760777)\n",
      "     | > log_mle: 0.7241144180297852  (0.7510143104556672)\n",
      "     | > loss_dur: 2.2916066646575928  (2.4101514605027203)\n",
      "     | > amp_scaler: 16384.0  (16413.627486437596)\n",
      "     | > grad_norm: tensor(5.6020, device='cuda:0')  (tensor(6.0737, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.6293  (0.6157556800255943)\n",
      "     | > loader_time: 0.0144  (0.008098578582404963)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:28:11 -- STEP: 578/811 -- GLOBAL_STEP: 2200\u001b[0m\n",
      "     | > loss: 3.043613910675049  (3.155751119847941)\n",
      "     | > log_mle: 0.7210056781768799  (0.7495156604938441)\n",
      "     | > loss_dur: 2.322608232498169  (2.4062354556416965)\n",
      "     | > amp_scaler: 16384.0  (16412.346020761226)\n",
      "     | > grad_norm: tensor(5.6251, device='cuda:0')  (tensor(6.0533, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 1.1201  (0.6147415419350863)\n",
      "     | > loader_time: 0.0059  (0.00805891178883483)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:28:26 -- STEP: 603/811 -- GLOBAL_STEP: 2225\u001b[0m\n",
      "     | > loss: 3.178483486175537  (3.150356354800425)\n",
      "     | > log_mle: 0.7072592377662659  (0.7480342204297952)\n",
      "     | > loss_dur: 2.471224308013916  (2.4023221310098375)\n",
      "     | > amp_scaler: 16384.0  (16411.17081260363)\n",
      "     | > grad_norm: tensor(5.7309, device='cuda:0')  (tensor(6.0333, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.496  (0.6142317928485023)\n",
      "     | > loader_time: 0.0054  (0.008115449750403661)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:28:42 -- STEP: 628/811 -- GLOBAL_STEP: 2250\u001b[0m\n",
      "     | > loss: 3.0607311725616455  (3.1448963219952426)\n",
      "     | > log_mle: 0.702937126159668  (0.7465603642972415)\n",
      "     | > loss_dur: 2.3577940464019775  (2.3983359541862628)\n",
      "     | > amp_scaler: 16384.0  (16410.089171974505)\n",
      "     | > grad_norm: tensor(5.6299, device='cuda:0')  (tensor(6.0141, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.6251  (0.6143443531291509)\n",
      "     | > loader_time: 0.0038  (0.008093650553636488)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:28:59 -- STEP: 653/811 -- GLOBAL_STEP: 2275\u001b[0m\n",
      "     | > loss: 2.8841872215270996  (3.138403385740691)\n",
      "     | > log_mle: 0.7133700847625732  (0.7450545986980246)\n",
      "     | > loss_dur: 2.1708171367645264  (2.393348783300262)\n",
      "     | > amp_scaler: 16384.0  (16409.0903522205)\n",
      "     | > grad_norm: tensor(5.3089, device='cuda:0')  (tensor(5.9939, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.4399  (0.6168367366148184)\n",
      "     | > loader_time: 0.0234  (0.00820142131121929)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:29:17 -- STEP: 678/811 -- GLOBAL_STEP: 2300\u001b[0m\n",
      "     | > loss: 2.949320077896118  (3.133326734413439)\n",
      "     | > log_mle: 0.7032771110534668  (0.7435623168242015)\n",
      "     | > loss_dur: 2.2460429668426514  (2.3897644147760397)\n",
      "     | > amp_scaler: 16384.0  (16408.165191740405)\n",
      "     | > grad_norm: tensor(5.4385, device='cuda:0')  (tensor(5.9756, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.6742  (0.6195948412284747)\n",
      "     | > loader_time: 0.0055  (0.00820899255859465)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:29:32 -- STEP: 703/811 -- GLOBAL_STEP: 2325\u001b[0m\n",
      "     | > loss: 3.000491142272949  (3.127965046704917)\n",
      "     | > log_mle: 0.7061767578125  (0.7420700026270673)\n",
      "     | > loss_dur: 2.294314384460449  (2.3858950406016195)\n",
      "     | > amp_scaler: 16384.0  (16407.30583214793)\n",
      "     | > grad_norm: tensor(5.4699, device='cuda:0')  (tensor(5.9572, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.4323  (0.6188295447131147)\n",
      "     | > loader_time: 0.0042  (0.0082341305392226)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:29:48 -- STEP: 728/811 -- GLOBAL_STEP: 2350\u001b[0m\n",
      "     | > loss: 2.979313850402832  (3.1219366815063974)\n",
      "     | > log_mle: 0.6998936533927917  (0.7405780903421914)\n",
      "     | > loss_dur: 2.2794201374053955  (2.3813585864973588)\n",
      "     | > amp_scaler: 16384.0  (16406.505494505494)\n",
      "     | > grad_norm: tensor(5.5040, device='cuda:0')  (tensor(5.9388, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.7251  (0.6189560710073833)\n",
      "     | > loader_time: 0.032  (0.008303564000915701)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:30:03 -- STEP: 753/811 -- GLOBAL_STEP: 2375\u001b[0m\n",
      "     | > loss: 2.9203734397888184  (3.115215034282223)\n",
      "     | > log_mle: 0.6976073980331421  (0.7390732537227797)\n",
      "     | > loss_dur: 2.2227659225463867  (2.376141775493446)\n",
      "     | > amp_scaler: 16384.0  (16405.758300132806)\n",
      "     | > grad_norm: tensor(5.3278, device='cuda:0')  (tensor(5.9192, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.6366  (0.6184166943726155)\n",
      "     | > loader_time: 0.0071  (0.00834838675946038)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:30:19 -- STEP: 778/811 -- GLOBAL_STEP: 2400\u001b[0m\n",
      "     | > loss: 2.898115634918213  (3.1088099951609234)\n",
      "     | > log_mle: 0.6940953731536865  (0.7376465137023238)\n",
      "     | > loss_dur: 2.2040202617645264  (2.3711634764021667)\n",
      "     | > amp_scaler: 16384.0  (16405.059125964002)\n",
      "     | > grad_norm: tensor(5.3056, device='cuda:0')  (tensor(5.9007, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.6888  (0.6174512384483319)\n",
      "     | > loader_time: 0.0044  (0.008454458879014836)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:30:32 -- STEP: 803/811 -- GLOBAL_STEP: 2425\u001b[0m\n",
      "     | > loss: 2.976294994354248  (3.1025966956636224)\n",
      "     | > log_mle: 0.6859859824180603  (0.7361774567797649)\n",
      "     | > loss_dur: 2.290308952331543  (2.3664192339848467)\n",
      "     | > amp_scaler: 16384.0  (16404.403486924028)\n",
      "     | > grad_norm: tensor(5.4287, device='cuda:0')  (tensor(5.8825, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.2803  (0.6146526597950557)\n",
      "     | > loader_time: 0.0053  (0.008467660597519744)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: 2.787235975265503  (2.787235975265503)\n",
      "     | > log_mle: 0.6971705555915833  (0.6971705555915833)\n",
      "     | > loss_dur: 2.0900654792785645  (2.0900654792785645)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: 2.719888210296631  (2.719888210296631)\n",
      "     | > log_mle: 0.6793206930160522  (0.6793206930160522)\n",
      "     | > loss_dur: 2.040567636489868  (2.040567636489868)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: 2.8049700260162354  (2.762429118156433)\n",
      "     | > log_mle: 0.7057256698608398  (0.692523181438446)\n",
      "     | > loss_dur: 2.0992443561553955  (2.069905996322632)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: 2.874983787536621  (2.7999473412831626)\n",
      "     | > log_mle: 0.6906598806381226  (0.6919020811716715)\n",
      "     | > loss_dur: 2.184323787689209  (2.1080452601114907)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: 2.855419635772705  (2.813815414905548)\n",
      "     | > log_mle: 0.6800602674484253  (0.68894162774086)\n",
      "     | > loss_dur: 2.1753594875335693  (2.1248738169670105)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: 2.813347339630127  (2.813721799850464)\n",
      "     | > log_mle: 0.685164749622345  (0.688186252117157)\n",
      "     | > loss_dur: 2.1281826496124268  (2.125535583496094)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: 2.8610410690307617  (2.8216083447138467)\n",
      "     | > log_mle: 0.6775373816490173  (0.686411440372467)\n",
      "     | > loss_dur: 2.1835036277770996  (2.1351969242095947)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: 2.8192837238311768  (2.8212762560163225)\n",
      "     | > log_mle: 0.6878724098205566  (0.6866201502936227)\n",
      "     | > loss_dur: 2.13141131401062  (2.1346561227525984)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: 2.7594783306121826  (2.813551515340805)\n",
      "     | > log_mle: 0.6814675331115723  (0.6859760731458664)\n",
      "     | > loss_dur: 2.0780107975006104  (2.1275754570961)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: 2.881086826324463  (2.821055438783434)\n",
      "     | > log_mle: 0.6916035413742065  (0.6866013473934598)\n",
      "     | > loss_dur: 2.189483404159546  (2.134454117880927)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: 2.815952777862549  (2.8205451726913453)\n",
      "     | > log_mle: 0.6948033571243286  (0.6874215483665467)\n",
      "     | > loss_dur: 2.1211495399475098  (2.1331236600875854)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: 2.8530309200286865  (2.823498422449285)\n",
      "     | > log_mle: 0.6907477378845215  (0.687723929231817)\n",
      "     | > loss_dur: 2.162283182144165  (2.1357745257290928)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: 2.7970311641693115  (2.821292817592621)\n",
      "     | > log_mle: 0.688241720199585  (0.6877670784791311)\n",
      "     | > loss_dur: 2.1087894439697266  (2.133525768915812)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: 2.9066200256347656  (2.8278564489804783)\n",
      "     | > log_mle: 0.6894830465316772  (0.6878990760216346)\n",
      "     | > loss_dur: 2.217137098312378  (2.139957409638625)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: 2.7682642936706543  (2.823599866458348)\n",
      "     | > log_mle: 0.6792751550674438  (0.6872830816677639)\n",
      "     | > loss_dur: 2.088989019393921  (2.136316810335432)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: 2.8054068088531494  (2.8223869959513346)\n",
      "     | > log_mle: 0.6909603476524353  (0.6875282327334086)\n",
      "     | > loss_dur: 2.1144464015960693  (2.1348587830861407)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: 2.8721492290496826  (2.8254971355199814)\n",
      "     | > log_mle: 0.6811611652374268  (0.6871302910149097)\n",
      "     | > loss_dur: 2.190988063812256  (2.138366863131523)\n",
      "\n",
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.003769233822822571 \u001b[0m(-0.0007562935352325439)\n",
      "     | > avg_loss:\u001b[92m 2.8254971355199814 \u001b[0m(-0.4290478676557541)\n",
      "     | > avg_log_mle:\u001b[92m 0.6871302910149097 \u001b[0m(-0.09098374098539352)\n",
      "     | > avg_loss_dur:\u001b[92m 2.138366863131523 \u001b[0m(-0.33806413412094116)\n",
      "\n",
      " > BEST MODEL : train/run-February-22-2025_01+01AM-9b6e3e6/best_model_2433.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 3/10\u001b[0m\n",
      " --> train/run-February-22-2025_01+01AM-9b6e3e6\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-22 01:30:46) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:30:54 -- STEP: 17/811 -- GLOBAL_STEP: 2450\u001b[0m\n",
      "     | > loss: 2.9323158264160156  (2.9423874266007366)\n",
      "     | > log_mle: 0.698108971118927  (0.695973301635069)\n",
      "     | > loss_dur: 2.2342069149017334  (2.246414086397956)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(5.3523, device='cuda:0')  (tensor(5.3591, device='cuda:0'))\n",
      "     | > current_lr: 7.5e-07 \n",
      "     | > step_time: 0.3661  (0.34740732697879567)\n",
      "     | > loader_time: 0.0039  (0.004255449070649988)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:31:02 -- STEP: 42/811 -- GLOBAL_STEP: 2475\u001b[0m\n",
      "     | > loss: 2.74354887008667  (2.9020052012943083)\n",
      "     | > log_mle: 0.6876963376998901  (0.6937503190267653)\n",
      "     | > loss_dur: 2.0558526515960693  (2.2082548538843794)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(5.1378, device='cuda:0')  (tensor(5.2995, device='cuda:0'))\n",
      "     | > current_lr: 7.5e-07 \n",
      "     | > step_time: 0.4749  (0.3425997211819603)\n",
      "     | > loader_time: 0.0045  (0.004239939507983979)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:31:15 -- STEP: 67/811 -- GLOBAL_STEP: 2500\u001b[0m\n",
      "     | > loss: 2.868861675262451  (2.8743243680071475)\n",
      "     | > log_mle: 0.6855260133743286  (0.6919019044335208)\n",
      "     | > loss_dur: 2.183335781097412  (2.1824224493396818)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(5.2502, device='cuda:0')  (tensor(5.2532, device='cuda:0'))\n",
      "     | > current_lr: 7.5e-07 \n",
      "     | > step_time: 0.3634  (0.39776636949226035)\n",
      "     | > loader_time: 0.021  (0.004766531844637288)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:31:29 -- STEP: 92/811 -- GLOBAL_STEP: 2525\u001b[0m\n",
      "     | > loss: 2.7949132919311523  (2.8525214920873228)\n",
      "     | > log_mle: 0.6834226846694946  (0.6902945236019464)\n",
      "     | > loss_dur: 2.1114907264709473  (2.1622269542320915)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(5.0023, device='cuda:0')  (tensor(5.2164, device='cuda:0'))\n",
      "     | > current_lr: 7.5e-07 \n",
      "     | > step_time: 0.3878  (0.43791756681773975)\n",
      "     | > loader_time: 0.0039  (0.005066223766492762)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:31:43 -- STEP: 117/811 -- GLOBAL_STEP: 2550\u001b[0m\n",
      "     | > loss: 2.8077120780944824  (2.84363811240237)\n",
      "     | > log_mle: 0.6758391857147217  (0.6879970069624418)\n",
      "     | > loss_dur: 2.1318728923797607  (2.1556410993266306)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(5.0389, device='cuda:0')  (tensor(5.1958, device='cuda:0'))\n",
      "     | > current_lr: 7.5e-07 \n",
      "     | > step_time: 0.5676  (0.4628227653666439)\n",
      "     | > loader_time: 0.0049  (0.004936134713327785)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:31:57 -- STEP: 142/811 -- GLOBAL_STEP: 2575\u001b[0m\n",
      "     | > loss: 2.8274989128112793  (2.8314204182423337)\n",
      "     | > log_mle: 0.6713112592697144  (0.685925435012495)\n",
      "     | > loss_dur: 2.1561877727508545  (2.145494978192826)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(5.0410, device='cuda:0')  (tensor(5.1717, device='cuda:0'))\n",
      "     | > current_lr: 7.5e-07 \n",
      "     | > step_time: 0.4968  (0.48084065276132504)\n",
      "     | > loader_time: 0.0198  (0.005547024834323938)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:32:11 -- STEP: 167/811 -- GLOBAL_STEP: 2600\u001b[0m\n",
      "     | > loss: 2.780198574066162  (2.8218792655510816)\n",
      "     | > log_mle: 0.6662867069244385  (0.6836525619386912)\n",
      "     | > loss_dur: 2.1139118671417236  (2.138226696117194)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(5.0907, device='cuda:0')  (tensor(5.1515, device='cuda:0'))\n",
      "     | > current_lr: 7.5e-07 \n",
      "     | > step_time: 0.4124  (0.4866317631955632)\n",
      "     | > loader_time: 0.0105  (0.005758332635114295)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:32:25 -- STEP: 192/811 -- GLOBAL_STEP: 2625\u001b[0m\n",
      "     | > loss: 2.827695369720459  (2.8088791631162167)\n",
      "     | > log_mle: 0.6611131429672241  (0.681330737968286)\n",
      "     | > loss_dur: 2.1665823459625244  (2.1275484189391127)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(5.1200, device='cuda:0')  (tensor(5.1280, device='cuda:0'))\n",
      "     | > current_lr: 7.5e-07 \n",
      "     | > step_time: 0.3969  (0.4976913308103879)\n",
      "     | > loader_time: 0.004  (0.005694781740506492)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:32:39 -- STEP: 217/811 -- GLOBAL_STEP: 2650\u001b[0m\n",
      "     | > loss: 2.6757471561431885  (2.796914790632538)\n",
      "     | > log_mle: 0.660391092300415  (0.6793028910039208)\n",
      "     | > loss_dur: 2.0153560638427734  (2.1176118927617233)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.9515, device='cuda:0')  (tensor(5.1038, device='cuda:0'))\n",
      "     | > current_lr: 7.5e-07 \n",
      "     | > step_time: 0.4062  (0.5014644537103892)\n",
      "     | > loader_time: 0.016  (0.005709514090542421)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:32:52 -- STEP: 242/811 -- GLOBAL_STEP: 2675\u001b[0m\n",
      "     | > loss: 2.7845511436462402  (2.7864477437389783)\n",
      "     | > log_mle: 0.6621036529541016  (0.6769798095068656)\n",
      "     | > loss_dur: 2.1224474906921387  (2.109467930537612)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(5.0444, device='cuda:0')  (tensor(5.0810, device='cuda:0'))\n",
      "     | > current_lr: 7.5e-07 \n",
      "     | > step_time: 0.5903  (0.5047074704130822)\n",
      "     | > loader_time: 0.0055  (0.005803841204682659)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:33:07 -- STEP: 267/811 -- GLOBAL_STEP: 2700\u001b[0m\n",
      "     | > loss: 2.702927589416504  (2.7765942262799554)\n",
      "     | > log_mle: 0.6496663689613342  (0.6745942132303332)\n",
      "     | > loss_dur: 2.0532612800598145  (2.1020000097010483)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.9195, device='cuda:0')  (tensor(5.0607, device='cuda:0'))\n",
      "     | > current_lr: 7.5e-07 \n",
      "     | > step_time: 0.4957  (0.5127980217951518)\n",
      "     | > loader_time: 0.0044  (0.00580748547328992)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:33:22 -- STEP: 292/811 -- GLOBAL_STEP: 2725\u001b[0m\n",
      "     | > loss: 2.6316945552825928  (2.769016968877349)\n",
      "     | > log_mle: 0.644832968711853  (0.6723342101051384)\n",
      "     | > loss_dur: 1.9868615865707397  (2.0966827559144545)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.7773, device='cuda:0')  (tensor(5.0436, device='cuda:0'))\n",
      "     | > current_lr: 7.5e-07 \n",
      "     | > step_time: 0.6063  (0.5181048496128766)\n",
      "     | > loader_time: 0.0059  (0.006069040461762312)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:33:37 -- STEP: 317/811 -- GLOBAL_STEP: 2750\u001b[0m\n",
      "     | > loss: 2.6559157371520996  (2.7608017462661225)\n",
      "     | > log_mle: 0.6391785144805908  (0.6702771942698242)\n",
      "     | > loss_dur: 2.016737222671509  (2.0905245482357526)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.7683, device='cuda:0')  (tensor(5.0266, device='cuda:0'))\n",
      "     | > current_lr: 7.5e-07 \n",
      "     | > step_time: 0.7387  (0.5241826287579465)\n",
      "     | > loader_time: 0.008  (0.0062664540408161554)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:33:51 -- STEP: 342/811 -- GLOBAL_STEP: 2775\u001b[0m\n",
      "     | > loss: 2.599088668823242  (2.7522506783580236)\n",
      "     | > log_mle: 0.6418133974075317  (0.6681170259651384)\n",
      "     | > loss_dur: 1.9572752714157104  (2.084133648384385)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.7244, device='cuda:0')  (tensor(5.0073, device='cuda:0'))\n",
      "     | > current_lr: 7.5e-07 \n",
      "     | > step_time: 0.5498  (0.5261277113741605)\n",
      "     | > loader_time: 0.0124  (0.00652587832066051)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:34:06 -- STEP: 367/811 -- GLOBAL_STEP: 2800\u001b[0m\n",
      "     | > loss: 2.6076912879943848  (2.7431629145827547)\n",
      "     | > log_mle: 0.6297531127929688  (0.6659173996312092)\n",
      "     | > loss_dur: 1.9779382944107056  (2.077245510891283)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.7357, device='cuda:0')  (tensor(4.9884, device='cuda:0'))\n",
      "     | > current_lr: 7.5e-07 \n",
      "     | > step_time: 0.4979  (0.5304149983689314)\n",
      "     | > loader_time: 0.0049  (0.006655599505764914)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:34:21 -- STEP: 392/811 -- GLOBAL_STEP: 2825\u001b[0m\n",
      "     | > loss: 2.604869842529297  (2.734832420032852)\n",
      "     | > log_mle: 0.6275557279586792  (0.6637107658447049)\n",
      "     | > loss_dur: 1.9773141145706177  (2.071121649778619)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.6685, device='cuda:0')  (tensor(4.9695, device='cuda:0'))\n",
      "     | > current_lr: 7.5e-07 \n",
      "     | > step_time: 0.6047  (0.5347944826495894)\n",
      "     | > loader_time: 0.0058  (0.0067053564957210016)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:34:36 -- STEP: 417/811 -- GLOBAL_STEP: 2850\u001b[0m\n",
      "     | > loss: 2.596318006515503  (2.7254997185951804)\n",
      "     | > log_mle: 0.6221301555633545  (0.6616391658211209)\n",
      "     | > loss_dur: 1.9741878509521484  (2.0638605476283347)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.6672, device='cuda:0')  (tensor(4.9502, device='cuda:0'))\n",
      "     | > current_lr: 7.5e-07 \n",
      "     | > step_time: 0.4947  (0.5363440313499326)\n",
      "     | > loader_time: 0.0141  (0.0070452861648669365)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:34:51 -- STEP: 442/811 -- GLOBAL_STEP: 2875\u001b[0m\n",
      "     | > loss: 2.64937424659729  (2.716563255538768)\n",
      "     | > log_mle: 0.6267234683036804  (0.6594628056519709)\n",
      "     | > loss_dur: 2.022650718688965  (2.057100444897268)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.7178, device='cuda:0')  (tensor(4.9319, device='cuda:0'))\n",
      "     | > current_lr: 7.5e-07 \n",
      "     | > step_time: 0.7382  (0.5397296744773834)\n",
      "     | > loader_time: 0.0316  (0.007240140060493851)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:35:06 -- STEP: 467/811 -- GLOBAL_STEP: 2900\u001b[0m\n",
      "     | > loss: 2.614802837371826  (2.7080411523006207)\n",
      "     | > log_mle: 0.6135638952255249  (0.6573280239003115)\n",
      "     | > loss_dur: 2.001239061355591  (2.0507131240607825)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.6705, device='cuda:0')  (tensor(4.9141, device='cuda:0'))\n",
      "     | > current_lr: 7.5e-07 \n",
      "     | > step_time: 0.6284  (0.5417084448853198)\n",
      "     | > loader_time: 0.006  (0.007342199697229032)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:35:21 -- STEP: 492/811 -- GLOBAL_STEP: 2925\u001b[0m\n",
      "     | > loss: 2.509922504425049  (2.7003052971227386)\n",
      "     | > log_mle: 0.6149188280105591  (0.6551667216832073)\n",
      "     | > loss_dur: 1.8950036764144897  (2.0451385705936236)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.4848, device='cuda:0')  (tensor(4.8972, device='cuda:0'))\n",
      "     | > current_lr: 7.5e-07 \n",
      "     | > step_time: 0.4364  (0.5444537536884716)\n",
      "     | > loader_time: 0.0048  (0.007503430533215285)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:35:35 -- STEP: 517/811 -- GLOBAL_STEP: 2950\u001b[0m\n",
      "     | > loss: 2.541226387023926  (2.6924556205535537)\n",
      "     | > log_mle: 0.6128706932067871  (0.653055685862351)\n",
      "     | > loss_dur: 1.9283555746078491  (2.039399930310202)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.5470, device='cuda:0')  (tensor(4.8810, device='cuda:0'))\n",
      "     | > current_lr: 7.5e-07 \n",
      "     | > step_time: 0.5793  (0.5447447129328896)\n",
      "     | > loader_time: 0.0112  (0.007623839424472714)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:35:51 -- STEP: 542/811 -- GLOBAL_STEP: 2975\u001b[0m\n",
      "     | > loss: 2.5490634441375732  (2.684374231254042)\n",
      "     | > log_mle: 0.6026864051818848  (0.6508962895817423)\n",
      "     | > loss_dur: 1.9463770389556885  (2.033477936723575)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.6143, device='cuda:0')  (tensor(4.8645, device='cuda:0'))\n",
      "     | > current_lr: 7.5e-07 \n",
      "     | > step_time: 0.4486  (0.5473868019906362)\n",
      "     | > loader_time: 0.0047  (0.007656305038621067)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:36:06 -- STEP: 567/811 -- GLOBAL_STEP: 3000\u001b[0m\n",
      "     | > loss: 2.50618314743042  (2.676257210854289)\n",
      "     | > log_mle: 0.6013872623443604  (0.6487992395379135)\n",
      "     | > loss_dur: 1.9047960042953491  (2.0274579663756023)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.4977, device='cuda:0')  (tensor(4.8476, device='cuda:0'))\n",
      "     | > current_lr: 7.5e-07 \n",
      "     | > step_time: 0.6552  (0.5497788508312628)\n",
      "     | > loader_time: 0.0065  (0.007709493082036419)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:36:22 -- STEP: 592/811 -- GLOBAL_STEP: 3025\u001b[0m\n",
      "     | > loss: 2.539355993270874  (2.6687501568246526)\n",
      "     | > log_mle: 0.6008912324905396  (0.6467238970704984)\n",
      "     | > loss_dur: 1.9384647607803345  (2.0220262543172454)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.5218, device='cuda:0')  (tensor(4.8319, device='cuda:0'))\n",
      "     | > current_lr: 7.5e-07 \n",
      "     | > step_time: 0.7314  (0.5527328651499108)\n",
      "     | > loader_time: 0.0048  (0.007818114113163304)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:36:38 -- STEP: 617/811 -- GLOBAL_STEP: 3050\u001b[0m\n",
      "     | > loss: 2.5131490230560303  (2.6614644639495895)\n",
      "     | > log_mle: 0.5913885831832886  (0.6446381266345086)\n",
      "     | > loss_dur: 1.9217604398727417  (2.0168263328712994)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.5032, device='cuda:0')  (tensor(4.8169, device='cuda:0'))\n",
      "     | > current_lr: 7.5e-07 \n",
      "     | > step_time: 0.9086  (0.5564265096593333)\n",
      "     | > loader_time: 0.0137  (0.00792187114202416)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:36:53 -- STEP: 642/811 -- GLOBAL_STEP: 3075\u001b[0m\n",
      "     | > loss: 2.43332839012146  (2.653467568653024)\n",
      "     | > log_mle: 0.5876227617263794  (0.6425607847833195)\n",
      "     | > loss_dur: 1.8457056283950806  (2.010906778206334)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.3888, device='cuda:0')  (tensor(4.8014, device='cuda:0'))\n",
      "     | > current_lr: 7.5e-07 \n",
      "     | > step_time: 0.5891  (0.5570761039620996)\n",
      "     | > loader_time: 0.0116  (0.007925250819910355)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:37:09 -- STEP: 667/811 -- GLOBAL_STEP: 3100\u001b[0m\n",
      "     | > loss: 2.475705146789551  (2.646354577709354)\n",
      "     | > log_mle: 0.5775116682052612  (0.6404718669100685)\n",
      "     | > loss_dur: 1.898193597793579  (2.0058827049907353)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.4787, device='cuda:0')  (tensor(4.7872, device='cuda:0'))\n",
      "     | > current_lr: 7.5e-07 \n",
      "     | > step_time: 0.581  (0.5590545712918541)\n",
      "     | > loader_time: 0.0134  (0.008143007844641824)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:37:24 -- STEP: 692/811 -- GLOBAL_STEP: 3125\u001b[0m\n",
      "     | > loss: 2.4131581783294678  (2.639591228755225)\n",
      "     | > log_mle: 0.57722407579422  (0.6383275019295643)\n",
      "     | > loss_dur: 1.835934042930603  (2.00126372062402)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.3594, device='cuda:0')  (tensor(4.7733, device='cuda:0'))\n",
      "     | > current_lr: 7.5e-07 \n",
      "     | > step_time: 0.6687  (0.5611247709720817)\n",
      "     | > loader_time: 0.0049  (0.008160446420570329)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:37:40 -- STEP: 717/811 -- GLOBAL_STEP: 3150\u001b[0m\n",
      "     | > loss: 2.3583407402038574  (2.632329754583343)\n",
      "     | > log_mle: 0.5669997930526733  (0.6361938015021374)\n",
      "     | > loss_dur: 1.791340947151184  (1.9961359460982322)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.2927, device='cuda:0')  (tensor(4.7586, device='cuda:0'))\n",
      "     | > current_lr: 7.5e-07 \n",
      "     | > step_time: 0.8791  (0.5633027510330443)\n",
      "     | > loader_time: 0.0164  (0.008251794378794053)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:37:56 -- STEP: 742/811 -- GLOBAL_STEP: 3175\u001b[0m\n",
      "     | > loss: 2.3068764209747314  (2.624507557028391)\n",
      "     | > log_mle: 0.5712224841117859  (0.6341102804456441)\n",
      "     | > loss_dur: 1.7356538772583008  (1.9903972698350483)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.1743, device='cuda:0')  (tensor(4.7435, device='cuda:0'))\n",
      "     | > current_lr: 7.5e-07 \n",
      "     | > step_time: 0.58  (0.5645715367761914)\n",
      "     | > loader_time: 0.0235  (0.008289313059290145)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:38:11 -- STEP: 767/811 -- GLOBAL_STEP: 3200\u001b[0m\n",
      "     | > loss: 2.384817600250244  (2.6171468174597465)\n",
      "     | > log_mle: 0.5795263648033142  (0.6320649694743654)\n",
      "     | > loss_dur: 1.8052912950515747  (1.9850818419238894)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.3017, device='cuda:0')  (tensor(4.7292, device='cuda:0'))\n",
      "     | > current_lr: 7.5e-07 \n",
      "     | > step_time: 0.4515  (0.5660515216991528)\n",
      "     | > loader_time: 0.0064  (0.008301881332596397)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:38:27 -- STEP: 792/811 -- GLOBAL_STEP: 3225\u001b[0m\n",
      "     | > loss: 2.351069450378418  (2.6095244333599585)\n",
      "     | > log_mle: 0.5655852556228638  (0.6299947887809595)\n",
      "     | > loss_dur: 1.7854840755462646  (1.9795296389346173)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.2205, device='cuda:0')  (tensor(4.7144, device='cuda:0'))\n",
      "     | > current_lr: 7.5e-07 \n",
      "     | > step_time: 0.41  (0.5672404148963973)\n",
      "     | > loader_time: 0.0052  (0.008402718137008967)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: 2.250122308731079  (2.250122308731079)\n",
      "     | > log_mle: 0.5795291066169739  (0.5795291066169739)\n",
      "     | > loss_dur: 1.6705931425094604  (1.6705931425094604)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: 2.192974090576172  (2.192974090576172)\n",
      "     | > log_mle: 0.5646558403968811  (0.5646558403968811)\n",
      "     | > loss_dur: 1.628318190574646  (1.628318190574646)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: 2.3145103454589844  (2.253742218017578)\n",
      "     | > log_mle: 0.5949971675872803  (0.5798265039920807)\n",
      "     | > loss_dur: 1.7195132970809937  (1.6739157438278198)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: 2.302919626235962  (2.270134687423706)\n",
      "     | > log_mle: 0.5698914527893066  (0.5765148202578226)\n",
      "     | > loss_dur: 1.7330281734466553  (1.6936198870340984)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: 2.3161983489990234  (2.2816506028175354)\n",
      "     | > log_mle: 0.5544054508209229  (0.5709874778985977)\n",
      "     | > loss_dur: 1.7617930173873901  (1.7106631696224213)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: 2.262223958969116  (2.2777652740478516)\n",
      "     | > log_mle: 0.5555603504180908  (0.5679020524024964)\n",
      "     | > loss_dur: 1.7066636085510254  (1.709863257408142)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: 2.317718029022217  (2.284424066543579)\n",
      "     | > log_mle: 0.5439703464508057  (0.5639134347438812)\n",
      "     | > loss_dur: 1.7737476825714111  (1.7205106616020203)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: 2.2863669395446777  (2.2847016198294505)\n",
      "     | > log_mle: 0.5659183263778687  (0.5641998478344509)\n",
      "     | > loss_dur: 1.7204484939575195  (1.7205017805099487)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: 2.239379405975342  (2.2790363430976868)\n",
      "     | > log_mle: 0.561822772026062  (0.5639027133584023)\n",
      "     | > loss_dur: 1.6775566339492798  (1.7151336371898651)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: 2.311814785003662  (2.282678392198351)\n",
      "     | > log_mle: 0.5668981075286865  (0.5642355349328783)\n",
      "     | > loss_dur: 1.744916558265686  (1.718442850642734)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: 2.2611515522003174  (2.2805257081985473)\n",
      "     | > log_mle: 0.5696181654930115  (0.5647737979888916)\n",
      "     | > loss_dur: 1.6915333271026611  (1.7157518982887268)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: 2.3280482292175293  (2.2848459373820913)\n",
      "     | > log_mle: 0.5639969110488892  (0.5647031719034369)\n",
      "     | > loss_dur: 1.7640513181686401  (1.7201427546414463)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: 2.2476158142089844  (2.2817434271176658)\n",
      "     | > log_mle: 0.5670017004013062  (0.564894715944926)\n",
      "     | > loss_dur: 1.6806142330169678  (1.7168487111727397)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: 2.351733446121216  (2.287127274733323)\n",
      "     | > log_mle: 0.562313437461853  (0.5646961560616127)\n",
      "     | > loss_dur: 1.7894200086593628  (1.7224311186717107)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: 2.2231571674346924  (2.2825579813548496)\n",
      "     | > log_mle: 0.5591473579406738  (0.5642998133386885)\n",
      "     | > loss_dur: 1.6640098094940186  (1.7182581680161613)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: 2.288203001022339  (2.282934315999349)\n",
      "     | > log_mle: 0.567253828048706  (0.5644967476526896)\n",
      "     | > loss_dur: 1.7209491729736328  (1.7184375683466593)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: 2.3386034965515137  (2.2864136397838593)\n",
      "     | > log_mle: 0.5560240745544434  (0.5639672055840492)\n",
      "     | > loss_dur: 1.7825793027877808  (1.7224464267492294)\n",
      "\n",
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.0034173130989074707 \u001b[0m(-0.0003519207239151001)\n",
      "     | > avg_loss:\u001b[92m 2.2864136397838593 \u001b[0m(-0.5390834957361221)\n",
      "     | > avg_log_mle:\u001b[92m 0.5639672055840492 \u001b[0m(-0.12316308543086052)\n",
      "     | > avg_loss_dur:\u001b[92m 1.7224464267492294 \u001b[0m(-0.4159204363822937)\n",
      "\n",
      " > BEST MODEL : train/run-February-22-2025_01+01AM-9b6e3e6/best_model_3244.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 4/10\u001b[0m\n",
      " --> train/run-February-22-2025_01+01AM-9b6e3e6\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-22 01:38:46) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:38:50 -- STEP: 6/811 -- GLOBAL_STEP: 3250\u001b[0m\n",
      "     | > loss: 2.39892578125  (2.4858224391937256)\n",
      "     | > log_mle: 0.5850676894187927  (0.5838255981604258)\n",
      "     | > loss_dur: 1.8138580322265625  (1.9019968112309773)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.1634, device='cuda:0')  (tensor(4.4077, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 0.3124  (0.355976939201355)\n",
      "     | > loader_time: 0.0024  (0.0036859909693400064)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:39:00 -- STEP: 31/811 -- GLOBAL_STEP: 3275\u001b[0m\n",
      "     | > loss: 2.347076177597046  (2.4266611299207135)\n",
      "     | > log_mle: 0.5722472071647644  (0.5792085316873365)\n",
      "     | > loss_dur: 1.7748289108276367  (1.8474525905424548)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.2474, device='cuda:0')  (tensor(4.3543, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 0.2901  (0.35599034832369897)\n",
      "     | > loader_time: 0.0032  (0.004831375614289315)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:39:13 -- STEP: 56/811 -- GLOBAL_STEP: 3300\u001b[0m\n",
      "     | > loss: 2.2718353271484375  (2.3936776135649)\n",
      "     | > log_mle: 0.5735306143760681  (0.5775723425405366)\n",
      "     | > loss_dur: 1.6983047723770142  (1.8161052763462067)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.1580, device='cuda:0')  (tensor(4.3163, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 0.8685  (0.4326421959059579)\n",
      "     | > loader_time: 0.0042  (0.007561930588313512)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:39:27 -- STEP: 81/811 -- GLOBAL_STEP: 3325\u001b[0m\n",
      "     | > loss: 2.226219892501831  (2.378818762155227)\n",
      "     | > log_mle: 0.578980028629303  (0.5752572902926693)\n",
      "     | > loss_dur: 1.6472398042678833  (1.8035614725984173)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.1116, device='cuda:0')  (tensor(4.2981, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 0.6057  (0.4631949324666718)\n",
      "     | > loader_time: 0.0043  (0.007488130051412701)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:39:40 -- STEP: 106/811 -- GLOBAL_STEP: 3350\u001b[0m\n",
      "     | > loss: 2.3241395950317383  (2.366658905767044)\n",
      "     | > log_mle: 0.5665294528007507  (0.5721319374048485)\n",
      "     | > loss_dur: 1.7576102018356323  (1.7945269672375805)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.1876, device='cuda:0')  (tensor(4.2772, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 0.6193  (0.4782834367932014)\n",
      "     | > loader_time: 0.0067  (0.006980846512992428)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:39:54 -- STEP: 131/811 -- GLOBAL_STEP: 3375\u001b[0m\n",
      "     | > loss: 2.305527925491333  (2.3554415702819815)\n",
      "     | > log_mle: 0.5585541725158691  (0.5692288561631708)\n",
      "     | > loss_dur: 1.7469737529754639  (1.7862127072938525)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.2153, device='cuda:0')  (tensor(4.2629, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 0.5386  (0.48721075239982314)\n",
      "     | > loader_time: 0.0048  (0.007152349894283383)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:40:08 -- STEP: 156/811 -- GLOBAL_STEP: 3400\u001b[0m\n",
      "     | > loss: 2.1594886779785156  (2.347905513567801)\n",
      "     | > log_mle: 0.5508763194084167  (0.5661873507958195)\n",
      "     | > loss_dur: 1.608612298965454  (1.781718155512443)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.9111, device='cuda:0')  (tensor(4.2528, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 0.4405  (0.4977520704269409)\n",
      "     | > loader_time: 0.0043  (0.006821779104379507)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:40:22 -- STEP: 181/811 -- GLOBAL_STEP: 3425\u001b[0m\n",
      "     | > loss: 2.2541418075561523  (2.338258686645253)\n",
      "     | > log_mle: 0.5375542640686035  (0.5632121250115711)\n",
      "     | > loss_dur: 1.7165875434875488  (1.775046556035458)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.1369, device='cuda:0')  (tensor(4.2412, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 0.6157  (0.5057141938920835)\n",
      "     | > loader_time: 0.0045  (0.006611207572136136)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:40:36 -- STEP: 206/811 -- GLOBAL_STEP: 3450\u001b[0m\n",
      "     | > loss: 2.2484934329986572  (2.3285300465463408)\n",
      "     | > log_mle: 0.5278393626213074  (0.5601613235126425)\n",
      "     | > loss_dur: 1.7206541299819946  (1.7683687186935573)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.1329, device='cuda:0')  (tensor(4.2274, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 0.567  (0.5127604459095925)\n",
      "     | > loader_time: 0.0044  (0.006623190583534611)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:40:51 -- STEP: 231/811 -- GLOBAL_STEP: 3475\u001b[0m\n",
      "     | > loss: 2.2246286869049072  (2.3184543791271355)\n",
      "     | > log_mle: 0.5414459705352783  (0.5574465484330151)\n",
      "     | > loss_dur: 1.683182716369629  (1.7610078260496065)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.0825, device='cuda:0')  (tensor(4.2138, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 0.4966  (0.5211849945448175)\n",
      "     | > loader_time: 0.0045  (0.006506969402362774)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:41:05 -- STEP: 256/811 -- GLOBAL_STEP: 3500\u001b[0m\n",
      "     | > loss: 2.2364587783813477  (2.310016181319949)\n",
      "     | > log_mle: 0.5384799838066101  (0.5545667465776207)\n",
      "     | > loss_dur: 1.6979787349700928  (1.7554494300857186)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.0514, device='cuda:0')  (tensor(4.2019, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 0.5005  (0.5244752885773774)\n",
      "     | > loader_time: 0.0049  (0.006546705029904842)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:41:19 -- STEP: 281/811 -- GLOBAL_STEP: 3525\u001b[0m\n",
      "     | > loss: 2.225175619125366  (2.3036567121213825)\n",
      "     | > log_mle: 0.523225724697113  (0.5516085013800245)\n",
      "     | > loss_dur: 1.7019498348236084  (1.7520482052263415)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.0898, device='cuda:0')  (tensor(4.1936, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 0.326  (0.5274184403470399)\n",
      "     | > loader_time: 0.0039  (0.006563984202320465)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:41:34 -- STEP: 306/811 -- GLOBAL_STEP: 3550\u001b[0m\n",
      "     | > loss: 2.1906204223632812  (2.2972256467233256)\n",
      "     | > log_mle: 0.514946699142456  (0.5489825826454785)\n",
      "     | > loss_dur: 1.6756737232208252  (1.7482430599873362)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.0399, device='cuda:0')  (tensor(4.1868, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 0.4081  (0.5302875447117421)\n",
      "     | > loader_time: 0.0055  (0.00660899262023128)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:41:48 -- STEP: 331/811 -- GLOBAL_STEP: 3575\u001b[0m\n",
      "     | > loss: 2.169917583465576  (2.2904402993596893)\n",
      "     | > log_mle: 0.502347469329834  (0.5463407199008229)\n",
      "     | > loss_dur: 1.6675701141357422  (1.7440995759474187)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.0153, device='cuda:0')  (tensor(4.1776, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 0.7267  (0.5327047927141908)\n",
      "     | > loader_time: 0.0064  (0.006747297650017407)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:42:03 -- STEP: 356/811 -- GLOBAL_STEP: 3600\u001b[0m\n",
      "     | > loss: 2.184553384780884  (2.283359490083842)\n",
      "     | > log_mle: 0.5089845061302185  (0.5439112538869464)\n",
      "     | > loss_dur: 1.6755688190460205  (1.7394482332668948)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.0381, device='cuda:0')  (tensor(4.1678, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 0.4348  (0.5363061053029604)\n",
      "     | > loader_time: 0.0038  (0.006762368625469422)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:42:17 -- STEP: 381/811 -- GLOBAL_STEP: 3625\u001b[0m\n",
      "     | > loss: 2.1914453506469727  (2.2770882009521225)\n",
      "     | > log_mle: 0.4939873218536377  (0.5412773162986978)\n",
      "     | > loss_dur: 1.6974579095840454  (1.735810881524574)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.0827, device='cuda:0')  (tensor(4.1591, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 0.3429  (0.5367085145214409)\n",
      "     | > loader_time: 0.0083  (0.007027706761998455)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:42:31 -- STEP: 406/811 -- GLOBAL_STEP: 3650\u001b[0m\n",
      "     | > loss: 2.192012310028076  (2.2695707987094735)\n",
      "     | > log_mle: 0.5027774572372437  (0.539017323422902)\n",
      "     | > loss_dur: 1.6892348527908325  (1.73055347198336)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.0985, device='cuda:0')  (tensor(4.1482, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 0.4209  (0.5368640663588575)\n",
      "     | > loader_time: 0.0037  (0.007377259249757663)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:42:46 -- STEP: 431/811 -- GLOBAL_STEP: 3675\u001b[0m\n",
      "     | > loss: 2.1756303310394287  (2.2624699776244537)\n",
      "     | > log_mle: 0.4881878197193146  (0.536537957025515)\n",
      "     | > loss_dur: 1.6874425411224365  (1.7259320178330637)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.0798, device='cuda:0')  (tensor(4.1391, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 0.6712  (0.5392742439101853)\n",
      "     | > loader_time: 0.0087  (0.007506699130595975)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:43:01 -- STEP: 456/811 -- GLOBAL_STEP: 3700\u001b[0m\n",
      "     | > loss: 2.20863676071167  (2.2558501216403215)\n",
      "     | > log_mle: 0.49011164903640747  (0.5341994946724494)\n",
      "     | > loss_dur: 1.7185250520706177  (1.7216506247457706)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.0548, device='cuda:0')  (tensor(4.1308, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 0.3336  (0.5419083718667944)\n",
      "     | > loader_time: 0.0041  (0.00744035003478067)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:43:16 -- STEP: 481/811 -- GLOBAL_STEP: 3725\u001b[0m\n",
      "     | > loss: 2.1252903938293457  (2.2497184147705895)\n",
      "     | > log_mle: 0.4843693673610687  (0.5318460072276503)\n",
      "     | > loss_dur: 1.6409211158752441  (1.7178724062417996)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.0369, device='cuda:0')  (tensor(4.1231, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 0.5878  (0.5437905158917268)\n",
      "     | > loader_time: 0.0099  (0.007602509738501789)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:43:31 -- STEP: 506/811 -- GLOBAL_STEP: 3750\u001b[0m\n",
      "     | > loss: 2.157653331756592  (2.2438011546379957)\n",
      "     | > log_mle: 0.4778827428817749  (0.5296165232248462)\n",
      "     | > loss_dur: 1.6797704696655273  (1.7141846305296826)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.9793, device='cuda:0')  (tensor(4.1155, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 0.4884  (0.5467009407729493)\n",
      "     | > loader_time: 0.0053  (0.007648437390685553)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:43:47 -- STEP: 531/811 -- GLOBAL_STEP: 3775\u001b[0m\n",
      "     | > loss: 2.086258888244629  (2.2373929733161417)\n",
      "     | > log_mle: 0.4858655035495758  (0.5273541097587116)\n",
      "     | > loss_dur: 1.600393295288086  (1.7100388633329315)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.9255, device='cuda:0')  (tensor(4.1077, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 0.4495  (0.551068163636489)\n",
      "     | > loader_time: 0.0067  (0.007686198767969164)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:44:07 -- STEP: 556/811 -- GLOBAL_STEP: 3800\u001b[0m\n",
      "     | > loss: 2.1276352405548096  (2.231292479115424)\n",
      "     | > log_mle: 0.48006123304367065  (0.5251531983129417)\n",
      "     | > loss_dur: 1.6475740671157837  (1.7061392802128692)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.9720, device='cuda:0')  (tensor(4.1002, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 0.4253  (0.5605234216443065)\n",
      "     | > loader_time: 0.0068  (0.007822458692591825)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:44:27 -- STEP: 581/811 -- GLOBAL_STEP: 3825\u001b[0m\n",
      "     | > loss: 2.123704195022583  (2.225422717823219)\n",
      "     | > log_mle: 0.46821436285972595  (0.5229742263352407)\n",
      "     | > loss_dur: 1.6554899215698242  (1.7024484905646717)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.9800, device='cuda:0')  (tensor(4.0933, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 0.8685  (0.5701855825269896)\n",
      "     | > loader_time: 0.0101  (0.008219750530748483)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:44:47 -- STEP: 606/811 -- GLOBAL_STEP: 3850\u001b[0m\n",
      "     | > loss: 2.100853204727173  (2.2199164867007704)\n",
      "     | > log_mle: 0.4773758351802826  (0.5209256487809403)\n",
      "     | > loss_dur: 1.6234773397445679  (1.6989908373788638)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.9821, device='cuda:0')  (tensor(4.0869, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 0.6012  (0.578883219473432)\n",
      "     | > loader_time: 0.0317  (0.00845592958305535)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:45:07 -- STEP: 631/811 -- GLOBAL_STEP: 3875\u001b[0m\n",
      "     | > loss: 2.044466257095337  (2.2139102073176735)\n",
      "     | > log_mle: 0.4705082178115845  (0.5188813293603644)\n",
      "     | > loss_dur: 1.5739580392837524  (1.6950288776739275)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.8797, device='cuda:0')  (tensor(4.0800, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 0.4293  (0.5866546506171364)\n",
      "     | > loader_time: 0.0053  (0.008494664674326658)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:45:28 -- STEP: 656/811 -- GLOBAL_STEP: 3900\u001b[0m\n",
      "     | > loss: 2.07706618309021  (2.207779460382172)\n",
      "     | > log_mle: 0.45772358775138855  (0.5168659487602922)\n",
      "     | > loss_dur: 1.6193426847457886  (1.6909135107587023)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.8795, device='cuda:0')  (tensor(4.0729, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 0.8161  (0.5954158204357791)\n",
      "     | > loader_time: 0.0172  (0.008808848697964736)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:45:45 -- STEP: 681/811 -- GLOBAL_STEP: 3925\u001b[0m\n",
      "     | > loss: 2.047760486602783  (2.2028845856718386)\n",
      "     | > log_mle: 0.45947855710983276  (0.5148499781777336)\n",
      "     | > loss_dur: 1.5882819890975952  (1.6880346065750906)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.8467, device='cuda:0')  (tensor(4.0674, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 0.9676  (0.599076551487792)\n",
      "     | > loader_time: 0.0127  (0.008831924628931346)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:46:04 -- STEP: 706/811 -- GLOBAL_STEP: 3950\u001b[0m\n",
      "     | > loss: 2.0958995819091797  (2.197773181682944)\n",
      "     | > log_mle: 0.44876009225845337  (0.5128163107309398)\n",
      "     | > loss_dur: 1.6471394300460815  (1.684956870234384)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.9577, device='cuda:0')  (tensor(4.0615, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 0.9931  (0.603961404254686)\n",
      "     | > loader_time: 0.0431  (0.008993224449265782)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:46:20 -- STEP: 731/811 -- GLOBAL_STEP: 3975\u001b[0m\n",
      "     | > loss: 1.9311765432357788  (2.191889451401342)\n",
      "     | > log_mle: 0.4626554548740387  (0.5108813066570611)\n",
      "     | > loss_dur: 1.4685211181640625  (1.6810081438881266)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.7089, device='cuda:0')  (tensor(4.0547, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 0.554  (0.6046503646918422)\n",
      "     | > loader_time: 0.0079  (0.009051976549641709)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:46:36 -- STEP: 756/811 -- GLOBAL_STEP: 4000\u001b[0m\n",
      "     | > loss: 1.980452299118042  (2.1860097881662783)\n",
      "     | > log_mle: 0.45741984248161316  (0.5089401501038724)\n",
      "     | > loss_dur: 1.5230324268341064  (1.6770696375105116)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.7527, device='cuda:0')  (tensor(4.0477, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 0.812  (0.6053709624305599)\n",
      "     | > loader_time: 0.0054  (0.009010096075673586)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:46:53 -- STEP: 781/811 -- GLOBAL_STEP: 4025\u001b[0m\n",
      "     | > loss: 2.0200414657592773  (2.1800818325768048)\n",
      "     | > log_mle: 0.43554627895355225  (0.507128336937877)\n",
      "     | > loss_dur: 1.5844953060150146  (1.6729534957534067)\n",
      "     | > amp_scaler: 32768.0  (16677.695262483994)\n",
      "     | > grad_norm: tensor(3.8541, device='cuda:0')  (tensor(4.0403, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 1.0191  (0.6065203810776081)\n",
      "     | > loader_time: 0.0096  (0.008971332435266006)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:47:06 -- STEP: 806/811 -- GLOBAL_STEP: 4050\u001b[0m\n",
      "     | > loss: 1.9213370084762573  (2.1743182063694313)\n",
      "     | > log_mle: 0.4524807035923004  (0.5052463317257602)\n",
      "     | > loss_dur: 1.4688563346862793  (1.6690718751983074)\n",
      "     | > amp_scaler: 32768.0  (17176.774193548386)\n",
      "     | > grad_norm: tensor(3.6778, device='cuda:0')  (tensor(4.0334, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 0.3662  (0.603838755830049)\n",
      "     | > loader_time: 0.0052  (0.00903123188255442)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: 1.9125487804412842  (1.9125487804412842)\n",
      "     | > log_mle: 0.466235876083374  (0.466235876083374)\n",
      "     | > loss_dur: 1.4463129043579102  (1.4463129043579102)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: 1.841171383857727  (1.841171383857727)\n",
      "     | > log_mle: 0.4533684253692627  (0.4533684253692627)\n",
      "     | > loss_dur: 1.3878029584884644  (1.3878029584884644)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: 1.9325276613235474  (1.8868495225906372)\n",
      "     | > log_mle: 0.49186787009239197  (0.47261814773082733)\n",
      "     | > loss_dur: 1.440659761428833  (1.4142313599586487)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: 1.931903600692749  (1.9018675486246746)\n",
      "     | > log_mle: 0.45652610063552856  (0.4672541320323944)\n",
      "     | > loss_dur: 1.4753774404525757  (1.4346133867899578)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: 1.9440500736236572  (1.9124131798744202)\n",
      "     | > log_mle: 0.43855929374694824  (0.46008042246103287)\n",
      "     | > loss_dur: 1.505490779876709  (1.4523327350616455)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: 1.8839441537857056  (1.9067193746566773)\n",
      "     | > log_mle: 0.43732750415802  (0.4555298388004303)\n",
      "     | > loss_dur: 1.4466166496276855  (1.4511895179748535)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: 1.9851785898208618  (1.9197959105173747)\n",
      "     | > log_mle: 0.42166176438331604  (0.44988515973091125)\n",
      "     | > loss_dur: 1.5635168552398682  (1.469910740852356)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: 1.9215657711029053  (1.920048747743879)\n",
      "     | > log_mle: 0.4575099050998688  (0.4509744090693338)\n",
      "     | > loss_dur: 1.4640558958053589  (1.4690743344170707)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: 1.9023747444152832  (1.9178394973278046)\n",
      "     | > log_mle: 0.4516885578632355  (0.45106367766857147)\n",
      "     | > loss_dur: 1.4506862163543701  (1.466775819659233)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: 1.9608914852142334  (1.9226230515374079)\n",
      "     | > log_mle: 0.45253831148147583  (0.4512275258700053)\n",
      "     | > loss_dur: 1.5083531141281128  (1.4713955190446641)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: 1.8981337547302246  (1.9201741218566895)\n",
      "     | > log_mle: 0.4552762508392334  (0.4516323983669281)\n",
      "     | > loss_dur: 1.4428575038909912  (1.468541717529297)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: 1.9288363456726074  (1.9209615967490457)\n",
      "     | > log_mle: 0.4487573206424713  (0.45137102766470477)\n",
      "     | > loss_dur: 1.4800790548324585  (1.4695905663750388)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: 1.890425443649292  (1.9184169173240662)\n",
      "     | > log_mle: 0.4576112926006317  (0.45189104974269867)\n",
      "     | > loss_dur: 1.432814121246338  (1.4665258626143138)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: 1.9661389589309692  (1.9220878436015203)\n",
      "     | > log_mle: 0.44497618079185486  (0.4513591367464799)\n",
      "     | > loss_dur: 1.521162748336792  (1.4707286999775813)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: 1.8696540594100952  (1.9183425733021326)\n",
      "     | > log_mle: 0.4471795856952667  (0.451060597385679)\n",
      "     | > loss_dur: 1.4224745035171509  (1.4672819716589791)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: 1.9155226945877075  (1.9181545813878378)\n",
      "     | > log_mle: 0.4529244899749756  (0.45118485689163207)\n",
      "     | > loss_dur: 1.462598204612732  (1.4669697205225627)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: 1.9199784994125366  (1.9182685762643814)\n",
      "     | > log_mle: 0.44425976276397705  (0.45075203850865364)\n",
      "     | > loss_dur: 1.4757187366485596  (1.4675165340304375)\n",
      "\n",
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[91m 0.05183854699134827 \u001b[0m(+0.048421233892440796)\n",
      "     | > avg_loss:\u001b[92m 1.9182685762643814 \u001b[0m(-0.36814506351947784)\n",
      "     | > avg_log_mle:\u001b[92m 0.45075203850865364 \u001b[0m(-0.11321516707539558)\n",
      "     | > avg_loss_dur:\u001b[92m 1.4675165340304375 \u001b[0m(-0.25492989271879196)\n",
      "\n",
      " > BEST MODEL : train/run-February-22-2025_01+01AM-9b6e3e6/best_model_4055.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 5/10\u001b[0m\n",
      " --> train/run-February-22-2025_01+01AM-9b6e3e6\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-22 01:47:21) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:47:30 -- STEP: 20/811 -- GLOBAL_STEP: 4075\u001b[0m\n",
      "     | > loss: 2.011863946914673  (2.0675160944461823)\n",
      "     | > log_mle: 0.4824083149433136  (0.4767155185341835)\n",
      "     | > loss_dur: 1.5294556617736816  (1.5908005654811859)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.8581, device='cuda:0')  (tensor(3.7404, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-06 \n",
      "     | > step_time: 0.3083  (0.349839973449707)\n",
      "     | > loader_time: 0.0034  (0.004535055160522461)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:47:40 -- STEP: 45/811 -- GLOBAL_STEP: 4100\u001b[0m\n",
      "     | > loss: 1.89646577835083  (2.0216362688276504)\n",
      "     | > log_mle: 0.471087783575058  (0.4729662756125132)\n",
      "     | > loss_dur: 1.4253779649734497  (1.5486700005001495)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.6663, device='cuda:0')  (tensor(3.7888, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-06 \n",
      "     | > step_time: 0.4039  (0.37459187507629393)\n",
      "     | > loader_time: 0.0043  (0.005562252468532986)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:47:55 -- STEP: 70/811 -- GLOBAL_STEP: 4125\u001b[0m\n",
      "     | > loss: 1.9722223281860352  (2.0041476096425734)\n",
      "     | > log_mle: 0.45214545726776123  (0.47089935966900415)\n",
      "     | > loss_dur: 1.520076870918274  (1.5332482542310446)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.8116, device='cuda:0')  (tensor(3.7948, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-06 \n",
      "     | > step_time: 0.4522  (0.4393754618508475)\n",
      "     | > loader_time: 0.0041  (0.00582188538142613)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:48:09 -- STEP: 95/811 -- GLOBAL_STEP: 4150\u001b[0m\n",
      "     | > loss: 1.9481730461120605  (1.989721071092706)\n",
      "     | > log_mle: 0.4362911283969879  (0.469426627535569)\n",
      "     | > loss_dur: 1.511881947517395  (1.520294446694224)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.7549, device='cuda:0')  (tensor(3.7860, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-06 \n",
      "     | > step_time: 0.5035  (0.47372807452553195)\n",
      "     | > loader_time: 0.0041  (0.006691478428087736)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:48:24 -- STEP: 120/811 -- GLOBAL_STEP: 4175\u001b[0m\n",
      "     | > loss: 1.929549217224121  (1.9805133849382401)\n",
      "     | > log_mle: 0.4418320059776306  (0.466352200259765)\n",
      "     | > loss_dur: 1.4877172708511353  (1.5141611893971765)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.8204, device='cuda:0')  (tensor(3.7810, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-06 \n",
      "     | > step_time: 0.7829  (0.4975194255510966)\n",
      "     | > loader_time: 0.0048  (0.007270063956578573)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:48:39 -- STEP: 145/811 -- GLOBAL_STEP: 4200\u001b[0m\n",
      "     | > loss: 1.91970956325531  (1.9707712559864439)\n",
      "     | > log_mle: 0.46718427538871765  (0.4643912728490501)\n",
      "     | > loss_dur: 1.45252525806427  (1.5063799866314596)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.7080, device='cuda:0')  (tensor(3.7725, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-06 \n",
      "     | > step_time: 0.5992  (0.5087537403764396)\n",
      "     | > loader_time: 0.0056  (0.00747043017683358)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:48:53 -- STEP: 170/811 -- GLOBAL_STEP: 4225\u001b[0m\n",
      "     | > loss: 1.9194204807281494  (1.963708252766553)\n",
      "     | > log_mle: 0.4397451877593994  (0.461748865071465)\n",
      "     | > loss_dur: 1.47967529296875  (1.5019593912012443)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.7981, device='cuda:0')  (tensor(3.7672, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-06 \n",
      "     | > step_time: 0.4813  (0.5177004154990702)\n",
      "     | > loader_time: 0.0041  (0.00746609463411219)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:49:08 -- STEP: 195/811 -- GLOBAL_STEP: 4250\u001b[0m\n",
      "     | > loss: 1.8965321779251099  (1.952814316138243)\n",
      "     | > log_mle: 0.43570879101753235  (0.4590830697463109)\n",
      "     | > loss_dur: 1.4608234167099  (1.4937312492957489)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.6867, device='cuda:0')  (tensor(3.7568, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-06 \n",
      "     | > step_time: 0.5409  (0.5249574490082572)\n",
      "     | > loader_time: 0.0047  (0.007397703024057242)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:49:22 -- STEP: 220/811 -- GLOBAL_STEP: 4275\u001b[0m\n",
      "     | > loss: 1.8624120950698853  (1.944367271119898)\n",
      "     | > log_mle: 0.44282177090644836  (0.4569787244905125)\n",
      "     | > loss_dur: 1.4195903539657593  (1.4873885474421766)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.6858, device='cuda:0')  (tensor(3.7486, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-06 \n",
      "     | > step_time: 0.5597  (0.5285341273654595)\n",
      "     | > loader_time: 0.0127  (0.007421844655817206)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:49:36 -- STEP: 245/811 -- GLOBAL_STEP: 4300\u001b[0m\n",
      "     | > loss: 1.8684991598129272  (1.9369855661781468)\n",
      "     | > log_mle: 0.45731380581855774  (0.45467713268435733)\n",
      "     | > loss_dur: 1.411185383796692  (1.4823084339803583)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.7392, device='cuda:0')  (tensor(3.7416, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-06 \n",
      "     | > step_time: 0.6664  (0.5312305722917833)\n",
      "     | > loader_time: 0.0044  (0.007364886147635323)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:49:50 -- STEP: 270/811 -- GLOBAL_STEP: 4325\u001b[0m\n",
      "     | > loss: 1.8977162837982178  (1.9307800421008356)\n",
      "     | > log_mle: 0.44109365344047546  (0.4523924888284118)\n",
      "     | > loss_dur: 1.45662260055542  (1.4783875536035613)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.7065, device='cuda:0')  (tensor(3.7357, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-06 \n",
      "     | > step_time: 0.7354  (0.5323962494179058)\n",
      "     | > loader_time: 0.0044  (0.007403978595027217)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:50:06 -- STEP: 295/811 -- GLOBAL_STEP: 4350\u001b[0m\n",
      "     | > loss: 1.9220389127731323  (1.9258040601924313)\n",
      "     | > log_mle: 0.43419793248176575  (0.45030012918730916)\n",
      "     | > loss_dur: 1.487841010093689  (1.4755039316112715)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.7997, device='cuda:0')  (tensor(3.7325, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-06 \n",
      "     | > step_time: 0.5472  (0.5389830670114294)\n",
      "     | > loader_time: 0.0054  (0.007569102109488794)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:50:21 -- STEP: 320/811 -- GLOBAL_STEP: 4375\u001b[0m\n",
      "     | > loss: 1.8264724016189575  (1.919999185949564)\n",
      "     | > log_mle: 0.42214539647102356  (0.44850813299417497)\n",
      "     | > loss_dur: 1.4043270349502563  (1.471491053327918)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.6137, device='cuda:0')  (tensor(3.7275, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-06 \n",
      "     | > step_time: 0.4558  (0.5423319019377237)\n",
      "     | > loader_time: 0.0038  (0.007654401659965515)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:50:36 -- STEP: 345/811 -- GLOBAL_STEP: 4400\u001b[0m\n",
      "     | > loss: 1.8526653051376343  (1.914207625043565)\n",
      "     | > log_mle: 0.434479683637619  (0.4466745415459508)\n",
      "     | > loss_dur: 1.4181855916976929  (1.4675330832384632)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.6469, device='cuda:0')  (tensor(3.7206, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-06 \n",
      "     | > step_time: 0.8652  (0.5459958636242416)\n",
      "     | > loader_time: 0.0055  (0.007701400397480398)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:50:50 -- STEP: 370/811 -- GLOBAL_STEP: 4425\u001b[0m\n",
      "     | > loss: 1.8135812282562256  (1.9090513000617155)\n",
      "     | > log_mle: 0.4119179844856262  (0.4448908795376082)\n",
      "     | > loss_dur: 1.4016631841659546  (1.4641604204435603)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.6792, device='cuda:0')  (tensor(3.7152, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-06 \n",
      "     | > step_time: 0.633  (0.5477017241555295)\n",
      "     | > loader_time: 0.0048  (0.007854452648678338)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:51:06 -- STEP: 395/811 -- GLOBAL_STEP: 4450\u001b[0m\n",
      "     | > loss: 1.7964963912963867  (1.9037687971622128)\n",
      "     | > log_mle: 0.4274592697620392  (0.4431318458122543)\n",
      "     | > loss_dur: 1.36903715133667  (1.4606369513499582)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.5752, device='cuda:0')  (tensor(3.7093, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-06 \n",
      "     | > step_time: 0.6501  (0.5516663720336146)\n",
      "     | > loader_time: 0.0194  (0.008029893681972844)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:51:20 -- STEP: 420/811 -- GLOBAL_STEP: 4475\u001b[0m\n",
      "     | > loss: 1.8280563354492188  (1.898324024393445)\n",
      "     | > log_mle: 0.4136602282524109  (0.4415291754972367)\n",
      "     | > loss_dur: 1.414396047592163  (1.456794848896208)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.6297, device='cuda:0')  (tensor(3.7031, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-06 \n",
      "     | > step_time: 0.553  (0.5519908609844392)\n",
      "     | > loader_time: 0.0063  (0.008065649441310335)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:51:35 -- STEP: 445/811 -- GLOBAL_STEP: 4500\u001b[0m\n",
      "     | > loss: 1.8120907545089722  (1.8924996255488877)\n",
      "     | > log_mle: 0.4098321199417114  (0.4398584146847886)\n",
      "     | > loss_dur: 1.4022586345672607  (1.4526412109310705)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.6146, device='cuda:0')  (tensor(3.6958, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-06 \n",
      "     | > step_time: 0.5626  (0.554000082444609)\n",
      "     | > loader_time: 0.0062  (0.008025543341475925)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:51:51 -- STEP: 470/811 -- GLOBAL_STEP: 4525\u001b[0m\n",
      "     | > loss: 1.773496150970459  (1.8875595128282587)\n",
      "     | > log_mle: 0.3980023264884949  (0.43824691823188294)\n",
      "     | > loss_dur: 1.3754937648773193  (1.4493125938354652)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.5762, device='cuda:0')  (tensor(3.6904, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-06 \n",
      "     | > step_time: 0.5855  (0.5570670609778546)\n",
      "     | > loader_time: 0.0144  (0.008157015861348907)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:52:06 -- STEP: 495/811 -- GLOBAL_STEP: 4550\u001b[0m\n",
      "     | > loss: 1.7120281457901  (1.882609290546841)\n",
      "     | > log_mle: 0.41486692428588867  (0.4367873109350301)\n",
      "     | > loss_dur: 1.2971612215042114  (1.4458219790699505)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.4009, device='cuda:0')  (tensor(3.6846, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-06 \n",
      "     | > step_time: 0.6659  (0.5587814321421614)\n",
      "     | > loader_time: 0.0231  (0.008213949203491215)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:52:20 -- STEP: 520/811 -- GLOBAL_STEP: 4575\u001b[0m\n",
      "     | > loss: 1.7762612104415894  (1.8782217264175416)\n",
      "     | > log_mle: 0.38997364044189453  (0.43518835409329487)\n",
      "     | > loss_dur: 1.3862875699996948  (1.443033371521876)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.5467, device='cuda:0')  (tensor(3.6794, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-06 \n",
      "     | > step_time: 0.613  (0.5592525280438937)\n",
      "     | > loader_time: 0.0057  (0.008231453712169944)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:52:36 -- STEP: 545/811 -- GLOBAL_STEP: 4600\u001b[0m\n",
      "     | > loss: 1.81034255027771  (1.8733640237685738)\n",
      "     | > log_mle: 0.3932264447212219  (0.4337026115404356)\n",
      "     | > loss_dur: 1.4171160459518433  (1.4396614109704249)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.6070, device='cuda:0')  (tensor(3.6729, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-06 \n",
      "     | > step_time: 0.8212  (0.561815337084849)\n",
      "     | > loader_time: 0.0043  (0.008345481015126641)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:52:52 -- STEP: 570/811 -- GLOBAL_STEP: 4625\u001b[0m\n",
      "     | > loss: 1.7549982070922852  (1.8688387145075882)\n",
      "     | > log_mle: 0.4101940989494324  (0.4323043370978874)\n",
      "     | > loss_dur: 1.344804048538208  (1.4365343758934424)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.4971, device='cuda:0')  (tensor(3.6674, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-06 \n",
      "     | > step_time: 0.3628  (0.5634714800014831)\n",
      "     | > loader_time: 0.0047  (0.008414718561005174)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:53:07 -- STEP: 595/811 -- GLOBAL_STEP: 4650\u001b[0m\n",
      "     | > loss: 1.7385505437850952  (1.8644726452707243)\n",
      "     | > log_mle: 0.39544105529785156  (0.430950320017438)\n",
      "     | > loss_dur: 1.3431094884872437  (1.4335223238007364)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.4991, device='cuda:0')  (tensor(3.6618, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-06 \n",
      "     | > step_time: 0.8673  (0.564672274148765)\n",
      "     | > loader_time: 0.0103  (0.008418998798402418)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:53:23 -- STEP: 620/811 -- GLOBAL_STEP: 4675\u001b[0m\n",
      "     | > loss: 1.7676024436950684  (1.860126684173461)\n",
      "     | > log_mle: 0.40271222591400146  (0.4296574727662148)\n",
      "     | > loss_dur: 1.364890217781067  (1.4304692099171308)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.5370, device='cuda:0')  (tensor(3.6562, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-06 \n",
      "     | > step_time: 0.8144  (0.5675019637230905)\n",
      "     | > loader_time: 0.0183  (0.008512421961753601)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:53:39 -- STEP: 645/811 -- GLOBAL_STEP: 4700\u001b[0m\n",
      "     | > loss: 1.7845144271850586  (1.8553024243938832)\n",
      "     | > log_mle: 0.394145667552948  (0.42831847219504127)\n",
      "     | > loss_dur: 1.3903687000274658  (1.4269839508588928)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.5949, device='cuda:0')  (tensor(3.6498, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-06 \n",
      "     | > step_time: 0.5503  (0.5689898801404379)\n",
      "     | > loader_time: 0.0121  (0.008610119930533474)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:53:54 -- STEP: 670/811 -- GLOBAL_STEP: 4725\u001b[0m\n",
      "     | > loss: 1.7497425079345703  (1.8512928601521164)\n",
      "     | > log_mle: 0.3763628602027893  (0.4269396016402031)\n",
      "     | > loss_dur: 1.3733795881271362  (1.424353257399887)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.5390, device='cuda:0')  (tensor(3.6448, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-06 \n",
      "     | > step_time: 0.5301  (0.5707592469542779)\n",
      "     | > loader_time: 0.0053  (0.00871487589024786)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:54:10 -- STEP: 695/811 -- GLOBAL_STEP: 4750\u001b[0m\n",
      "     | > loss: 1.7876653671264648  (1.8475141103319126)\n",
      "     | > log_mle: 0.40944987535476685  (0.42557147839944137)\n",
      "     | > loss_dur: 1.3782154321670532  (1.421942630946208)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.5555, device='cuda:0')  (tensor(3.6398, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-06 \n",
      "     | > step_time: 0.7065  (0.5719090911124254)\n",
      "     | > loader_time: 0.0408  (0.008768168456262826)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:54:25 -- STEP: 720/811 -- GLOBAL_STEP: 4775\u001b[0m\n",
      "     | > loss: 1.7683911323547363  (1.8434192288253042)\n",
      "     | > log_mle: 0.37365400791168213  (0.42420236505568026)\n",
      "     | > loss_dur: 1.3947371244430542  (1.4192168626520376)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.5275, device='cuda:0')  (tensor(3.6343, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-06 \n",
      "     | > step_time: 0.4625  (0.5720656239324148)\n",
      "     | > loader_time: 0.0047  (0.008797470066282488)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:54:41 -- STEP: 745/811 -- GLOBAL_STEP: 4800\u001b[0m\n",
      "     | > loss: 1.701174259185791  (1.838637547044946)\n",
      "     | > log_mle: 0.40020233392715454  (0.42292590689339093)\n",
      "     | > loss_dur: 1.3009718656539917  (1.4157116390714715)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.4502, device='cuda:0')  (tensor(3.6275, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-06 \n",
      "     | > step_time: 0.5459  (0.5738785727712132)\n",
      "     | > loader_time: 0.0055  (0.008830604617227646)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:54:56 -- STEP: 770/811 -- GLOBAL_STEP: 4825\u001b[0m\n",
      "     | > loss: 1.7144606113433838  (1.8343490670253704)\n",
      "     | > log_mle: 0.3942590355873108  (0.4217250626969647)\n",
      "     | > loss_dur: 1.3202016353607178  (1.4126240032059811)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.4480, device='cuda:0')  (tensor(3.6209, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-06 \n",
      "     | > step_time: 0.421  (0.5745489634476698)\n",
      "     | > loader_time: 0.0061  (0.008896960530962263)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:55:12 -- STEP: 795/811 -- GLOBAL_STEP: 4850\u001b[0m\n",
      "     | > loss: 1.709869146347046  (1.829867604543578)\n",
      "     | > log_mle: 0.37868040800094604  (0.42042732092569457)\n",
      "     | > loss_dur: 1.331188678741455  (1.4094402829056272)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.4439, device='cuda:0')  (tensor(3.6142, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-06 \n",
      "     | > step_time: 0.7007  (0.5769778929416493)\n",
      "     | > loader_time: 0.0062  (0.008889103235688598)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: 1.6133522987365723  (1.6133522987365723)\n",
      "     | > log_mle: 0.40486830472946167  (0.40486830472946167)\n",
      "     | > loss_dur: 1.2084840536117554  (1.2084840536117554)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: 1.5351111888885498  (1.5351111888885498)\n",
      "     | > log_mle: 0.3895326256752014  (0.3895326256752014)\n",
      "     | > loss_dur: 1.1455785036087036  (1.1455785036087036)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: 1.6333420276641846  (1.5842266082763672)\n",
      "     | > log_mle: 0.4323590397834778  (0.4109458327293396)\n",
      "     | > loss_dur: 1.200982928276062  (1.1732807159423828)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: 1.6351068019866943  (1.6011866728464763)\n",
      "     | > log_mle: 0.393507719039917  (0.40513312816619873)\n",
      "     | > loss_dur: 1.2415990829467773  (1.1960535049438477)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: 1.650067687034607  (1.613406926393509)\n",
      "     | > log_mle: 0.37438786029815674  (0.39744681119918823)\n",
      "     | > loss_dur: 1.2756798267364502  (1.2159600853919983)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: 1.592085361480713  (1.6091426134109497)\n",
      "     | > log_mle: 0.3698144555091858  (0.39192034006118776)\n",
      "     | > loss_dur: 1.2222708463668823  (1.217222237586975)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: 1.6838046312332153  (1.621586283047994)\n",
      "     | > log_mle: 0.35215747356414795  (0.38529319564501446)\n",
      "     | > loss_dur: 1.3316471576690674  (1.2362930576006572)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: 1.6119616031646729  (1.6202113287789481)\n",
      "     | > log_mle: 0.39748650789260864  (0.38703509739467074)\n",
      "     | > loss_dur: 1.2144750356674194  (1.2331761973244804)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: 1.601330041885376  (1.6178511679172516)\n",
      "     | > log_mle: 0.38852882385253906  (0.3872218132019043)\n",
      "     | > loss_dur: 1.212801218032837  (1.230629324913025)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: 1.6676702499389648  (1.6233866214752197)\n",
      "     | > log_mle: 0.3874630928039551  (0.3872486220465766)\n",
      "     | > loss_dur: 1.2802071571350098  (1.2361379729376898)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: 1.5954599380493164  (1.6205939531326294)\n",
      "     | > log_mle: 0.3906872868537903  (0.387592488527298)\n",
      "     | > loss_dur: 1.204772710800171  (1.233001446723938)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: 1.6244795322418213  (1.6209471875971013)\n",
      "     | > log_mle: 0.3836868405342102  (0.38723742961883545)\n",
      "     | > loss_dur: 1.2407927513122559  (1.2337097471410579)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: 1.5976366996765137  (1.6190046469370525)\n",
      "     | > log_mle: 0.39555609226226807  (0.38793065150578815)\n",
      "     | > loss_dur: 1.2020806074142456  (1.2310739854971569)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: 1.6696515083312988  (1.6229005593519945)\n",
      "     | > log_mle: 0.3778098225593567  (0.3871521262022165)\n",
      "     | > loss_dur: 1.2918416261672974  (1.2357484193948598)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: 1.583622932434082  (1.6200950145721436)\n",
      "     | > log_mle: 0.38352757692337036  (0.38689322982515606)\n",
      "     | > loss_dur: 1.2000954151153564  (1.2332017762320382)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: 1.6204493045806885  (1.6201186339060465)\n",
      "     | > log_mle: 0.388296902179718  (0.38698680798212687)\n",
      "     | > loss_dur: 1.2321523427963257  (1.2331318140029908)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: 1.630444884300232  (1.6207640245556831)\n",
      "     | > log_mle: 0.3831446170806885  (0.38674667105078697)\n",
      "     | > loss_dur: 1.2473002672195435  (1.2340173423290253)\n",
      "\n",
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.011228621006011963 \u001b[0m(-0.040609925985336304)\n",
      "     | > avg_loss:\u001b[92m 1.6207640245556831 \u001b[0m(-0.2975045517086983)\n",
      "     | > avg_log_mle:\u001b[92m 0.38674667105078697 \u001b[0m(-0.06400536745786667)\n",
      "     | > avg_loss_dur:\u001b[92m 1.2340173423290253 \u001b[0m(-0.2334991917014122)\n",
      "\n",
      " > BEST MODEL : train/run-February-22-2025_01+01AM-9b6e3e6/best_model_4866.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 6/10\u001b[0m\n",
      " --> train/run-February-22-2025_01+01AM-9b6e3e6\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-22 01:55:31) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:55:36 -- STEP: 9/811 -- GLOBAL_STEP: 4875\u001b[0m\n",
      "     | > loss: 1.914139986038208  (1.8107544978459675)\n",
      "     | > log_mle: 0.423015296459198  (0.41746894187397426)\n",
      "     | > loss_dur: 1.4911246299743652  (1.3932855526606243)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.7733, device='cuda:0')  (tensor(3.5613, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 0.3596  (0.3770880964067247)\n",
      "     | > loader_time: 0.0041  (0.0040842956966824)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:55:45 -- STEP: 34/811 -- GLOBAL_STEP: 4900\u001b[0m\n",
      "     | > loss: 1.6616191864013672  (1.73620422447429)\n",
      "     | > log_mle: 0.42442864179611206  (0.41178471814183626)\n",
      "     | > loss_dur: 1.2371906042099  (1.324419494937448)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.3888, device='cuda:0')  (tensor(3.4895, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 0.3675  (0.36574384044198427)\n",
      "     | > loader_time: 0.0048  (0.004734901820912081)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:55:59 -- STEP: 59/811 -- GLOBAL_STEP: 4925\u001b[0m\n",
      "     | > loss: 1.6402380466461182  (1.7064228845854936)\n",
      "     | > log_mle: 0.40761226415634155  (0.411205287707054)\n",
      "     | > loss_dur: 1.2326257228851318  (1.2952175867759574)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.3281, device='cuda:0')  (tensor(3.4317, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 0.3961  (0.4374877032587084)\n",
      "     | > loader_time: 0.0034  (0.0058828935784808675)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:56:13 -- STEP: 84/811 -- GLOBAL_STEP: 4950\u001b[0m\n",
      "     | > loss: 1.6442967653274536  (1.692871237084979)\n",
      "     | > log_mle: 0.39917993545532227  (0.4104042489613806)\n",
      "     | > loss_dur: 1.2451168298721313  (1.2824669835113347)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.2959, device='cuda:0')  (tensor(3.3901, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 0.3296  (0.4705523791767302)\n",
      "     | > loader_time: 0.0052  (0.006383458773295085)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:56:28 -- STEP: 109/811 -- GLOBAL_STEP: 4975\u001b[0m\n",
      "     | > loss: 1.6500310897827148  (1.6849423231334861)\n",
      "     | > log_mle: 0.4009096026420593  (0.4078520719611317)\n",
      "     | > loss_dur: 1.2491214275360107  (1.2770902465242862)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.3206, device='cuda:0')  (tensor(3.3768, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 0.5412  (0.49270146702407697)\n",
      "     | > loader_time: 0.0044  (0.00641643672908118)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:56:42 -- STEP: 134/811 -- GLOBAL_STEP: 5000\u001b[0m\n",
      "     | > loss: 1.6551620960235596  (1.6770799355720407)\n",
      "     | > log_mle: 0.3820316195487976  (0.4054987708579249)\n",
      "     | > loss_dur: 1.2731305360794067  (1.2715811604884137)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.3214, device='cuda:0')  (tensor(3.3674, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 0.6702  (0.5032804261392623)\n",
      "     | > loader_time: 0.0153  (0.006822838712094435)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:56:57 -- STEP: 159/811 -- GLOBAL_STEP: 5025\u001b[0m\n",
      "     | > loss: 1.6351282596588135  (1.671566718029526)\n",
      "     | > log_mle: 0.3850973844528198  (0.4030851487468625)\n",
      "     | > loss_dur: 1.2500308752059937  (1.268481564971636)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.3689, device='cuda:0')  (tensor(3.3599, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 0.4935  (0.5171995642800002)\n",
      "     | > loader_time: 0.0055  (0.006775085281276103)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:57:12 -- STEP: 184/811 -- GLOBAL_STEP: 5050\u001b[0m\n",
      "     | > loss: 1.6098415851593018  (1.6643779582303504)\n",
      "     | > log_mle: 0.3696872591972351  (0.4005909171765267)\n",
      "     | > loss_dur: 1.2401543855667114  (1.2637870350609663)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.2969, device='cuda:0')  (tensor(3.3477, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 0.8465  (0.527424533729968)\n",
      "     | > loader_time: 0.0042  (0.006847182045812192)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:57:26 -- STEP: 209/811 -- GLOBAL_STEP: 5075\u001b[0m\n",
      "     | > loss: 1.6045995950698853  (1.6574917101974123)\n",
      "     | > log_mle: 0.38780462741851807  (0.3982833576829811)\n",
      "     | > loss_dur: 1.2167949676513672  (1.2592083478088023)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.2021, device='cuda:0')  (tensor(3.3365, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 0.5935  (0.5314744340175647)\n",
      "     | > loader_time: 0.0053  (0.007007895474228563)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:57:41 -- STEP: 234/811 -- GLOBAL_STEP: 5100\u001b[0m\n",
      "     | > loss: 1.6669559478759766  (1.6513805312988086)\n",
      "     | > log_mle: 0.36557304859161377  (0.3962344508140516)\n",
      "     | > loss_dur: 1.3013828992843628  (1.2551460760271456)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.3860, device='cuda:0')  (tensor(3.3232, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 0.7006  (0.5350600307823247)\n",
      "     | > loader_time: 0.0052  (0.006965990759368636)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:57:55 -- STEP: 259/811 -- GLOBAL_STEP: 5125\u001b[0m\n",
      "     | > loss: 1.5933905839920044  (1.6457636747581157)\n",
      "     | > log_mle: 0.3657238483428955  (0.3940546288223341)\n",
      "     | > loss_dur: 1.2276667356491089  (1.2517090423687092)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.3046, device='cuda:0')  (tensor(3.3132, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 0.8306  (0.5370937516790559)\n",
      "     | > loader_time: 0.0249  (0.007156959371677237)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:58:10 -- STEP: 284/811 -- GLOBAL_STEP: 5150\u001b[0m\n",
      "     | > loss: 1.5936453342437744  (1.6422632441554272)\n",
      "     | > log_mle: 0.3707907795906067  (0.39206034207428014)\n",
      "     | > loss_dur: 1.2228546142578125  (1.250202897568824)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.2940, device='cuda:0')  (tensor(3.3062, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 0.5765  (0.5419403633601229)\n",
      "     | > loader_time: 0.0065  (0.007377212316217557)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:58:25 -- STEP: 309/811 -- GLOBAL_STEP: 5175\u001b[0m\n",
      "     | > loss: 1.5301053524017334  (1.6379173662284425)\n",
      "     | > log_mle: 0.38038569688796997  (0.39044855414470814)\n",
      "     | > loss_dur: 1.1497195959091187  (1.2474688079364866)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.0788, device='cuda:0')  (tensor(3.2976, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 0.6451  (0.5445134963804074)\n",
      "     | > loader_time: 0.0207  (0.007485862688725049)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:58:39 -- STEP: 334/811 -- GLOBAL_STEP: 5200\u001b[0m\n",
      "     | > loss: 1.5459892749786377  (1.6338218700386087)\n",
      "     | > log_mle: 0.3671000003814697  (0.38856069511639135)\n",
      "     | > loss_dur: 1.178889274597168  (1.2452611712638497)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.0268, device='cuda:0')  (tensor(3.2889, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 0.5599  (0.5454162330684542)\n",
      "     | > loader_time: 0.0044  (0.007462896272807778)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:58:54 -- STEP: 359/811 -- GLOBAL_STEP: 5225\u001b[0m\n",
      "     | > loss: 1.5238734483718872  (1.6299569188386278)\n",
      "     | > log_mle: 0.35104429721832275  (0.38712021675282526)\n",
      "     | > loss_dur: 1.1728291511535645  (1.242836698516166)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.0350, device='cuda:0')  (tensor(3.2793, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 0.9229  (0.5482433745455937)\n",
      "     | > loader_time: 0.0048  (0.0075638725897063785)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:59:08 -- STEP: 384/811 -- GLOBAL_STEP: 5250\u001b[0m\n",
      "     | > loss: 1.5290486812591553  (1.6264630227039252)\n",
      "     | > log_mle: 0.3545263409614563  (0.3852858477427313)\n",
      "     | > loss_dur: 1.1745223999023438  (1.241177171779176)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.0676, device='cuda:0')  (tensor(3.2717, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 0.4023  (0.5488747165848806)\n",
      "     | > loader_time: 0.0094  (0.007699669649203618)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:59:23 -- STEP: 409/811 -- GLOBAL_STEP: 5275\u001b[0m\n",
      "     | > loss: 1.5554527044296265  (1.6224758595883986)\n",
      "     | > log_mle: 0.35291433334350586  (0.38394780212917645)\n",
      "     | > loss_dur: 1.2025383710861206  (1.2385280540345065)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.1269, device='cuda:0')  (tensor(3.2623, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 0.3289  (0.5492836583797384)\n",
      "     | > loader_time: 0.0047  (0.007974599567777076)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:59:39 -- STEP: 434/811 -- GLOBAL_STEP: 5300\u001b[0m\n",
      "     | > loss: 1.55411958694458  (1.6185247428406213)\n",
      "     | > log_mle: 0.3525407910346985  (0.3822870870477043)\n",
      "     | > loss_dur: 1.2015788555145264  (1.236237652840153)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.2025, device='cuda:0')  (tensor(3.2539, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 0.654  (0.5537259941276863)\n",
      "     | > loader_time: 0.0046  (0.00804831300462995)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 01:59:54 -- STEP: 459/811 -- GLOBAL_STEP: 5325\u001b[0m\n",
      "     | > loss: 1.5395662784576416  (1.6148183112050967)\n",
      "     | > log_mle: 0.3559383749961853  (0.38089815067829386)\n",
      "     | > loss_dur: 1.183627963066101  (1.2339201576050074)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.0432, device='cuda:0')  (tensor(3.2446, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 0.9712  (0.5555593453201594)\n",
      "     | > loader_time: 0.0051  (0.008119426781315678)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:00:08 -- STEP: 484/811 -- GLOBAL_STEP: 5350\u001b[0m\n",
      "     | > loss: 1.5831141471862793  (1.6115476902851384)\n",
      "     | > log_mle: 0.33791667222976685  (0.3793666035798955)\n",
      "     | > loss_dur: 1.2451975345611572  (1.2321810845501169)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.1733, device='cuda:0')  (tensor(3.2369, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 0.385  (0.5557937469364199)\n",
      "     | > loader_time: 0.0047  (0.00820098484843229)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:00:23 -- STEP: 509/811 -- GLOBAL_STEP: 5375\u001b[0m\n",
      "     | > loss: 1.574652075767517  (1.6085523659681755)\n",
      "     | > log_mle: 0.3401740789413452  (0.37796721248823434)\n",
      "     | > loss_dur: 1.2344779968261719  (1.2305851511964632)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.1599, device='cuda:0')  (tensor(3.2305, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 0.4373  (0.5566381040397)\n",
      "     | > loader_time: 0.0057  (0.00845121306848431)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:00:38 -- STEP: 534/811 -- GLOBAL_STEP: 5400\u001b[0m\n",
      "     | > loss: 1.5503469705581665  (1.6049672106232085)\n",
      "     | > log_mle: 0.36003684997558594  (0.3766505114929506)\n",
      "     | > loss_dur: 1.1903101205825806  (1.2283166970653037)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.0180, device='cuda:0')  (tensor(3.2218, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 0.7019  (0.5580870533703867)\n",
      "     | > loader_time: 0.0059  (0.008528086576568934)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:00:53 -- STEP: 559/811 -- GLOBAL_STEP: 5425\u001b[0m\n",
      "     | > loss: 1.5528085231781006  (1.601656001241134)\n",
      "     | > log_mle: 0.349537193775177  (0.3752803701727462)\n",
      "     | > loss_dur: 1.2032712697982788  (1.2263756286692749)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.0470, device='cuda:0')  (tensor(3.2143, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 0.5791  (0.5587795514326832)\n",
      "     | > loader_time: 0.0048  (0.008730412382559173)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:01:08 -- STEP: 584/811 -- GLOBAL_STEP: 5450\u001b[0m\n",
      "     | > loss: 1.5649333000183105  (1.5985850010016185)\n",
      "     | > log_mle: 0.3659301996231079  (0.3739466739129529)\n",
      "     | > loss_dur: 1.1990031003952026  (1.2246383248943176)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(2.9944, device='cuda:0')  (tensor(3.2071, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 0.4143  (0.561581523451087)\n",
      "     | > loader_time: 0.0068  (0.0087215190064417)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:01:24 -- STEP: 609/811 -- GLOBAL_STEP: 5475\u001b[0m\n",
      "     | > loss: 1.5045666694641113  (1.595662198826205)\n",
      "     | > log_mle: 0.342123806476593  (0.3726680871398969)\n",
      "     | > loss_dur: 1.162442922592163  (1.2229941094841672)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.0163, device='cuda:0')  (tensor(3.2002, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 0.9097  (0.5633188272736149)\n",
      "     | > loader_time: 0.0099  (0.008644520159816883)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:01:40 -- STEP: 634/811 -- GLOBAL_STEP: 5500\u001b[0m\n",
      "     | > loss: 1.5273497104644775  (1.5923693067267857)\n",
      "     | > log_mle: 0.3551729917526245  (0.3714364209103659)\n",
      "     | > loss_dur: 1.172176718711853  (1.220932884359209)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.0876, device='cuda:0')  (tensor(3.1924, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 0.4684  (0.5652156590663298)\n",
      "     | > loader_time: 0.0058  (0.008693004256167229)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:01:55 -- STEP: 659/811 -- GLOBAL_STEP: 5525\u001b[0m\n",
      "     | > loss: 1.5284312963485718  (1.5892524357449835)\n",
      "     | > log_mle: 0.34763312339782715  (0.3702301201672039)\n",
      "     | > loss_dur: 1.1807981729507446  (1.2190223143567438)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.0491, device='cuda:0')  (tensor(3.1846, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 0.399  (0.567183006153483)\n",
      "     | > loader_time: 0.0057  (0.008785612485477505)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:02:10 -- STEP: 684/811 -- GLOBAL_STEP: 5550\u001b[0m\n",
      "     | > loss: 1.5303434133529663  (1.5868291643976458)\n",
      "     | > log_mle: 0.31014299392700195  (0.36890137931931083)\n",
      "     | > loss_dur: 1.2202004194259644  (1.2179277833790805)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.0757, device='cuda:0')  (tensor(3.1786, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 0.5621  (0.5679424164587991)\n",
      "     | > loader_time: 0.015  (0.008916329570681005)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:02:26 -- STEP: 709/811 -- GLOBAL_STEP: 5575\u001b[0m\n",
      "     | > loss: 1.4659383296966553  (1.5843949928270231)\n",
      "     | > log_mle: 0.3247324228286743  (0.3676476630320501)\n",
      "     | > loss_dur: 1.141205906867981  (1.216747328323773)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(2.9010, device='cuda:0')  (tensor(3.1726, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 0.7883  (0.5692939062212687)\n",
      "     | > loader_time: 0.0055  (0.009026895961573135)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:02:43 -- STEP: 734/811 -- GLOBAL_STEP: 5600\u001b[0m\n",
      "     | > loss: 1.495898723602295  (1.5810954604876455)\n",
      "     | > log_mle: 0.3281649947166443  (0.36641980122967693)\n",
      "     | > loss_dur: 1.1677337884902954  (1.214675658080493)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(2.9409, device='cuda:0')  (tensor(3.1647, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 0.5832  (0.5722051683498661)\n",
      "     | > loader_time: 0.0095  (0.008989622547451068)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:02:58 -- STEP: 759/811 -- GLOBAL_STEP: 5625\u001b[0m\n",
      "     | > loss: 1.4913244247436523  (1.577985433250547)\n",
      "     | > log_mle: 0.3186628818511963  (0.36520042025995814)\n",
      "     | > loss_dur: 1.172661542892456  (1.212785011851897)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(2.9065, device='cuda:0')  (tensor(3.1565, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 0.5824  (0.5733983010956737)\n",
      "     | > loader_time: 0.0176  (0.008993013731261624)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:03:14 -- STEP: 784/811 -- GLOBAL_STEP: 5650\u001b[0m\n",
      "     | > loss: 1.4803144931793213  (1.5748042131260942)\n",
      "     | > log_mle: 0.32560795545578003  (0.36406612209975714)\n",
      "     | > loss_dur: 1.1547064781188965  (1.2107380899239557)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(2.9918, device='cuda:0')  (tensor(3.1487, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 0.6409  (0.5746705556402403)\n",
      "     | > loader_time: 0.0324  (0.009060654409077685)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:03:26 -- STEP: 809/811 -- GLOBAL_STEP: 5675\u001b[0m\n",
      "     | > loss: 1.4570119380950928  (1.5718001458789266)\n",
      "     | > log_mle: 0.3390875458717346  (0.3628532259882748)\n",
      "     | > loss_dur: 1.1179243326187134  (1.2089469188223365)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(2.8782, device='cuda:0')  (tensor(3.1417, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 0.3526  (0.5708444908316557)\n",
      "     | > loader_time: 0.0062  (0.009049425608442789)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: 1.4171357154846191  (1.4171357154846191)\n",
      "     | > log_mle: 0.35313040018081665  (0.35313040018081665)\n",
      "     | > loss_dur: 1.0640053749084473  (1.0640053749084473)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: 1.34634530544281  (1.34634530544281)\n",
      "     | > log_mle: 0.3371070623397827  (0.3371070623397827)\n",
      "     | > loss_dur: 1.0092382431030273  (1.0092382431030273)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: 1.4221820831298828  (1.3842636942863464)\n",
      "     | > log_mle: 0.379868745803833  (0.35848790407180786)\n",
      "     | > loss_dur: 1.0423133373260498  (1.0257757902145386)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: 1.4331510066986084  (1.4005594650904338)\n",
      "     | > log_mle: 0.340808629989624  (0.3525948127110799)\n",
      "     | > loss_dur: 1.0923423767089844  (1.0479646523793538)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: 1.443054437637329  (1.4111832082271576)\n",
      "     | > log_mle: 0.31934964656829834  (0.3442835211753845)\n",
      "     | > loss_dur: 1.1237047910690308  (1.066899687051773)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: 1.391319990158081  (1.4072105646133424)\n",
      "     | > log_mle: 0.3140386939048767  (0.33823455572128297)\n",
      "     | > loss_dur: 1.0772812366485596  (1.0689759969711303)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: 1.464684009552002  (1.416789472103119)\n",
      "     | > log_mle: 0.2959578037261963  (0.3311884303887685)\n",
      "     | > loss_dur: 1.1687262058258057  (1.085601031780243)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: 1.4231202602386475  (1.4176938704081945)\n",
      "     | > log_mle: 0.34515756368637085  (0.33318402085985455)\n",
      "     | > loss_dur: 1.0779627561569214  (1.0845098495483398)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: 1.3941243886947632  (1.4147476851940155)\n",
      "     | > log_mle: 0.335094690322876  (0.33342285454273224)\n",
      "     | > loss_dur: 1.0590296983718872  (1.0813248306512833)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: 1.455209732055664  (1.4192434681786432)\n",
      "     | > log_mle: 0.3338891863822937  (0.3334746691915724)\n",
      "     | > loss_dur: 1.1213204860687256  (1.0857687923643324)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: 1.3976491689682007  (1.4170840382575989)\n",
      "     | > log_mle: 0.3373984098434448  (0.33386704325675964)\n",
      "     | > loss_dur: 1.0602507591247559  (1.0832169890403747)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: 1.4140409231185913  (1.41680739142678)\n",
      "     | > log_mle: 0.3277808427810669  (0.33331375230442395)\n",
      "     | > loss_dur: 1.0862600803375244  (1.083493633703752)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: 1.3992154598236084  (1.4153413971265156)\n",
      "     | > log_mle: 0.34082621335983276  (0.333939790725708)\n",
      "     | > loss_dur: 1.0583893060684204  (1.0814016064008076)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: 1.4690442085266113  (1.4194723826188307)\n",
      "     | > log_mle: 0.3233482241630554  (0.3331250548362732)\n",
      "     | > loss_dur: 1.1456960439682007  (1.0863473323675303)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: 1.3947138786315918  (1.4177039180483137)\n",
      "     | > log_mle: 0.3301622271537781  (0.3329134242875235)\n",
      "     | > loss_dur: 1.0645517110824585  (1.0847905022757396)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: 1.4135053157806396  (1.4174240112304688)\n",
      "     | > log_mle: 0.3344123959541321  (0.3330133557319641)\n",
      "     | > loss_dur: 1.0790928602218628  (1.0844106594721479)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: 1.4369810819625854  (1.418646328151226)\n",
      "     | > log_mle: 0.32925450801849365  (0.3327784277498722)\n",
      "     | > loss_dur: 1.1077265739440918  (1.0858679041266444)\n",
      "\n",
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.0033444613218307495 \u001b[0m(-0.007884159684181213)\n",
      "     | > avg_loss:\u001b[92m 1.418646328151226 \u001b[0m(-0.2021176964044571)\n",
      "     | > avg_log_mle:\u001b[92m 0.3327784277498722 \u001b[0m(-0.053968243300914764)\n",
      "     | > avg_loss_dur:\u001b[92m 1.0858679041266444 \u001b[0m(-0.1481494382023809)\n",
      "\n",
      " > BEST MODEL : train/run-February-22-2025_01+01AM-9b6e3e6/best_model_5677.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 7/10\u001b[0m\n",
      " --> train/run-February-22-2025_01+01AM-9b6e3e6\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-22 02:03:38) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:03:50 -- STEP: 23/811 -- GLOBAL_STEP: 5700\u001b[0m\n",
      "     | > loss: 1.5111110210418701  (1.534935624703117)\n",
      "     | > log_mle: 0.34658724069595337  (0.3645387991614964)\n",
      "     | > loss_dur: 1.1645238399505615  (1.1703968410906584)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(2.9531, device='cuda:0')  (tensor(3.0296, device='cuda:0'))\n",
      "     | > current_lr: 1.75e-06 \n",
      "     | > step_time: 0.368  (0.3709601941316024)\n",
      "     | > loader_time: 0.0045  (0.005152070004007091)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:04:01 -- STEP: 48/811 -- GLOBAL_STEP: 5725\u001b[0m\n",
      "     | > loss: 1.5204192399978638  (1.4972307508190472)\n",
      "     | > log_mle: 0.383736252784729  (0.36119862024982763)\n",
      "     | > loss_dur: 1.1366829872131348  (1.1360321417450907)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(2.7726, device='cuda:0')  (tensor(2.9452, device='cuda:0'))\n",
      "     | > current_lr: 1.75e-06 \n",
      "     | > step_time: 0.5953  (0.39107459286848706)\n",
      "     | > loader_time: 0.0054  (0.00509886940320333)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:04:15 -- STEP: 73/811 -- GLOBAL_STEP: 5750\u001b[0m\n",
      "     | > loss: 1.4367666244506836  (1.4846313114035619)\n",
      "     | > log_mle: 0.37125998735427856  (0.35921165061323607)\n",
      "     | > loss_dur: 1.0655065774917603  (1.1254196656893378)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(2.7735, device='cuda:0')  (tensor(2.9059, device='cuda:0'))\n",
      "     | > current_lr: 1.75e-06 \n",
      "     | > step_time: 0.5819  (0.4478175019564694)\n",
      "     | > loader_time: 0.0191  (0.005724995103600907)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:04:30 -- STEP: 98/811 -- GLOBAL_STEP: 5775\u001b[0m\n",
      "     | > loss: 1.4948581457138062  (1.4762827486408001)\n",
      "     | > log_mle: 0.35572385787963867  (0.3577469538669197)\n",
      "     | > loss_dur: 1.1391342878341675  (1.1185358008559867)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(2.9338, device='cuda:0')  (tensor(2.8808, device='cuda:0'))\n",
      "     | > current_lr: 1.75e-06 \n",
      "     | > step_time: 0.6474  (0.4816722431961371)\n",
      "     | > loader_time: 0.0047  (0.006205850717972736)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:04:44 -- STEP: 123/811 -- GLOBAL_STEP: 5800\u001b[0m\n",
      "     | > loss: 1.4765965938568115  (1.4707235679393862)\n",
      "     | > log_mle: 0.33928197622299194  (0.35449345615821154)\n",
      "     | > loss_dur: 1.1373145580291748  (1.1162301166270807)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(2.8469, device='cuda:0')  (tensor(2.8739, device='cuda:0'))\n",
      "     | > current_lr: 1.75e-06 \n",
      "     | > step_time: 0.7827  (0.49980006179189296)\n",
      "     | > loader_time: 0.0452  (0.00650262251132872)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:04:58 -- STEP: 148/811 -- GLOBAL_STEP: 5825\u001b[0m\n",
      "     | > loss: 1.5001072883605957  (1.4655388690329891)\n",
      "     | > log_mle: 0.304080069065094  (0.3521794193499797)\n",
      "     | > loss_dur: 1.1960272789001465  (1.1133594529048814)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.0255, device='cuda:0')  (tensor(2.8683, device='cuda:0'))\n",
      "     | > current_lr: 1.75e-06 \n",
      "     | > step_time: 0.5201  (0.5076513080983549)\n",
      "     | > loader_time: 0.0047  (0.0067723699518152155)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:05:13 -- STEP: 173/811 -- GLOBAL_STEP: 5850\u001b[0m\n",
      "     | > loss: 1.3549251556396484  (1.4609264996699522)\n",
      "     | > log_mle: 0.3369879126548767  (0.34991693910146715)\n",
      "     | > loss_dur: 1.0179373025894165  (1.1110095633247676)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(2.6489, device='cuda:0')  (tensor(2.8628, device='cuda:0'))\n",
      "     | > current_lr: 1.75e-06 \n",
      "     | > step_time: 0.6099  (0.5190965261073471)\n",
      "     | > loader_time: 0.0041  (0.0069537686474750475)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:05:29 -- STEP: 198/811 -- GLOBAL_STEP: 5875\u001b[0m\n",
      "     | > loss: 1.4629255533218384  (1.4546065264277994)\n",
      "     | > log_mle: 0.33174586296081543  (0.3474952437058843)\n",
      "     | > loss_dur: 1.131179690361023  (1.10711128663535)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(2.8939, device='cuda:0')  (tensor(2.8559, device='cuda:0'))\n",
      "     | > current_lr: 1.75e-06 \n",
      "     | > step_time: 0.5678  (0.5325094449399698)\n",
      "     | > loader_time: 0.0037  (0.0069311086577598475)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:05:45 -- STEP: 223/811 -- GLOBAL_STEP: 5900\u001b[0m\n",
      "     | > loss: 1.397045612335205  (1.4491394806335864)\n",
      "     | > log_mle: 0.32241129875183105  (0.34517809467999916)\n",
      "     | > loss_dur: 1.074634313583374  (1.1039613894282967)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(2.7500, device='cuda:0')  (tensor(2.8464, device='cuda:0'))\n",
      "     | > current_lr: 1.75e-06 \n",
      "     | > step_time: 0.6202  (0.5408588492816871)\n",
      "     | > loader_time: 0.006  (0.006947676697119467)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:06:02 -- STEP: 248/811 -- GLOBAL_STEP: 5925\u001b[0m\n",
      "     | > loss: 1.4213488101959229  (1.445488943207649)\n",
      "     | > log_mle: 0.32148754596710205  (0.3430624825339163)\n",
      "     | > loss_dur: 1.0998612642288208  (1.1024264642788513)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(2.7618, device='cuda:0')  (tensor(2.8379, device='cuda:0'))\n",
      "     | > current_lr: 1.75e-06 \n",
      "     | > step_time: 0.712  (0.5562808696300753)\n",
      "     | > loader_time: 0.0163  (0.007171366483934462)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:06:19 -- STEP: 273/811 -- GLOBAL_STEP: 5950\u001b[0m\n",
      "     | > loss: 1.4284647703170776  (1.4420224624675713)\n",
      "     | > log_mle: 0.324548602104187  (0.34098759872136086)\n",
      "     | > loss_dur: 1.1039161682128906  (1.101034866366194)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(2.6910, device='cuda:0')  (tensor(2.8321, device='cuda:0'))\n",
      "     | > current_lr: 1.75e-06 \n",
      "     | > step_time: 0.5698  (0.5646089634179196)\n",
      "     | > loader_time: 0.0056  (0.007215469311445186)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:06:35 -- STEP: 298/811 -- GLOBAL_STEP: 5975\u001b[0m\n",
      "     | > loss: 1.405432939529419  (1.439318330095919)\n",
      "     | > log_mle: 0.3208006024360657  (0.3391268675359302)\n",
      "     | > loss_dur: 1.0846322774887085  (1.1001914641601125)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(2.8475, device='cuda:0')  (tensor(2.8300, device='cuda:0'))\n",
      "     | > current_lr: 1.75e-06 \n",
      "     | > step_time: 0.6271  (0.5692364745492104)\n",
      "     | > loader_time: 0.0047  (0.007175459157700504)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:06:49 -- STEP: 323/811 -- GLOBAL_STEP: 6000\u001b[0m\n",
      "     | > loss: 1.437875747680664  (1.4361537790888985)\n",
      "     | > log_mle: 0.30010467767715454  (0.3375073730391982)\n",
      "     | > loss_dur: 1.1377711296081543  (1.09864640734144)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(2.9461, device='cuda:0')  (tensor(2.8254, device='cuda:0'))\n",
      "     | > current_lr: 1.75e-06 \n",
      "     | > step_time: 0.6555  (0.5690210072248715)\n",
      "     | > loader_time: 0.0173  (0.007313690687480723)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:07:04 -- STEP: 348/811 -- GLOBAL_STEP: 6025\u001b[0m\n",
      "     | > loss: 1.36981201171875  (1.4330764320389988)\n",
      "     | > log_mle: 0.3090651035308838  (0.335861830533236)\n",
      "     | > loss_dur: 1.0607469081878662  (1.0972146016770399)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(2.6574, device='cuda:0')  (tensor(2.8187, device='cuda:0'))\n",
      "     | > current_lr: 1.75e-06 \n",
      "     | > step_time: 0.5996  (0.5710502602588174)\n",
      "     | > loader_time: 0.0048  (0.007318877625739435)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:07:19 -- STEP: 373/811 -- GLOBAL_STEP: 6050\u001b[0m\n",
      "     | > loss: 1.3721907138824463  (1.4298862794129528)\n",
      "     | > log_mle: 0.3101957440376282  (0.33424631711944514)\n",
      "     | > loss_dur: 1.061995029449463  (1.0956399624533057)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(2.6904, device='cuda:0')  (tensor(2.8117, device='cuda:0'))\n",
      "     | > current_lr: 1.75e-06 \n",
      "     | > step_time: 0.5647  (0.5727719762050437)\n",
      "     | > loader_time: 0.0043  (0.0074236744530399084)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:07:36 -- STEP: 398/811 -- GLOBAL_STEP: 6075\u001b[0m\n",
      "     | > loss: 1.402794599533081  (1.4272396627383022)\n",
      "     | > log_mle: 0.3089790344238281  (0.33263118722331)\n",
      "     | > loss_dur: 1.093815565109253  (1.0946084750657108)\n",
      "     | > amp_scaler: 32768.0  (17207.316582914573)\n",
      "     | > grad_norm: tensor(2.7428, device='cuda:0')  (tensor(2.8083, device='cuda:0'))\n",
      "     | > current_lr: 1.75e-06 \n",
      "     | > step_time: 1.0044  (0.5782830331792785)\n",
      "     | > loader_time: 0.0049  (0.00772713836114011)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:07:51 -- STEP: 423/811 -- GLOBAL_STEP: 6100\u001b[0m\n",
      "     | > loss: 1.3519808053970337  (1.4239328877018422)\n",
      "     | > log_mle: 0.31918418407440186  (0.3312425599312389)\n",
      "     | > loss_dur: 1.0327966213226318  (1.092690326502419)\n",
      "     | > amp_scaler: 32768.0  (18126.978723404245)\n",
      "     | > grad_norm: tensor(2.6648, device='cuda:0')  (tensor(2.8022, device='cuda:0'))\n",
      "     | > current_lr: 1.75e-06 \n",
      "     | > step_time: 0.3458  (0.5779487647063345)\n",
      "     | > loader_time: 0.0059  (0.0077353594714586315)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:08:07 -- STEP: 448/811 -- GLOBAL_STEP: 6125\u001b[0m\n",
      "     | > loss: 1.3624541759490967  (1.4207915453506372)\n",
      "     | > log_mle: 0.32246726751327515  (0.3297358768592989)\n",
      "     | > loss_dur: 1.0399868488311768  (1.0910556671608769)\n",
      "     | > amp_scaler: 32768.0  (18943.99999999998)\n",
      "     | > grad_norm: tensor(2.6303, device='cuda:0')  (tensor(2.7963, device='cuda:0'))\n",
      "     | > current_lr: 1.75e-06 \n",
      "     | > step_time: 0.4732  (0.5798715017735959)\n",
      "     | > loader_time: 0.0046  (0.00784558536750929)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:08:21 -- STEP: 473/811 -- GLOBAL_STEP: 6150\u001b[0m\n",
      "     | > loss: 1.3618052005767822  (1.4181552001336164)\n",
      "     | > log_mle: 0.3192352056503296  (0.3284011295431513)\n",
      "     | > loss_dur: 1.0425699949264526  (1.0897540692043097)\n",
      "     | > amp_scaler: 32768.0  (19674.65539112049)\n",
      "     | > grad_norm: tensor(2.7721, device='cuda:0')  (tensor(2.7915, device='cuda:0'))\n",
      "     | > current_lr: 1.75e-06 \n",
      "     | > step_time: 0.6578  (0.5792329548277262)\n",
      "     | > loader_time: 0.0061  (0.007930044896002799)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:08:37 -- STEP: 498/811 -- GLOBAL_STEP: 6175\u001b[0m\n",
      "     | > loss: 1.3590443134307861  (1.4154705165859212)\n",
      "     | > log_mle: 0.2997403144836426  (0.3270309478882327)\n",
      "     | > loss_dur: 1.0593039989471436  (1.088439567022055)\n",
      "     | > amp_scaler: 32768.0  (20331.9518072289)\n",
      "     | > grad_norm: tensor(2.6224, device='cuda:0')  (tensor(2.7865, device='cuda:0'))\n",
      "     | > current_lr: 1.75e-06 \n",
      "     | > step_time: 0.4853  (0.5802043805639429)\n",
      "     | > loader_time: 0.0229  (0.00810236911697081)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:08:52 -- STEP: 523/811 -- GLOBAL_STEP: 6200\u001b[0m\n",
      "     | > loss: 1.3503012657165527  (1.4128666099581166)\n",
      "     | > log_mle: 0.29736053943634033  (0.32558725247191667)\n",
      "     | > loss_dur: 1.0529407262802124  (1.0872793560046305)\n",
      "     | > amp_scaler: 32768.0  (20926.409177820253)\n",
      "     | > grad_norm: tensor(2.7122, device='cuda:0')  (tensor(2.7828, device='cuda:0'))\n",
      "     | > current_lr: 1.75e-06 \n",
      "     | > step_time: 0.3639  (0.5816649738734814)\n",
      "     | > loader_time: 0.0149  (0.00816761284895654)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:09:07 -- STEP: 548/811 -- GLOBAL_STEP: 6225\u001b[0m\n",
      "     | > loss: 1.3541975021362305  (1.4102971442859544)\n",
      "     | > log_mle: 0.2910616993904114  (0.324275547788091)\n",
      "     | > loss_dur: 1.0631358623504639  (1.0860215950838836)\n",
      "     | > amp_scaler: 32768.0  (21466.627737226263)\n",
      "     | > grad_norm: tensor(2.7475, device='cuda:0')  (tensor(2.7775, device='cuda:0'))\n",
      "     | > current_lr: 1.75e-06 \n",
      "     | > step_time: 0.426  (0.5814445262407735)\n",
      "     | > loader_time: 0.0048  (0.008255202404774016)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:09:24 -- STEP: 573/811 -- GLOBAL_STEP: 6250\u001b[0m\n",
      "     | > loss: 1.3795262575149536  (1.4078136819819513)\n",
      "     | > log_mle: 0.29689109325408936  (0.3230911552593971)\n",
      "     | > loss_dur: 1.0826351642608643  (1.0847225256823325)\n",
      "     | > amp_scaler: 32768.0  (21959.706806282702)\n",
      "     | > grad_norm: tensor(2.6999, device='cuda:0')  (tensor(2.7729, device='cuda:0'))\n",
      "     | > current_lr: 1.75e-06 \n",
      "     | > step_time: 0.4285  (0.5843632346048404)\n",
      "     | > loader_time: 0.0056  (0.008448021990258446)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:09:41 -- STEP: 598/811 -- GLOBAL_STEP: 6275\u001b[0m\n",
      "     | > loss: 1.321685552597046  (1.4054575709993635)\n",
      "     | > log_mle: 0.2929365038871765  (0.32196069949845396)\n",
      "     | > loss_dur: 1.0287489891052246  (1.083496870504175)\n",
      "     | > amp_scaler: 32768.0  (22411.558528428064)\n",
      "     | > grad_norm: tensor(2.5597, device='cuda:0')  (tensor(2.7668, device='cuda:0'))\n",
      "     | > current_lr: 1.75e-06 \n",
      "     | > step_time: 0.3925  (0.5886785362077795)\n",
      "     | > loader_time: 0.008  (0.008588330004127528)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:09:58 -- STEP: 623/811 -- GLOBAL_STEP: 6300\u001b[0m\n",
      "     | > loss: 1.3567240238189697  (1.4029726520970018)\n",
      "     | > log_mle: 0.3013381361961365  (0.3208426411232251)\n",
      "     | > loss_dur: 1.055385947227478  (1.0821300099213655)\n",
      "     | > amp_scaler: 32768.0  (22827.146067415702)\n",
      "     | > grad_norm: tensor(2.6400, device='cuda:0')  (tensor(2.7614, device='cuda:0'))\n",
      "     | > current_lr: 1.75e-06 \n",
      "     | > step_time: 0.4127  (0.5913531083739205)\n",
      "     | > loader_time: 0.0066  (0.008583621075601103)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:10:15 -- STEP: 648/811 -- GLOBAL_STEP: 6325\u001b[0m\n",
      "     | > loss: 1.3059300184249878  (1.4002463379759857)\n",
      "     | > log_mle: 0.2913355827331543  (0.3196857371999894)\n",
      "     | > loss_dur: 1.0145944356918335  (1.0805605998561707)\n",
      "     | > amp_scaler: 32768.0  (23210.66666666664)\n",
      "     | > grad_norm: tensor(2.5917, device='cuda:0')  (tensor(2.7550, device='cuda:0'))\n",
      "     | > current_lr: 1.75e-06 \n",
      "     | > step_time: 0.3587  (0.5948596953609843)\n",
      "     | > loader_time: 0.0053  (0.008667491836312375)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:10:32 -- STEP: 673/811 -- GLOBAL_STEP: 6350\u001b[0m\n",
      "     | > loss: 1.2982159852981567  (1.3983098656426225)\n",
      "     | > log_mle: 0.28138232231140137  (0.3185104067045724)\n",
      "     | > loss_dur: 1.0168336629867554  (1.079799457786697)\n",
      "     | > amp_scaler: 32768.0  (23565.693907875157)\n",
      "     | > grad_norm: tensor(2.6143, device='cuda:0')  (tensor(2.7506, device='cuda:0'))\n",
      "     | > current_lr: 1.75e-06 \n",
      "     | > step_time: 0.4949  (0.5961818843858558)\n",
      "     | > loader_time: 0.0136  (0.00865576490427729)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:10:45 -- STEP: 698/811 -- GLOBAL_STEP: 6375\u001b[0m\n",
      "     | > loss: 1.3830320835113525  (1.396350975364533)\n",
      "     | > log_mle: 0.274938702583313  (0.31734276603491035)\n",
      "     | > loss_dur: 1.1080933809280396  (1.0790082084756878)\n",
      "     | > amp_scaler: 32768.0  (23895.28939828078)\n",
      "     | > grad_norm: tensor(2.7294, device='cuda:0')  (tensor(2.7460, device='cuda:0'))\n",
      "     | > current_lr: 1.75e-06 \n",
      "     | > step_time: 0.4433  (0.5941438811556314)\n",
      "     | > loader_time: 0.005  (0.0086309117369119)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:11:00 -- STEP: 723/811 -- GLOBAL_STEP: 6400\u001b[0m\n",
      "     | > loss: 1.2949179410934448  (1.3938866645963368)\n",
      "     | > log_mle: 0.2902628183364868  (0.3162170975864507)\n",
      "     | > loss_dur: 1.004655122756958  (1.077669566267919)\n",
      "     | > amp_scaler: 32768.0  (24202.091286307033)\n",
      "     | > grad_norm: tensor(2.4908, device='cuda:0')  (tensor(2.7399, device='cuda:0'))\n",
      "     | > current_lr: 1.75e-06 \n",
      "     | > step_time: 0.7554  (0.592810388092843)\n",
      "     | > loader_time: 0.0052  (0.0087257836369558)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:11:14 -- STEP: 748/811 -- GLOBAL_STEP: 6425\u001b[0m\n",
      "     | > loss: 1.3086293935775757  (1.3910864942214078)\n",
      "     | > log_mle: 0.28870487213134766  (0.31508387338350136)\n",
      "     | > loss_dur: 1.019924521446228  (1.0760026202004225)\n",
      "     | > amp_scaler: 32768.0  (24488.38502673795)\n",
      "     | > grad_norm: tensor(2.4603, device='cuda:0')  (tensor(2.7331, device='cuda:0'))\n",
      "     | > current_lr: 1.75e-06 \n",
      "     | > step_time: 0.9123  (0.5914970145506016)\n",
      "     | > loader_time: 0.005  (0.008730699353039587)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:11:29 -- STEP: 773/811 -- GLOBAL_STEP: 6450\u001b[0m\n",
      "     | > loss: 1.3528509140014648  (1.388654180362648)\n",
      "     | > log_mle: 0.2836679220199585  (0.31412885391079864)\n",
      "     | > loss_dur: 1.0691829919815063  (1.0745253253723333)\n",
      "     | > amp_scaler: 32768.0  (24756.16041397152)\n",
      "     | > grad_norm: tensor(2.6131, device='cuda:0')  (tensor(2.7274, device='cuda:0'))\n",
      "     | > current_lr: 1.75e-06 \n",
      "     | > step_time: 0.5903  (0.5915975246824234)\n",
      "     | > loader_time: 0.0366  (0.008827203303999616)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:11:44 -- STEP: 798/811 -- GLOBAL_STEP: 6475\u001b[0m\n",
      "     | > loss: 1.3037859201431274  (1.386098365287734)\n",
      "     | > log_mle: 0.2800772190093994  (0.3129752350779699)\n",
      "     | > loss_dur: 1.023708701133728  (1.073123129014682)\n",
      "     | > amp_scaler: 32768.0  (25007.15789473682)\n",
      "     | > grad_norm: tensor(2.5314, device='cuda:0')  (tensor(2.7227, device='cuda:0'))\n",
      "     | > current_lr: 1.75e-06 \n",
      "     | > step_time: 0.3137  (0.591993258710493)\n",
      "     | > loader_time: 0.0049  (0.00884206372693667)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: 1.2725098133087158  (1.2725098133087158)\n",
      "     | > log_mle: 0.3065081238746643  (0.3065081238746643)\n",
      "     | > loss_dur: 0.9660016298294067  (0.9660016298294067)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: 1.1951379776000977  (1.1951379776000977)\n",
      "     | > log_mle: 0.2894410490989685  (0.2894410490989685)\n",
      "     | > loss_dur: 0.9056969881057739  (0.9056969881057739)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: 1.2826910018920898  (1.2389144897460938)\n",
      "     | > log_mle: 0.3339911699295044  (0.31171610951423645)\n",
      "     | > loss_dur: 0.9486998915672302  (0.9271984398365021)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: 1.2778918743133545  (1.251906951268514)\n",
      "     | > log_mle: 0.2944263815879822  (0.3059528668721517)\n",
      "     | > loss_dur: 0.9834655523300171  (0.9459541440010071)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: 1.290182113647461  (1.2614757418632507)\n",
      "     | > log_mle: 0.27171945571899414  (0.2973945140838623)\n",
      "     | > loss_dur: 1.0184626579284668  (0.964081272482872)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: 1.2368451356887817  (1.2565496206283568)\n",
      "     | > log_mle: 0.2672794461250305  (0.2913715004920959)\n",
      "     | > loss_dur: 0.9695656895637512  (0.9651781558990479)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: 1.309628963470459  (1.2653961777687073)\n",
      "     | > log_mle: 0.24913763999938965  (0.2843325237433116)\n",
      "     | > loss_dur: 1.0604913234710693  (0.9810636838277181)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: 1.2662458419799805  (1.2655175583703178)\n",
      "     | > log_mle: 0.3004688024520874  (0.28663770641599384)\n",
      "     | > loss_dur: 0.9657770991325378  (0.9788798860141209)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: 1.2398499250411987  (1.2623091042041779)\n",
      "     | > log_mle: 0.2896043658256531  (0.28700853884220123)\n",
      "     | > loss_dur: 0.9502455592155457  (0.975300595164299)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: 1.3241889476776123  (1.2691846423678927)\n",
      "     | > log_mle: 0.2876816391944885  (0.28708332777023315)\n",
      "     | > loss_dur: 1.036507248878479  (0.9821013344658746)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: 1.2534573078155518  (1.2676119089126587)\n",
      "     | > log_mle: 0.29140567779541016  (0.28751556277275087)\n",
      "     | > loss_dur: 0.9620516300201416  (0.9800963640213013)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: 1.2554748058319092  (1.2665085359053179)\n",
      "     | > log_mle: 0.27967339754104614  (0.2868026386607777)\n",
      "     | > loss_dur: 0.975801408290863  (0.9797059135003523)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: 1.2467725276947021  (1.2648638685544331)\n",
      "     | > log_mle: 0.2930535078048706  (0.28732354442278546)\n",
      "     | > loss_dur: 0.9537190198898315  (0.9775403390328089)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: 1.3090605735778809  (1.2682636150946984)\n",
      "     | > log_mle: 0.2771136164665222  (0.2865381653492267)\n",
      "     | > loss_dur: 1.0319470167160034  (0.9817254680853623)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: 1.2443946599960327  (1.266558689730508)\n",
      "     | > log_mle: 0.28414392471313477  (0.28636714816093445)\n",
      "     | > loss_dur: 0.960250735282898  (0.980191558599472)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: 1.2687721252441406  (1.2667062520980834)\n",
      "     | > log_mle: 0.2879346013069153  (0.2864716450373332)\n",
      "     | > loss_dur: 0.9808375835418701  (0.9802346269289652)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: 1.2879562377929688  (1.2680343762040138)\n",
      "     | > log_mle: 0.2835370898246765  (0.28628823533654213)\n",
      "     | > loss_dur: 1.0044190883636475  (0.9817461557686329)\n",
      "\n",
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[91m 0.004212915897369385 \u001b[0m(+0.0008684545755386353)\n",
      "     | > avg_loss:\u001b[92m 1.2680343762040138 \u001b[0m(-0.15061195194721222)\n",
      "     | > avg_log_mle:\u001b[92m 0.28628823533654213 \u001b[0m(-0.04649019241333008)\n",
      "     | > avg_loss_dur:\u001b[92m 0.9817461557686329 \u001b[0m(-0.10412174835801147)\n",
      "\n",
      " > BEST MODEL : train/run-February-22-2025_01+01AM-9b6e3e6/best_model_6488.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 8/10\u001b[0m\n",
      " --> train/run-February-22-2025_01+01AM-9b6e3e6\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-22 02:12:02) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:12:07 -- STEP: 12/811 -- GLOBAL_STEP: 6500\u001b[0m\n",
      "     | > loss: 1.2466061115264893  (1.3861116965611775)\n",
      "     | > log_mle: 0.3046932816505432  (0.3209903786579768)\n",
      "     | > loss_dur: 0.941912829875946  (1.0651213079690933)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.5796, device='cuda:0')  (tensor(2.7561, device='cuda:0'))\n",
      "     | > current_lr: 2e-06 \n",
      "     | > step_time: 0.4179  (0.33221296469370526)\n",
      "     | > loader_time: 0.002  (0.004132707913716634)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:12:16 -- STEP: 37/811 -- GLOBAL_STEP: 6525\u001b[0m\n",
      "     | > loss: 1.262139081954956  (1.3410024352975793)\n",
      "     | > log_mle: 0.31535905599594116  (0.3148164217536514)\n",
      "     | > loss_dur: 0.9467800259590149  (1.0261860054892462)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.4390, device='cuda:0')  (tensor(2.6599, device='cuda:0'))\n",
      "     | > current_lr: 2e-06 \n",
      "     | > step_time: 0.2927  (0.324426760544648)\n",
      "     | > loader_time: 0.0044  (0.00427642384090939)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:12:29 -- STEP: 62/811 -- GLOBAL_STEP: 6550\u001b[0m\n",
      "     | > loss: 1.276350498199463  (1.3205792903900144)\n",
      "     | > log_mle: 0.3204198479652405  (0.3146732622577298)\n",
      "     | > loss_dur: 0.9559305906295776  (1.005906024286824)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.4796, device='cuda:0')  (tensor(2.5769, device='cuda:0'))\n",
      "     | > current_lr: 2e-06 \n",
      "     | > step_time: 0.5501  (0.40372255156117093)\n",
      "     | > loader_time: 0.0041  (0.005366483042317051)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:12:42 -- STEP: 87/811 -- GLOBAL_STEP: 6575\u001b[0m\n",
      "     | > loss: 1.2274961471557617  (1.311527650931786)\n",
      "     | > log_mle: 0.3036314845085144  (0.31393747151583085)\n",
      "     | > loss_dur: 0.9238646030426025  (0.9975901794159546)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.3164, device='cuda:0')  (tensor(2.5285, device='cuda:0'))\n",
      "     | > current_lr: 2e-06 \n",
      "     | > step_time: 0.471  (0.43794029060451456)\n",
      "     | > loader_time: 0.0037  (0.00593782019341129)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:12:56 -- STEP: 112/811 -- GLOBAL_STEP: 6600\u001b[0m\n",
      "     | > loss: 1.289825201034546  (1.306422165461949)\n",
      "     | > log_mle: 0.31197595596313477  (0.31092902113284376)\n",
      "     | > loss_dur: 0.9778492450714111  (0.9954931427325519)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.3429, device='cuda:0')  (tensor(2.5201, device='cuda:0'))\n",
      "     | > current_lr: 2e-06 \n",
      "     | > step_time: 0.5656  (0.45768084057739794)\n",
      "     | > loader_time: 0.0038  (0.006190221224512372)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:13:09 -- STEP: 137/811 -- GLOBAL_STEP: 6625\u001b[0m\n",
      "     | > loss: 1.272046446800232  (1.3013486879585434)\n",
      "     | > log_mle: 0.2987781763076782  (0.3090077220958514)\n",
      "     | > loss_dur: 0.9732682704925537  (0.9923409632522693)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.5225, device='cuda:0')  (tensor(2.5095, device='cuda:0'))\n",
      "     | > current_lr: 2e-06 \n",
      "     | > step_time: 0.619  (0.4721120500216519)\n",
      "     | > loader_time: 0.0043  (0.006316318999241738)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 02:13:22 -- STEP: 162/811 -- GLOBAL_STEP: 6650\u001b[0m\n",
      "     | > loss: 1.2619036436080933  (1.2979816610430503)\n",
      "     | > log_mle: 0.2977207899093628  (0.30663258867499255)\n",
      "     | > loss_dur: 0.9641828536987305  (0.9913490686887575)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.3742, device='cuda:0')  (tensor(2.5064, device='cuda:0'))\n",
      "     | > current_lr: 2e-06 \n",
      "     | > step_time: 0.5534  (0.47727618246902653)\n",
      "     | > loader_time: 0.0039  (0.006490024519555363)\n",
      "\n",
      " > Keyboard interrupt detected.\n",
      " > Saving model before exiting...\n",
      "\n",
      " > CHECKPOINT : train/run-February-22-2025_01+01AM-9b6e3e6/checkpoint_6673.pth\n",
      " ! Run is kept in train/run-February-22-2025_01+01AM-9b6e3e6\n"
     ]
    }
   ],
   "source": [
    "trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resume training\n",
    "\n",
    "trainer_args = TrainerArgs(\n",
    "    restore_path=os.path.join(output_path, \"run-February-22-2025_02+19AM-9b6e3e6/best_model.pth\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " > Training Environment:\n",
      " | > Backend: Torch\n",
      " | > Mixed precision: True\n",
      " | > Precision: fp16\n",
      " | > Current device: 0\n",
      " | > Num. of GPUs: 1\n",
      " | > Num. of CPUs: 16\n",
      " | > Num. of Torch Threads: 8\n",
      " | > Torch seed: 54321\n",
      " | > Torch CUDNN: True\n",
      " | > Torch CUDNN deterministic: False\n",
      " | > Torch CUDNN benchmark: False\n",
      " | > Torch TF32 MatMul: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " > Start Tensorboard: tensorboard --logdir=train/run-February-22-2025_10+59PM-fa84af3\n",
      " > Restoring from best_model.pth ...\n",
      " > Restoring Model...\n",
      " > Restoring Optimizer...\n",
      " > Restoring Scaler...\n",
      " > Model restored from step 22729\n",
      "\n",
      " > Model has 28610449 parameters\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    trainer_args, config, output_path, model=model, train_samples=train_samples, eval_samples=eval_samples\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 0/100\u001b[0m\n",
      " --> train/run-February-22-2025_10+59PM-fa84af3\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-22 22:59:43) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 22:59:59 -- STEP: 20/406 -- GLOBAL_STEP: 22750\u001b[0m\n",
      "     | > loss: 0.06345455348491669  (0.04589533656835556)\n",
      "     | > log_mle: -0.1602722406387329  (-0.17688823938369752)\n",
      "     | > loss_dur: 0.2237267941236496  (0.22278357595205306)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(1.3683, device='cuda:0')  (tensor(2.2992, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.4049  (0.5272315979003906)\n",
      "     | > loader_time: 0.003  (0.006970047950744629)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:00:16 -- STEP: 45/406 -- GLOBAL_STEP: 22775\u001b[0m\n",
      "     | > loss: 0.046437233686447144  (0.04957967334323459)\n",
      "     | > log_mle: -0.1792736053466797  (-0.17695660061306423)\n",
      "     | > loss_dur: 0.22571083903312683  (0.22653627395629883)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(0.9909, device='cuda:0')  (tensor(2.0398, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.774  (0.6041408061981202)\n",
      "     | > loader_time: 0.0132  (0.008193286259969075)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:00:35 -- STEP: 70/406 -- GLOBAL_STEP: 22800\u001b[0m\n",
      "     | > loss: 0.023806974291801453  (0.0510217839053699)\n",
      "     | > log_mle: -0.19013988971710205  (-0.17976988894598825)\n",
      "     | > loss_dur: 0.2139468640089035  (0.23079167285135815)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(3.5445, device='cuda:0')  (tensor(1.8812, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.4467  (0.6453272887638637)\n",
      "     | > loader_time: 0.0063  (0.00958991391318185)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:00:55 -- STEP: 95/406 -- GLOBAL_STEP: 22825\u001b[0m\n",
      "     | > loss: 0.0559442937374115  (0.0507070015919836)\n",
      "     | > log_mle: -0.18931663036346436  (-0.1828634287181654)\n",
      "     | > loss_dur: 0.24526092410087585  (0.23357043031014893)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(3.6509, device='cuda:0')  (tensor(1.8735, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.9107  (0.6814363655291106)\n",
      "     | > loader_time: 0.0175  (0.010155645169709855)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:01:15 -- STEP: 120/406 -- GLOBAL_STEP: 22850\u001b[0m\n",
      "     | > loss: 0.06232661008834839  (0.050750072797139494)\n",
      "     | > log_mle: -0.19280946254730225  (-0.1852601697047552)\n",
      "     | > loss_dur: 0.25513607263565063  (0.23601024250189465)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(1.3591, device='cuda:0')  (tensor(1.8682, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.7066  (0.7006595154603322)\n",
      "     | > loader_time: 0.0221  (0.011017439762751258)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:01:33 -- STEP: 145/406 -- GLOBAL_STEP: 22875\u001b[0m\n",
      "     | > loss: 0.05886028707027435  (0.05090323481066476)\n",
      "     | > log_mle: -0.18056142330169678  (-0.18726394258696463)\n",
      "     | > loss_dur: 0.23942171037197113  (0.2381671773976293)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(1.6786, device='cuda:0')  (tensor(1.9456, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 1.0286  (0.7045914469094111)\n",
      "     | > loader_time: 0.0069  (0.011014887382244237)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:01:53 -- STEP: 170/406 -- GLOBAL_STEP: 22900\u001b[0m\n",
      "     | > loss: 0.03790701925754547  (0.05117592013934082)\n",
      "     | > log_mle: -0.1938784122467041  (-0.18869961850783404)\n",
      "     | > loss_dur: 0.23178543150424957  (0.23987553864717484)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(1.3331, device='cuda:0')  (tensor(1.9517, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.6255  (0.714108065997853)\n",
      "     | > loader_time: 0.0049  (0.011778475256527159)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:02:13 -- STEP: 195/406 -- GLOBAL_STEP: 22925\u001b[0m\n",
      "     | > loss: 0.06797590851783752  (0.051324491088206976)\n",
      "     | > log_mle: -0.18879401683807373  (-0.1901729852725298)\n",
      "     | > loss_dur: 0.25676992535591125  (0.24149747636073676)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(1.6761, device='cuda:0')  (tensor(1.9528, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.816  (0.7237242918748122)\n",
      "     | > loader_time: 0.0133  (0.012166231106489121)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:02:40 -- STEP: 220/406 -- GLOBAL_STEP: 22950\u001b[0m\n",
      "     | > loss: 0.04399740695953369  (0.051037542115558304)\n",
      "     | > log_mle: -0.2207956314086914  (-0.1914923841303045)\n",
      "     | > loss_dur: 0.2647930383682251  (0.24252992624586278)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(1.5928, device='cuda:0')  (tensor(1.9430, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 2.1464  (0.7622069402174516)\n",
      "     | > loader_time: 0.0659  (0.013492808558724133)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:03:03 -- STEP: 245/406 -- GLOBAL_STEP: 22975\u001b[0m\n",
      "     | > loss: 0.060975462198257446  (0.05119189401062169)\n",
      "     | > log_mle: -0.19979000091552734  (-0.1927231671858807)\n",
      "     | > loss_dur: 0.2607654631137848  (0.2439150611965024)\n",
      "     | > amp_scaler: 16384.0  (8961.044897959184)\n",
      "     | > grad_norm: tensor(1.1025, device='cuda:0')  (tensor(1.9264, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.8814  (0.7746313795751455)\n",
      "     | > loader_time: 0.012  (0.01425556163398586)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:03:22 -- STEP: 270/406 -- GLOBAL_STEP: 23000\u001b[0m\n",
      "     | > loss: 0.0326896607875824  (0.05082176200769567)\n",
      "     | > log_mle: -0.20940625667572021  (-0.19369061125649345)\n",
      "     | > loss_dur: 0.2420959174633026  (0.24451237326418912)\n",
      "     | > amp_scaler: 16384.0  (9648.355555555554)\n",
      "     | > grad_norm: tensor(0.8528, device='cuda:0')  (tensor(1.9452, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.9687  (0.7709868510564166)\n",
      "     | > loader_time: 0.0069  (0.014251807000901956)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:03:42 -- STEP: 295/406 -- GLOBAL_STEP: 23025\u001b[0m\n",
      "     | > loss: 0.043990716338157654  (0.0506292964947426)\n",
      "     | > log_mle: -0.20189201831817627  (-0.19454444788270078)\n",
      "     | > loss_dur: 0.24588273465633392  (0.24517374437744335)\n",
      "     | > amp_scaler: 16384.0  (10219.172881355928)\n",
      "     | > grad_norm: tensor(1.1579, device='cuda:0')  (tensor(1.9178, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.6613  (0.7706030530444643)\n",
      "     | > loader_time: 0.0062  (0.014218993914329393)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:04:05 -- STEP: 320/406 -- GLOBAL_STEP: 23050\u001b[0m\n",
      "     | > loss: 0.059105753898620605  (0.05056759035214784)\n",
      "     | > log_mle: -0.19634830951690674  (-0.195328115299344)\n",
      "     | > loss_dur: 0.25545406341552734  (0.24589570565149188)\n",
      "     | > amp_scaler: 16384.0  (10700.799999999994)\n",
      "     | > grad_norm: tensor(1.1893, device='cuda:0')  (tensor(1.8963, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.8999  (0.7814585231244561)\n",
      "     | > loader_time: 0.0067  (0.014352198690176005)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:04:29 -- STEP: 345/406 -- GLOBAL_STEP: 23075\u001b[0m\n",
      "     | > loss: 0.05211281776428223  (0.05071202291958576)\n",
      "     | > log_mle: -0.2085590362548828  (-0.1960440791171529)\n",
      "     | > loss_dur: 0.26067185401916504  (0.24675610203673873)\n",
      "     | > amp_scaler: 16384.0  (11112.62608695652)\n",
      "     | > grad_norm: tensor(1.2518, device='cuda:0')  (tensor(1.8722, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 1.6235  (0.7920499829278472)\n",
      "     | > loader_time: 0.0308  (0.014408904918725934)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:04:52 -- STEP: 370/406 -- GLOBAL_STEP: 23100\u001b[0m\n",
      "     | > loss: 0.044179767370224  (0.05063835865742453)\n",
      "     | > log_mle: -0.22743141651153564  (-0.19685972091313947)\n",
      "     | > loss_dur: 0.27161118388175964  (0.24749807957056405)\n",
      "     | > amp_scaler: 16384.0  (11468.8)\n",
      "     | > grad_norm: tensor(1.7800, device='cuda:0')  (tensor(1.8632, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 1.0056  (0.799443089639818)\n",
      "     | > loader_time: 0.0102  (0.014630888603829044)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:05:15 -- STEP: 395/406 -- GLOBAL_STEP: 23125\u001b[0m\n",
      "     | > loss: 0.04609516263008118  (0.05064410672912117)\n",
      "     | > log_mle: -0.2135235071182251  (-0.19753519191017627)\n",
      "     | > loss_dur: 0.2596186697483063  (0.2481792986392975)\n",
      "     | > amp_scaler: 16384.0  (11779.888607594936)\n",
      "     | > grad_norm: tensor(3.0901, device='cuda:0')  (tensor(1.8659, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.53  (0.8069857367986363)\n",
      "     | > loader_time: 0.0063  (0.014612033095540876)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: 0.050066426396369934  (0.050066426396369934)\n",
      "     | > log_mle: -0.17948532104492188  (-0.17948532104492188)\n",
      "     | > loss_dur: 0.2295517474412918  (0.2295517474412918)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: -0.009086668491363525  (-0.009086668491363525)\n",
      "     | > log_mle: -0.21531319618225098  (-0.21531319618225098)\n",
      "     | > loss_dur: 0.20622652769088745  (0.20622652769088745)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: 0.027710050344467163  (0.009311690926551819)\n",
      "     | > log_mle: -0.17489659786224365  (-0.19510489702224731)\n",
      "     | > loss_dur: 0.20260664820671082  (0.20441658794879913)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: 0.02934470772743225  (0.015989363193511963)\n",
      "     | > log_mle: -0.1890876293182373  (-0.19309914112091064)\n",
      "     | > loss_dur: 0.21843233704566956  (0.2090885043144226)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: 0.029095754027366638  (0.01926596090197563)\n",
      "     | > log_mle: -0.21541380882263184  (-0.19867780804634094)\n",
      "     | > loss_dur: 0.24450956284999847  (0.21794376894831657)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: 0.024848133325576782  (0.02038239538669586)\n",
      "     | > log_mle: -0.20898044109344482  (-0.2007383346557617)\n",
      "     | > loss_dur: 0.2338285744190216  (0.22112073004245758)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: 0.06017899513244629  (0.0270151620109876)\n",
      "     | > log_mle: -0.22173500061035156  (-0.2042377789815267)\n",
      "     | > loss_dur: 0.28191399574279785  (0.23125294099251428)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: 0.02924412488937378  (0.02733358527932848)\n",
      "     | > log_mle: -0.1903529167175293  (-0.20225422722952707)\n",
      "     | > loss_dur: 0.21959704160690308  (0.22958781250885554)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: 0.01869693398475647  (0.02625400386750698)\n",
      "     | > log_mle: -0.19791746139526367  (-0.20171213150024414)\n",
      "     | > loss_dur: 0.21661439538002014  (0.22796613536775112)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: 0.0521293580532074  (0.029129043221473694)\n",
      "     | > log_mle: -0.20752274990081787  (-0.20235775576697457)\n",
      "     | > loss_dur: 0.25965210795402527  (0.23148679898844826)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: 0.048646122217178345  (0.031080751121044158)\n",
      "     | > log_mle: -0.19564378261566162  (-0.20168635845184327)\n",
      "     | > loss_dur: 0.24428990483283997  (0.23276710957288743)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: 0.03354683518409729  (0.031304940581321716)\n",
      "     | > log_mle: -0.211564302444458  (-0.2025843533602628)\n",
      "     | > loss_dur: 0.2451111376285553  (0.2338892939415845)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: 0.007043495774269104  (0.029283153514067333)\n",
      "     | > log_mle: -0.20021629333496094  (-0.20238701502482095)\n",
      "     | > loss_dur: 0.20725978910923004  (0.2316701685388883)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: -0.012036457657814026  (0.026104721885461073)\n",
      "     | > log_mle: -0.2176135778427124  (-0.20355828908773568)\n",
      "     | > loss_dur: 0.20557712018489838  (0.22966301097319677)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: 0.03576502203941345  (0.0267947433250291)\n",
      "     | > log_mle: -0.21158146858215332  (-0.20413137333733694)\n",
      "     | > loss_dur: 0.24734649062156677  (0.23092611666236604)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: 0.021152138710021973  (0.026418569684028625)\n",
      "     | > log_mle: -0.20560038089752197  (-0.20422930717468263)\n",
      "     | > loss_dur: 0.22675251960754395  (0.23064787685871124)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: 0.05217188596725464  (0.02802815195173025)\n",
      "     | > log_mle: -0.20129656791687012  (-0.20404601097106934)\n",
      "     | > loss_dur: 0.25346845388412476  (0.2320741629227996)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: audio amplitude out of range, auto clipped.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time: 0.003610953688621521 \u001b[0m(+0.0)\n",
      "     | > avg_loss: 0.02802815195173025 \u001b[0m(+0.0)\n",
      "     | > avg_log_mle: -0.20404601097106934 \u001b[0m(+0.0)\n",
      "     | > avg_loss_dur: 0.2320741629227996 \u001b[0m(+0.0)\n",
      "\n",
      " > BEST MODEL : train/run-February-22-2025_10+59PM-fa84af3/best_model_23136.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 1/100\u001b[0m\n",
      " --> train/run-February-22-2025_10+59PM-fa84af3\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-22 23:05:41) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:05:48 -- STEP: 14/406 -- GLOBAL_STEP: 23150\u001b[0m\n",
      "     | > loss: 0.052101537585258484  (0.04619621272597994)\n",
      "     | > log_mle: -0.19037580490112305  (-0.17942217418125697)\n",
      "     | > loss_dur: 0.24247734248638153  (0.22561838690723693)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.0855, device='cuda:0')  (tensor(2.2254, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.7128  (0.3739775078637259)\n",
      "     | > loader_time: 0.0034  (0.00515672138759068)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:06:03 -- STEP: 39/406 -- GLOBAL_STEP: 23175\u001b[0m\n",
      "     | > loss: 0.07048898935317993  (0.05099433354842357)\n",
      "     | > log_mle: -0.1742802858352661  (-0.17794025555635112)\n",
      "     | > loss_dur: 0.24476927518844604  (0.22893458910477468)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(1.0598, device='cuda:0')  (tensor(2.0674, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.5522  (0.4950687090555827)\n",
      "     | > loader_time: 0.0066  (0.008078782986371944)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:06:18 -- STEP: 64/406 -- GLOBAL_STEP: 23200\u001b[0m\n",
      "     | > loss: 0.04491704702377319  (0.05247284099459648)\n",
      "     | > log_mle: -0.1892833709716797  (-0.17976468801498413)\n",
      "     | > loss_dur: 0.23420041799545288  (0.2322375290095806)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(1.9879, device='cuda:0')  (tensor(1.9319, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.4594  (0.5400298573076725)\n",
      "     | > loader_time: 0.0035  (0.009457703679800032)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:06:34 -- STEP: 89/406 -- GLOBAL_STEP: 23225\u001b[0m\n",
      "     | > loss: 0.05597527325153351  (0.05212301986940791)\n",
      "     | > log_mle: -0.18635332584381104  (-0.1823969396312585)\n",
      "     | > loss_dur: 0.24232859909534454  (0.23451995950066643)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(1.9260, device='cuda:0')  (tensor(1.8822, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.7076  (0.5592061428541549)\n",
      "     | > loader_time: 0.021  (0.010236761543188203)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:06:51 -- STEP: 114/406 -- GLOBAL_STEP: 23250\u001b[0m\n",
      "     | > loss: 0.020449936389923096  (0.05132016382719341)\n",
      "     | > log_mle: -0.2197026014328003  (-0.18541792819374486)\n",
      "     | > loss_dur: 0.2401525378227234  (0.23673809202093826)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(2.1248, device='cuda:0')  (tensor(1.8822, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 1.1374  (0.587562065375479)\n",
      "     | > loader_time: 0.0055  (0.010061952105739663)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:07:08 -- STEP: 139/406 -- GLOBAL_STEP: 23275\u001b[0m\n",
      "     | > loss: 0.059754401445388794  (0.05169891399874104)\n",
      "     | > log_mle: -0.19346511363983154  (-0.18733505465143876)\n",
      "     | > loss_dur: 0.25321951508522034  (0.2390339686501798)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(1.3160, device='cuda:0')  (tensor(1.8369, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.7364  (0.6001986942702919)\n",
      "     | > loader_time: 0.0053  (0.010678368506671717)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:07:24 -- STEP: 164/406 -- GLOBAL_STEP: 23300\u001b[0m\n",
      "     | > loss: 0.05252183973789215  (0.051949401272506246)\n",
      "     | > log_mle: -0.1860727071762085  (-0.1887951013518542)\n",
      "     | > loss_dur: 0.23859454691410065  (0.24074450262436053)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(2.2649, device='cuda:0')  (tensor(1.9187, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.5549  (0.6000797356047279)\n",
      "     | > loader_time: 0.0064  (0.010351950075568226)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:07:40 -- STEP: 189/406 -- GLOBAL_STEP: 23325\u001b[0m\n",
      "     | > loss: 0.04270043969154358  (0.05167153832458314)\n",
      "     | > log_mle: -0.20220327377319336  (-0.19031815491025403)\n",
      "     | > loss_dur: 0.24490371346473694  (0.24198969323483724)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(1.6103, device='cuda:0')  (tensor(1.9466, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.5207  (0.6052760850815544)\n",
      "     | > loader_time: 0.0053  (0.010593001804654565)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:07:57 -- STEP: 214/406 -- GLOBAL_STEP: 23350\u001b[0m\n",
      "     | > loss: 0.04417848587036133  (0.051294786002591394)\n",
      "     | > log_mle: -0.2058805227279663  (-0.19153409082198805)\n",
      "     | > loss_dur: 0.25005900859832764  (0.24282887682457951)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(2.2122, device='cuda:0')  (tensor(1.9341, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.8563  (0.6106567360530385)\n",
      "     | > loader_time: 0.0228  (0.010869012814815917)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:08:15 -- STEP: 239/406 -- GLOBAL_STEP: 23375\u001b[0m\n",
      "     | > loss: 0.05629098415374756  (0.05141745825691702)\n",
      "     | > log_mle: -0.19940173625946045  (-0.19279571557144734)\n",
      "     | > loss_dur: 0.255692720413208  (0.2442131738283644)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(1.7022, device='cuda:0')  (tensor(1.9326, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 1.0165  (0.6217962508421059)\n",
      "     | > loader_time: 0.0134  (0.0108825531963524)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:08:37 -- STEP: 264/406 -- GLOBAL_STEP: 23400\u001b[0m\n",
      "     | > loss: 0.06056585907936096  (0.05107369849627668)\n",
      "     | > log_mle: -0.19715666770935059  (-0.19384003001632108)\n",
      "     | > loss_dur: 0.25772252678871155  (0.2449137285125978)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(2.8636, device='cuda:0')  (tensor(1.9693, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.3752  (0.6426164282090732)\n",
      "     | > loader_time: 0.0069  (0.011330620809034872)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:08:56 -- STEP: 289/406 -- GLOBAL_STEP: 23425\u001b[0m\n",
      "     | > loss: 0.05339142680168152  (0.0507622231764777)\n",
      "     | > log_mle: -0.19180238246917725  (-0.1947379244240097)\n",
      "     | > loss_dur: 0.24519380927085876  (0.24550014760048744)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(1.1704, device='cuda:0')  (tensor(1.9869, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.9072  (0.653052502437446)\n",
      "     | > loader_time: 0.0187  (0.011853823612305534)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:09:17 -- STEP: 314/406 -- GLOBAL_STEP: 23450\u001b[0m\n",
      "     | > loss: 0.03911733627319336  (0.0506254846503021)\n",
      "     | > log_mle: -0.21252381801605225  (-0.19557142789196813)\n",
      "     | > loss_dur: 0.2516411542892456  (0.24619691254227025)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(1.9206, device='cuda:0')  (tensor(2.0173, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.9173  (0.6660121588190645)\n",
      "     | > loader_time: 0.036  (0.01223271363859723)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:09:43 -- STEP: 339/406 -- GLOBAL_STEP: 23475\u001b[0m\n",
      "     | > loss: 0.041360706090927124  (0.050847259067152824)\n",
      "     | > log_mle: -0.20769619941711426  (-0.19622317316961144)\n",
      "     | > loss_dur: 0.24905690550804138  (0.24707043223676428)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(2.5498, device='cuda:0')  (tensor(2.0225, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 1.1209  (0.6915753576959477)\n",
      "     | > loader_time: 0.0458  (0.013010736060353504)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:10:11 -- STEP: 364/406 -- GLOBAL_STEP: 23500\u001b[0m\n",
      "     | > loss: 0.0457724928855896  (0.05071768070479018)\n",
      "     | > log_mle: -0.2030036449432373  (-0.19699477297919132)\n",
      "     | > loss_dur: 0.2487761378288269  (0.24771245368398154)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(1.3450, device='cuda:0')  (tensor(2.0250, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.7401  (0.7184565787786963)\n",
      "     | > loader_time: 0.0349  (0.01338181783864786)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:10:35 -- STEP: 389/406 -- GLOBAL_STEP: 23525\u001b[0m\n",
      "     | > loss: 0.04210469126701355  (0.050757239402719534)\n",
      "     | > log_mle: -0.20530664920806885  (-0.19765476395967377)\n",
      "     | > loss_dur: 0.2474113404750824  (0.24841200336239333)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(2.1753, device='cuda:0')  (tensor(2.0161, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.5747  (0.7324995136506144)\n",
      "     | > loader_time: 0.0109  (0.01361462328305281)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: 0.048952311277389526  (0.048952311277389526)\n",
      "     | > log_mle: -0.17982840538024902  (-0.17982840538024902)\n",
      "     | > loss_dur: 0.22878071665763855  (0.22878071665763855)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: -0.009742498397827148  (-0.009742498397827148)\n",
      "     | > log_mle: -0.21564745903015137  (-0.21564745903015137)\n",
      "     | > loss_dur: 0.20590496063232422  (0.20590496063232422)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: 0.026930689811706543  (0.008594095706939697)\n",
      "     | > log_mle: -0.17526817321777344  (-0.1954578161239624)\n",
      "     | > loss_dur: 0.20219886302947998  (0.2040519118309021)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: 0.02880142629146576  (0.015329872568448385)\n",
      "     | > log_mle: -0.1893988847732544  (-0.19343817234039307)\n",
      "     | > loss_dur: 0.21820031106472015  (0.20876804490884146)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: 0.029574602842330933  (0.01889105513691902)\n",
      "     | > log_mle: -0.215720534324646  (-0.1990087628364563)\n",
      "     | > loss_dur: 0.24529513716697693  (0.21789981797337532)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: 0.020957350730895996  (0.019304314255714418)\n",
      "     | > log_mle: -0.20956659317016602  (-0.20112032890319825)\n",
      "     | > loss_dur: 0.230523943901062  (0.22042464315891266)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: 0.06257671117782593  (0.02651638040939967)\n",
      "     | > log_mle: -0.22222912311553955  (-0.20463846127192178)\n",
      "     | > loss_dur: 0.2848058342933655  (0.23115484168132147)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: 0.029601886868476868  (0.026957167046410695)\n",
      "     | > log_mle: -0.19070923328399658  (-0.20264857155936106)\n",
      "     | > loss_dur: 0.22031112015247345  (0.22960573860577174)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: 0.01855236291885376  (0.02590656653046608)\n",
      "     | > log_mle: -0.19826674461364746  (-0.20210084319114685)\n",
      "     | > loss_dur: 0.21681910753250122  (0.22800740972161293)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: 0.05466708540916443  (0.02910217973921034)\n",
      "     | > log_mle: -0.20792150497436523  (-0.20274758338928223)\n",
      "     | > loss_dur: 0.26258859038352966  (0.23184976312849256)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: 0.047814011573791504  (0.030973362922668456)\n",
      "     | > log_mle: -0.19603490829467773  (-0.20207631587982178)\n",
      "     | > loss_dur: 0.24384891986846924  (0.23304967880249022)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: 0.031548380851745605  (0.03102563727985729)\n",
      "     | > log_mle: -0.21197044849395752  (-0.20297578248110684)\n",
      "     | > loss_dur: 0.24351882934570312  (0.23400141976096414)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: 0.006386473774909973  (0.02897237365444501)\n",
      "     | > log_mle: -0.2005826234817505  (-0.2027763525644938)\n",
      "     | > loss_dur: 0.20696909725666046  (0.23174872621893883)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: -0.012201502919197083  (0.025805152379549466)\n",
      "     | > log_mle: -0.21815836429595947  (-0.20395958423614502)\n",
      "     | > loss_dur: 0.2059568613767624  (0.2297647366156945)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: 0.03328494727611542  (0.02633942344358989)\n",
      "     | > log_mle: -0.21199357509613037  (-0.20453344072614396)\n",
      "     | > loss_dur: 0.2452785223722458  (0.23087286416973388)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: 0.022217094898223877  (0.02606460154056549)\n",
      "     | > log_mle: -0.20603299140930176  (-0.2046334107716878)\n",
      "     | > loss_dur: 0.22825008630752563  (0.23069801231225331)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: 0.05227458477020264  (0.027702725492417812)\n",
      "     | > log_mle: -0.20162856578826904  (-0.20444560796022415)\n",
      "     | > loss_dur: 0.2539031505584717  (0.23214833345264196)\n",
      "\n",
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.00327087938785553 \u001b[0m(-0.0003400743007659912)\n",
      "     | > avg_loss:\u001b[92m 0.027702725492417812 \u001b[0m(-0.00032542645931243896)\n",
      "     | > avg_log_mle:\u001b[92m -0.20444560796022415 \u001b[0m(-0.0003995969891548157)\n",
      "     | > avg_loss_dur:\u001b[91m 0.23214833345264196 \u001b[0m(+7.417052984237671e-05)\n",
      "\n",
      " > BEST MODEL : train/run-February-22-2025_10+59PM-fa84af3/best_model_23542.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 2/100\u001b[0m\n",
      " --> train/run-February-22-2025_10+59PM-fa84af3\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-22 23:11:00) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:11:06 -- STEP: 8/406 -- GLOBAL_STEP: 23550\u001b[0m\n",
      "     | > loss: 0.017184928059577942  (0.04198827967047691)\n",
      "     | > log_mle: -0.18595874309539795  (-0.17621298134326935)\n",
      "     | > loss_dur: 0.2031436711549759  (0.21820126101374626)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(1.0123, device='cuda:0')  (tensor(1.6420, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.5761  (0.4600473940372467)\n",
      "     | > loader_time: 0.0051  (0.009613990783691406)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:11:20 -- STEP: 33/406 -- GLOBAL_STEP: 23575\u001b[0m\n",
      "     | > loss: 0.07139216363430023  (0.04726577121199984)\n",
      "     | > log_mle: -0.1724163293838501  (-0.17794197255914862)\n",
      "     | > loss_dur: 0.24380849301815033  (0.22520774377114844)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(1.6371, device='cuda:0')  (tensor(1.8287, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.8519  (0.5294628576798873)\n",
      "     | > loader_time: 0.0043  (0.007880312023740827)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:11:37 -- STEP: 58/406 -- GLOBAL_STEP: 23600\u001b[0m\n",
      "     | > loss: 0.05049821734428406  (0.05085332743052779)\n",
      "     | > log_mle: -0.18503832817077637  (-0.1793376453991594)\n",
      "     | > loss_dur: 0.23553654551506042  (0.23019097282968717)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(2.6762, device='cuda:0')  (tensor(1.8065, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.5818  (0.5791429568981306)\n",
      "     | > loader_time: 0.0037  (0.009175045736904806)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:11:53 -- STEP: 83/406 -- GLOBAL_STEP: 23625\u001b[0m\n",
      "     | > loss: 0.0456148236989975  (0.050575962447258364)\n",
      "     | > log_mle: -0.1933194398880005  (-0.1817530781389719)\n",
      "     | > loss_dur: 0.23893426358699799  (0.23232904058623027)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.5823, device='cuda:0')  (tensor(2.1739, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.5907  (0.5933646983410942)\n",
      "     | > loader_time: 0.0258  (0.009594704731401196)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:12:11 -- STEP: 108/406 -- GLOBAL_STEP: 23650\u001b[0m\n",
      "     | > loss: 0.04772929847240448  (0.05012286454439163)\n",
      "     | > log_mle: -0.18733835220336914  (-0.18432381638774165)\n",
      "     | > loss_dur: 0.23506765067577362  (0.23444668093213328)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(5.5506, device='cuda:0')  (tensor(2.5968, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 1.0078  (0.6185443092275551)\n",
      "     | > loader_time: 0.0059  (0.009712570243411598)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:12:28 -- STEP: 133/406 -- GLOBAL_STEP: 23675\u001b[0m\n",
      "     | > loss: 0.048613280057907104  (0.05006071387377)\n",
      "     | > log_mle: -0.20045340061187744  (-0.18690678678957143)\n",
      "     | > loss_dur: 0.24906668066978455  (0.23696750066334143)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(5.9949, device='cuda:0')  (tensor(3.3094, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.5652  (0.6272608588512681)\n",
      "     | > loader_time: 0.0118  (0.009554574364110047)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:12:47 -- STEP: 158/406 -- GLOBAL_STEP: 23700\u001b[0m\n",
      "     | > loss: 0.054783523082733154  (0.05079219961845422)\n",
      "     | > log_mle: -0.20423388481140137  (-0.18847163493120214)\n",
      "     | > loss_dur: 0.2590174078941345  (0.23926383454965638)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.4158, device='cuda:0')  (tensor(3.7204, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.7854  (0.6450521674337265)\n",
      "     | > loader_time: 0.0051  (0.009912816784049896)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:13:05 -- STEP: 183/406 -- GLOBAL_STEP: 23725\u001b[0m\n",
      "     | > loss: 0.03917025029659271  (0.050608094435571974)\n",
      "     | > log_mle: -0.2041919231414795  (-0.18991881511250477)\n",
      "     | > loss_dur: 0.2433621734380722  (0.2405269095480768)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.8362, device='cuda:0')  (tensor(3.5198, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.695  (0.6557816039017642)\n",
      "     | > loader_time: 0.0055  (0.01023190138769932)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:13:24 -- STEP: 208/406 -- GLOBAL_STEP: 23750\u001b[0m\n",
      "     | > loss: 0.0334649533033371  (0.05068756754581745)\n",
      "     | > log_mle: -0.20689284801483154  (-0.19120303541421887)\n",
      "     | > loss_dur: 0.24035780131816864  (0.24189060296003634)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(1.6762, device='cuda:0')  (tensor(3.4784, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.476  (0.665778568157783)\n",
      "     | > loader_time: 0.029  (0.010937987611843995)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:13:44 -- STEP: 233/406 -- GLOBAL_STEP: 23775\u001b[0m\n",
      "     | > loss: 0.056948572397232056  (0.05045453353501185)\n",
      "     | > log_mle: -0.20748257637023926  (-0.1925971334072653)\n",
      "     | > loss_dur: 0.2644311487674713  (0.24305166694227717)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(5.3043, device='cuda:0')  (tensor(3.4016, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.6837  (0.6763963249108311)\n",
      "     | > loader_time: 0.0063  (0.011214500844734427)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:14:05 -- STEP: 258/406 -- GLOBAL_STEP: 23800\u001b[0m\n",
      "     | > loss: 0.07056882977485657  (0.05029990576034368)\n",
      "     | > log_mle: -0.1908423900604248  (-0.19370926812637682)\n",
      "     | > loss_dur: 0.26141121983528137  (0.24400917388672053)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.7054, device='cuda:0')  (tensor(3.3535, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.8583  (0.6911635953326559)\n",
      "     | > loader_time: 0.0164  (0.011734857115634658)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:14:25 -- STEP: 283/406 -- GLOBAL_STEP: 23825\u001b[0m\n",
      "     | > loss: 0.055188268423080444  (0.049780583739701935)\n",
      "     | > log_mle: -0.20402801036834717  (-0.1947549328787166)\n",
      "     | > loss_dur: 0.2592162787914276  (0.2445355166184186)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.9691, device='cuda:0')  (tensor(3.4391, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.6323  (0.698671355264347)\n",
      "     | > loader_time: 0.0191  (0.012256891061897415)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:14:44 -- STEP: 308/406 -- GLOBAL_STEP: 23850\u001b[0m\n",
      "     | > loss: 0.036308422684669495  (0.0497246194969524)\n",
      "     | > log_mle: -0.20646440982818604  (-0.1955422062378424)\n",
      "     | > loss_dur: 0.24277283251285553  (0.2452668257347949)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.8812, device='cuda:0')  (tensor(3.5395, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.7547  (0.7037341083799091)\n",
      "     | > loader_time: 0.0166  (0.012568987809218364)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:15:06 -- STEP: 333/406 -- GLOBAL_STEP: 23875\u001b[0m\n",
      "     | > loss: 0.037367820739746094  (0.0498394768785786)\n",
      "     | > log_mle: -0.21446740627288818  (-0.19620159008839458)\n",
      "     | > loss_dur: 0.2518352270126343  (0.24604106696697325)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(2.6204, device='cuda:0')  (tensor(3.4701, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.906  (0.7147260943690581)\n",
      "     | > loader_time: 0.0143  (0.012865890611757382)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:15:26 -- STEP: 358/406 -- GLOBAL_STEP: 23900\u001b[0m\n",
      "     | > loss: 0.029845386743545532  (0.049939016098749706)\n",
      "     | > log_mle: -0.22195661067962646  (-0.19702987031563693)\n",
      "     | > loss_dur: 0.251801997423172  (0.24696888641438672)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(1.8989, device='cuda:0')  (tensor(3.3961, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.5062  (0.7192280818630203)\n",
      "     | > loader_time: 0.0098  (0.01297365353760106)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:15:52 -- STEP: 383/406 -- GLOBAL_STEP: 23925\u001b[0m\n",
      "     | > loss: 0.05721291899681091  (0.04992874328523641)\n",
      "     | > log_mle: -0.19982397556304932  (-0.19770440638220957)\n",
      "     | > loss_dur: 0.25703689455986023  (0.24763314966744604)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(1.9127, device='cuda:0')  (tensor(3.3383, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 1.2909  (0.7372304832966464)\n",
      "     | > loader_time: 0.0109  (0.013145603025550937)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: 0.048952773213386536  (0.048952773213386536)\n",
      "     | > log_mle: -0.1798950433731079  (-0.1798950433731079)\n",
      "     | > loss_dur: 0.22884781658649445  (0.22884781658649445)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: -0.010139241814613342  (-0.010139241814613342)\n",
      "     | > log_mle: -0.2148975133895874  (-0.2148975133895874)\n",
      "     | > loss_dur: 0.20475827157497406  (0.20475827157497406)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: 0.027218103408813477  (0.008539430797100067)\n",
      "     | > log_mle: -0.17500412464141846  (-0.19495081901550293)\n",
      "     | > loss_dur: 0.20222222805023193  (0.203490249812603)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: 0.0296688973903656  (0.015582586328188578)\n",
      "     | > log_mle: -0.1882854700088501  (-0.1927290360132853)\n",
      "     | > loss_dur: 0.2179543673992157  (0.2083116223414739)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: 0.03032153844833374  (0.01926732435822487)\n",
      "     | > log_mle: -0.21438908576965332  (-0.19814404845237732)\n",
      "     | > loss_dur: 0.24471062421798706  (0.2174113728106022)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: 0.02472008764743805  (0.020357877016067505)\n",
      "     | > log_mle: -0.206229567527771  (-0.19976115226745605)\n",
      "     | > loss_dur: 0.23094965517520905  (0.22011902928352356)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: 0.060040950775146484  (0.02697172264258067)\n",
      "     | > log_mle: -0.21861600875854492  (-0.2029036283493042)\n",
      "     | > loss_dur: 0.2786569595336914  (0.22987535099188486)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: 0.032005175948143005  (0.027690787400518144)\n",
      "     | > log_mle: -0.1891404390335083  (-0.20093745844704763)\n",
      "     | > loss_dur: 0.2211456149816513  (0.22862824584756578)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: 0.018815383315086365  (0.026581361889839172)\n",
      "     | > log_mle: -0.197332501411438  (-0.20048683881759644)\n",
      "     | > loss_dur: 0.21614788472652435  (0.2270682007074356)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: 0.05462995171546936  (0.02969787187046475)\n",
      "     | > log_mle: -0.2056868076324463  (-0.20106461313035753)\n",
      "     | > loss_dur: 0.26031675934791565  (0.23076248500082228)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: 0.047421544790267944  (0.03147023916244507)\n",
      "     | > log_mle: -0.1946631669998169  (-0.20042446851730347)\n",
      "     | > loss_dur: 0.24208471179008484  (0.23189470767974854)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: 0.03286844491958618  (0.03159734877673062)\n",
      "     | > log_mle: -0.2102222442626953  (-0.20131517540324817)\n",
      "     | > loss_dur: 0.2430906891822815  (0.2329125241799788)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: 0.007236942648887634  (0.02956731493274371)\n",
      "     | > log_mle: -0.19970393180847168  (-0.20118090510368347)\n",
      "     | > loss_dur: 0.20694087445735931  (0.23074822003642717)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: -0.009442239999771118  (0.026566579937934875)\n",
      "     | > log_mle: -0.21555280685424805  (-0.20228643600757307)\n",
      "     | > loss_dur: 0.20611056685447693  (0.22885301594550794)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: 0.036826059222221375  (0.027299399886812483)\n",
      "     | > log_mle: -0.21038269996643066  (-0.20286474057606288)\n",
      "     | > loss_dur: 0.24720875918865204  (0.23016414046287537)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: 0.023716405034065247  (0.027060533563296)\n",
      "     | > log_mle: -0.20449388027191162  (-0.20297334988911947)\n",
      "     | > loss_dur: 0.22821028530597687  (0.23003388345241546)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: 0.0512867271900177  (0.028574670664966106)\n",
      "     | > log_mle: -0.19963359832763672  (-0.2027646154165268)\n",
      "     | > loss_dur: 0.2509203255176544  (0.2313392860814929)\n",
      "\n",
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[91m 0.004258662462234497 \u001b[0m(+0.0009877830743789673)\n",
      "     | > avg_loss:\u001b[91m 0.028574670664966106 \u001b[0m(+0.0008719451725482941)\n",
      "     | > avg_log_mle:\u001b[91m -0.2027646154165268 \u001b[0m(+0.0016809925436973572)\n",
      "     | > avg_loss_dur:\u001b[92m 0.2313392860814929 \u001b[0m(-0.0008090473711490631)\n",
      "\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 3/100\u001b[0m\n",
      " --> train/run-February-22-2025_10+59PM-fa84af3\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-22 23:16:21) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:16:24 -- STEP: 2/406 -- GLOBAL_STEP: 23950\u001b[0m\n",
      "     | > loss: 0.030918240547180176  (0.03836298733949661)\n",
      "     | > log_mle: -0.190809965133667  (-0.18324899673461914)\n",
      "     | > loss_dur: 0.22172820568084717  (0.22161198407411575)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.1658, device='cuda:0')  (tensor(3.1211, device='cuda:0'))\n",
      "     | > current_lr: 7.5e-07 \n",
      "     | > step_time: 0.2954  (0.46640658378601074)\n",
      "     | > loader_time: 0.005  (0.012993335723876953)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:16:36 -- STEP: 27/406 -- GLOBAL_STEP: 23975\u001b[0m\n",
      "     | > loss: 0.040244340896606445  (0.04693745959688116)\n",
      "     | > log_mle: -0.1744617223739624  (-0.1782182013546979)\n",
      "     | > loss_dur: 0.21470606327056885  (0.22515566095157905)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.2899, device='cuda:0')  (tensor(2.5481, device='cuda:0'))\n",
      "     | > current_lr: 7.5e-07 \n",
      "     | > step_time: 0.674  (0.46358893535755297)\n",
      "     | > loader_time: 0.0102  (0.011129370442143193)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:16:51 -- STEP: 52/406 -- GLOBAL_STEP: 24000\u001b[0m\n",
      "     | > loss: 0.07373255491256714  (0.050676113997514434)\n",
      "     | > log_mle: -0.17953240871429443  (-0.1791740174476917)\n",
      "     | > loss_dur: 0.2532649636268616  (0.22985013144520614)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(2.7709, device='cuda:0')  (tensor(2.5575, device='cuda:0'))\n",
      "     | > current_lr: 7.5e-07 \n",
      "     | > step_time: 0.3123  (0.5140123734107381)\n",
      "     | > loader_time: 0.0104  (0.010277656408456654)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:17:06 -- STEP: 77/406 -- GLOBAL_STEP: 24025\u001b[0m\n",
      "     | > loss: 0.07217666506767273  (0.050309105159400354)\n",
      "     | > log_mle: -0.1790217161178589  (-0.18160831154166882)\n",
      "     | > loss_dur: 0.2511983811855316  (0.23191741670106913)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(1.7156, device='cuda:0')  (tensor(2.8713, device='cuda:0'))\n",
      "     | > current_lr: 7.5e-07 \n",
      "     | > step_time: 0.3965  (0.5351596466906655)\n",
      "     | > loader_time: 0.0053  (0.01088809657406497)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:17:22 -- STEP: 102/406 -- GLOBAL_STEP: 24050\u001b[0m\n",
      "     | > loss: 0.026387199759483337  (0.050255122576274125)\n",
      "     | > log_mle: -0.20337748527526855  (-0.18438318079593138)\n",
      "     | > loss_dur: 0.2297646850347519  (0.23463830337220548)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.1282, device='cuda:0')  (tensor(3.1900, device='cuda:0'))\n",
      "     | > current_lr: 7.5e-07 \n",
      "     | > step_time: 0.4867  (0.55617655024809)\n",
      "     | > loader_time: 0.0042  (0.010675986607869467)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:17:37 -- STEP: 127/406 -- GLOBAL_STEP: 24075\u001b[0m\n",
      "     | > loss: 0.053530991077423096  (0.04935596613433418)\n",
      "     | > log_mle: -0.19856739044189453  (-0.1868873609332588)\n",
      "     | > loss_dur: 0.2520983815193176  (0.23624332706759296)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(9.2099, device='cuda:0')  (tensor(3.3886, device='cuda:0'))\n",
      "     | > current_lr: 7.5e-07 \n",
      "     | > step_time: 0.5778  (0.5683596791244868)\n",
      "     | > loader_time: 0.0055  (0.010724981938760111)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:17:54 -- STEP: 152/406 -- GLOBAL_STEP: 24100\u001b[0m\n",
      "     | > loss: 0.05995699763298035  (0.04965956303242006)\n",
      "     | > log_mle: -0.19591426849365234  (-0.1887484671253907)\n",
      "     | > loss_dur: 0.2558712661266327  (0.23840803015781076)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.7220, device='cuda:0')  (tensor(4.2044, device='cuda:0'))\n",
      "     | > current_lr: 7.5e-07 \n",
      "     | > step_time: 0.5234  (0.5812785703884927)\n",
      "     | > loader_time: 0.0128  (0.011556013634330347)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:18:10 -- STEP: 177/406 -- GLOBAL_STEP: 24125\u001b[0m\n",
      "     | > loss: 0.047979459166526794  (0.04964338983856352)\n",
      "     | > log_mle: -0.2011575698852539  (-0.1901580788994912)\n",
      "     | > loss_dur: 0.2491370290517807  (0.23980146873805483)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(5.4084, device='cuda:0')  (tensor(4.7502, device='cuda:0'))\n",
      "     | > current_lr: 7.5e-07 \n",
      "     | > step_time: 0.8169  (0.586219503381158)\n",
      "     | > loader_time: 0.0375  (0.01167583196176647)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:18:27 -- STEP: 202/406 -- GLOBAL_STEP: 24150\u001b[0m\n",
      "     | > loss: 0.06546533107757568  (0.04963410948172654)\n",
      "     | > log_mle: -0.18994784355163574  (-0.1914708230755116)\n",
      "     | > loss_dur: 0.2554131746292114  (0.24110493255723822)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(18.3415, device='cuda:0')  (tensor(5.5479, device='cuda:0'))\n",
      "     | > current_lr: 7.5e-07 \n",
      "     | > step_time: 0.8131  (0.5947081287308496)\n",
      "     | > loader_time: 0.0053  (0.011981788248118783)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:18:45 -- STEP: 227/406 -- GLOBAL_STEP: 24175\u001b[0m\n",
      "     | > loss: 0.06034320592880249  (0.049501633722876665)\n",
      "     | > log_mle: -0.1998072862625122  (-0.1928409926166618)\n",
      "     | > loss_dur: 0.2601504921913147  (0.2423426263395385)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(7.6051, device='cuda:0')  (tensor(6.5896, device='cuda:0'))\n",
      "     | > current_lr: 7.5e-07 \n",
      "     | > step_time: 0.7929  (0.6068711291325775)\n",
      "     | > loader_time: 0.0296  (0.012019424186404053)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:19:03 -- STEP: 252/406 -- GLOBAL_STEP: 24200\u001b[0m\n",
      "     | > loss: 0.05239933729171753  (0.04948703081361831)\n",
      "     | > log_mle: -0.20188021659851074  (-0.19401858250300083)\n",
      "     | > loss_dur: 0.25427955389022827  (0.2435056133166192)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(7.7667, device='cuda:0')  (tensor(7.5615, device='cuda:0'))\n",
      "     | > current_lr: 7.5e-07 \n",
      "     | > step_time: 0.7873  (0.6170687666015019)\n",
      "     | > loader_time: 0.0169  (0.012023975924840046)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:19:22 -- STEP: 277/406 -- GLOBAL_STEP: 24225\u001b[0m\n",
      "     | > loss: 0.040543511509895325  (0.04924760925640698)\n",
      "     | > log_mle: -0.20126855373382568  (-0.19507054258339668)\n",
      "     | > loss_dur: 0.241812065243721  (0.2443181518398037)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(11.6464, device='cuda:0')  (tensor(8.2066, device='cuda:0'))\n",
      "     | > current_lr: 7.5e-07 \n",
      "     | > step_time: 1.1797  (0.6285605267066818)\n",
      "     | > loader_time: 0.0102  (0.012525116923914056)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:19:43 -- STEP: 302/406 -- GLOBAL_STEP: 24250\u001b[0m\n",
      "     | > loss: 0.05501946806907654  (0.049251550130102004)\n",
      "     | > log_mle: -0.20936930179595947  (-0.19591289837628803)\n",
      "     | > loss_dur: 0.264388769865036  (0.24516444850639002)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(9.3906, device='cuda:0')  (tensor(8.1044, device='cuda:0'))\n",
      "     | > current_lr: 7.5e-07 \n",
      "     | > step_time: 0.9003  (0.6429692048900174)\n",
      "     | > loader_time: 0.009  (0.012760050249415516)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:20:02 -- STEP: 327/406 -- GLOBAL_STEP: 24275\u001b[0m\n",
      "     | > loss: 0.05243408679962158  (0.049120162514007)\n",
      "     | > log_mle: -0.20181000232696533  (-0.19656752045366013)\n",
      "     | > loss_dur: 0.2542440891265869  (0.2456876829676672)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(15.2694, device='cuda:0')  (tensor(8.0498, device='cuda:0'))\n",
      "     | > current_lr: 7.5e-07 \n",
      "     | > step_time: 0.5283  (0.6503481500374796)\n",
      "     | > loader_time: 0.0059  (0.012751055784546272)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:20:22 -- STEP: 352/406 -- GLOBAL_STEP: 24300\u001b[0m\n",
      "     | > loss: 0.047142863273620605  (0.049242223062637126)\n",
      "     | > log_mle: -0.2027188539505005  (-0.19731431860815396)\n",
      "     | > loss_dur: 0.2498617172241211  (0.24655654167079114)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(9.0716, device='cuda:0')  (tensor(8.3281, device='cuda:0'))\n",
      "     | > current_lr: 7.5e-07 \n",
      "     | > step_time: 0.7738  (0.6604825420813122)\n",
      "     | > loader_time: 0.0231  (0.012947243723002348)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:20:42 -- STEP: 377/406 -- GLOBAL_STEP: 24325\u001b[0m\n",
      "     | > loss: 0.057381510734558105  (0.0490830841842317)\n",
      "     | > log_mle: -0.2066422700881958  (-0.19816683774285354)\n",
      "     | > loss_dur: 0.2640237808227539  (0.24724992192708528)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.1980, device='cuda:0')  (tensor(8.1312, device='cuda:0'))\n",
      "     | > current_lr: 7.5e-07 \n",
      "     | > step_time: 0.6852  (0.6681782870457087)\n",
      "     | > loader_time: 0.0059  (0.012925918918073336)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:21:00 -- STEP: 402/406 -- GLOBAL_STEP: 24350\u001b[0m\n",
      "     | > loss: 0.041926175355911255  (0.049039025471281604)\n",
      "     | > log_mle: -0.21565580368041992  (-0.1988990013279132)\n",
      "     | > loss_dur: 0.2575819790363312  (0.24793802679919485)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(1.6038, device='cuda:0')  (tensor(7.8180, device='cuda:0'))\n",
      "     | > current_lr: 7.5e-07 \n",
      "     | > step_time: 0.5436  (0.6699344471319395)\n",
      "     | > loader_time: 0.0068  (0.012901965658463056)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: 0.04817846417427063  (0.04817846417427063)\n",
      "     | > log_mle: -0.18044912815093994  (-0.18044912815093994)\n",
      "     | > loss_dur: 0.22862759232521057  (0.22862759232521057)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: -0.008655592799186707  (-0.008655592799186707)\n",
      "     | > log_mle: -0.21614718437194824  (-0.21614718437194824)\n",
      "     | > loss_dur: 0.20749159157276154  (0.20749159157276154)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: 0.026121854782104492  (0.008733130991458893)\n",
      "     | > log_mle: -0.1758744716644287  (-0.19601082801818848)\n",
      "     | > loss_dur: 0.2019963264465332  (0.20474395900964737)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: 0.028006568551063538  (0.015157610177993774)\n",
      "     | > log_mle: -0.1900113821029663  (-0.1940110127131144)\n",
      "     | > loss_dur: 0.21801795065402985  (0.20916862289110819)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: 0.024830728769302368  (0.017575889825820923)\n",
      "     | > log_mle: -0.21632647514343262  (-0.19958987832069397)\n",
      "     | > loss_dur: 0.24115720391273499  (0.2171657681465149)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: 0.022842153906822205  (0.01862914264202118)\n",
      "     | > log_mle: -0.2095721960067749  (-0.20158634185791016)\n",
      "     | > loss_dur: 0.2324143499135971  (0.22021548449993134)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: 0.05750167369842529  (0.02510789781808853)\n",
      "     | > log_mle: -0.22251546382904053  (-0.20507452885309854)\n",
      "     | > loss_dur: 0.2800171375274658  (0.23018242667118707)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: 0.029183968901634216  (0.025690193687166487)\n",
      "     | > log_mle: -0.19122695922851562  (-0.20309630462101527)\n",
      "     | > loss_dur: 0.22041092813014984  (0.22878649830818176)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: 0.017361924052238464  (0.024649159982800484)\n",
      "     | > log_mle: -0.19877934455871582  (-0.20255668461322784)\n",
      "     | > loss_dur: 0.21614126861095428  (0.22720584459602833)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: 0.047139763832092285  (0.02714811596605513)\n",
      "     | > log_mle: -0.20833313465118408  (-0.203198512395223)\n",
      "     | > loss_dur: 0.25547289848327637  (0.23034662836127812)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: 0.044047728180885315  (0.02883807718753815)\n",
      "     | > log_mle: -0.19669222831726074  (-0.20254788398742676)\n",
      "     | > loss_dur: 0.24073995649814606  (0.2313859611749649)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: 0.031209871172904968  (0.029053694822571495)\n",
      "     | > log_mle: -0.2122659683227539  (-0.20343134619972922)\n",
      "     | > loss_dur: 0.24347583949565887  (0.23248504102230072)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: 0.005402013659477234  (0.02708272139231364)\n",
      "     | > log_mle: -0.20120763778686523  (-0.20324603716532388)\n",
      "     | > loss_dur: 0.20660965144634247  (0.23032875855763754)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: -0.013124048709869385  (0.023989892922914945)\n",
      "     | > log_mle: -0.2181304693222046  (-0.20439099348508394)\n",
      "     | > loss_dur: 0.2050064206123352  (0.2283808864079989)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: 0.03179679811000824  (0.024547529007707323)\n",
      "     | > log_mle: -0.21250271797180176  (-0.20497040237699235)\n",
      "     | > loss_dur: 0.24429951608181  (0.2295179313846997)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: 0.023167774081230164  (0.02445554534594218)\n",
      "     | > log_mle: -0.20653116703033447  (-0.20507445335388183)\n",
      "     | > loss_dur: 0.22969894111156464  (0.22952999869982402)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: 0.045302197337150574  (0.025758461095392704)\n",
      "     | > log_mle: -0.2021031379699707  (-0.2048887461423874)\n",
      "     | > loss_dur: 0.24740533530712128  (0.2306472072377801)\n",
      "\n",
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.003388524055480957 \u001b[0m(-0.00087013840675354)\n",
      "     | > avg_loss:\u001b[92m 0.025758461095392704 \u001b[0m(-0.0028162095695734024)\n",
      "     | > avg_log_mle:\u001b[92m -0.2048887461423874 \u001b[0m(-0.0021241307258605957)\n",
      "     | > avg_loss_dur:\u001b[92m 0.2306472072377801 \u001b[0m(-0.0006920788437128067)\n",
      "\n",
      " > BEST MODEL : train/run-February-22-2025_10+59PM-fa84af3/best_model_24354.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 4/100\u001b[0m\n",
      " --> train/run-February-22-2025_10+59PM-fa84af3\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-22 23:21:17) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:21:28 -- STEP: 21/406 -- GLOBAL_STEP: 24375\u001b[0m\n",
      "     | > loss: 0.04095543920993805  (0.040395738113494145)\n",
      "     | > log_mle: -0.1815187931060791  (-0.17890159289042154)\n",
      "     | > loss_dur: 0.22247423231601715  (0.21929733100391569)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(2.5440, device='cuda:0')  (tensor(3.4215, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 0.7905  (0.43460180645897273)\n",
      "     | > loader_time: 0.011  (0.004817429042997814)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:21:42 -- STEP: 46/406 -- GLOBAL_STEP: 24400\u001b[0m\n",
      "     | > loss: 0.0635678768157959  (0.04682370210471361)\n",
      "     | > log_mle: -0.17503833770751953  (-0.17854412223981775)\n",
      "     | > loss_dur: 0.23860621452331543  (0.22536782434453134)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(2.4196, device='cuda:0')  (tensor(3.0737, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 0.5766  (0.4973965986915257)\n",
      "     | > loader_time: 0.0046  (0.00749485389046047)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:21:57 -- STEP: 71/406 -- GLOBAL_STEP: 24425\u001b[0m\n",
      "     | > loss: 0.0546959787607193  (0.04835308038852584)\n",
      "     | > log_mle: -0.19517576694488525  (-0.18157086909656797)\n",
      "     | > loss_dur: 0.24987174570560455  (0.2299239494850938)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(2.1177, device='cuda:0')  (tensor(3.7355, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 0.5286  (0.5229919628358223)\n",
      "     | > loader_time: 0.004  (0.008815342271831674)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:22:12 -- STEP: 96/406 -- GLOBAL_STEP: 24450\u001b[0m\n",
      "     | > loss: 0.05956330895423889  (0.047706627597411476)\n",
      "     | > log_mle: -0.19613373279571533  (-0.18453234806656837)\n",
      "     | > loss_dur: 0.2556970417499542  (0.23223897566397986)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.8601, device='cuda:0')  (tensor(4.0126, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 0.5015  (0.5387670074899993)\n",
      "     | > loader_time: 0.0079  (0.010032745699087776)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:22:29 -- STEP: 121/406 -- GLOBAL_STEP: 24475\u001b[0m\n",
      "     | > loss: 0.03422759473323822  (0.04740925576568635)\n",
      "     | > log_mle: -0.19459772109985352  (-0.1868661494294474)\n",
      "     | > loss_dur: 0.22882531583309174  (0.23427540519513373)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(8.0115, device='cuda:0')  (tensor(4.8304, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 0.4513  (0.564792950291279)\n",
      "     | > loader_time: 0.0042  (0.009759609364281012)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:22:45 -- STEP: 146/406 -- GLOBAL_STEP: 24500\u001b[0m\n",
      "     | > loss: 0.042536914348602295  (0.04797690759782921)\n",
      "     | > log_mle: -0.19327902793884277  (-0.18881908508196268)\n",
      "     | > loss_dur: 0.23581594228744507  (0.2367959926797919)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(8.6514, device='cuda:0')  (tensor(5.4441, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 0.8234  (0.5738339097532508)\n",
      "     | > loader_time: 0.0194  (0.009714469517747014)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:23:01 -- STEP: 171/406 -- GLOBAL_STEP: 24525\u001b[0m\n",
      "     | > loss: 0.03761431574821472  (0.04791556908721812)\n",
      "     | > log_mle: -0.2041558027267456  (-0.19030924080408107)\n",
      "     | > loss_dur: 0.24177011847496033  (0.2382248098912992)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(5.0510, device='cuda:0')  (tensor(5.7526, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 0.5206  (0.5820448719270048)\n",
      "     | > loader_time: 0.0053  (0.010231851834302754)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:23:18 -- STEP: 196/406 -- GLOBAL_STEP: 24550\u001b[0m\n",
      "     | > loss: 0.046700939536094666  (0.04802613104788624)\n",
      "     | > log_mle: -0.20134377479553223  (-0.19175385942264478)\n",
      "     | > loss_dur: 0.2480447143316269  (0.23977999047053103)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(13.3855, device='cuda:0')  (tensor(6.4798, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 0.3968  (0.5917537479984518)\n",
      "     | > loader_time: 0.0076  (0.010606976187959005)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:23:35 -- STEP: 221/406 -- GLOBAL_STEP: 24575\u001b[0m\n",
      "     | > loss: 0.0706728994846344  (0.04801327529536113)\n",
      "     | > log_mle: -0.20122945308685303  (-0.19306538817030272)\n",
      "     | > loss_dur: 0.2719023525714874  (0.24107866346566387)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(8.6359, device='cuda:0')  (tensor(7.1751, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 0.5509  (0.6019130378826714)\n",
      "     | > loader_time: 0.0061  (0.011102461706998657)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:23:54 -- STEP: 246/406 -- GLOBAL_STEP: 24600\u001b[0m\n",
      "     | > loss: 0.045007750391960144  (0.048095175587549444)\n",
      "     | > log_mle: -0.20025575160980225  (-0.1942922807321316)\n",
      "     | > loss_dur: 0.2452635020017624  (0.24238745631968103)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(5.1355, device='cuda:0')  (tensor(7.3936, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 0.5644  (0.6149563915361236)\n",
      "     | > loader_time: 0.0052  (0.011079709704329324)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:24:12 -- STEP: 271/406 -- GLOBAL_STEP: 24625\u001b[0m\n",
      "     | > loss: 0.02561117708683014  (0.04775434721439967)\n",
      "     | > log_mle: -0.21480834484100342  (-0.19531252771286067)\n",
      "     | > loss_dur: 0.24041952192783356  (0.24306687492726034)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(18.1839, device='cuda:0')  (tensor(7.7428, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 0.72  (0.6237153769419205)\n",
      "     | > loader_time: 0.0163  (0.011686494869499625)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:24:32 -- STEP: 296/406 -- GLOBAL_STEP: 24650\u001b[0m\n",
      "     | > loss: 0.057593464851379395  (0.04765059960049552)\n",
      "     | > log_mle: -0.20987975597381592  (-0.19614037992181002)\n",
      "     | > loss_dur: 0.2674732208251953  (0.24379097952230558)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(10.3890, device='cuda:0')  (tensor(7.8229, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 0.8079  (0.637303314498953)\n",
      "     | > loader_time: 0.0399  (0.012165117908168483)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:24:51 -- STEP: 321/406 -- GLOBAL_STEP: 24675\u001b[0m\n",
      "     | > loss: 0.05731847882270813  (0.04767450940943209)\n",
      "     | > log_mle: -0.20251214504241943  (-0.1968965868340845)\n",
      "     | > loss_dur: 0.25983062386512756  (0.24457109624351667)\n",
      "     | > amp_scaler: 8192.0  (15848.074766355141)\n",
      "     | > grad_norm: tensor(7.1441, device='cuda:0')  (tensor(8.1037, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 0.8069  (0.6442539209146)\n",
      "     | > loader_time: 0.007  (0.012336179846172395)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:25:10 -- STEP: 346/406 -- GLOBAL_STEP: 24700\u001b[0m\n",
      "     | > loss: 0.03949594497680664  (0.0478528814250334)\n",
      "     | > log_mle: -0.2127002477645874  (-0.19763560687875464)\n",
      "     | > loss_dur: 0.25219619274139404  (0.24548848830378814)\n",
      "     | > amp_scaler: 8192.0  (15294.890173410404)\n",
      "     | > grad_norm: tensor(16.7118, device='cuda:0')  (tensor(8.3940, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 0.7617  (0.6522219994164621)\n",
      "     | > loader_time: 0.0318  (0.01264712231696686)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:25:30 -- STEP: 371/406 -- GLOBAL_STEP: 24725\u001b[0m\n",
      "     | > loss: 0.05241087079048157  (0.047733732913382274)\n",
      "     | > log_mle: -0.2087174654006958  (-0.1984370991868792)\n",
      "     | > loss_dur: 0.26112833619117737  (0.24617083210026158)\n",
      "     | > amp_scaler: 8192.0  (14816.258760107818)\n",
      "     | > grad_norm: tensor(9.4194, device='cuda:0')  (tensor(8.3589, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 0.7683  (0.6614188344652127)\n",
      "     | > loader_time: 0.0433  (0.012959320911500012)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:25:50 -- STEP: 396/406 -- GLOBAL_STEP: 24750\u001b[0m\n",
      "     | > loss: 0.04653477668762207  (0.047715822629856325)\n",
      "     | > log_mle: -0.21395111083984375  (-0.19912732038835076)\n",
      "     | > loss_dur: 0.2604858875274658  (0.24684314301820717)\n",
      "     | > amp_scaler: 8192.0  (14398.060606060606)\n",
      "     | > grad_norm: tensor(5.8955, device='cuda:0')  (tensor(8.2235, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 0.5416  (0.6685827073424759)\n",
      "     | > loader_time: 0.006  (0.012965554540807552)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: 0.04813012480735779  (0.04813012480735779)\n",
      "     | > log_mle: -0.1807798147201538  (-0.1807798147201538)\n",
      "     | > loss_dur: 0.2289099395275116  (0.2289099395275116)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: -0.014170333743095398  (-0.014170333743095398)\n",
      "     | > log_mle: -0.2154618501663208  (-0.2154618501663208)\n",
      "     | > loss_dur: 0.2012915164232254  (0.2012915164232254)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: 0.02621743083000183  (0.0060235485434532166)\n",
      "     | > log_mle: -0.1756373643875122  (-0.1955496072769165)\n",
      "     | > loss_dur: 0.20185479521751404  (0.20157315582036972)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: 0.02932138741016388  (0.013789494832356771)\n",
      "     | > log_mle: -0.18849444389343262  (-0.19319788614908853)\n",
      "     | > loss_dur: 0.2178158313035965  (0.2069873809814453)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: 0.026814386248588562  (0.01704571768641472)\n",
      "     | > log_mle: -0.21461987495422363  (-0.19855338335037231)\n",
      "     | > loss_dur: 0.2414342612028122  (0.21559910103678703)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: 0.025907889008522034  (0.018818151950836182)\n",
      "     | > log_mle: -0.20461773872375488  (-0.19976625442504883)\n",
      "     | > loss_dur: 0.23052562773227692  (0.218584406375885)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: 0.060644328594207764  (0.025789181391398113)\n",
      "     | > log_mle: -0.21754837036132812  (-0.2027299404144287)\n",
      "     | > loss_dur: 0.2781926989555359  (0.2285191218058268)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: 0.03147502243518829  (0.026601444397653853)\n",
      "     | > log_mle: -0.18891513347625732  (-0.20075639656611852)\n",
      "     | > loss_dur: 0.22039015591144562  (0.22735784096377237)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: 0.018955066800117493  (0.025645647197961807)\n",
      "     | > log_mle: -0.19763541221618652  (-0.20036627352237701)\n",
      "     | > loss_dur: 0.21659047901630402  (0.22601192072033882)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: 0.049791306257247925  (0.028328498204549152)\n",
      "     | > log_mle: -0.20529508590698242  (-0.2009139193428887)\n",
      "     | > loss_dur: 0.25508639216423035  (0.22924241754743788)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: 0.04569101333618164  (0.0300647497177124)\n",
      "     | > log_mle: -0.1949390172958374  (-0.2003164291381836)\n",
      "     | > loss_dur: 0.24063003063201904  (0.23038117885589598)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: 0.033261463046073914  (0.030355360020290722)\n",
      "     | > log_mle: -0.2100389003753662  (-0.20120029015974564)\n",
      "     | > loss_dur: 0.24330036342144012  (0.23155565018003638)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: 0.006437167525291443  (0.028362177312374115)\n",
      "     | > log_mle: -0.1999351978302002  (-0.2010948657989502)\n",
      "     | > loss_dur: 0.20637236535549164  (0.2294570431113243)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: -0.009484708309173584  (0.025450878418408908)\n",
      "     | > log_mle: -0.21411478519439697  (-0.2020963980601384)\n",
      "     | > loss_dur: 0.2046300768852234  (0.2275472764785473)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: 0.03422582149505615  (0.026077660066740855)\n",
      "     | > log_mle: -0.21045935153961182  (-0.2026937518801008)\n",
      "     | > loss_dur: 0.24468517303466797  (0.22877141194684164)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: 0.025269493460655212  (0.02602378229300181)\n",
      "     | > log_mle: -0.20428812503814697  (-0.20280004342397054)\n",
      "     | > loss_dur: 0.22955761849880219  (0.22882382571697235)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: 0.056506991386413574  (0.027928982861340046)\n",
      "     | > log_mle: -0.19907844066619873  (-0.2025674432516098)\n",
      "     | > loss_dur: 0.2555854320526123  (0.23049642611294985)\n",
      "\n",
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[91m 0.003822565078735352 \u001b[0m(+0.00043404102325439496)\n",
      "     | > avg_loss:\u001b[91m 0.027928982861340046 \u001b[0m(+0.002170521765947342)\n",
      "     | > avg_log_mle:\u001b[91m -0.2025674432516098 \u001b[0m(+0.002321302890777588)\n",
      "     | > avg_loss_dur:\u001b[92m 0.23049642611294985 \u001b[0m(-0.00015078112483024597)\n",
      "\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 5/100\u001b[0m\n",
      " --> train/run-February-22-2025_10+59PM-fa84af3\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-22 23:26:11) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:26:18 -- STEP: 15/406 -- GLOBAL_STEP: 24775\u001b[0m\n",
      "     | > loss: 0.04242268204689026  (0.0397245575984319)\n",
      "     | > log_mle: -0.18269598484039307  (-0.1812616030375163)\n",
      "     | > loss_dur: 0.22511866688728333  (0.22098616063594817)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(2.7583, device='cuda:0')  (tensor(2.7997, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-06 \n",
      "     | > step_time: 0.3931  (0.38704946835835774)\n",
      "     | > loader_time: 0.0158  (0.007026386260986328)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:26:33 -- STEP: 40/406 -- GLOBAL_STEP: 24800\u001b[0m\n",
      "     | > loss: 0.05033314228057861  (0.04487197995185852)\n",
      "     | > log_mle: -0.16195714473724365  (-0.17917630970478057)\n",
      "     | > loss_dur: 0.21229028701782227  (0.2240482896566391)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(1.9480, device='cuda:0')  (tensor(2.6774, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-06 \n",
      "     | > step_time: 0.7983  (0.4942495822906494)\n",
      "     | > loader_time: 0.0435  (0.007603996992111206)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:26:46 -- STEP: 65/406 -- GLOBAL_STEP: 24825\u001b[0m\n",
      "     | > loss: 0.05332176387310028  (0.04676498472690582)\n",
      "     | > log_mle: -0.17778825759887695  (-0.18136497460878812)\n",
      "     | > loss_dur: 0.23111002147197723  (0.22812995933569394)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(2.5030, device='cuda:0')  (tensor(2.8448, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-06 \n",
      "     | > step_time: 0.5115  (0.5062147103823149)\n",
      "     | > loader_time: 0.0246  (0.008410574839665336)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:27:01 -- STEP: 90/406 -- GLOBAL_STEP: 24850\u001b[0m\n",
      "     | > loss: 0.02890390157699585  (0.04665383249521256)\n",
      "     | > log_mle: -0.19852542877197266  (-0.184231079949273)\n",
      "     | > loss_dur: 0.2274293303489685  (0.23088491244448556)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(4.7966, device='cuda:0')  (tensor(3.3928, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-06 \n",
      "     | > step_time: 0.3328  (0.5294377353456289)\n",
      "     | > loader_time: 0.0059  (0.008621658219231497)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:27:17 -- STEP: 115/406 -- GLOBAL_STEP: 24875\u001b[0m\n",
      "     | > loss: 0.05808331072330475  (0.04672967623109403)\n",
      "     | > log_mle: -0.1812378168106079  (-0.18701017524885094)\n",
      "     | > loss_dur: 0.23932112753391266  (0.23373985147994497)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(1.8335, device='cuda:0')  (tensor(3.6512, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-06 \n",
      "     | > step_time: 0.4379  (0.5484754292861277)\n",
      "     | > loader_time: 0.0236  (0.009111885402513585)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:27:33 -- STEP: 140/406 -- GLOBAL_STEP: 24900\u001b[0m\n",
      "     | > loss: 0.051734358072280884  (0.04715716519526073)\n",
      "     | > log_mle: -0.2051607370376587  (-0.18909107276371548)\n",
      "     | > loss_dur: 0.2568950951099396  (0.2362482379589762)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(11.8483, device='cuda:0')  (tensor(3.9579, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-06 \n",
      "     | > step_time: 0.5094  (0.5645092623574395)\n",
      "     | > loader_time: 0.0043  (0.00914100408554077)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:27:49 -- STEP: 165/406 -- GLOBAL_STEP: 24925\u001b[0m\n",
      "     | > loss: 0.021966546773910522  (0.04757511814435323)\n",
      "     | > log_mle: -0.2182401418685913  (-0.1906217112685695)\n",
      "     | > loss_dur: 0.24020668864250183  (0.23819682941292272)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(6.6298, device='cuda:0')  (tensor(4.1052, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-06 \n",
      "     | > step_time: 0.6291  (0.5715694716482452)\n",
      "     | > loader_time: 0.0348  (0.009501559806592537)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:28:05 -- STEP: 190/406 -- GLOBAL_STEP: 24950\u001b[0m\n",
      "     | > loss: 0.04686221480369568  (0.04725937725682008)\n",
      "     | > log_mle: -0.21112167835235596  (-0.19209568814227457)\n",
      "     | > loss_dur: 0.25798389315605164  (0.23935506539909462)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(4.2705, device='cuda:0')  (tensor(4.0321, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-06 \n",
      "     | > step_time: 1.0982  (0.5810326701716374)\n",
      "     | > loader_time: 0.0095  (0.009551042004635461)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:28:22 -- STEP: 215/406 -- GLOBAL_STEP: 24975\u001b[0m\n",
      "     | > loss: 0.053027838468551636  (0.047002176351325455)\n",
      "     | > log_mle: -0.1993088722229004  (-0.19322979283887287)\n",
      "     | > loss_dur: 0.252336710691452  (0.24023196919019832)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(10.7730, device='cuda:0')  (tensor(4.1837, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-06 \n",
      "     | > step_time: 0.956  (0.588832070106684)\n",
      "     | > loader_time: 0.0053  (0.009818275584730989)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:28:40 -- STEP: 240/406 -- GLOBAL_STEP: 25000\u001b[0m\n",
      "     | > loss: 0.0301503986120224  (0.04722801446914673)\n",
      "     | > log_mle: -0.21458423137664795  (-0.1945541928211848)\n",
      "     | > loss_dur: 0.24473462998867035  (0.24178220729033154)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(2.9764, device='cuda:0')  (tensor(4.2939, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-06 \n",
      "     | > step_time: 0.5371  (0.5998990396658582)\n",
      "     | > loader_time: 0.007  (0.01004879573980967)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:28:58 -- STEP: 265/406 -- GLOBAL_STEP: 25025\u001b[0m\n",
      "     | > loss: 0.04583007097244263  (0.0470899113506641)\n",
      "     | > log_mle: -0.20958387851715088  (-0.19558143840645845)\n",
      "     | > loss_dur: 0.2554139494895935  (0.24267134975712254)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(5.5933, device='cuda:0')  (tensor(4.2484, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-06 \n",
      "     | > step_time: 0.9721  (0.6097580909729006)\n",
      "     | > loader_time: 0.0213  (0.010827629521207988)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:29:16 -- STEP: 290/406 -- GLOBAL_STEP: 25050\u001b[0m\n",
      "     | > loss: 0.03592517971992493  (0.046843240744081034)\n",
      "     | > log_mle: -0.21696186065673828  (-0.19650911832677906)\n",
      "     | > loss_dur: 0.2528870403766632  (0.2433523590708601)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(4.8309, device='cuda:0')  (tensor(4.2951, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-06 \n",
      "     | > step_time: 0.8345  (0.618211158390703)\n",
      "     | > loader_time: 0.0226  (0.011054093262244912)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:29:36 -- STEP: 315/406 -- GLOBAL_STEP: 25075\u001b[0m\n",
      "     | > loss: 0.04745882749557495  (0.046698608001073214)\n",
      "     | > log_mle: -0.20630300045013428  (-0.19731479523673892)\n",
      "     | > loss_dur: 0.25376182794570923  (0.2440134032378121)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(1.9277, device='cuda:0')  (tensor(4.2417, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-06 \n",
      "     | > step_time: 0.618  (0.6284354300726028)\n",
      "     | > loader_time: 0.0061  (0.01134566882299998)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:29:54 -- STEP: 340/406 -- GLOBAL_STEP: 25100\u001b[0m\n",
      "     | > loss: 0.052377939224243164  (0.046850421411149666)\n",
      "     | > log_mle: -0.19981729984283447  (-0.19796007976812474)\n",
      "     | > loss_dur: 0.25219523906707764  (0.2448105011792744)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(1.4653, device='cuda:0')  (tensor(4.1172, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-06 \n",
      "     | > step_time: 0.6434  (0.636190267871408)\n",
      "     | > loader_time: 0.0069  (0.01164988419588874)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:30:14 -- STEP: 365/406 -- GLOBAL_STEP: 25125\u001b[0m\n",
      "     | > loss: 0.03773804008960724  (0.04683640125679645)\n",
      "     | > log_mle: -0.21112477779388428  (-0.1987903013621291)\n",
      "     | > loss_dur: 0.24886281788349152  (0.24562670261892555)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(5.1598, device='cuda:0')  (tensor(4.2945, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-06 \n",
      "     | > step_time: 0.5448  (0.6442755333364825)\n",
      "     | > loader_time: 0.0084  (0.011790577352863466)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:30:35 -- STEP: 390/406 -- GLOBAL_STEP: 25150\u001b[0m\n",
      "     | > loss: 0.041212230920791626  (0.046865733846639994)\n",
      "     | > log_mle: -0.22220158576965332  (-0.1995075366435907)\n",
      "     | > loss_dur: 0.26341381669044495  (0.24637327049023067)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(9.0489, device='cuda:0')  (tensor(4.3453, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-06 \n",
      "     | > step_time: 0.8871  (0.6553495046419979)\n",
      "     | > loader_time: 0.0079  (0.012070283522972692)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: 0.04757705330848694  (0.04757705330848694)\n",
      "     | > log_mle: -0.1815863847732544  (-0.1815863847732544)\n",
      "     | > loss_dur: 0.22916343808174133  (0.22916343808174133)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: -0.01738986372947693  (-0.01738986372947693)\n",
      "     | > log_mle: -0.2163839340209961  (-0.2163839340209961)\n",
      "     | > loss_dur: 0.19899407029151917  (0.19899407029151917)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: 0.02543412148952484  (0.004022128880023956)\n",
      "     | > log_mle: -0.1763676404953003  (-0.1963757872581482)\n",
      "     | > loss_dur: 0.20180176198482513  (0.20039791613817215)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: 0.02829386293888092  (0.012112706899642944)\n",
      "     | > log_mle: -0.18923592567443848  (-0.19399583339691162)\n",
      "     | > loss_dur: 0.2175297886133194  (0.20610854029655457)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: 0.02427215874195099  (0.015152569860219955)\n",
      "     | > log_mle: -0.21562087535858154  (-0.1994020938873291)\n",
      "     | > loss_dur: 0.23989303410053253  (0.21455466374754906)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: 0.025507748126983643  (0.017223605513572694)\n",
      "     | > log_mle: -0.20488512516021729  (-0.20049870014190674)\n",
      "     | > loss_dur: 0.23039287328720093  (0.21772230565547943)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: 0.05879071354866028  (0.024151456852753956)\n",
      "     | > log_mle: -0.21788012981414795  (-0.20339560508728027)\n",
      "     | > loss_dur: 0.2766708433628082  (0.22754706194003424)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: 0.028556019067764282  (0.02478068002632686)\n",
      "     | > log_mle: -0.1895207166671753  (-0.20141347817012242)\n",
      "     | > loss_dur: 0.21807673573493958  (0.22619415819644928)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: 0.01814158260822296  (0.023950792849063873)\n",
      "     | > log_mle: -0.19833600521087646  (-0.20102879405021667)\n",
      "     | > loss_dur: 0.21647758781909943  (0.22497958689928055)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: 0.05452093482017517  (0.027347475290298462)\n",
      "     | > log_mle: -0.20592987537384033  (-0.20157335864173043)\n",
      "     | > loss_dur: 0.2604508101940155  (0.2289208339320289)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: 0.048810407519340515  (0.029493768513202668)\n",
      "     | > log_mle: -0.195764422416687  (-0.20099246501922607)\n",
      "     | > loss_dur: 0.24457482993602753  (0.23048623353242875)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: 0.029944226145744324  (0.02953471920707009)\n",
      "     | > log_mle: -0.2106989622116089  (-0.20187487385489725)\n",
      "     | > loss_dur: 0.2406431883573532  (0.23140959306196732)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: 0.005478188395500183  (0.02753000830610593)\n",
      "     | > log_mle: -0.20080232620239258  (-0.2017854948838552)\n",
      "     | > loss_dur: 0.20628051459789276  (0.2293155031899611)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: -0.009613826870918274  (0.024672790215565607)\n",
      "     | > log_mle: -0.21455776691436768  (-0.20276797734774077)\n",
      "     | > loss_dur: 0.2049439400434494  (0.22744076756330636)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: 0.033571839332580566  (0.025308436581066678)\n",
      "     | > log_mle: -0.21115124225616455  (-0.20336678198405675)\n",
      "     | > loss_dur: 0.24472308158874512  (0.22867521856512343)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: 0.024259746074676514  (0.025238523880640667)\n",
      "     | > log_mle: -0.20500922203063965  (-0.20347627798716228)\n",
      "     | > loss_dur: 0.22926896810531616  (0.22871480186780294)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: 0.046889662742614746  (0.026591720059514046)\n",
      "     | > log_mle: -0.20003890991210938  (-0.20326144248247147)\n",
      "     | > loss_dur: 0.24692857265472412  (0.2298531625419855)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: audio amplitude out of range, auto clipped.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[91m 0.00457213819026947 \u001b[0m(+0.0007495731115341182)\n",
      "     | > avg_loss:\u001b[92m 0.026591720059514046 \u001b[0m(-0.0013372628018260002)\n",
      "     | > avg_log_mle:\u001b[92m -0.20326144248247147 \u001b[0m(-0.0006939992308616638)\n",
      "     | > avg_loss_dur:\u001b[92m 0.2298531625419855 \u001b[0m(-0.0006432635709643364)\n",
      "\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 6/100\u001b[0m\n",
      " --> train/run-February-22-2025_10+59PM-fa84af3\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-22 23:30:58) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:31:03 -- STEP: 9/406 -- GLOBAL_STEP: 25175\u001b[0m\n",
      "     | > loss: 0.04912281036376953  (0.0377556367052926)\n",
      "     | > log_mle: -0.18724000453948975  (-0.17943898836771646)\n",
      "     | > loss_dur: 0.23636281490325928  (0.21719462507300907)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(2.5075, device='cuda:0')  (tensor(2.4870, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 0.3612  (0.374241484536065)\n",
      "     | > loader_time: 0.0026  (0.007754431830512153)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:31:17 -- STEP: 34/406 -- GLOBAL_STEP: 25200\u001b[0m\n",
      "     | > loss: 0.059128180146217346  (0.04216592495932298)\n",
      "     | > log_mle: -0.1760629415512085  (-0.1800554394721985)\n",
      "     | > loss_dur: 0.23519112169742584  (0.22222136443152146)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(9.9553, device='cuda:0')  (tensor(4.3739, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 0.6721  (0.492121836718391)\n",
      "     | > loader_time: 0.0079  (0.009325854918536018)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:31:31 -- STEP: 59/406 -- GLOBAL_STEP: 25225\u001b[0m\n",
      "     | > loss: 0.040304288268089294  (0.0456648289652194)\n",
      "     | > log_mle: -0.18686699867248535  (-0.18168931896403684)\n",
      "     | > loss_dur: 0.22717128694057465  (0.22735414792925623)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(3.7241, device='cuda:0')  (tensor(4.9974, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 0.7389  (0.5161219491796979)\n",
      "     | > loader_time: 0.0151  (0.009493989459538863)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:31:46 -- STEP: 84/406 -- GLOBAL_STEP: 25250\u001b[0m\n",
      "     | > loss: 0.055364787578582764  (0.04574157315350715)\n",
      "     | > log_mle: -0.19564831256866455  (-0.18424320362863084)\n",
      "     | > loss_dur: 0.2510131001472473  (0.229984776782138)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(3.9002, device='cuda:0')  (tensor(4.9643, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 0.3294  (0.5349702976998829)\n",
      "     | > loader_time: 0.0042  (0.009439391749245785)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:32:02 -- STEP: 109/406 -- GLOBAL_STEP: 25275\u001b[0m\n",
      "     | > loss: 0.04961502552032471  (0.04540955350486511)\n",
      "     | > log_mle: -0.20680701732635498  (-0.18690869676957436)\n",
      "     | > loss_dur: 0.2564220428466797  (0.23231825027443948)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(2.0344, device='cuda:0')  (tensor(5.2763, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 0.4888  (0.5571652202431219)\n",
      "     | > loader_time: 0.007  (0.009667282804436643)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:32:18 -- STEP: 134/406 -- GLOBAL_STEP: 25300\u001b[0m\n",
      "     | > loss: 0.06302663683891296  (0.045360550173182995)\n",
      "     | > log_mle: -0.19133079051971436  (-0.1893663317409914)\n",
      "     | > loss_dur: 0.2543574273586273  (0.23472688191417437)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(5.2546, device='cuda:0')  (tensor(5.0856, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 0.6209  (0.5677280123554062)\n",
      "     | > loader_time: 0.016  (0.009477464120779468)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:32:34 -- STEP: 159/406 -- GLOBAL_STEP: 25325\u001b[0m\n",
      "     | > loss: 0.04162856936454773  (0.04601928647959009)\n",
      "     | > log_mle: -0.20174551010131836  (-0.1909720995141275)\n",
      "     | > loss_dur: 0.2433740794658661  (0.2369913859937176)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(3.8075, device='cuda:0')  (tensor(5.1199, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 0.374  (0.5757508967657512)\n",
      "     | > loader_time: 0.0052  (0.009918107926470684)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:32:51 -- STEP: 184/406 -- GLOBAL_STEP: 25350\u001b[0m\n",
      "     | > loss: 0.06679987907409668  (0.04590845464364345)\n",
      "     | > log_mle: -0.2083960771560669  (-0.19244414114433783)\n",
      "     | > loss_dur: 0.2751959562301636  (0.2383525957879813)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(6.5777, device='cuda:0')  (tensor(4.9327, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 0.6702  (0.5899960722612296)\n",
      "     | > loader_time: 0.0179  (0.01006836087807365)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:33:08 -- STEP: 209/406 -- GLOBAL_STEP: 25375\u001b[0m\n",
      "     | > loss: 0.030366405844688416  (0.045755344144465276)\n",
      "     | > log_mle: -0.20789837837219238  (-0.19370945161609554)\n",
      "     | > loss_dur: 0.2382647842168808  (0.23946479576056084)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(8.5553, device='cuda:0')  (tensor(5.3139, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 0.5655  (0.6003808005574787)\n",
      "     | > loader_time: 0.019  (0.010426001115278765)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:33:25 -- STEP: 234/406 -- GLOBAL_STEP: 25400\u001b[0m\n",
      "     | > loss: 0.05036696791648865  (0.04578440840172974)\n",
      "     | > log_mle: -0.2149667739868164  (-0.19513135639011348)\n",
      "     | > loss_dur: 0.26533374190330505  (0.2409157647918432)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(7.3399, device='cuda:0')  (tensor(5.4260, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 0.5861  (0.6073271718799559)\n",
      "     | > loader_time: 0.0051  (0.01067834328382443)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:33:43 -- STEP: 259/406 -- GLOBAL_STEP: 25425\u001b[0m\n",
      "     | > loss: 0.04100614786148071  (0.045539834266924054)\n",
      "     | > log_mle: -0.2225741147994995  (-0.19627228666916774)\n",
      "     | > loss_dur: 0.2635802626609802  (0.2418121209360918)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(7.8688, device='cuda:0')  (tensor(5.3327, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 0.6355  (0.6156839993009235)\n",
      "     | > loader_time: 0.016  (0.011330022775068246)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:34:02 -- STEP: 284/406 -- GLOBAL_STEP: 25450\u001b[0m\n",
      "     | > loss: 0.041245847940444946  (0.04504954741454462)\n",
      "     | > log_mle: -0.21251177787780762  (-0.19728399204536226)\n",
      "     | > loss_dur: 0.25375762581825256  (0.24233353945990682)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(8.3164, device='cuda:0')  (tensor(5.6071, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 0.8214  (0.6247699520957303)\n",
      "     | > loader_time: 0.0058  (0.011789084320337)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:34:21 -- STEP: 309/406 -- GLOBAL_STEP: 25475\u001b[0m\n",
      "     | > loss: 0.027831286191940308  (0.04515106238207772)\n",
      "     | > log_mle: -0.20673739910125732  (-0.19806049518214847)\n",
      "     | > loss_dur: 0.23456868529319763  (0.24321155756422616)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(4.3047, device='cuda:0')  (tensor(5.7515, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 0.749  (0.6351087131932329)\n",
      "     | > loader_time: 0.0324  (0.012253588457323588)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:34:40 -- STEP: 334/406 -- GLOBAL_STEP: 25500\u001b[0m\n",
      "     | > loss: 0.03903225064277649  (0.04510179603706579)\n",
      "     | > log_mle: -0.21556365489959717  (-0.19876583678993637)\n",
      "     | > loss_dur: 0.25459590554237366  (0.24386763282700213)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(5.4882, device='cuda:0')  (tensor(5.6926, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 0.7702  (0.6425488537657043)\n",
      "     | > loader_time: 0.018  (0.012507581425284197)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:35:00 -- STEP: 359/406 -- GLOBAL_STEP: 25525\u001b[0m\n",
      "     | > loss: 0.045860305428504944  (0.04511859763963644)\n",
      "     | > log_mle: -0.20052456855773926  (-0.19956047023571302)\n",
      "     | > loss_dur: 0.2463848739862442  (0.24467906787534943)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(4.0903, device='cuda:0')  (tensor(5.5882, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 0.746  (0.6519106384107328)\n",
      "     | > loader_time: 0.0115  (0.012765991322509426)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:35:22 -- STEP: 384/406 -- GLOBAL_STEP: 25550\u001b[0m\n",
      "     | > loss: 0.05135264992713928  (0.045197679428383736)\n",
      "     | > log_mle: -0.21290791034698486  (-0.20028500662495693)\n",
      "     | > loss_dur: 0.26426056027412415  (0.24548268605334064)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(4.0366, device='cuda:0')  (tensor(5.5967, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 1.0608  (0.6647025924175974)\n",
      "     | > loader_time: 0.0123  (0.013081733137369156)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: 0.04610414803028107  (0.04610414803028107)\n",
      "     | > log_mle: -0.18206071853637695  (-0.18206071853637695)\n",
      "     | > loss_dur: 0.22816486656665802  (0.22816486656665802)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: -0.016927778720855713  (-0.016927778720855713)\n",
      "     | > log_mle: -0.21635520458221436  (-0.21635520458221436)\n",
      "     | > loss_dur: 0.19942742586135864  (0.19942742586135864)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: 0.027144894003868103  (0.005108557641506195)\n",
      "     | > log_mle: -0.17666244506835938  (-0.19650882482528687)\n",
      "     | > loss_dur: 0.20380733907222748  (0.20161738246679306)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: 0.02861766517162323  (0.012944926818211874)\n",
      "     | > log_mle: -0.1891946792602539  (-0.19407077630360922)\n",
      "     | > loss_dur: 0.21781234443187714  (0.20701570312182108)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: 0.0257750004529953  (0.01615244522690773)\n",
      "     | > log_mle: -0.21540141105651855  (-0.19940343499183655)\n",
      "     | > loss_dur: 0.24117641150951385  (0.21555588021874428)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: 0.02817898988723755  (0.018557754158973695)\n",
      "     | > log_mle: -0.20294344425201416  (-0.20011143684387206)\n",
      "     | > loss_dur: 0.2311224341392517  (0.21866919100284576)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: 0.05272677540779114  (0.0242525910337766)\n",
      "     | > log_mle: -0.2160123586654663  (-0.20276159048080444)\n",
      "     | > loss_dur: 0.26873913407325745  (0.22701418151458105)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: 0.02785426378250122  (0.024767115712165833)\n",
      "     | > log_mle: -0.18912780284881592  (-0.20081390653337752)\n",
      "     | > loss_dur: 0.21698206663131714  (0.22558102224554336)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: 0.017267897725105286  (0.023829713463783264)\n",
      "     | > log_mle: -0.19836997985839844  (-0.20050841569900513)\n",
      "     | > loss_dur: 0.21563787758350372  (0.2243381291627884)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: 0.05155140161514282  (0.02690990103615655)\n",
      "     | > log_mle: -0.20502924919128418  (-0.20101073053148058)\n",
      "     | > loss_dur: 0.256580650806427  (0.22792063156763712)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: 0.047928586602211  (0.029011769592761992)\n",
      "     | > log_mle: -0.19535958766937256  (-0.20044561624526977)\n",
      "     | > loss_dur: 0.24328817427158356  (0.22945738583803177)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: 0.030589640140533447  (0.029155212369832127)\n",
      "     | > log_mle: -0.21014022827148438  (-0.20132694461128928)\n",
      "     | > loss_dur: 0.24072986841201782  (0.2304821569811214)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: 0.005667060613632202  (0.0271978663901488)\n",
      "     | > log_mle: -0.20084023475646973  (-0.20128638545672098)\n",
      "     | > loss_dur: 0.20650729537010193  (0.2284842518468698)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: -0.007366642355918884  (0.02453905802506667)\n",
      "     | > log_mle: -0.21328604221343994  (-0.2022094359764686)\n",
      "     | > loss_dur: 0.20591939985752106  (0.22674849400153527)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: 0.03662523627281189  (0.025402356471334184)\n",
      "     | > log_mle: -0.2105644941329956  (-0.20280622584479197)\n",
      "     | > loss_dur: 0.2471897304058075  (0.22820858231612615)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: 0.020981252193450928  (0.02510761618614197)\n",
      "     | > log_mle: -0.20456945896148682  (-0.20292377471923828)\n",
      "     | > loss_dur: 0.22555071115493774  (0.22803139090538024)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: 0.042283445596694946  (0.02618110552430153)\n",
      "     | > log_mle: -0.19938862323760986  (-0.2027028277516365)\n",
      "     | > loss_dur: 0.2416720688343048  (0.22888393327593803)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: audio amplitude out of range, auto clipped.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.0033722668886184692 \u001b[0m(-0.001199871301651001)\n",
      "     | > avg_loss:\u001b[92m 0.02618110552430153 \u001b[0m(-0.0004106145352125168)\n",
      "     | > avg_log_mle:\u001b[91m -0.2027028277516365 \u001b[0m(+0.0005586147308349609)\n",
      "     | > avg_loss_dur:\u001b[92m 0.22888393327593803 \u001b[0m(-0.0009692292660474777)\n",
      "\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 7/100\u001b[0m\n",
      " --> train/run-February-22-2025_10+59PM-fa84af3\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-22 23:35:50) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:35:53 -- STEP: 3/406 -- GLOBAL_STEP: 25575\u001b[0m\n",
      "     | > loss: 0.04951350390911102  (0.040132299065589905)\n",
      "     | > log_mle: -0.18557071685791016  (-0.1857469081878662)\n",
      "     | > loss_dur: 0.23508422076702118  (0.22587920725345612)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(3.1364, device='cuda:0')  (tensor(4.8230, device='cuda:0'))\n",
      "     | > current_lr: 1.75e-06 \n",
      "     | > step_time: 0.3555  (0.4495578606923421)\n",
      "     | > loader_time: 0.0148  (0.009146690368652344)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:36:05 -- STEP: 28/406 -- GLOBAL_STEP: 25600\u001b[0m\n",
      "     | > loss: 0.06563925743103027  (0.03994773221867425)\n",
      "     | > log_mle: -0.18097102642059326  (-0.18129647629601614)\n",
      "     | > loss_dur: 0.24661028385162354  (0.2212442085146904)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(6.1392, device='cuda:0')  (tensor(3.0695, device='cuda:0'))\n",
      "     | > current_lr: 1.75e-06 \n",
      "     | > step_time: 0.5151  (0.4516015478542873)\n",
      "     | > loader_time: 0.0109  (0.006784405027117048)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:36:18 -- STEP: 53/406 -- GLOBAL_STEP: 25625\u001b[0m\n",
      "     | > loss: 0.03878846764564514  (0.04537669976927199)\n",
      "     | > log_mle: -0.18022370338439941  (-0.18215883902783664)\n",
      "     | > loss_dur: 0.21901217103004456  (0.22753553879710864)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(3.0953, device='cuda:0')  (tensor(3.6029, device='cuda:0'))\n",
      "     | > current_lr: 1.75e-06 \n",
      "     | > step_time: 0.5572  (0.4919644436746273)\n",
      "     | > loader_time: 0.0044  (0.007954413036130509)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:36:32 -- STEP: 78/406 -- GLOBAL_STEP: 25650\u001b[0m\n",
      "     | > loss: 0.0402771532535553  (0.04474119689220038)\n",
      "     | > log_mle: -0.18667852878570557  (-0.18465162699039164)\n",
      "     | > loss_dur: 0.22695568203926086  (0.22939282388259202)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(4.2548, device='cuda:0')  (tensor(3.9665, device='cuda:0'))\n",
      "     | > current_lr: 1.75e-06 \n",
      "     | > step_time: 0.8226  (0.5085883079430996)\n",
      "     | > loader_time: 0.0041  (0.009454030257004958)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:36:47 -- STEP: 103/406 -- GLOBAL_STEP: 25675\u001b[0m\n",
      "     | > loss: 0.01353985071182251  (0.04419820560413658)\n",
      "     | > log_mle: -0.20404255390167236  (-0.18755515686516622)\n",
      "     | > loss_dur: 0.21758240461349487  (0.2317533624693028)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(4.0831, device='cuda:0')  (tensor(4.9393, device='cuda:0'))\n",
      "     | > current_lr: 1.75e-06 \n",
      "     | > step_time: 0.6696  (0.5231673208255215)\n",
      "     | > loader_time: 0.0042  (0.010317411237550015)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:37:02 -- STEP: 128/406 -- GLOBAL_STEP: 25700\u001b[0m\n",
      "     | > loss: 0.0332772433757782  (0.04391874792054296)\n",
      "     | > log_mle: -0.19760525226593018  (-0.18992928322404623)\n",
      "     | > loss_dur: 0.23088249564170837  (0.23384803114458919)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(4.0265, device='cuda:0')  (tensor(4.9668, device='cuda:0'))\n",
      "     | > current_lr: 1.75e-06 \n",
      "     | > step_time: 0.5097  (0.5375967938452962)\n",
      "     | > loader_time: 0.0225  (0.010753354057669641)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:37:18 -- STEP: 153/406 -- GLOBAL_STEP: 25725\u001b[0m\n",
      "     | > loss: 0.03219161927700043  (0.04436260452067932)\n",
      "     | > log_mle: -0.20719194412231445  (-0.1918417480256823)\n",
      "     | > loss_dur: 0.23938356339931488  (0.23620435254636155)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(5.5581, device='cuda:0')  (tensor(4.9284, device='cuda:0'))\n",
      "     | > current_lr: 1.75e-06 \n",
      "     | > step_time: 0.4385  (0.5515504506678366)\n",
      "     | > loader_time: 0.0048  (0.010624241984747594)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:37:35 -- STEP: 178/406 -- GLOBAL_STEP: 25750\u001b[0m\n",
      "     | > loss: 0.055079832673072815  (0.04458807442295419)\n",
      "     | > log_mle: -0.18939554691314697  (-0.1931557655334473)\n",
      "     | > loss_dur: 0.2444753795862198  (0.23774383995640144)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(5.8572, device='cuda:0')  (tensor(5.0181, device='cuda:0'))\n",
      "     | > current_lr: 1.75e-06 \n",
      "     | > step_time: 0.7574  (0.5677887040577578)\n",
      "     | > loader_time: 0.0185  (0.010805661758680023)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:37:52 -- STEP: 203/406 -- GLOBAL_STEP: 25775\u001b[0m\n",
      "     | > loss: 0.05921143293380737  (0.04455757897182052)\n",
      "     | > log_mle: -0.20028924942016602  (-0.19456082259492924)\n",
      "     | > loss_dur: 0.2595006823539734  (0.2391184015667497)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(13.0151, device='cuda:0')  (tensor(5.3543, device='cuda:0'))\n",
      "     | > current_lr: 1.75e-06 \n",
      "     | > step_time: 0.3988  (0.5801113333020894)\n",
      "     | > loader_time: 0.0052  (0.011238508036571183)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:38:10 -- STEP: 228/406 -- GLOBAL_STEP: 25800\u001b[0m\n",
      "     | > loss: 0.02801339328289032  (0.044356021376555435)\n",
      "     | > log_mle: -0.2061671018600464  (-0.1959882179896037)\n",
      "     | > loss_dur: 0.2341804951429367  (0.24034423936615912)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(12.7086, device='cuda:0')  (tensor(5.7204, device='cuda:0'))\n",
      "     | > current_lr: 1.75e-06 \n",
      "     | > step_time: 0.6187  (0.5905659052363618)\n",
      "     | > loader_time: 0.0057  (0.011353085961258202)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:38:28 -- STEP: 253/406 -- GLOBAL_STEP: 25825\u001b[0m\n",
      "     | > loss: 0.0312657356262207  (0.044335053018901664)\n",
      "     | > log_mle: -0.22217071056365967  (-0.19725625269968994)\n",
      "     | > loss_dur: 0.25343644618988037  (0.24159130571859155)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(18.3055, device='cuda:0')  (tensor(6.3349, device='cuda:0'))\n",
      "     | > current_lr: 1.75e-06 \n",
      "     | > step_time: 0.8347  (0.6020848779339097)\n",
      "     | > loader_time: 0.0239  (0.01153070747616734)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:38:46 -- STEP: 278/406 -- GLOBAL_STEP: 25850\u001b[0m\n",
      "     | > loss: 0.047715216875076294  (0.04397496157627311)\n",
      "     | > log_mle: -0.19948482513427734  (-0.1982355199271827)\n",
      "     | > loss_dur: 0.24720004200935364  (0.24221048150345575)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(5.5309, device='cuda:0')  (tensor(6.6879, device='cuda:0'))\n",
      "     | > current_lr: 1.75e-06 \n",
      "     | > step_time: 0.9124  (0.6125194889178384)\n",
      "     | > loader_time: 0.0442  (0.011527991980957471)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:39:06 -- STEP: 303/406 -- GLOBAL_STEP: 25875\u001b[0m\n",
      "     | > loss: 0.05541229248046875  (0.04393579385461587)\n",
      "     | > log_mle: -0.20929014682769775  (-0.19911174058127332)\n",
      "     | > loss_dur: 0.2647024393081665  (0.2430475344358891)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(11.2295, device='cuda:0')  (tensor(7.0454, device='cuda:0'))\n",
      "     | > current_lr: 1.75e-06 \n",
      "     | > step_time: 0.5454  (0.6267628197622779)\n",
      "     | > loader_time: 0.0062  (0.011813834162041695)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:39:27 -- STEP: 328/406 -- GLOBAL_STEP: 25900\u001b[0m\n",
      "     | > loss: 0.05750226974487305  (0.043818691109375245)\n",
      "     | > log_mle: -0.21791279315948486  (-0.19979266386206565)\n",
      "     | > loss_dur: 0.2754150629043579  (0.24361135497144082)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(10.4191, device='cuda:0')  (tensor(7.2343, device='cuda:0'))\n",
      "     | > current_lr: 1.75e-06 \n",
      "     | > step_time: 0.9903  (0.6404282334374225)\n",
      "     | > loader_time: 0.0237  (0.012093717732080603)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:39:46 -- STEP: 353/406 -- GLOBAL_STEP: 25925\u001b[0m\n",
      "     | > loss: 0.047892361879348755  (0.04389007406430607)\n",
      "     | > log_mle: -0.221480131149292  (-0.20054462070843324)\n",
      "     | > loss_dur: 0.26937249302864075  (0.24443469477273924)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(5.7892, device='cuda:0')  (tensor(7.3109, device='cuda:0'))\n",
      "     | > current_lr: 1.75e-06 \n",
      "     | > step_time: 1.038  (0.6476507963607407)\n",
      "     | > loader_time: 0.0061  (0.01225541468720261)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:40:06 -- STEP: 378/406 -- GLOBAL_STEP: 25950\u001b[0m\n",
      "     | > loss: 0.04410848021507263  (0.04367478791052699)\n",
      "     | > log_mle: -0.20932984352111816  (-0.2013506495132649)\n",
      "     | > loss_dur: 0.2534383237361908  (0.24502543742379185)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(8.4168, device='cuda:0')  (tensor(7.2960, device='cuda:0'))\n",
      "     | > current_lr: 1.75e-06 \n",
      "     | > step_time: 0.7809  (0.6559812852314553)\n",
      "     | > loader_time: 0.0222  (0.01250894422884341)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:40:23 -- STEP: 403/406 -- GLOBAL_STEP: 25975\u001b[0m\n",
      "     | > loss: 0.028639286756515503  (0.04364232500788588)\n",
      "     | > log_mle: -0.20697903633117676  (-0.20207757304974888)\n",
      "     | > loss_dur: 0.23561832308769226  (0.24571989805763472)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(4.5202, device='cuda:0')  (tensor(7.2519, device='cuda:0'))\n",
      "     | > current_lr: 1.75e-06 \n",
      "     | > step_time: 0.5366  (0.6563888353390386)\n",
      "     | > loader_time: 0.0072  (0.01247966082456982)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: 0.04574382305145264  (0.04574382305145264)\n",
      "     | > log_mle: -0.18285560607910156  (-0.18285560607910156)\n",
      "     | > loss_dur: 0.2285994291305542  (0.2285994291305542)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: -0.014287129044532776  (-0.014287129044532776)\n",
      "     | > log_mle: -0.21756243705749512  (-0.21756243705749512)\n",
      "     | > loss_dur: 0.20327530801296234  (0.20327530801296234)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: 0.022134438157081604  (0.003923654556274414)\n",
      "     | > log_mle: -0.17785561084747314  (-0.19770902395248413)\n",
      "     | > loss_dur: 0.19999004900455475  (0.20163267850875854)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: 0.02133399248123169  (0.009727100531260172)\n",
      "     | > log_mle: -0.19087278842926025  (-0.19543027877807617)\n",
      "     | > loss_dur: 0.21220678091049194  (0.20515737930933634)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: 0.020208433270454407  (0.012347433716058731)\n",
      "     | > log_mle: -0.21692383289337158  (-0.20080366730690002)\n",
      "     | > loss_dur: 0.237132266163826  (0.21315110102295876)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: 0.025140509009361267  (0.014906048774719238)\n",
      "     | > log_mle: -0.20546960830688477  (-0.20173685550689696)\n",
      "     | > loss_dur: 0.23061011731624603  (0.2166429042816162)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: 0.047895848751068115  (0.020404348770777386)\n",
      "     | > log_mle: -0.2184969186782837  (-0.20453019936879477)\n",
      "     | > loss_dur: 0.2663927674293518  (0.22493454813957214)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: 0.022855058312416077  (0.020754450133868625)\n",
      "     | > log_mle: -0.19098114967346191  (-0.20259462084089006)\n",
      "     | > loss_dur: 0.213836207985878  (0.2233490709747587)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: 0.015400364995002747  (0.02008518949151039)\n",
      "     | > log_mle: -0.1997889280319214  (-0.20224390923976898)\n",
      "     | > loss_dur: 0.21518929302692413  (0.22232909873127937)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: 0.05012354254722595  (0.023422784275478788)\n",
      "     | > log_mle: -0.2070620059967041  (-0.2027792533238729)\n",
      "     | > loss_dur: 0.25718554854393005  (0.22620203759935167)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: 0.04620712995529175  (0.025701218843460084)\n",
      "     | > log_mle: -0.19687426090240479  (-0.20218875408172607)\n",
      "     | > loss_dur: 0.24308139085769653  (0.22788997292518615)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: 0.02923630177974701  (0.026022590019486168)\n",
      "     | > log_mle: -0.21191048622131348  (-0.20307254791259766)\n",
      "     | > loss_dur: 0.24114678800106049  (0.22909513793208383)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: 0.0055727362632751465  (0.024318435539801914)\n",
      "     | > log_mle: -0.20230185985565186  (-0.20300832390785217)\n",
      "     | > loss_dur: 0.207874596118927  (0.2273267594476541)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: -0.010760977864265442  (0.021620019124104425)\n",
      "     | > log_mle: -0.21601414680480957  (-0.20400877182300275)\n",
      "     | > loss_dur: 0.20525316894054413  (0.22562879094710717)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: 0.035856351256370544  (0.022636899990694865)\n",
      "     | > log_mle: -0.21203017234802246  (-0.2045817290033613)\n",
      "     | > loss_dur: 0.247886523604393  (0.22721862899405615)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: 0.017432421445846558  (0.022289934754371642)\n",
      "     | > log_mle: -0.20633113384246826  (-0.20469835599263508)\n",
      "     | > loss_dur: 0.22376355528831482  (0.22698829074700674)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: 0.03596918284893036  (0.023144887760281563)\n",
      "     | > log_mle: -0.20171701908111572  (-0.20451202243566513)\n",
      "     | > loss_dur: 0.23768620193004608  (0.2276569101959467)\n",
      "\n",
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[91m 0.003481552004814148 \u001b[0m(+0.00010928511619567871)\n",
      "     | > avg_loss:\u001b[92m 0.023144887760281563 \u001b[0m(-0.003036217764019966)\n",
      "     | > avg_log_mle:\u001b[92m -0.20451202243566513 \u001b[0m(-0.0018091946840286255)\n",
      "     | > avg_loss_dur:\u001b[92m 0.2276569101959467 \u001b[0m(-0.0012270230799913406)\n",
      "\n",
      " > BEST MODEL : train/run-February-22-2025_10+59PM-fa84af3/best_model_25978.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 8/100\u001b[0m\n",
      " --> train/run-February-22-2025_10+59PM-fa84af3\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-22 23:40:40) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:40:52 -- STEP: 22/406 -- GLOBAL_STEP: 26000\u001b[0m\n",
      "     | > loss: 0.04618898034095764  (0.03706690262664448)\n",
      "     | > log_mle: -0.1734175682067871  (-0.18157132105393844)\n",
      "     | > loss_dur: 0.21960654854774475  (0.21863822368058292)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(1.7487, device='cuda:0')  (tensor(3.0234, device='cuda:0'))\n",
      "     | > current_lr: 2e-06 \n",
      "     | > step_time: 0.5352  (0.4523072134364735)\n",
      "     | > loader_time: 0.017  (0.005265582691539418)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:41:06 -- STEP: 47/406 -- GLOBAL_STEP: 26025\u001b[0m\n",
      "     | > loss: 0.04082648456096649  (0.04094409657285569)\n",
      "     | > log_mle: -0.205369234085083  (-0.1820061993091664)\n",
      "     | > loss_dur: 0.2461957186460495  (0.22295029588202211)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(4.3992, device='cuda:0')  (tensor(3.2386, device='cuda:0'))\n",
      "     | > current_lr: 2e-06 \n",
      "     | > step_time: 0.39  (0.5128472967350738)\n",
      "     | > loader_time: 0.0219  (0.008725815630973651)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:41:21 -- STEP: 72/406 -- GLOBAL_STEP: 26050\u001b[0m\n",
      "     | > loss: 0.04632560908794403  (0.042830795670549086)\n",
      "     | > log_mle: -0.1761488914489746  (-0.1844440119134055)\n",
      "     | > loss_dur: 0.22247450053691864  (0.2272748075839546)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(3.1705, device='cuda:0')  (tensor(3.7607, device='cuda:0'))\n",
      "     | > current_lr: 2e-06 \n",
      "     | > step_time: 0.496  (0.5285535984569127)\n",
      "     | > loader_time: 0.0041  (0.009775973028606838)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:41:36 -- STEP: 97/406 -- GLOBAL_STEP: 26075\u001b[0m\n",
      "     | > loss: 0.05264247953891754  (0.04303123364129019)\n",
      "     | > log_mle: -0.1940072774887085  (-0.1875733985114343)\n",
      "     | > loss_dur: 0.24664975702762604  (0.2306046321527245)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(4.2301, device='cuda:0')  (tensor(5.6156, device='cuda:0'))\n",
      "     | > current_lr: 2e-06 \n",
      "     | > step_time: 0.753  (0.54418924911735)\n",
      "     | > loader_time: 0.0082  (0.009938817663291064)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:41:51 -- STEP: 122/406 -- GLOBAL_STEP: 26100\u001b[0m\n",
      "     | > loss: 0.040373653173446655  (0.042857826855339)\n",
      "     | > log_mle: -0.18773818016052246  (-0.18986948005488657)\n",
      "     | > loss_dur: 0.22811183333396912  (0.2327273069102256)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(2.4866, device='cuda:0')  (tensor(5.9318, device='cuda:0'))\n",
      "     | > current_lr: 2e-06 \n",
      "     | > step_time: 0.7433  (0.5552359584902153)\n",
      "     | > loader_time: 0.0177  (0.010253796811963688)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:42:08 -- STEP: 147/406 -- GLOBAL_STEP: 26125\u001b[0m\n",
      "     | > loss: 0.059773653745651245  (0.04338006077169562)\n",
      "     | > log_mle: -0.19991815090179443  (-0.1919259051887356)\n",
      "     | > loss_dur: 0.2596918046474457  (0.23530596596043127)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(5.3009, device='cuda:0')  (tensor(6.0538, device='cuda:0'))\n",
      "     | > current_lr: 2e-06 \n",
      "     | > step_time: 0.3541  (0.5712619314388353)\n",
      "     | > loader_time: 0.0047  (0.01004453743396162)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:42:23 -- STEP: 172/406 -- GLOBAL_STEP: 26150\u001b[0m\n",
      "     | > loss: 0.054326385259628296  (0.04350359772526941)\n",
      "     | > log_mle: -0.2024378776550293  (-0.19343672242275503)\n",
      "     | > loss_dur: 0.2567642629146576  (0.23694032014802444)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(5.0594, device='cuda:0')  (tensor(6.4763, device='cuda:0'))\n",
      "     | > current_lr: 2e-06 \n",
      "     | > step_time: 0.4077  (0.577808421711589)\n",
      "     | > loader_time: 0.0048  (0.01026539192643276)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:42:40 -- STEP: 197/406 -- GLOBAL_STEP: 26175\u001b[0m\n",
      "     | > loss: 0.027027875185012817  (0.043218752756941745)\n",
      "     | > log_mle: -0.20263409614562988  (-0.19491090266232564)\n",
      "     | > loss_dur: 0.2296619713306427  (0.23812965541926737)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(3.5712, device='cuda:0')  (tensor(6.2632, device='cuda:0'))\n",
      "     | > current_lr: 2e-06 \n",
      "     | > step_time: 0.8208  (0.5892133252874849)\n",
      "     | > loader_time: 0.0069  (0.010176845008346634)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:42:58 -- STEP: 222/406 -- GLOBAL_STEP: 26200\u001b[0m\n",
      "     | > loss: 0.03187000751495361  (0.04310270929121756)\n",
      "     | > log_mle: -0.2045431137084961  (-0.19625736625344903)\n",
      "     | > loss_dur: 0.2364131212234497  (0.2393600755446666)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(7.9834, device='cuda:0')  (tensor(6.4497, device='cuda:0'))\n",
      "     | > current_lr: 2e-06 \n",
      "     | > step_time: 0.6022  (0.5989123615058692)\n",
      "     | > loader_time: 0.0062  (0.01054659620061651)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:43:16 -- STEP: 247/406 -- GLOBAL_STEP: 26225\u001b[0m\n",
      "     | > loss: 0.046151965856552124  (0.043017614889241426)\n",
      "     | > log_mle: -0.19502413272857666  (-0.19748648699478583)\n",
      "     | > loss_dur: 0.24117609858512878  (0.24050410188402724)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(3.8798, device='cuda:0')  (tensor(6.4112, device='cuda:0'))\n",
      "     | > current_lr: 2e-06 \n",
      "     | > step_time: 0.5299  (0.6090049511990566)\n",
      "     | > loader_time: 0.0051  (0.010941303693331204)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:43:33 -- STEP: 272/406 -- GLOBAL_STEP: 26250\u001b[0m\n",
      "     | > loss: 0.025021865963935852  (0.04248593550394563)\n",
      "     | > log_mle: -0.21923422813415527  (-0.19864805130397573)\n",
      "     | > loss_dur: 0.24425609409809113  (0.24113398680792136)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(10.4868, device='cuda:0')  (tensor(6.3812, device='cuda:0'))\n",
      "     | > current_lr: 2e-06 \n",
      "     | > step_time: 0.5725  (0.6150655913002351)\n",
      "     | > loader_time: 0.0205  (0.011286510264172274)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:43:50 -- STEP: 297/406 -- GLOBAL_STEP: 26275\u001b[0m\n",
      "     | > loss: 0.034075915813446045  (0.042358827510666754)\n",
      "     | > log_mle: -0.20955991744995117  (-0.19949067441702692)\n",
      "     | > loss_dur: 0.24363583326339722  (0.2418495019276937)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(14.9519, device='cuda:0')  (tensor(6.8724, device='cuda:0'))\n",
      "     | > current_lr: 2e-06 \n",
      "     | > step_time: 0.6772  (0.6201020146058467)\n",
      "     | > loader_time: 0.0169  (0.011301146613226993)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:44:09 -- STEP: 322/406 -- GLOBAL_STEP: 26300\u001b[0m\n",
      "     | > loss: 0.022683143615722656  (0.04222663427176681)\n",
      "     | > log_mle: -0.21076655387878418  (-0.2003023683654595)\n",
      "     | > loss_dur: 0.23344969749450684  (0.24252900263722638)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(13.4220, device='cuda:0')  (tensor(7.2009, device='cuda:0'))\n",
      "     | > current_lr: 2e-06 \n",
      "     | > step_time: 0.7165  (0.6280936854226247)\n",
      "     | > loader_time: 0.0064  (0.011332729588384216)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:44:28 -- STEP: 347/406 -- GLOBAL_STEP: 26325\u001b[0m\n",
      "     | > loss: 0.04236197471618652  (0.042181200055292745)\n",
      "     | > log_mle: -0.20874786376953125  (-0.20108617107875063)\n",
      "     | > loss_dur: 0.2511098384857178  (0.24326737113404343)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(15.2892, device='cuda:0')  (tensor(7.5754, device='cuda:0'))\n",
      "     | > current_lr: 2e-06 \n",
      "     | > step_time: 0.6809  (0.6370110168237156)\n",
      "     | > loader_time: 0.0083  (0.011584475679425067)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:44:48 -- STEP: 372/406 -- GLOBAL_STEP: 26350\u001b[0m\n",
      "     | > loss: 0.05034986138343811  (0.04217214037173534)\n",
      "     | > log_mle: -0.20486748218536377  (-0.20190986189790947)\n",
      "     | > loss_dur: 0.2552173435688019  (0.24408200226964488)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(7.3362, device='cuda:0')  (tensor(7.7392, device='cuda:0'))\n",
      "     | > current_lr: 2e-06 \n",
      "     | > step_time: 0.8806  (0.6454179017774514)\n",
      "     | > loader_time: 0.0184  (0.01184309938902496)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:45:07 -- STEP: 397/406 -- GLOBAL_STEP: 26375\u001b[0m\n",
      "     | > loss: 0.03482586145401001  (0.04208118267713923)\n",
      "     | > log_mle: -0.2226858139038086  (-0.20266987274515835)\n",
      "     | > loss_dur: 0.2575116753578186  (0.24475105542229766)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(10.5179, device='cuda:0')  (tensor(7.6746, device='cuda:0'))\n",
      "     | > current_lr: 2e-06 \n",
      "     | > step_time: 0.5496  (0.6537692949213363)\n",
      "     | > loader_time: 0.007  (0.011935826813243799)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: 0.04424671828746796  (0.04424671828746796)\n",
      "     | > log_mle: -0.18429410457611084  (-0.18429410457611084)\n",
      "     | > loss_dur: 0.2285408228635788  (0.2285408228635788)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: -0.02466447651386261  (-0.02466447651386261)\n",
      "     | > log_mle: -0.21891891956329346  (-0.21891891956329346)\n",
      "     | > loss_dur: 0.19425444304943085  (0.19425444304943085)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: 0.01967926323413849  (-0.0024926066398620605)\n",
      "     | > log_mle: -0.1793816089630127  (-0.19915026426315308)\n",
      "     | > loss_dur: 0.19906087219715118  (0.19665765762329102)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: 0.020591601729393005  (0.005202129483222961)\n",
      "     | > log_mle: -0.1921224594116211  (-0.19680766264597574)\n",
      "     | > loss_dur: 0.2127140611410141  (0.2020097921291987)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: 0.020417436957359314  (0.00900595635175705)\n",
      "     | > log_mle: -0.2182168960571289  (-0.20215997099876404)\n",
      "     | > loss_dur: 0.23863433301448822  (0.2111659273505211)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: 0.020918548107147217  (0.011388474702835083)\n",
      "     | > log_mle: -0.20866143703460693  (-0.2034602642059326)\n",
      "     | > loss_dur: 0.22957998514175415  (0.2148487389087677)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: 0.05312046408653259  (0.018343806266784668)\n",
      "     | > log_mle: -0.22056686878204346  (-0.20631136496861777)\n",
      "     | > loss_dur: 0.27368733286857605  (0.22465517123540243)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: 0.019302383065223694  (0.018480745809418813)\n",
      "     | > log_mle: -0.19241821765899658  (-0.20432662963867188)\n",
      "     | > loss_dur: 0.21172060072422028  (0.22280737544809068)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: 0.009700790047645569  (0.01738325133919716)\n",
      "     | > log_mle: -0.2015148401260376  (-0.2039751559495926)\n",
      "     | > loss_dur: 0.21121563017368317  (0.22135840728878975)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: 0.049861907958984375  (0.020991990963617962)\n",
      "     | > log_mle: -0.20869183540344238  (-0.2044992314444648)\n",
      "     | > loss_dur: 0.25855374336242676  (0.22549122240808275)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: 0.0443136990070343  (0.023324161767959595)\n",
      "     | > log_mle: -0.19826912879943848  (-0.20387622117996215)\n",
      "     | > loss_dur: 0.24258282780647278  (0.22720038294792175)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: 0.02640499174594879  (0.023604237220504067)\n",
      "     | > log_mle: -0.2136005163192749  (-0.20476024801080878)\n",
      "     | > loss_dur: 0.2400055080652237  (0.22836448523131284)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: 0.00016891956329345703  (0.021651294082403183)\n",
      "     | > log_mle: -0.20397913455963135  (-0.20469515522321066)\n",
      "     | > loss_dur: 0.2041480541229248  (0.22634644930561384)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: -0.01336468756198883  (0.018957757032834567)\n",
      "     | > log_mle: -0.2183396816253662  (-0.2057447341772226)\n",
      "     | > loss_dur: 0.20497499406337738  (0.2247024912100572)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: 0.025952845811843872  (0.019457406231335232)\n",
      "     | > log_mle: -0.21364176273345947  (-0.20630880764552526)\n",
      "     | > loss_dur: 0.23959460854530334  (0.2257662138768605)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: 0.014653295278549194  (0.01913713216781616)\n",
      "     | > log_mle: -0.20815885066986084  (-0.20643214384714761)\n",
      "     | > loss_dur: 0.22281214594841003  (0.2255692760149638)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: 0.03211815655231476  (0.019948446191847324)\n",
      "     | > log_mle: -0.20342230796813965  (-0.20624402910470963)\n",
      "     | > loss_dur: 0.2355404645204544  (0.22619247529655695)\n",
      "\n",
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.0033522099256515503 \u001b[0m(-0.00012934207916259766)\n",
      "     | > avg_loss:\u001b[92m 0.019948446191847324 \u001b[0m(-0.0031964415684342384)\n",
      "     | > avg_log_mle:\u001b[92m -0.20624402910470963 \u001b[0m(-0.0017320066690444946)\n",
      "     | > avg_loss_dur:\u001b[92m 0.22619247529655695 \u001b[0m(-0.0014644348993897438)\n",
      "\n",
      " > BEST MODEL : train/run-February-22-2025_10+59PM-fa84af3/best_model_26384.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 9/100\u001b[0m\n",
      " --> train/run-February-22-2025_10+59PM-fa84af3\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-22 23:45:28) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:45:37 -- STEP: 16/406 -- GLOBAL_STEP: 26400\u001b[0m\n",
      "     | > loss: 0.04067915678024292  (0.032948996871709824)\n",
      "     | > log_mle: -0.18657076358795166  (-0.18521923571825027)\n",
      "     | > loss_dur: 0.22724992036819458  (0.2181682325899601)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(2.7929, device='cuda:0')  (tensor(4.8405, device='cuda:0'))\n",
      "     | > current_lr: 2.25e-06 \n",
      "     | > step_time: 0.5607  (0.39045457541942596)\n",
      "     | > loader_time: 0.0053  (0.005263149738311768)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:45:51 -- STEP: 41/406 -- GLOBAL_STEP: 26425\u001b[0m\n",
      "     | > loss: 0.03392387926578522  (0.03886396674121299)\n",
      "     | > log_mle: -0.18129611015319824  (-0.1829011207673608)\n",
      "     | > loss_dur: 0.21521998941898346  (0.22176508750857377)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(13.3575, device='cuda:0')  (tensor(5.7800, device='cuda:0'))\n",
      "     | > current_lr: 2.25e-06 \n",
      "     | > step_time: 0.6947  (0.4931678946425275)\n",
      "     | > loader_time: 0.0168  (0.007991511647294208)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:46:06 -- STEP: 66/406 -- GLOBAL_STEP: 26450\u001b[0m\n",
      "     | > loss: 0.06074485182762146  (0.04095495921192748)\n",
      "     | > log_mle: -0.1917891502380371  (-0.18520995342370236)\n",
      "     | > loss_dur: 0.25253400206565857  (0.22616491263562982)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(4.4570, device='cuda:0')  (tensor(5.6037, device='cuda:0'))\n",
      "     | > current_lr: 2.25e-06 \n",
      "     | > step_time: 0.5446  (0.5267246780973492)\n",
      "     | > loader_time: 0.0037  (0.008803887800736864)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:46:21 -- STEP: 91/406 -- GLOBAL_STEP: 26475\u001b[0m\n",
      "     | > loss: 0.04545441269874573  (0.040961996539608456)\n",
      "     | > log_mle: -0.20315468311309814  (-0.18815284901922877)\n",
      "     | > loss_dur: 0.24860909581184387  (0.2291148455588372)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(6.6910, device='cuda:0')  (tensor(5.4932, device='cuda:0'))\n",
      "     | > current_lr: 2.25e-06 \n",
      "     | > step_time: 0.7955  (0.5364807071266594)\n",
      "     | > loader_time: 0.0067  (0.008524307837853072)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:46:37 -- STEP: 116/406 -- GLOBAL_STEP: 26500\u001b[0m\n",
      "     | > loss: 0.04924413561820984  (0.04043217722711892)\n",
      "     | > log_mle: -0.18963980674743652  (-0.19080047258015337)\n",
      "     | > loss_dur: 0.23888394236564636  (0.2312326498072723)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(10.4449, device='cuda:0')  (tensor(5.5501, device='cuda:0'))\n",
      "     | > current_lr: 2.25e-06 \n",
      "     | > step_time: 0.8245  (0.5548234027007533)\n",
      "     | > loader_time: 0.0191  (0.009505167089659598)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:46:53 -- STEP: 141/406 -- GLOBAL_STEP: 26525\u001b[0m\n",
      "     | > loss: 0.04892835021018982  (0.04076527598056388)\n",
      "     | > log_mle: -0.2074272632598877  (-0.19303961003080333)\n",
      "     | > loss_dur: 0.2563556134700775  (0.23380488601136715)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(8.7343, device='cuda:0')  (tensor(5.6925, device='cuda:0'))\n",
      "     | > current_lr: 2.25e-06 \n",
      "     | > step_time: 1.0956  (0.5674920673911454)\n",
      "     | > loader_time: 0.0235  (0.009741299541284013)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:47:10 -- STEP: 166/406 -- GLOBAL_STEP: 26550\u001b[0m\n",
      "     | > loss: 0.03176817297935486  (0.04096167866724082)\n",
      "     | > log_mle: -0.20899581909179688  (-0.19459052832729845)\n",
      "     | > loss_dur: 0.24076399207115173  (0.23555220699453927)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(10.5511, device='cuda:0')  (tensor(6.3522, device='cuda:0'))\n",
      "     | > current_lr: 2.25e-06 \n",
      "     | > step_time: 0.6292  (0.5835057482661972)\n",
      "     | > loader_time: 0.0061  (0.00965957325625133)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:47:27 -- STEP: 191/406 -- GLOBAL_STEP: 26575\u001b[0m\n",
      "     | > loss: 0.042671769857406616  (0.04072156673326541)\n",
      "     | > log_mle: -0.20124435424804688  (-0.19603962548740247)\n",
      "     | > loss_dur: 0.2439161241054535  (0.23676119222066788)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(4.8015, device='cuda:0')  (tensor(6.8933, device='cuda:0'))\n",
      "     | > current_lr: 2.25e-06 \n",
      "     | > step_time: 0.5053  (0.5972963465445952)\n",
      "     | > loader_time: 0.0066  (0.009886797810100142)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:47:46 -- STEP: 216/406 -- GLOBAL_STEP: 26600\u001b[0m\n",
      "     | > loss: 0.04133963584899902  (0.04065350470719512)\n",
      "     | > log_mle: -0.2166001796722412  (-0.19728442971353177)\n",
      "     | > loss_dur: 0.25793981552124023  (0.23793793442072692)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(16.1531, device='cuda:0')  (tensor(7.0075, device='cuda:0'))\n",
      "     | > current_lr: 2.25e-06 \n",
      "     | > step_time: 0.663  (0.6102665938712932)\n",
      "     | > loader_time: 0.0063  (0.010471486383014258)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:48:03 -- STEP: 241/406 -- GLOBAL_STEP: 26625\u001b[0m\n",
      "     | > loss: 0.0434037446975708  (0.04082687594831236)\n",
      "     | > log_mle: -0.2042142152786255  (-0.1985886853760209)\n",
      "     | > loss_dur: 0.2476179599761963  (0.23941556132433325)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(5.0122, device='cuda:0')  (tensor(7.1422, device='cuda:0'))\n",
      "     | > current_lr: 2.25e-06 \n",
      "     | > step_time: 0.4605  (0.6183240067414723)\n",
      "     | > loader_time: 0.0053  (0.01066202444654283)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:48:21 -- STEP: 266/406 -- GLOBAL_STEP: 26650\u001b[0m\n",
      "     | > loss: 0.03409169614315033  (0.04053837072132225)\n",
      "     | > log_mle: -0.20997023582458496  (-0.1996483386011052)\n",
      "     | > loss_dur: 0.2440619319677353  (0.24018670932242744)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(9.4043, device='cuda:0')  (tensor(7.0523, device='cuda:0'))\n",
      "     | > current_lr: 2.25e-06 \n",
      "     | > step_time: 0.7518  (0.6271466142252872)\n",
      "     | > loader_time: 0.0064  (0.011024588929083116)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:48:40 -- STEP: 291/406 -- GLOBAL_STEP: 26675\u001b[0m\n",
      "     | > loss: 0.04654589295387268  (0.040190492759865165)\n",
      "     | > log_mle: -0.20441079139709473  (-0.20058850406371442)\n",
      "     | > loss_dur: 0.2509566843509674  (0.2407789968235796)\n",
      "     | > amp_scaler: 16384.0  (8783.175257731955)\n",
      "     | > grad_norm: tensor(6.6212, device='cuda:0')  (tensor(6.9958, device='cuda:0'))\n",
      "     | > current_lr: 2.25e-06 \n",
      "     | > step_time: 0.7074  (0.6367401470433396)\n",
      "     | > loader_time: 0.006  (0.011529268677701657)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:49:00 -- STEP: 316/406 -- GLOBAL_STEP: 26700\u001b[0m\n",
      "     | > loss: 0.03316962718963623  (0.04003984339629545)\n",
      "     | > log_mle: -0.2177664041519165  (-0.20146478882318813)\n",
      "     | > loss_dur: 0.25093603134155273  (0.24150463221948357)\n",
      "     | > amp_scaler: 16384.0  (9384.506329113921)\n",
      "     | > grad_norm: tensor(11.9500, device='cuda:0')  (tensor(7.0653, device='cuda:0'))\n",
      "     | > current_lr: 2.25e-06 \n",
      "     | > step_time: 1.1246  (0.6458688800847984)\n",
      "     | > loader_time: 0.0622  (0.012116332597370393)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:49:19 -- STEP: 341/406 -- GLOBAL_STEP: 26725\u001b[0m\n",
      "     | > loss: 0.04420328140258789  (0.040175109664715616)\n",
      "     | > log_mle: -0.21230947971343994  (-0.2021070666327155)\n",
      "     | > loss_dur: 0.25651276111602783  (0.24228217629743112)\n",
      "     | > amp_scaler: 16384.0  (9897.665689149557)\n",
      "     | > grad_norm: tensor(6.3983, device='cuda:0')  (tensor(7.1151, device='cuda:0'))\n",
      "     | > current_lr: 2.25e-06 \n",
      "     | > step_time: 0.7795  (0.6547266472120087)\n",
      "     | > loader_time: 0.0208  (0.012094603256046603)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:49:39 -- STEP: 366/406 -- GLOBAL_STEP: 26750\u001b[0m\n",
      "     | > loss: 0.031150072813034058  (0.0399921229058276)\n",
      "     | > log_mle: -0.2185816764831543  (-0.20296776783270915)\n",
      "     | > loss_dur: 0.24973174929618835  (0.24295989073853674)\n",
      "     | > amp_scaler: 16384.0  (10340.721311475407)\n",
      "     | > grad_norm: tensor(6.5486, device='cuda:0')  (tensor(7.1769, device='cuda:0'))\n",
      "     | > current_lr: 2.25e-06 \n",
      "     | > step_time: 0.8709  (0.6628780286820202)\n",
      "     | > loader_time: 0.0077  (0.01206854588347055)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:50:00 -- STEP: 391/406 -- GLOBAL_STEP: 26775\u001b[0m\n",
      "     | > loss: 0.03179389238357544  (0.039950891071573236)\n",
      "     | > log_mle: -0.22140705585479736  (-0.20371428718957144)\n",
      "     | > loss_dur: 0.2532009482383728  (0.2436651782611447)\n",
      "     | > amp_scaler: 16384.0  (10727.120204603583)\n",
      "     | > grad_norm: tensor(2.0553, device='cuda:0')  (tensor(7.1787, device='cuda:0'))\n",
      "     | > current_lr: 2.25e-06 \n",
      "     | > step_time: 0.6314  (0.6722160702776113)\n",
      "     | > loader_time: 0.02  (0.012234035355355739)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: 0.04271601140499115  (0.04271601140499115)\n",
      "     | > log_mle: -0.18623638153076172  (-0.18623638153076172)\n",
      "     | > loss_dur: 0.22895239293575287  (0.22895239293575287)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: -0.028628110885620117  (-0.028628110885620117)\n",
      "     | > log_mle: -0.22281789779663086  (-0.22281789779663086)\n",
      "     | > loss_dur: 0.19418978691101074  (0.19418978691101074)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: 0.017063245177268982  (-0.005782432854175568)\n",
      "     | > log_mle: -0.18211328983306885  (-0.20246559381484985)\n",
      "     | > loss_dur: 0.19917653501033783  (0.19668316096067429)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: 0.021376609802246094  (0.003270581364631653)\n",
      "     | > log_mle: -0.19670379161834717  (-0.20054499308268228)\n",
      "     | > loss_dur: 0.21808040142059326  (0.20381557444731394)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: 0.015248328447341919  (0.006265018135309219)\n",
      "     | > log_mle: -0.22327733039855957  (-0.2062280774116516)\n",
      "     | > loss_dur: 0.2385256588459015  (0.21249309554696083)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: 0.011576130986213684  (0.007327240705490112)\n",
      "     | > log_mle: -0.21818876266479492  (-0.20862021446228027)\n",
      "     | > loss_dur: 0.2297648936510086  (0.2159474551677704)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: 0.034824907779693604  (0.01191018521785736)\n",
      "     | > log_mle: -0.23072171211242676  (-0.21230379740397134)\n",
      "     | > loss_dur: 0.26554661989212036  (0.2242139826218287)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: 0.01363341510295868  (0.012156360915728978)\n",
      "     | > log_mle: -0.1979895830154419  (-0.21025890963418142)\n",
      "     | > loss_dur: 0.21162299811840057  (0.22241527054991042)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: 0.00945378839969635  (0.0118185393512249)\n",
      "     | > log_mle: -0.20563769340515137  (-0.20968125760555267)\n",
      "     | > loss_dur: 0.21509148180484772  (0.22149979695677757)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: 0.04195481538772583  (0.01516701446639167)\n",
      "     | > log_mle: -0.21595251560211182  (-0.2103780640496148)\n",
      "     | > loss_dur: 0.25790733098983765  (0.22554507851600647)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: 0.03367877006530762  (0.017018190026283263)\n",
      "     | > log_mle: -0.20369994640350342  (-0.20971025228500367)\n",
      "     | > loss_dur: 0.23737871646881104  (0.22672844231128692)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: 0.018786892294883728  (0.01717898114161058)\n",
      "     | > log_mle: -0.21975159645080566  (-0.21062310175462204)\n",
      "     | > loss_dur: 0.2385384887456894  (0.2278020828962326)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: -0.004044860601425171  (0.015410327663024267)\n",
      "     | > log_mle: -0.20815753936767578  (-0.2104176382223765)\n",
      "     | > loss_dur: 0.2041126787662506  (0.22582796588540077)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: -0.025909796357154846  (0.01223185658454895)\n",
      "     | > log_mle: -0.2263185977935791  (-0.21164078895862287)\n",
      "     | > loss_dur: 0.20040880143642426  (0.22387264554317182)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: 0.021551743149757385  (0.012897562767778124)\n",
      "     | > log_mle: -0.21946978569030762  (-0.21220000301088607)\n",
      "     | > loss_dur: 0.241021528840065  (0.2250975657786642)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: 0.011248499155044556  (0.012787625193595886)\n",
      "     | > log_mle: -0.21376407146453857  (-0.21230427424112955)\n",
      "     | > loss_dur: 0.22501257061958313  (0.22509189943472543)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: 0.02569293975830078  (0.013594207353889942)\n",
      "     | > log_mle: -0.21009624004364014  (-0.21216627210378647)\n",
      "     | > loss_dur: 0.23578917980194092  (0.2257604794576764)\n",
      "\n",
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.003090083599090576 \u001b[0m(-0.0002621263265609741)\n",
      "     | > avg_loss:\u001b[92m 0.013594207353889942 \u001b[0m(-0.006354238837957382)\n",
      "     | > avg_log_mle:\u001b[92m -0.21216627210378647 \u001b[0m(-0.005922242999076843)\n",
      "     | > avg_loss_dur:\u001b[92m 0.2257604794576764 \u001b[0m(-0.00043199583888053894)\n",
      "\n",
      " > BEST MODEL : train/run-February-22-2025_10+59PM-fa84af3/best_model_26790.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 10/100\u001b[0m\n",
      " --> train/run-February-22-2025_10+59PM-fa84af3\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-22 23:50:24) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:50:31 -- STEP: 10/406 -- GLOBAL_STEP: 26800\u001b[0m\n",
      "     | > loss: 0.013236969709396362  (0.02640713006258011)\n",
      "     | > log_mle: -0.18782520294189453  (-0.1843328595161438)\n",
      "     | > loss_dur: 0.2010621726512909  (0.21073998957872392)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(6.1453, device='cuda:0')  (tensor(4.9224, device='cuda:0'))\n",
      "     | > current_lr: 2.4999999999999998e-06 \n",
      "     | > step_time: 0.3395  (0.33756217956542967)\n",
      "     | > loader_time: 0.0045  (0.004394125938415527)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:50:45 -- STEP: 35/406 -- GLOBAL_STEP: 26825\u001b[0m\n",
      "     | > loss: 0.025063693523406982  (0.03383127748966217)\n",
      "     | > log_mle: -0.19561398029327393  (-0.18475172519683838)\n",
      "     | > loss_dur: 0.2206776738166809  (0.21858300268650055)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(8.8172, device='cuda:0')  (tensor(6.9730, device='cuda:0'))\n",
      "     | > current_lr: 2.4999999999999998e-06 \n",
      "     | > step_time: 0.4816  (0.4927884919302804)\n",
      "     | > loader_time: 0.0045  (0.007991940634591238)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:51:00 -- STEP: 60/406 -- GLOBAL_STEP: 26850\u001b[0m\n",
      "     | > loss: 0.02807345986366272  (0.03823365916808446)\n",
      "     | > log_mle: -0.19056916236877441  (-0.186114102602005)\n",
      "     | > loss_dur: 0.21864262223243713  (0.22434776177008947)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.9485, device='cuda:0')  (tensor(6.6837, device='cuda:0'))\n",
      "     | > current_lr: 2.4999999999999998e-06 \n",
      "     | > step_time: 0.655  (0.537387530008952)\n",
      "     | > loader_time: 0.0045  (0.0077485760052998865)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:51:16 -- STEP: 85/406 -- GLOBAL_STEP: 26875\u001b[0m\n",
      "     | > loss: 0.02230900526046753  (0.03924833080347846)\n",
      "     | > log_mle: -0.20930969715118408  (-0.1888062827727374)\n",
      "     | > loss_dur: 0.2316187024116516  (0.22805461357621587)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(19.3363, device='cuda:0')  (tensor(7.1753, device='cuda:0'))\n",
      "     | > current_lr: 2.4999999999999998e-06 \n",
      "     | > step_time: 0.3954  (0.5606991487390858)\n",
      "     | > loader_time: 0.0044  (0.008069122538847086)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:51:32 -- STEP: 110/406 -- GLOBAL_STEP: 26900\u001b[0m\n",
      "     | > loss: 0.04800772666931152  (0.038880271396853704)\n",
      "     | > log_mle: -0.21271872520446777  (-0.19140436866066673)\n",
      "     | > loss_dur: 0.2607264518737793  (0.23028464005752045)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(11.5756, device='cuda:0')  (tensor(7.3808, device='cuda:0'))\n",
      "     | > current_lr: 2.4999999999999998e-06 \n",
      "     | > step_time: 0.4946  (0.5712052453647964)\n",
      "     | > loader_time: 0.005  (0.008624477819962935)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:51:48 -- STEP: 135/406 -- GLOBAL_STEP: 26925\u001b[0m\n",
      "     | > loss: 0.04794427752494812  (0.038713153865602284)\n",
      "     | > log_mle: -0.2083684206008911  (-0.19379495956279613)\n",
      "     | > loss_dur: 0.25631269812583923  (0.23250811342839842)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(5.3440, device='cuda:0')  (tensor(7.4846, device='cuda:0'))\n",
      "     | > current_lr: 2.4999999999999998e-06 \n",
      "     | > step_time: 0.7125  (0.5806263905984387)\n",
      "     | > loader_time: 0.0168  (0.009707604514227973)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:52:05 -- STEP: 160/406 -- GLOBAL_STEP: 26950\u001b[0m\n",
      "     | > loss: 0.055942028760910034  (0.039459934923797874)\n",
      "     | > log_mle: -0.2081986665725708  (-0.1954052120447159)\n",
      "     | > loss_dur: 0.26414069533348083  (0.23486514696851374)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(7.1758, device='cuda:0')  (tensor(8.0112, device='cuda:0'))\n",
      "     | > current_lr: 2.4999999999999998e-06 \n",
      "     | > step_time: 0.8208  (0.593957264721394)\n",
      "     | > loader_time: 0.0066  (0.010273034870624542)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:52:22 -- STEP: 185/406 -- GLOBAL_STEP: 26975\u001b[0m\n",
      "     | > loss: 0.050931185483932495  (0.039297601419526214)\n",
      "     | > log_mle: -0.21262860298156738  (-0.19689908027648925)\n",
      "     | > loss_dur: 0.2635597884654999  (0.23619668169601543)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(1.9913, device='cuda:0')  (tensor(7.7725, device='cuda:0'))\n",
      "     | > current_lr: 2.4999999999999998e-06 \n",
      "     | > step_time: 0.4726  (0.6032838409011432)\n",
      "     | > loader_time: 0.0068  (0.010343371210871517)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:52:39 -- STEP: 210/406 -- GLOBAL_STEP: 27000\u001b[0m\n",
      "     | > loss: 0.02938947081565857  (0.03894328538860597)\n",
      "     | > log_mle: -0.20774197578430176  (-0.19813926503771828)\n",
      "     | > loss_dur: 0.23713144659996033  (0.2370825504263242)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(10.3076, device='cuda:0')  (tensor(7.9298, device='cuda:0'))\n",
      "     | > current_lr: 2.4999999999999998e-06 \n",
      "     | > step_time: 0.6656  (0.6130291723069693)\n",
      "     | > loader_time: 0.0195  (0.01056227797553653)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:52:57 -- STEP: 235/406 -- GLOBAL_STEP: 27025\u001b[0m\n",
      "     | > loss: 0.044288456439971924  (0.038948280887400884)\n",
      "     | > log_mle: -0.206823468208313  (-0.19956704910765302)\n",
      "     | > loss_dur: 0.2511119246482849  (0.23851532999505387)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.0502, device='cuda:0')  (tensor(7.9210, device='cuda:0'))\n",
      "     | > current_lr: 2.4999999999999998e-06 \n",
      "     | > step_time: 0.5963  (0.62259833153258)\n",
      "     | > loader_time: 0.0048  (0.01110587627329725)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:53:15 -- STEP: 260/406 -- GLOBAL_STEP: 27050\u001b[0m\n",
      "     | > loss: 0.03302198648452759  (0.0387656689836429)\n",
      "     | > log_mle: -0.21891045570373535  (-0.20078176901890682)\n",
      "     | > loss_dur: 0.25193244218826294  (0.23954743800254968)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(10.3617, device='cuda:0')  (tensor(8.0642, device='cuda:0'))\n",
      "     | > current_lr: 2.4999999999999998e-06 \n",
      "     | > step_time: 0.7393  (0.6286574923075164)\n",
      "     | > loader_time: 0.0153  (0.011365788716536304)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:53:34 -- STEP: 285/406 -- GLOBAL_STEP: 27075\u001b[0m\n",
      "     | > loss: 0.04585304856300354  (0.03832149223277446)\n",
      "     | > log_mle: -0.20455527305603027  (-0.20177468207844515)\n",
      "     | > loss_dur: 0.2504083216190338  (0.2400961743112196)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.5837, device='cuda:0')  (tensor(8.0960, device='cuda:0'))\n",
      "     | > current_lr: 2.4999999999999998e-06 \n",
      "     | > step_time: 0.8426  (0.6388093044883327)\n",
      "     | > loader_time: 0.0169  (0.01154205422652395)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:53:54 -- STEP: 310/406 -- GLOBAL_STEP: 27100\u001b[0m\n",
      "     | > loss: 0.031142860651016235  (0.03808249840813299)\n",
      "     | > log_mle: -0.21400892734527588  (-0.20261019160670615)\n",
      "     | > loss_dur: 0.24515178799629211  (0.24069269001483917)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.1884, device='cuda:0')  (tensor(8.0045, device='cuda:0'))\n",
      "     | > current_lr: 2.4999999999999998e-06 \n",
      "     | > step_time: 0.8059  (0.6502434099874189)\n",
      "     | > loader_time: 0.0067  (0.011942702724087621)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:54:15 -- STEP: 335/406 -- GLOBAL_STEP: 27125\u001b[0m\n",
      "     | > loss: 0.04710543155670166  (0.03820724780879803)\n",
      "     | > log_mle: -0.21469640731811523  (-0.20332739566689104)\n",
      "     | > loss_dur: 0.2618018388748169  (0.2415346434756891)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(6.5031, device='cuda:0')  (tensor(7.9488, device='cuda:0'))\n",
      "     | > current_lr: 2.4999999999999998e-06 \n",
      "     | > step_time: 0.5992  (0.6613590809836317)\n",
      "     | > loader_time: 0.0223  (0.01221397172159223)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:54:36 -- STEP: 360/406 -- GLOBAL_STEP: 27150\u001b[0m\n",
      "     | > loss: 0.02870592474937439  (0.03805929116076893)\n",
      "     | > log_mle: -0.21633124351501465  (-0.20413686633110043)\n",
      "     | > loss_dur: 0.24503716826438904  (0.2421961574918694)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(12.6109, device='cuda:0')  (tensor(8.4436, device='cuda:0'))\n",
      "     | > current_lr: 2.4999999999999998e-06 \n",
      "     | > step_time: 1.1779  (0.6730069471730123)\n",
      "     | > loader_time: 0.0092  (0.01216699083646138)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:54:56 -- STEP: 385/406 -- GLOBAL_STEP: 27175\u001b[0m\n",
      "     | > loss: 0.03451058268547058  (0.037952579693360765)\n",
      "     | > log_mle: -0.2081587314605713  (-0.20486370928875808)\n",
      "     | > loss_dur: 0.24266931414604187  (0.24281628898211888)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(8.8387, device='cuda:0')  (tensor(8.8976, device='cuda:0'))\n",
      "     | > current_lr: 2.4999999999999998e-06 \n",
      "     | > step_time: 0.7556  (0.679583644247674)\n",
      "     | > loader_time: 0.0067  (0.012267656450147747)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: 0.03808480501174927  (0.03808480501174927)\n",
      "     | > log_mle: -0.18741393089294434  (-0.18741393089294434)\n",
      "     | > loss_dur: 0.2254987359046936  (0.2254987359046936)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: -0.03232879936695099  (-0.03232879936695099)\n",
      "     | > log_mle: -0.22380924224853516  (-0.22380924224853516)\n",
      "     | > loss_dur: 0.19148044288158417  (0.19148044288158417)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: 0.014104202389717102  (-0.009112298488616943)\n",
      "     | > log_mle: -0.18335533142089844  (-0.2035822868347168)\n",
      "     | > loss_dur: 0.19745953381061554  (0.19446998834609985)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: 0.018431365489959717  (6.892283757527669e-05)\n",
      "     | > log_mle: -0.19750404357910156  (-0.20155620574951172)\n",
      "     | > loss_dur: 0.21593540906906128  (0.201625128587087)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: 0.01401539146900177  (0.0035555399954319)\n",
      "     | > log_mle: -0.22397065162658691  (-0.20715981721878052)\n",
      "     | > loss_dur: 0.23798604309558868  (0.21071535721421242)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: 0.009601414203643799  (0.0047647148370742794)\n",
      "     | > log_mle: -0.21825361251831055  (-0.20937857627868653)\n",
      "     | > loss_dur: 0.22785502672195435  (0.2141432911157608)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: 0.03612658381462097  (0.009991692999998728)\n",
      "     | > log_mle: -0.2305436134338379  (-0.21290608247121176)\n",
      "     | > loss_dur: 0.26667019724845886  (0.22289777547121048)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: 0.009178683161735535  (0.009875548737389701)\n",
      "     | > log_mle: -0.1984187364578247  (-0.21083646161215647)\n",
      "     | > loss_dur: 0.20759741961956024  (0.22071201034954616)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: 0.00441405177116394  (0.00919286161661148)\n",
      "     | > log_mle: -0.20659172534942627  (-0.21030586957931519)\n",
      "     | > loss_dur: 0.2110057771205902  (0.21949873119592667)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: 0.0388680100440979  (0.01249010033077664)\n",
      "     | > log_mle: -0.21628034114837646  (-0.21096969975365532)\n",
      "     | > loss_dur: 0.25514835119247437  (0.22345980008443198)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: 0.03364203870296478  (0.014605294167995452)\n",
      "     | > log_mle: -0.20409560203552246  (-0.21028228998184204)\n",
      "     | > loss_dur: 0.23773764073848724  (0.2248875841498375)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: 0.017626866698265076  (0.014879982579838146)\n",
      "     | > log_mle: -0.22022771835327148  (-0.21118641983379016)\n",
      "     | > loss_dur: 0.23785458505153656  (0.22606640241362833)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: -0.005486205220222473  (0.013182800263166428)\n",
      "     | > log_mle: -0.20901262760162354  (-0.21100527048110962)\n",
      "     | > loss_dur: 0.20352642238140106  (0.22418807074427605)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: -0.02499932050704956  (0.01024571405007289)\n",
      "     | > log_mle: -0.22670626640319824  (-0.21221303939819336)\n",
      "     | > loss_dur: 0.20170694589614868  (0.22245875344826624)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: 0.01892682909965515  (0.010865793696471624)\n",
      "     | > log_mle: -0.22012221813201904  (-0.21277798073632376)\n",
      "     | > loss_dur: 0.2390490472316742  (0.2236437744327954)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: 0.008476823568344116  (0.010706529021263123)\n",
      "     | > log_mle: -0.21423733234405518  (-0.21287527084350585)\n",
      "     | > loss_dur: 0.2227141559123993  (0.22358179986476898)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: 0.02484714984893799  (0.011590317822992802)\n",
      "     | > log_mle: -0.2105618715286255  (-0.21273068338632584)\n",
      "     | > loss_dur: 0.23540902137756348  (0.22432100120931864)\n",
      "\n",
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[91m 0.005981087684631348 \u001b[0m(+0.0028910040855407715)\n",
      "     | > avg_loss:\u001b[92m 0.011590317822992802 \u001b[0m(-0.0020038895308971405)\n",
      "     | > avg_log_mle:\u001b[92m -0.21273068338632584 \u001b[0m(-0.0005644112825393677)\n",
      "     | > avg_loss_dur:\u001b[92m 0.22432100120931864 \u001b[0m(-0.0014394782483577728)\n",
      "\n",
      " > BEST MODEL : train/run-February-22-2025_10+59PM-fa84af3/best_model_27196.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 11/100\u001b[0m\n",
      " --> train/run-February-22-2025_10+59PM-fa84af3\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-22 23:55:24) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:55:28 -- STEP: 4/406 -- GLOBAL_STEP: 27200\u001b[0m\n",
      "     | > loss: 0.056269571185112  (0.029312577098608017)\n",
      "     | > log_mle: -0.1664431095123291  (-0.1846991777420044)\n",
      "     | > loss_dur: 0.2227126806974411  (0.2140117548406124)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(1.1263, device='cuda:0')  (tensor(8.9580, device='cuda:0'))\n",
      "     | > current_lr: 2.75e-06 \n",
      "     | > step_time: 0.2967  (0.5318830013275146)\n",
      "     | > loader_time: 0.0037  (0.003756582736968994)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:55:41 -- STEP: 29/406 -- GLOBAL_STEP: 27225\u001b[0m\n",
      "     | > loss: 0.0198013037443161  (0.031458920445935484)\n",
      "     | > log_mle: -0.19286775588989258  (-0.1860481171772398)\n",
      "     | > loss_dur: 0.21266905963420868  (0.21750703762317525)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(2.1311, device='cuda:0')  (tensor(5.5591, device='cuda:0'))\n",
      "     | > current_lr: 2.75e-06 \n",
      "     | > step_time: 0.4678  (0.5132959135647478)\n",
      "     | > loader_time: 0.0087  (0.006320106572118299)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:55:56 -- STEP: 54/406 -- GLOBAL_STEP: 27250\u001b[0m\n",
      "     | > loss: 0.03844292461872101  (0.037079013608120125)\n",
      "     | > log_mle: -0.19087862968444824  (-0.18658594952689278)\n",
      "     | > loss_dur: 0.22932155430316925  (0.22366496313501288)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(5.2087, device='cuda:0')  (tensor(5.4175, device='cuda:0'))\n",
      "     | > current_lr: 2.75e-06 \n",
      "     | > step_time: 0.3897  (0.5364612914897777)\n",
      "     | > loader_time: 0.0052  (0.007224493556552463)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:56:11 -- STEP: 79/406 -- GLOBAL_STEP: 27275\u001b[0m\n",
      "     | > loss: 0.04486644268035889  (0.03755514700955984)\n",
      "     | > log_mle: -0.1970808506011963  (-0.18904051297827615)\n",
      "     | > loss_dur: 0.24194729328155518  (0.22659565998783596)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(5.5606, device='cuda:0')  (tensor(5.1907, device='cuda:0'))\n",
      "     | > current_lr: 2.75e-06 \n",
      "     | > step_time: 0.9629  (0.5536210144622417)\n",
      "     | > loader_time: 0.0227  (0.008124324339854563)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:56:26 -- STEP: 104/406 -- GLOBAL_STEP: 27300\u001b[0m\n",
      "     | > loss: 0.033362433314323425  (0.03716567244667274)\n",
      "     | > log_mle: -0.19656777381896973  (-0.19189796997950628)\n",
      "     | > loss_dur: 0.22993020713329315  (0.229063642426179)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(2.5400, device='cuda:0')  (tensor(5.7558, device='cuda:0'))\n",
      "     | > current_lr: 2.75e-06 \n",
      "     | > step_time: 0.4129  (0.5642765026826123)\n",
      "     | > loader_time: 0.005  (0.008951118359198934)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:56:42 -- STEP: 129/406 -- GLOBAL_STEP: 27325\u001b[0m\n",
      "     | > loss: 0.0315428227186203  (0.036810928305914245)\n",
      "     | > log_mle: -0.2102419137954712  (-0.19436088366101878)\n",
      "     | > loss_dur: 0.2417847365140915  (0.231171811966933)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(6.7223, device='cuda:0')  (tensor(5.9768, device='cuda:0'))\n",
      "     | > current_lr: 2.75e-06 \n",
      "     | > step_time: 0.3158  (0.576984082081521)\n",
      "     | > loader_time: 0.0047  (0.008958343387574187)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:56:59 -- STEP: 154/406 -- GLOBAL_STEP: 27350\u001b[0m\n",
      "     | > loss: 0.05623207986354828  (0.037258388740675795)\n",
      "     | > log_mle: -0.18738162517547607  (-0.1960882304550766)\n",
      "     | > loss_dur: 0.24361370503902435  (0.23334661919575234)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(13.2363, device='cuda:0')  (tensor(6.5902, device='cuda:0'))\n",
      "     | > current_lr: 2.75e-06 \n",
      "     | > step_time: 0.41  (0.5865901956310517)\n",
      "     | > loader_time: 0.0251  (0.009925105355002663)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:57:15 -- STEP: 179/406 -- GLOBAL_STEP: 27375\u001b[0m\n",
      "     | > loss: 0.02791754901409149  (0.03702337532070097)\n",
      "     | > log_mle: -0.21842873096466064  (-0.19758374664370582)\n",
      "     | > loss_dur: 0.24634627997875214  (0.2346071219644067)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(8.2197, device='cuda:0')  (tensor(7.5445, device='cuda:0'))\n",
      "     | > current_lr: 2.75e-06 \n",
      "     | > step_time: 0.811  (0.592921675250517)\n",
      "     | > loader_time: 0.0051  (0.009966723745761637)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:57:33 -- STEP: 204/406 -- GLOBAL_STEP: 27400\u001b[0m\n",
      "     | > loss: 0.02989603579044342  (0.03702557671303843)\n",
      "     | > log_mle: -0.20940935611724854  (-0.19893920363164422)\n",
      "     | > loss_dur: 0.23930539190769196  (0.23596478034468257)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(15.3173, device='cuda:0')  (tensor(8.2082, device='cuda:0'))\n",
      "     | > current_lr: 2.75e-06 \n",
      "     | > step_time: 0.5263  (0.6052375482577902)\n",
      "     | > loader_time: 0.009  (0.010580398288427615)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:57:49 -- STEP: 229/406 -- GLOBAL_STEP: 27425\u001b[0m\n",
      "     | > loss: 0.03465591371059418  (0.0367348956749429)\n",
      "     | > log_mle: -0.20762956142425537  (-0.20035889263236373)\n",
      "     | > loss_dur: 0.24228547513484955  (0.23709378830730654)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(12.3675, device='cuda:0')  (tensor(9.0094, device='cuda:0'))\n",
      "     | > current_lr: 2.75e-06 \n",
      "     | > step_time: 0.6945  (0.6106156313783737)\n",
      "     | > loader_time: 0.0224  (0.010799373601721885)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:58:07 -- STEP: 254/406 -- GLOBAL_STEP: 27450\u001b[0m\n",
      "     | > loss: 0.035824254155159  (0.03677591652147415)\n",
      "     | > log_mle: -0.2072352170944214  (-0.20163727792229244)\n",
      "     | > loss_dur: 0.24305947124958038  (0.23841319444376652)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(7.8864, device='cuda:0')  (tensor(9.4270, device='cuda:0'))\n",
      "     | > current_lr: 2.75e-06 \n",
      "     | > step_time: 0.4694  (0.6178816556930542)\n",
      "     | > loader_time: 0.0156  (0.010971766757214164)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:58:25 -- STEP: 279/406 -- GLOBAL_STEP: 27475\u001b[0m\n",
      "     | > loss: 0.05616140365600586  (0.036432858062474115)\n",
      "     | > log_mle: -0.2005699872970581  (-0.2026165975891989)\n",
      "     | > loss_dur: 0.25673139095306396  (0.23904945565167293)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.7613, device='cuda:0')  (tensor(9.2936, device='cuda:0'))\n",
      "     | > current_lr: 2.75e-06 \n",
      "     | > step_time: 0.7495  (0.6260031329260934)\n",
      "     | > loader_time: 0.0065  (0.011370936602247231)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:58:44 -- STEP: 304/406 -- GLOBAL_STEP: 27500\u001b[0m\n",
      "     | > loss: 0.02334815263748169  (0.036241814641183936)\n",
      "     | > log_mle: -0.21303009986877441  (-0.20354339794108744)\n",
      "     | > loss_dur: 0.2363782525062561  (0.23978521258227134)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(20.6895, device='cuda:0')  (tensor(9.8007, device='cuda:0'))\n",
      "     | > current_lr: 2.75e-06 \n",
      "     | > step_time: 0.5912  (0.6358820482304226)\n",
      "     | > loader_time: 0.0194  (0.011515855789184567)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:59:04 -- STEP: 329/406 -- GLOBAL_STEP: 27525\u001b[0m\n",
      "     | > loss: 0.034322112798690796  (0.03615052486263148)\n",
      "     | > log_mle: -0.20213258266448975  (-0.2041618722550413)\n",
      "     | > loss_dur: 0.23645469546318054  (0.24031239711767272)\n",
      "     | > amp_scaler: 8192.0  (16060.303951367781)\n",
      "     | > grad_norm: tensor(11.6165, device='cuda:0')  (tensor(10.8287, device='cuda:0'))\n",
      "     | > current_lr: 2.75e-06 \n",
      "     | > step_time: 0.8377  (0.645181410218445)\n",
      "     | > loader_time: 0.0113  (0.011753362725208594)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:59:23 -- STEP: 354/406 -- GLOBAL_STEP: 27550\u001b[0m\n",
      "     | > loss: 0.03886064887046814  (0.03626408074366844)\n",
      "     | > log_mle: -0.21429908275604248  (-0.20492741415056134)\n",
      "     | > loss_dur: 0.2531597316265106  (0.24119149489422975)\n",
      "     | > amp_scaler: 8192.0  (15504.632768361582)\n",
      "     | > grad_norm: tensor(8.9172, device='cuda:0')  (tensor(11.6000, device='cuda:0'))\n",
      "     | > current_lr: 2.75e-06 \n",
      "     | > step_time: 0.7863  (0.6534530631566455)\n",
      "     | > loader_time: 0.0357  (0.0120017434244102)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-22 23:59:44 -- STEP: 379/406 -- GLOBAL_STEP: 27575\u001b[0m\n",
      "     | > loss: 0.030807048082351685  (0.035993005952608625)\n",
      "     | > log_mle: -0.21607911586761475  (-0.20575247779685152)\n",
      "     | > loss_dur: 0.24688616394996643  (0.24174548374946012)\n",
      "     | > amp_scaler: 8192.0  (15022.269129287599)\n",
      "     | > grad_norm: tensor(15.7666, device='cuda:0')  (tensor(11.6108, device='cuda:0'))\n",
      "     | > current_lr: 2.75e-06 \n",
      "     | > step_time: 0.6802  (0.6633594520488327)\n",
      "     | > loader_time: 0.0299  (0.01230621337890625)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:00:01 -- STEP: 404/406 -- GLOBAL_STEP: 27600\u001b[0m\n",
      "     | > loss: 0.029877513647079468  (0.03597527008393022)\n",
      "     | > log_mle: -0.21491289138793945  (-0.20648457803348508)\n",
      "     | > loss_dur: 0.24479040503501892  (0.24245984811741528)\n",
      "     | > amp_scaler: 8192.0  (14599.60396039604)\n",
      "     | > grad_norm: tensor(10.1137, device='cuda:0')  (tensor(11.6871, device='cuda:0'))\n",
      "     | > current_lr: 2.75e-06 \n",
      "     | > step_time: 0.5289  (0.6638234310811109)\n",
      "     | > loader_time: 0.0067  (0.012307525271236306)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: 0.03891602158546448  (0.03891602158546448)\n",
      "     | > log_mle: -0.1892244815826416  (-0.1892244815826416)\n",
      "     | > loss_dur: 0.22814050316810608  (0.22814050316810608)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: -0.0364544540643692  (-0.0364544540643692)\n",
      "     | > log_mle: -0.22628307342529297  (-0.22628307342529297)\n",
      "     | > loss_dur: 0.18982861936092377  (0.18982861936092377)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: 0.011212736368179321  (-0.01262085884809494)\n",
      "     | > log_mle: -0.1855757236480713  (-0.20592939853668213)\n",
      "     | > loss_dur: 0.1967884600162506  (0.1933085396885872)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: 0.009545698761940002  (-0.005232006311416626)\n",
      "     | > log_mle: -0.20020103454589844  (-0.20401994387308756)\n",
      "     | > loss_dur: 0.20974673330783844  (0.19878793756167093)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: 0.0087890625  (-0.0017267391085624695)\n",
      "     | > log_mle: -0.22692525386810303  (-0.20974627137184143)\n",
      "     | > loss_dur: 0.23571431636810303  (0.20801953226327896)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: 0.003142833709716797  (-0.0007528245449066162)\n",
      "     | > log_mle: -0.2232532501220703  (-0.2124476671218872)\n",
      "     | > loss_dur: 0.2263960838317871  (0.2116948425769806)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: 0.03375059366226196  (0.004997745156288147)\n",
      "     | > log_mle: -0.23578143119812012  (-0.21633662780125937)\n",
      "     | > loss_dur: 0.2695320248603821  (0.22133437295754751)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: 0.0067504048347473145  (0.005248125110353742)\n",
      "     | > log_mle: -0.2015063762664795  (-0.21421802043914795)\n",
      "     | > loss_dur: 0.2082567811012268  (0.2194661455495017)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: 0.0005901157855987549  (0.004665873944759369)\n",
      "     | > log_mle: -0.2093280553817749  (-0.21360677480697632)\n",
      "     | > loss_dur: 0.20991817116737366  (0.2182726487517357)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: 0.03683727979660034  (0.008240474594963921)\n",
      "     | > log_mle: -0.22024214267730713  (-0.21434403790367973)\n",
      "     | > loss_dur: 0.25707942247390747  (0.22258451249864367)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: 0.03168809413909912  (0.01058523654937744)\n",
      "     | > log_mle: -0.20734858512878418  (-0.21364449262619017)\n",
      "     | > loss_dur: 0.2390366792678833  (0.22422972917556763)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: 0.012788116931915283  (0.010785498402335426)\n",
      "     | > log_mle: -0.2236708402633667  (-0.21455597877502441)\n",
      "     | > loss_dur: 0.23645895719528198  (0.22534147717735983)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: -0.007837876677513123  (0.009233550479014715)\n",
      "     | > log_mle: -0.21150219440460205  (-0.21430149674415588)\n",
      "     | > loss_dur: 0.20366431772708893  (0.2235350472231706)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: -0.02927801012992859  (0.0062711227398652295)\n",
      "     | > log_mle: -0.23107004165649414  (-0.21559138481433576)\n",
      "     | > loss_dur: 0.20179203152656555  (0.22186250755420098)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: 0.015437185764312744  (0.006925841527325767)\n",
      "     | > log_mle: -0.22356021404266357  (-0.21616058690207346)\n",
      "     | > loss_dur: 0.23899739980697632  (0.22308642842939921)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: 0.0023992955684661865  (0.006624071796735128)\n",
      "     | > log_mle: -0.217484712600708  (-0.2162488619486491)\n",
      "     | > loss_dur: 0.2198840081691742  (0.22287293374538422)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: 0.01921600103378296  (0.007411067374050617)\n",
      "     | > log_mle: -0.2141948938369751  (-0.21612048894166946)\n",
      "     | > loss_dur: 0.23341089487075806  (0.22353155631572008)\n",
      "\n",
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.003998622298240662 \u001b[0m(-0.001982465386390686)\n",
      "     | > avg_loss:\u001b[92m 0.007411067374050617 \u001b[0m(-0.0041792504489421844)\n",
      "     | > avg_log_mle:\u001b[92m -0.21612048894166946 \u001b[0m(-0.003389805555343628)\n",
      "     | > avg_loss_dur:\u001b[92m 0.22353155631572008 \u001b[0m(-0.0007894448935985565)\n",
      "\n",
      " > BEST MODEL : train/run-February-22-2025_10+59PM-fa84af3/best_model_27602.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 12/100\u001b[0m\n",
      " --> train/run-February-22-2025_10+59PM-fa84af3\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-23 00:00:17) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:00:32 -- STEP: 23/406 -- GLOBAL_STEP: 27625\u001b[0m\n",
      "     | > loss: 0.02879396080970764  (0.03145109570544699)\n",
      "     | > log_mle: -0.1918102502822876  (-0.18659683932428775)\n",
      "     | > loss_dur: 0.22060421109199524  (0.21804793502973474)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(8.8939, device='cuda:0')  (tensor(4.9374, device='cuda:0'))\n",
      "     | > current_lr: 3e-06 \n",
      "     | > step_time: 0.5  (0.5554719074912693)\n",
      "     | > loader_time: 0.0043  (0.009764598763507347)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:00:48 -- STEP: 48/406 -- GLOBAL_STEP: 27650\u001b[0m\n",
      "     | > loss: 0.08263921737670898  (0.03561794757843017)\n",
      "     | > log_mle: -0.18068742752075195  (-0.18664955099423727)\n",
      "     | > loss_dur: 0.26332664489746094  (0.22226749857266745)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(5.1362, device='cuda:0')  (tensor(5.5051, device='cuda:0'))\n",
      "     | > current_lr: 3e-06 \n",
      "     | > step_time: 0.6449  (0.5877271344264346)\n",
      "     | > loader_time: 0.0041  (0.008879487713178001)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:01:03 -- STEP: 73/406 -- GLOBAL_STEP: 27675\u001b[0m\n",
      "     | > loss: 0.022564157843589783  (0.035238793247366604)\n",
      "     | > log_mle: -0.2051163911819458  (-0.18949738593950663)\n",
      "     | > loss_dur: 0.22768054902553558  (0.22473617918687325)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(7.6077, device='cuda:0')  (tensor(5.7354, device='cuda:0'))\n",
      "     | > current_lr: 3e-06 \n",
      "     | > step_time: 0.5838  (0.5879041103467549)\n",
      "     | > loader_time: 0.0044  (0.00908855869345469)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:01:19 -- STEP: 98/406 -- GLOBAL_STEP: 27700\u001b[0m\n",
      "     | > loss: 0.04205898940563202  (0.035284482094706325)\n",
      "     | > log_mle: -0.18926548957824707  (-0.19245403761766394)\n",
      "     | > loss_dur: 0.2313244789838791  (0.22773851971237027)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(8.9256, device='cuda:0')  (tensor(8.9145, device='cuda:0'))\n",
      "     | > current_lr: 3e-06 \n",
      "     | > step_time: 0.5253  (0.5965154754872226)\n",
      "     | > loader_time: 0.0047  (0.009457417896815706)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:01:34 -- STEP: 123/406 -- GLOBAL_STEP: 27725\u001b[0m\n",
      "     | > loss: 0.04925081133842468  (0.03515181127117903)\n",
      "     | > log_mle: -0.21169543266296387  (-0.19496069303373012)\n",
      "     | > loss_dur: 0.26094624400138855  (0.23011250430490912)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(18.6442, device='cuda:0')  (tensor(10.1350, device='cuda:0'))\n",
      "     | > current_lr: 3e-06 \n",
      "     | > step_time: 0.4983  (0.593573634217425)\n",
      "     | > loader_time: 0.0045  (0.010153597932520918)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:01:50 -- STEP: 148/406 -- GLOBAL_STEP: 27750\u001b[0m\n",
      "     | > loss: 0.03442443907260895  (0.03541771856111451)\n",
      "     | > log_mle: -0.21416687965393066  (-0.19706806943223282)\n",
      "     | > loss_dur: 0.2485913187265396  (0.23248578799334732)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(10.6393, device='cuda:0')  (tensor(11.0071, device='cuda:0'))\n",
      "     | > current_lr: 3e-06 \n",
      "     | > step_time: 0.5669  (0.6005433942820575)\n",
      "     | > loader_time: 0.0175  (0.010509101120201316)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:02:07 -- STEP: 173/406 -- GLOBAL_STEP: 27775\u001b[0m\n",
      "     | > loss: 0.03858447074890137  (0.03531438198392792)\n",
      "     | > log_mle: -0.2049553394317627  (-0.19855441799053564)\n",
      "     | > loss_dur: 0.24353981018066406  (0.23386879997446358)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(14.1309, device='cuda:0')  (tensor(11.5389, device='cuda:0'))\n",
      "     | > current_lr: 3e-06 \n",
      "     | > step_time: 0.8279  (0.6061396309406081)\n",
      "     | > loader_time: 0.0112  (0.01064373440825181)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:02:23 -- STEP: 198/406 -- GLOBAL_STEP: 27800\u001b[0m\n",
      "     | > loss: 0.04144418239593506  (0.035108734336164266)\n",
      "     | > log_mle: -0.21304726600646973  (-0.20008626309308136)\n",
      "     | > loss_dur: 0.2544914484024048  (0.23519499742924566)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(16.3684, device='cuda:0')  (tensor(12.0131, device='cuda:0'))\n",
      "     | > current_lr: 3e-06 \n",
      "     | > step_time: 0.4151  (0.611839313699741)\n",
      "     | > loader_time: 0.0159  (0.010862508205452348)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:02:41 -- STEP: 223/406 -- GLOBAL_STEP: 27825\u001b[0m\n",
      "     | > loss: 0.028913751244544983  (0.034996742290766256)\n",
      "     | > log_mle: -0.21205592155456543  (-0.201458034493998)\n",
      "     | > loss_dur: 0.2409696727991104  (0.2364547767847643)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(16.5184, device='cuda:0')  (tensor(12.5404, device='cuda:0'))\n",
      "     | > current_lr: 3e-06 \n",
      "     | > step_time: 0.6283  (0.6202165257235811)\n",
      "     | > loader_time: 0.0057  (0.011256312041004675)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:02:58 -- STEP: 248/406 -- GLOBAL_STEP: 27850\u001b[0m\n",
      "     | > loss: 0.024673625826835632  (0.03483696137705157)\n",
      "     | > log_mle: -0.21185123920440674  (-0.2027065946209815)\n",
      "     | > loss_dur: 0.23652486503124237  (0.2375435559980331)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(20.0255, device='cuda:0')  (tensor(12.9071, device='cuda:0'))\n",
      "     | > current_lr: 3e-06 \n",
      "     | > step_time: 0.6206  (0.6258956703447525)\n",
      "     | > loader_time: 0.0046  (0.011388940195883473)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:03:16 -- STEP: 273/406 -- GLOBAL_STEP: 27875\u001b[0m\n",
      "     | > loss: 0.027406111359596252  (0.034259671202072746)\n",
      "     | > log_mle: -0.2158259153366089  (-0.20387623161623325)\n",
      "     | > loss_dur: 0.24323202669620514  (0.23813590281830602)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(26.4881, device='cuda:0')  (tensor(13.2265, device='cuda:0'))\n",
      "     | > current_lr: 3e-06 \n",
      "     | > step_time: 0.4707  (0.6327057836693283)\n",
      "     | > loader_time: 0.0058  (0.011573166200966187)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:03:37 -- STEP: 298/406 -- GLOBAL_STEP: 27900\u001b[0m\n",
      "     | > loss: 0.03681251406669617  (0.0341386934054778)\n",
      "     | > log_mle: -0.20530200004577637  (-0.20466251581307218)\n",
      "     | > loss_dur: 0.24211451411247253  (0.23880120921855005)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(10.2882, device='cuda:0')  (tensor(13.4096, device='cuda:0'))\n",
      "     | > current_lr: 3e-06 \n",
      "     | > step_time: 0.6413  (0.647790439976942)\n",
      "     | > loader_time: 0.0071  (0.011758120267983245)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:03:57 -- STEP: 323/406 -- GLOBAL_STEP: 27925\u001b[0m\n",
      "     | > loss: 0.028960540890693665  (0.033878578351747145)\n",
      "     | > log_mle: -0.2192448377609253  (-0.20549159596209915)\n",
      "     | > loss_dur: 0.24820537865161896  (0.23937017431384638)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(16.5730, device='cuda:0')  (tensor(13.5878, device='cuda:0'))\n",
      "     | > current_lr: 3e-06 \n",
      "     | > step_time: 0.7436  (0.6577295349109283)\n",
      "     | > loader_time: 0.0091  (0.011758159926801267)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:04:18 -- STEP: 348/406 -- GLOBAL_STEP: 27950\u001b[0m\n",
      "     | > loss: 0.032756149768829346  (0.033993759331689494)\n",
      "     | > log_mle: -0.21873211860656738  (-0.20624833442698942)\n",
      "     | > loss_dur: 0.25148826837539673  (0.24024209375867897)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(27.8956, device='cuda:0')  (tensor(13.8810, device='cuda:0'))\n",
      "     | > current_lr: 3e-06 \n",
      "     | > step_time: 1.0454  (0.6686084845970418)\n",
      "     | > loader_time: 0.0389  (0.012044807960247166)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:04:39 -- STEP: 373/406 -- GLOBAL_STEP: 27975\u001b[0m\n",
      "     | > loss: -0.0006529241800308228  (0.033846399020253826)\n",
      "     | > log_mle: -0.2242206335067749  (-0.20707487452765244)\n",
      "     | > loss_dur: 0.22356770932674408  (0.24092127354790635)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(11.6991, device='cuda:0')  (tensor(14.1147, device='cuda:0'))\n",
      "     | > current_lr: 3e-06 \n",
      "     | > step_time: 0.794  (0.6784728864562418)\n",
      "     | > loader_time: 0.0071  (0.012193399204325736)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:04:58 -- STEP: 398/406 -- GLOBAL_STEP: 28000\u001b[0m\n",
      "     | > loss: 0.029635533690452576  (0.03374144296400512)\n",
      "     | > log_mle: -0.21924495697021484  (-0.2078171656958421)\n",
      "     | > loss_dur: 0.24888049066066742  (0.2415586086598473)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(13.0180, device='cuda:0')  (tensor(14.3413, device='cuda:0'))\n",
      "     | > current_lr: 3e-06 \n",
      "     | > step_time: 0.5744  (0.6836531449801958)\n",
      "     | > loader_time: 0.0075  (0.012451937450236407)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: 0.037322014570236206  (0.037322014570236206)\n",
      "     | > log_mle: -0.19016408920288086  (-0.19016408920288086)\n",
      "     | > loss_dur: 0.22748610377311707  (0.22748610377311707)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: -0.03699004650115967  (-0.03699004650115967)\n",
      "     | > log_mle: -0.22726750373840332  (-0.22726750373840332)\n",
      "     | > loss_dur: 0.19027745723724365  (0.19027745723724365)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: 0.008985787630081177  (-0.014002129435539246)\n",
      "     | > log_mle: -0.18655610084533691  (-0.20691180229187012)\n",
      "     | > loss_dur: 0.1955418884754181  (0.19290967285633087)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: 0.007481694221496582  (-0.00684085488319397)\n",
      "     | > log_mle: -0.20087790489196777  (-0.20490050315856934)\n",
      "     | > loss_dur: 0.20835959911346436  (0.19805964827537537)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: 0.007432654500007629  (-0.00327247753739357)\n",
      "     | > log_mle: -0.22783315181732178  (-0.21063366532325745)\n",
      "     | > loss_dur: 0.2352658063173294  (0.20736118778586388)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: 0.0021637529134750366  (-0.0021852314472198485)\n",
      "     | > log_mle: -0.22411108016967773  (-0.21332914829254152)\n",
      "     | > loss_dur: 0.22627483308315277  (0.21114391684532166)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: 0.0319695770740509  (0.00350723663965861)\n",
      "     | > log_mle: -0.23650610446929932  (-0.21719197432200113)\n",
      "     | > loss_dur: 0.2684756815433502  (0.22069921096165976)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: 0.004601284861564636  (0.0036635292427880423)\n",
      "     | > log_mle: -0.2022237777709961  (-0.2150536605290004)\n",
      "     | > loss_dur: 0.20682506263256073  (0.21871718977178847)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: -0.0007558763027191162  (0.0031111035495996475)\n",
      "     | > log_mle: -0.21010947227478027  (-0.2144356369972229)\n",
      "     | > loss_dur: 0.20935359597206116  (0.21754674054682255)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: 0.0323808491230011  (0.006363297502199809)\n",
      "     | > log_mle: -0.22107172012329102  (-0.21517297956678602)\n",
      "     | > loss_dur: 0.2534525692462921  (0.22153627706898582)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: 0.030223682522773743  (0.008749336004257202)\n",
      "     | > log_mle: -0.20794451236724854  (-0.2144501328468323)\n",
      "     | > loss_dur: 0.23816819489002228  (0.2231994688510895)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: 0.013282150030136108  (0.00916141000660983)\n",
      "     | > log_mle: -0.22447514533996582  (-0.21536149761893533)\n",
      "     | > loss_dur: 0.23775729537010193  (0.22452290762554517)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: -0.008548438549041748  (0.007685589293638866)\n",
      "     | > log_mle: -0.21245050430297852  (-0.2151189148426056)\n",
      "     | > loss_dur: 0.20390206575393677  (0.22280450413624445)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: -0.03268091380596161  (0.004580473670592676)\n",
      "     | > log_mle: -0.23178136348724365  (-0.2164006416614239)\n",
      "     | > loss_dur: 0.19910044968128204  (0.2209811153320166)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: 0.015065595507621765  (0.005329410944666183)\n",
      "     | > log_mle: -0.2245326042175293  (-0.21698149612971715)\n",
      "     | > loss_dur: 0.23959819972515106  (0.22231090707438333)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: -0.0005637109279632568  (0.004936536153157553)\n",
      "     | > log_mle: -0.21851801872253418  (-0.21708393096923828)\n",
      "     | > loss_dur: 0.21795430779457092  (0.22202046712239584)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: 0.02097681164741516  (0.0059390533715486535)\n",
      "     | > log_mle: -0.21516478061676025  (-0.2169639840722084)\n",
      "     | > loss_dur: 0.23614159226417542  (0.22290303744375706)\n",
      "\n",
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[91m 0.006294727325439453 \u001b[0m(+0.0022961050271987915)\n",
      "     | > avg_loss:\u001b[92m 0.0059390533715486535 \u001b[0m(-0.0014720140025019637)\n",
      "     | > avg_log_mle:\u001b[92m -0.2169639840722084 \u001b[0m(-0.0008434951305389404)\n",
      "     | > avg_loss_dur:\u001b[92m 0.22290303744375706 \u001b[0m(-0.0006285188719630241)\n",
      "\n",
      " > BEST MODEL : train/run-February-22-2025_10+59PM-fa84af3/best_model_28008.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 13/100\u001b[0m\n",
      " --> train/run-February-22-2025_10+59PM-fa84af3\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-23 00:05:19) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:05:27 -- STEP: 17/406 -- GLOBAL_STEP: 28025\u001b[0m\n",
      "     | > loss: 0.03507925570011139  (0.025970750871826622)\n",
      "     | > log_mle: -0.19075119495391846  (-0.19009776676402373)\n",
      "     | > loss_dur: 0.22583045065402985  (0.21606851763585033)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(1.4560, device='cuda:0')  (tensor(4.7648, device='cuda:0'))\n",
      "     | > current_lr: 3.25e-06 \n",
      "     | > step_time: 0.3929  (0.39632195584914265)\n",
      "     | > loader_time: 0.0063  (0.005815646227668314)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:05:43 -- STEP: 42/406 -- GLOBAL_STEP: 28050\u001b[0m\n",
      "     | > loss: 0.0291316956281662  (0.030876661695185163)\n",
      "     | > log_mle: -0.19439268112182617  (-0.18791290408089048)\n",
      "     | > loss_dur: 0.22352437674999237  (0.21878956577607564)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(9.1260, device='cuda:0')  (tensor(6.4535, device='cuda:0'))\n",
      "     | > current_lr: 3.25e-06 \n",
      "     | > step_time: 0.4481  (0.5360598166783651)\n",
      "     | > loader_time: 0.0049  (0.008609527633303688)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:05:58 -- STEP: 67/406 -- GLOBAL_STEP: 28075\u001b[0m\n",
      "     | > loss: 0.030941545963287354  (0.03327017444283215)\n",
      "     | > log_mle: -0.20211410522460938  (-0.19026004556399673)\n",
      "     | > loss_dur: 0.23305565118789673  (0.22353022000682887)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(18.4630, device='cuda:0')  (tensor(6.8931, device='cuda:0'))\n",
      "     | > current_lr: 3.25e-06 \n",
      "     | > step_time: 0.4789  (0.5527243863290815)\n",
      "     | > loader_time: 0.0197  (0.009090804342013686)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:06:13 -- STEP: 92/406 -- GLOBAL_STEP: 28100\u001b[0m\n",
      "     | > loss: 0.02334447205066681  (0.03279565566259883)\n",
      "     | > log_mle: -0.21573090553283691  (-0.19334460859713348)\n",
      "     | > loss_dur: 0.23907537758350372  (0.2261402642597323)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(19.4113, device='cuda:0')  (tensor(6.8555, device='cuda:0'))\n",
      "     | > current_lr: 3.25e-06 \n",
      "     | > step_time: 0.5466  (0.5626935077750165)\n",
      "     | > loader_time: 0.0049  (0.00867884832879771)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:06:29 -- STEP: 117/406 -- GLOBAL_STEP: 28125\u001b[0m\n",
      "     | > loss: 0.030046895146369934  (0.03246429766345228)\n",
      "     | > log_mle: -0.2047499418258667  (-0.19588146556136954)\n",
      "     | > loss_dur: 0.23479683697223663  (0.22834576322482183)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(2.2384, device='cuda:0')  (tensor(7.1285, device='cuda:0'))\n",
      "     | > current_lr: 3.25e-06 \n",
      "     | > step_time: 0.7229  (0.5756035584669846)\n",
      "     | > loader_time: 0.0137  (0.008911951994284609)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:06:47 -- STEP: 142/406 -- GLOBAL_STEP: 28150\u001b[0m\n",
      "     | > loss: 0.024841278791427612  (0.03258177795460527)\n",
      "     | > log_mle: -0.21406292915344238  (-0.19819256621347348)\n",
      "     | > loss_dur: 0.23890420794487  (0.23077434416807874)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(15.0518, device='cuda:0')  (tensor(7.2470, device='cuda:0'))\n",
      "     | > current_lr: 3.25e-06 \n",
      "     | > step_time: 0.942  (0.598613757482717)\n",
      "     | > loader_time: 0.0053  (0.009661192625341283)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:07:05 -- STEP: 167/406 -- GLOBAL_STEP: 28175\u001b[0m\n",
      "     | > loss: 0.033126100897789  (0.03277064574335863)\n",
      "     | > log_mle: -0.20610380172729492  (-0.19968329646630198)\n",
      "     | > loss_dur: 0.23922990262508392  (0.23245394220966065)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(19.0718, device='cuda:0')  (tensor(8.0494, device='cuda:0'))\n",
      "     | > current_lr: 3.25e-06 \n",
      "     | > step_time: 0.9055  (0.6140267277906046)\n",
      "     | > loader_time: 0.0061  (0.009659988437584057)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:07:25 -- STEP: 192/406 -- GLOBAL_STEP: 28200\u001b[0m\n",
      "     | > loss: 0.02559274435043335  (0.03245642005155482)\n",
      "     | > log_mle: -0.214882493019104  (-0.20117196254432199)\n",
      "     | > loss_dur: 0.24047523736953735  (0.23362838259587684)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(18.6604, device='cuda:0')  (tensor(9.0756, device='cuda:0'))\n",
      "     | > current_lr: 3.25e-06 \n",
      "     | > step_time: 0.759  (0.6362374176581708)\n",
      "     | > loader_time: 0.0224  (0.01016974945863088)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:07:44 -- STEP: 217/406 -- GLOBAL_STEP: 28225\u001b[0m\n",
      "     | > loss: 0.03139035403728485  (0.03234271224467982)\n",
      "     | > log_mle: -0.21745336055755615  (-0.20244184617073302)\n",
      "     | > loss_dur: 0.248843714594841  (0.2347845584154129)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(26.0453, device='cuda:0')  (tensor(10.5640, device='cuda:0'))\n",
      "     | > current_lr: 3.25e-06 \n",
      "     | > step_time: 0.5146  (0.6478856367998965)\n",
      "     | > loader_time: 0.0069  (0.010499277422505041)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:08:02 -- STEP: 242/406 -- GLOBAL_STEP: 28250\u001b[0m\n",
      "     | > loss: 0.03054937720298767  (0.0323400642137882)\n",
      "     | > log_mle: -0.22205376625061035  (-0.20379839012445494)\n",
      "     | > loss_dur: 0.252603143453598  (0.23613845433824318)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(12.2281, device='cuda:0')  (tensor(10.8283, device='cuda:0'))\n",
      "     | > current_lr: 3.25e-06 \n",
      "     | > step_time: 0.9567  (0.6540155046242334)\n",
      "     | > loader_time: 0.006  (0.010890147902748802)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:08:22 -- STEP: 267/406 -- GLOBAL_STEP: 28275\u001b[0m\n",
      "     | > loss: 0.03372526168823242  (0.03202349460973274)\n",
      "     | > log_mle: -0.20969033241271973  (-0.20485905806223548)\n",
      "     | > loss_dur: 0.24341559410095215  (0.23688255267196826)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(7.5961, device='cuda:0')  (tensor(10.7316, device='cuda:0'))\n",
      "     | > current_lr: 3.25e-06 \n",
      "     | > step_time: 0.7861  (0.6631313325760522)\n",
      "     | > loader_time: 0.0056  (0.011114276750257399)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:08:41 -- STEP: 292/406 -- GLOBAL_STEP: 28300\u001b[0m\n",
      "     | > loss: 0.03104284405708313  (0.031602252734034025)\n",
      "     | > log_mle: -0.20898759365081787  (-0.20581551773907383)\n",
      "     | > loss_dur: 0.240030437707901  (0.2374177704731079)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(13.6265, device='cuda:0')  (tensor(10.7297, device='cuda:0'))\n",
      "     | > current_lr: 3.25e-06 \n",
      "     | > step_time: 0.7069  (0.6718039912720254)\n",
      "     | > loader_time: 0.0306  (0.011445163047476994)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:09:02 -- STEP: 317/406 -- GLOBAL_STEP: 28325\u001b[0m\n",
      "     | > loss: 0.036535054445266724  (0.03136045173139602)\n",
      "     | > log_mle: -0.2185739278793335  (-0.20673547746255194)\n",
      "     | > loss_dur: 0.2551089823246002  (0.23809592919394798)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(4.2533, device='cuda:0')  (tensor(10.7783, device='cuda:0'))\n",
      "     | > current_lr: 3.25e-06 \n",
      "     | > step_time: 0.7602  (0.6815114412397999)\n",
      "     | > loader_time: 0.0246  (0.01211381861088028)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:09:24 -- STEP: 342/406 -- GLOBAL_STEP: 28350\u001b[0m\n",
      "     | > loss: 0.027062445878982544  (0.031479717564513086)\n",
      "     | > log_mle: -0.2320265769958496  (-0.20742230248032956)\n",
      "     | > loss_dur: 0.25908902287483215  (0.23890202004484265)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(8.4607, device='cuda:0')  (tensor(10.6498, device='cuda:0'))\n",
      "     | > current_lr: 3.25e-06 \n",
      "     | > step_time: 0.824  (0.6944360014987974)\n",
      "     | > loader_time: 0.0242  (0.012733311681022423)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:09:49 -- STEP: 367/406 -- GLOBAL_STEP: 28375\u001b[0m\n",
      "     | > loss: 0.022701561450958252  (0.031370286192815997)\n",
      "     | > log_mle: -0.22178828716278076  (-0.20826270534816815)\n",
      "     | > loss_dur: 0.244489848613739  (0.23963299154098416)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(9.6700, device='cuda:0')  (tensor(10.5617, device='cuda:0'))\n",
      "     | > current_lr: 3.25e-06 \n",
      "     | > step_time: 1.0962  (0.7140510634440497)\n",
      "     | > loader_time: 0.0186  (0.013260117018904935)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:10:11 -- STEP: 392/406 -- GLOBAL_STEP: 28400\u001b[0m\n",
      "     | > loss: 0.024117812514305115  (0.03130942929003918)\n",
      "     | > log_mle: -0.2160872220993042  (-0.2089960228423683)\n",
      "     | > loss_dur: 0.24020503461360931  (0.2403054521324075)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(9.5033, device='cuda:0')  (tensor(10.6467, device='cuda:0'))\n",
      "     | > current_lr: 3.25e-06 \n",
      "     | > step_time: 0.7007  (0.7220758716670839)\n",
      "     | > loader_time: 0.0171  (0.013457219819633331)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: 0.03465186059474945  (0.03465186059474945)\n",
      "     | > log_mle: -0.19207072257995605  (-0.19207072257995605)\n",
      "     | > loss_dur: 0.2267225831747055  (0.2267225831747055)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: -0.03838494420051575  (-0.03838494420051575)\n",
      "     | > log_mle: -0.22842133045196533  (-0.22842133045196533)\n",
      "     | > loss_dur: 0.19003638625144958  (0.19003638625144958)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: 0.0037191063165664673  (-0.01733291894197464)\n",
      "     | > log_mle: -0.18796658515930176  (-0.20819395780563354)\n",
      "     | > loss_dur: 0.19168569147586823  (0.1908610388636589)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: 0.010010838508605957  (-0.008218333125114441)\n",
      "     | > log_mle: -0.2016282081604004  (-0.20600537459055582)\n",
      "     | > loss_dur: 0.21163904666900635  (0.19778704146544138)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: 0.0060190558433532715  (-0.004658985882997513)\n",
      "     | > log_mle: -0.22810232639312744  (-0.21152961254119873)\n",
      "     | > loss_dur: 0.2341213822364807  (0.20687062665820122)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: 0.0010690242052078247  (-0.0035133838653564455)\n",
      "     | > log_mle: -0.22331535816192627  (-0.21388676166534423)\n",
      "     | > loss_dur: 0.2243843823671341  (0.2103733777999878)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: 0.026345491409301758  (0.0014630953470865886)\n",
      "     | > log_mle: -0.23552727699279785  (-0.21749351421991983)\n",
      "     | > loss_dur: 0.2618727684020996  (0.21895660956700644)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: 0.008550629019737244  (0.0024756001574652536)\n",
      "     | > log_mle: -0.20258677005767822  (-0.2153639793395996)\n",
      "     | > loss_dur: 0.21113739907741547  (0.21783957949706487)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: 0.002040565013885498  (0.002421220764517784)\n",
      "     | > log_mle: -0.2111372947692871  (-0.21483564376831055)\n",
      "     | > loss_dur: 0.2131778597831726  (0.21725686453282833)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: 0.02394258975982666  (0.00481248398621877)\n",
      "     | > log_mle: -0.22094810009002686  (-0.21551480558183458)\n",
      "     | > loss_dur: 0.24489068984985352  (0.22032728956805336)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: 0.026565417647361755  (0.006987777352333069)\n",
      "     | > log_mle: -0.20838212966918945  (-0.21480153799057006)\n",
      "     | > loss_dur: 0.2349475473165512  (0.22178931534290314)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: 0.013580963015556335  (0.007587157867171548)\n",
      "     | > log_mle: -0.22474539279937744  (-0.21570552479137073)\n",
      "     | > loss_dur: 0.23832635581493378  (0.2232926826585423)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: -0.01143452525138855  (0.006002017607291539)\n",
      "     | > log_mle: -0.21333670616149902  (-0.21550812323888144)\n",
      "     | > loss_dur: 0.20190218091011047  (0.22151014084617296)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: -0.03494316339492798  (0.0028523882994284998)\n",
      "     | > log_mle: -0.23145461082458496  (-0.2167347761300894)\n",
      "     | > loss_dur: 0.19651144742965698  (0.2195871644295179)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: 0.013569340109825134  (0.0036178848573139737)\n",
      "     | > log_mle: -0.2247694730758667  (-0.21730868305478776)\n",
      "     | > loss_dur: 0.23833881318569183  (0.22092656791210175)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: -0.0010778158903121948  (0.003304838140805562)\n",
      "     | > log_mle: -0.21874427795410156  (-0.21740438938140869)\n",
      "     | > loss_dur: 0.21766646206378937  (0.22070922752221425)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: 0.02698369324207306  (0.004784766584634781)\n",
      "     | > log_mle: -0.21477150917053223  (-0.2172398343682289)\n",
      "     | > loss_dur: 0.24175520241260529  (0.2220246009528637)\n",
      "\n",
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.0036775320768356323 \u001b[0m(-0.002617195248603821)\n",
      "     | > avg_loss:\u001b[92m 0.004784766584634781 \u001b[0m(-0.0011542867869138726)\n",
      "     | > avg_log_mle:\u001b[92m -0.2172398343682289 \u001b[0m(-0.0002758502960205078)\n",
      "     | > avg_loss_dur:\u001b[92m 0.2220246009528637 \u001b[0m(-0.000878436490893364)\n",
      "\n",
      " > BEST MODEL : train/run-February-22-2025_10+59PM-fa84af3/best_model_28414.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 14/100\u001b[0m\n",
      " --> train/run-February-22-2025_10+59PM-fa84af3\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-23 00:10:35) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:10:41 -- STEP: 11/406 -- GLOBAL_STEP: 28425\u001b[0m\n",
      "     | > loss: -0.0032939165830612183  (0.021765394644303757)\n",
      "     | > log_mle: -0.18618500232696533  (-0.1896580240943215)\n",
      "     | > loss_dur: 0.1828910857439041  (0.21142341873862527)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(3.9092, device='cuda:0')  (tensor(3.9228, device='cuda:0'))\n",
      "     | > current_lr: 3.5e-06 \n",
      "     | > step_time: 0.275  (0.3339444507252086)\n",
      "     | > loader_time: 0.0029  (0.005490779876708984)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:10:57 -- STEP: 36/406 -- GLOBAL_STEP: 28450\u001b[0m\n",
      "     | > loss: 0.02133198082447052  (0.026928799433840647)\n",
      "     | > log_mle: -0.18570101261138916  (-0.19016398986180624)\n",
      "     | > loss_dur: 0.20703299343585968  (0.21709278929564688)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(6.4087, device='cuda:0')  (tensor(6.0825, device='cuda:0'))\n",
      "     | > current_lr: 3.5e-06 \n",
      "     | > step_time: 0.8713  (0.5274061626858182)\n",
      "     | > loader_time: 0.0163  (0.008458084530300565)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:11:12 -- STEP: 61/406 -- GLOBAL_STEP: 28475\u001b[0m\n",
      "     | > loss: 0.03480401635169983  (0.029875310473754756)\n",
      "     | > log_mle: -0.19808876514434814  (-0.1917947569831473)\n",
      "     | > loss_dur: 0.23289278149604797  (0.22167006745690204)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(3.6093, device='cuda:0')  (tensor(7.1298, device='cuda:0'))\n",
      "     | > current_lr: 3.5e-06 \n",
      "     | > step_time: 0.4474  (0.5565923980024995)\n",
      "     | > loader_time: 0.0048  (0.00876898843733991)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:11:28 -- STEP: 86/406 -- GLOBAL_STEP: 28500\u001b[0m\n",
      "     | > loss: 0.03826361894607544  (0.029737483276877294)\n",
      "     | > log_mle: -0.1946200132369995  (-0.19444507914920187)\n",
      "     | > loss_dur: 0.23288363218307495  (0.22418256242607915)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(11.3655, device='cuda:0')  (tensor(7.0264, device='cuda:0'))\n",
      "     | > current_lr: 3.5e-06 \n",
      "     | > step_time: 0.8558  (0.5785161339959433)\n",
      "     | > loader_time: 0.0058  (0.009721403898194779)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:11:48 -- STEP: 111/406 -- GLOBAL_STEP: 28525\u001b[0m\n",
      "     | > loss: 0.02313275635242462  (0.029341876372560725)\n",
      "     | > log_mle: -0.22598505020141602  (-0.19733623448792878)\n",
      "     | > loss_dur: 0.24911780655384064  (0.2266781108604895)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(5.1130, device='cuda:0')  (tensor(7.6188, device='cuda:0'))\n",
      "     | > current_lr: 3.5e-06 \n",
      "     | > step_time: 1.0355  (0.6236645036989504)\n",
      "     | > loader_time: 0.0047  (0.010444883827690606)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:12:04 -- STEP: 136/406 -- GLOBAL_STEP: 28550\u001b[0m\n",
      "     | > loss: 0.052866458892822266  (0.02920288800754968)\n",
      "     | > log_mle: -0.21476805210113525  (-0.19960160991724799)\n",
      "     | > loss_dur: 0.2676345109939575  (0.22880449792479768)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(5.2082, device='cuda:0')  (tensor(7.9511, device='cuda:0'))\n",
      "     | > current_lr: 3.5e-06 \n",
      "     | > step_time: 0.5553  (0.6240319153841805)\n",
      "     | > loader_time: 0.0037  (0.010305685155531938)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:12:21 -- STEP: 161/406 -- GLOBAL_STEP: 28575\u001b[0m\n",
      "     | > loss: 0.038606539368629456  (0.029712584725818277)\n",
      "     | > log_mle: -0.2085343599319458  (-0.20115254014175135)\n",
      "     | > loss_dur: 0.24714089930057526  (0.23086512486756958)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(12.7438, device='cuda:0')  (tensor(8.1838, device='cuda:0'))\n",
      "     | > current_lr: 3.5e-06 \n",
      "     | > step_time: 0.8368  (0.6270204908359123)\n",
      "     | > loader_time: 0.0329  (0.01053854989709321)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:12:38 -- STEP: 186/406 -- GLOBAL_STEP: 28600\u001b[0m\n",
      "     | > loss: 0.02762511372566223  (0.02953112293635645)\n",
      "     | > log_mle: -0.21631598472595215  (-0.20268953487437263)\n",
      "     | > loss_dur: 0.24394109845161438  (0.23222065781072904)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(13.2641, device='cuda:0')  (tensor(8.7244, device='cuda:0'))\n",
      "     | > current_lr: 3.5e-06 \n",
      "     | > step_time: 0.6202  (0.633701133471663)\n",
      "     | > loader_time: 0.0057  (0.01092186025393906)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:12:55 -- STEP: 211/406 -- GLOBAL_STEP: 28625\u001b[0m\n",
      "     | > loss: 0.02022746205329895  (0.029209489011651532)\n",
      "     | > log_mle: -0.218225359916687  (-0.20395302433538215)\n",
      "     | > loss_dur: 0.23845282196998596  (0.23316251334703364)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(12.5652, device='cuda:0')  (tensor(9.0604, device='cuda:0'))\n",
      "     | > current_lr: 3.5e-06 \n",
      "     | > step_time: 0.9081  (0.6381827688895131)\n",
      "     | > loader_time: 0.0053  (0.010961471575696317)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:13:13 -- STEP: 236/406 -- GLOBAL_STEP: 28650\u001b[0m\n",
      "     | > loss: 0.030983582139015198  (0.029204958071142942)\n",
      "     | > log_mle: -0.2036581039428711  (-0.20532345367690266)\n",
      "     | > loss_dur: 0.2346416860818863  (0.2345284117480456)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(7.5370, device='cuda:0')  (tensor(9.2280, device='cuda:0'))\n",
      "     | > current_lr: 3.5e-06 \n",
      "     | > step_time: 0.8087  (0.645842306694742)\n",
      "     | > loader_time: 0.0064  (0.011169733637470307)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:13:32 -- STEP: 261/406 -- GLOBAL_STEP: 28675\u001b[0m\n",
      "     | > loss: 0.025853365659713745  (0.028997500965878425)\n",
      "     | > log_mle: -0.21731066703796387  (-0.2065527672055124)\n",
      "     | > loss_dur: 0.2431640326976776  (0.2355502681713908)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(25.2752, device='cuda:0')  (tensor(10.3940, device='cuda:0'))\n",
      "     | > current_lr: 3.5e-06 \n",
      "     | > step_time: 0.7792  (0.6529005834426003)\n",
      "     | > loader_time: 0.0115  (0.0113040332136483)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:13:54 -- STEP: 286/406 -- GLOBAL_STEP: 28700\u001b[0m\n",
      "     | > loss: 0.018954291939735413  (0.028565849874403092)\n",
      "     | > log_mle: -0.21574270725250244  (-0.20749488452097756)\n",
      "     | > loss_dur: 0.23469699919223785  (0.2360607343953806)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(35.4893, device='cuda:0')  (tensor(11.5972, device='cuda:0'))\n",
      "     | > current_lr: 3.5e-06 \n",
      "     | > step_time: 0.7142  (0.6717656950850587)\n",
      "     | > loader_time: 0.0345  (0.011817813753248089)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:14:15 -- STEP: 311/406 -- GLOBAL_STEP: 28725\u001b[0m\n",
      "     | > loss: 0.022792130708694458  (0.02831436262445051)\n",
      "     | > log_mle: -0.21477162837982178  (-0.20830237098828772)\n",
      "     | > loss_dur: 0.23756375908851624  (0.23661673361273824)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(10.4925, device='cuda:0')  (tensor(12.4507, device='cuda:0'))\n",
      "     | > current_lr: 3.5e-06 \n",
      "     | > step_time: 0.4946  (0.6831077509754339)\n",
      "     | > loader_time: 0.0078  (0.012128491876976276)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:14:36 -- STEP: 336/406 -- GLOBAL_STEP: 28750\u001b[0m\n",
      "     | > loss: 0.012477129697799683  (0.028291944990910235)\n",
      "     | > log_mle: -0.2203981876373291  (-0.20902901000919796)\n",
      "     | > loss_dur: 0.23287531733512878  (0.2373209550001082)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(12.7364, device='cuda:0')  (tensor(12.9208, device='cuda:0'))\n",
      "     | > current_lr: 3.5e-06 \n",
      "     | > step_time: 0.6558  (0.692624061590149)\n",
      "     | > loader_time: 0.0072  (0.0123696866489592)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:14:57 -- STEP: 361/406 -- GLOBAL_STEP: 28775\u001b[0m\n",
      "     | > loss: 0.0366097092628479  (0.028288668666519946)\n",
      "     | > log_mle: -0.21691954135894775  (-0.20982870831053674)\n",
      "     | > loss_dur: 0.25352925062179565  (0.23811737697705668)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(5.5742, device='cuda:0')  (tensor(12.8397, device='cuda:0'))\n",
      "     | > current_lr: 3.5e-06 \n",
      "     | > step_time: 1.0409  (0.7031287162918133)\n",
      "     | > loader_time: 0.0074  (0.012518776420741196)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:15:19 -- STEP: 386/406 -- GLOBAL_STEP: 28800\u001b[0m\n",
      "     | > loss: 0.04071715474128723  (0.02822527825986783)\n",
      "     | > log_mle: -0.2207401990890503  (-0.21054424553955156)\n",
      "     | > loss_dur: 0.2614573538303375  (0.2387695237994194)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(4.9716, device='cuda:0')  (tensor(13.2177, device='cuda:0'))\n",
      "     | > current_lr: 3.5e-06 \n",
      "     | > step_time: 0.7842  (0.711001089199837)\n",
      "     | > loader_time: 0.0247  (0.012742201898999777)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: 0.03164547681808472  (0.03164547681808472)\n",
      "     | > log_mle: -0.19418680667877197  (-0.19418680667877197)\n",
      "     | > loss_dur: 0.2258322834968567  (0.2258322834968567)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: -0.03901702165603638  (-0.03901702165603638)\n",
      "     | > log_mle: -0.2324157953262329  (-0.2324157953262329)\n",
      "     | > loss_dur: 0.19339877367019653  (0.19339877367019653)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: -0.0018248260021209717  (-0.020420923829078674)\n",
      "     | > log_mle: -0.1908942461013794  (-0.21165502071380615)\n",
      "     | > loss_dur: 0.18906942009925842  (0.19123409688472748)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: 0.005160793662071228  (-0.01189368466536204)\n",
      "     | > log_mle: -0.20625150203704834  (-0.20985384782155356)\n",
      "     | > loss_dur: 0.21141229569911957  (0.1979601631561915)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: -0.0018647760152816772  (-0.00938645750284195)\n",
      "     | > log_mle: -0.23368120193481445  (-0.21581068634986877)\n",
      "     | > loss_dur: 0.23181642591953278  (0.20642422884702682)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: -0.00569838285446167  (-0.008648842573165894)\n",
      "     | > log_mle: -0.2319188117980957  (-0.21903231143951415)\n",
      "     | > loss_dur: 0.22622042894363403  (0.21038346886634826)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: 0.01242285966873169  (-0.005136892199516296)\n",
      "     | > log_mle: -0.24502205848693848  (-0.2233639359474182)\n",
      "     | > loss_dur: 0.25744491815567017  (0.21822704374790192)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: 0.0031606853008270264  (-0.003951523985181536)\n",
      "     | > log_mle: -0.2076892852783203  (-0.2211247001375471)\n",
      "     | > loss_dur: 0.21084997057914734  (0.21717317615236556)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: 0.0013993829488754272  (-0.003282660618424416)\n",
      "     | > log_mle: -0.21546387672424316  (-0.2204170972108841)\n",
      "     | > loss_dur: 0.2168632596731186  (0.21713443659245968)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: 0.0197380930185318  (-0.0007247991032070587)\n",
      "     | > log_mle: -0.2277967929840088  (-0.22123706340789795)\n",
      "     | > loss_dur: 0.2475348860025406  (0.2205122643046909)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: 0.023653864860534668  (0.0017130672931671138)\n",
      "     | > log_mle: -0.21420490741729736  (-0.2205338478088379)\n",
      "     | > loss_dur: 0.23785877227783203  (0.222246915102005)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: 0.008202403783798218  (0.002303006974133578)\n",
      "     | > log_mle: -0.23040509223937988  (-0.22143123366615988)\n",
      "     | > loss_dur: 0.2386074960231781  (0.22373424064029346)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: -0.014078959822654724  (0.0009378430744012194)\n",
      "     | > log_mle: -0.2176445722579956  (-0.22111567854881287)\n",
      "     | > loss_dur: 0.20356561243534088  (0.2220535216232141)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: -0.044794440269470215  (-0.0025800248751273523)\n",
      "     | > log_mle: -0.23818528652191162  (-0.2224287253159743)\n",
      "     | > loss_dur: 0.1933908462524414  (0.21984870044084695)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: 0.004499837756156921  (-0.0020743204014641897)\n",
      "     | > log_mle: -0.230712890625  (-0.22302045140947616)\n",
      "     | > loss_dur: 0.23521272838115692  (0.22094613100801194)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: -0.004342496395111084  (-0.0022255321343739825)\n",
      "     | > log_mle: -0.22414827346801758  (-0.22309563954671224)\n",
      "     | > loss_dur: 0.2198057770729065  (0.22087010741233826)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: 0.012894541025161743  (-0.0012805275619029999)\n",
      "     | > log_mle: -0.22176790237426758  (-0.22301265597343445)\n",
      "     | > loss_dur: 0.23466244339942932  (0.22173212841153145)\n",
      "\n",
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.0036400705575942993 \u001b[0m(-3.746151924133301e-05)\n",
      "     | > avg_loss:\u001b[92m -0.0012805275619029999 \u001b[0m(-0.006065294146537781)\n",
      "     | > avg_log_mle:\u001b[92m -0.22301265597343445 \u001b[0m(-0.005772821605205536)\n",
      "     | > avg_loss_dur:\u001b[92m 0.22173212841153145 \u001b[0m(-0.0002924725413322449)\n",
      "\n",
      " > BEST MODEL : train/run-February-22-2025_10+59PM-fa84af3/best_model_28820.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 15/100\u001b[0m\n",
      " --> train/run-February-22-2025_10+59PM-fa84af3\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-23 00:15:47) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:15:51 -- STEP: 5/406 -- GLOBAL_STEP: 28825\u001b[0m\n",
      "     | > loss: 0.02926802635192871  (0.02418493330478668)\n",
      "     | > log_mle: -0.18366789817810059  (-0.18939707279205323)\n",
      "     | > loss_dur: 0.2129359245300293  (0.21358200609683992)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(5.1832, device='cuda:0')  (tensor(5.9981, device='cuda:0'))\n",
      "     | > current_lr: 3.7499999999999997e-06 \n",
      "     | > step_time: 0.3136  (0.43582744598388673)\n",
      "     | > loader_time: 0.0023  (0.003456592559814453)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:16:03 -- STEP: 30/406 -- GLOBAL_STEP: 28850\u001b[0m\n",
      "     | > loss: 0.03440546989440918  (0.023495047291119894)\n",
      "     | > log_mle: -0.190740704536438  (-0.19188044865926107)\n",
      "     | > loss_dur: 0.22514617443084717  (0.21537549595038097)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(5.9726, device='cuda:0')  (tensor(9.0246, device='cuda:0'))\n",
      "     | > current_lr: 3.7499999999999997e-06 \n",
      "     | > step_time: 0.6932  (0.4682245413462321)\n",
      "     | > loader_time: 0.0059  (0.005765636761983235)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:16:16 -- STEP: 55/406 -- GLOBAL_STEP: 28875\u001b[0m\n",
      "     | > loss: 0.019759848713874817  (0.02764341587370092)\n",
      "     | > log_mle: -0.20773494243621826  (-0.1927690787748857)\n",
      "     | > loss_dur: 0.22749479115009308  (0.22041249464858662)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(7.9264, device='cuda:0')  (tensor(8.5858, device='cuda:0'))\n",
      "     | > current_lr: 3.7499999999999997e-06 \n",
      "     | > step_time: 0.8027  (0.5017504778775301)\n",
      "     | > loader_time: 0.0042  (0.0071124076843261715)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:16:31 -- STEP: 80/406 -- GLOBAL_STEP: 28900\u001b[0m\n",
      "     | > loss: 0.03681531548500061  (0.028147976472973818)\n",
      "     | > log_mle: -0.19743311405181885  (-0.19502010047435758)\n",
      "     | > loss_dur: 0.23424842953681946  (0.22316807694733143)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(13.5491, device='cuda:0')  (tensor(8.3613, device='cuda:0'))\n",
      "     | > current_lr: 3.7499999999999997e-06 \n",
      "     | > step_time: 0.5564  (0.5194950073957442)\n",
      "     | > loader_time: 0.0178  (0.008558809757232666)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:16:47 -- STEP: 105/406 -- GLOBAL_STEP: 28925\u001b[0m\n",
      "     | > loss: 0.00716930627822876  (0.02756314547288985)\n",
      "     | > log_mle: -0.2036120891571045  (-0.19786129906063987)\n",
      "     | > loss_dur: 0.21078139543533325  (0.22542444453352972)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(7.2883, device='cuda:0')  (tensor(8.7987, device='cuda:0'))\n",
      "     | > current_lr: 3.7499999999999997e-06 \n",
      "     | > step_time: 0.8493  (0.5487219356355213)\n",
      "     | > loader_time: 0.0109  (0.009050285248529348)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:17:04 -- STEP: 130/406 -- GLOBAL_STEP: 28950\u001b[0m\n",
      "     | > loss: 0.033405452966690063  (0.027365784920178923)\n",
      "     | > log_mle: -0.1996697187423706  (-0.2002461763528677)\n",
      "     | > loss_dur: 0.23307517170906067  (0.22761196127304664)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(11.0917, device='cuda:0')  (tensor(9.0898, device='cuda:0'))\n",
      "     | > current_lr: 3.7499999999999997e-06 \n",
      "     | > step_time: 1.1054  (0.5680999682499811)\n",
      "     | > loader_time: 0.005  (0.009697941633371211)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:17:21 -- STEP: 155/406 -- GLOBAL_STEP: 28975\u001b[0m\n",
      "     | > loss: 0.023315712809562683  (0.027900849907628946)\n",
      "     | > log_mle: -0.20808351039886475  (-0.20199475980574083)\n",
      "     | > loss_dur: 0.23139922320842743  (0.2298956097133698)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(5.0976, device='cuda:0')  (tensor(9.4921, device='cuda:0'))\n",
      "     | > current_lr: 3.7499999999999997e-06 \n",
      "     | > step_time: 0.5263  (0.581193204079905)\n",
      "     | > loader_time: 0.0057  (0.009763266963343469)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:17:41 -- STEP: 180/406 -- GLOBAL_STEP: 29000\u001b[0m\n",
      "     | > loss: 0.02286602556705475  (0.027633076575067302)\n",
      "     | > log_mle: -0.2129908800125122  (-0.2034830954339769)\n",
      "     | > loss_dur: 0.23585690557956696  (0.23111617200904422)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(4.7582, device='cuda:0')  (tensor(9.5958, device='cuda:0'))\n",
      "     | > current_lr: 3.7499999999999997e-06 \n",
      "     | > step_time: 0.8005  (0.6092660718493995)\n",
      "     | > loader_time: 0.02  (0.010553455352783205)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:17:59 -- STEP: 205/406 -- GLOBAL_STEP: 29025\u001b[0m\n",
      "     | > loss: 0.03350639343261719  (0.027802567293004288)\n",
      "     | > log_mle: -0.220863938331604  (-0.20483066454166318)\n",
      "     | > loss_dur: 0.2543703317642212  (0.2326332318346675)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(3.4155, device='cuda:0')  (tensor(9.7280, device='cuda:0'))\n",
      "     | > current_lr: 3.7499999999999997e-06 \n",
      "     | > step_time: 0.8656  (0.6244074239963441)\n",
      "     | > loader_time: 0.0453  (0.011071887830408607)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:18:18 -- STEP: 230/406 -- GLOBAL_STEP: 29050\u001b[0m\n",
      "     | > loss: 0.033674195408821106  (0.02741202705580255)\n",
      "     | > log_mle: -0.21308481693267822  (-0.20619138634723166)\n",
      "     | > loss_dur: 0.24675901234149933  (0.2336034134030342)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(16.3185, device='cuda:0')  (tensor(10.1774, device='cuda:0'))\n",
      "     | > current_lr: 3.7499999999999997e-06 \n",
      "     | > step_time: 0.7304  (0.6354484371517019)\n",
      "     | > loader_time: 0.0139  (0.011333871924358866)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:18:36 -- STEP: 255/406 -- GLOBAL_STEP: 29075\u001b[0m\n",
      "     | > loss: 0.01931406557559967  (0.02733941183370702)\n",
      "     | > log_mle: -0.2130500078201294  (-0.2074477471557318)\n",
      "     | > loss_dur: 0.23236407339572906  (0.23478715898943883)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(20.2140, device='cuda:0')  (tensor(10.9204, device='cuda:0'))\n",
      "     | > current_lr: 3.7499999999999997e-06 \n",
      "     | > step_time: 0.6797  (0.643400183845969)\n",
      "     | > loader_time: 0.0233  (0.011750483980365828)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:18:56 -- STEP: 280/406 -- GLOBAL_STEP: 29100\u001b[0m\n",
      "     | > loss: 0.01601298153400421  (0.026926108290042192)\n",
      "     | > log_mle: -0.2263782024383545  (-0.20844868464129315)\n",
      "     | > loss_dur: 0.2423911839723587  (0.2353747929313353)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(17.8402, device='cuda:0')  (tensor(11.8364, device='cuda:0'))\n",
      "     | > current_lr: 3.7499999999999997e-06 \n",
      "     | > step_time: 1.481  (0.6536611267498563)\n",
      "     | > loader_time: 0.0074  (0.011857944726943969)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:19:18 -- STEP: 305/406 -- GLOBAL_STEP: 29125\u001b[0m\n",
      "     | > loss: 0.01864542067050934  (0.02653113422823734)\n",
      "     | > log_mle: -0.22201716899871826  (-0.20936297627746078)\n",
      "     | > loss_dur: 0.2406625896692276  (0.23589411050569817)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(21.0783, device='cuda:0')  (tensor(12.6181, device='cuda:0'))\n",
      "     | > current_lr: 3.7499999999999997e-06 \n",
      "     | > step_time: 1.0765  (0.6696986331314339)\n",
      "     | > loader_time: 0.0064  (0.012220192737266667)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:19:39 -- STEP: 330/406 -- GLOBAL_STEP: 29150\u001b[0m\n",
      "     | > loss: 0.04682403802871704  (0.02651796011310635)\n",
      "     | > log_mle: -0.22477424144744873  (-0.21002381606535478)\n",
      "     | > loss_dur: 0.27159827947616577  (0.23654177617846114)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(32.8521, device='cuda:0')  (tensor(13.2291, device='cuda:0'))\n",
      "     | > current_lr: 3.7499999999999997e-06 \n",
      "     | > step_time: 0.9419  (0.6817256631273213)\n",
      "     | > loader_time: 0.0285  (0.012726861057859478)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:20:02 -- STEP: 355/406 -- GLOBAL_STEP: 29175\u001b[0m\n",
      "     | > loss: 0.02102521061897278  (0.02647402089246562)\n",
      "     | > log_mle: -0.22956514358520508  (-0.2108257854488534)\n",
      "     | > loss_dur: 0.25059035420417786  (0.23729980634131903)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(11.9172, device='cuda:0')  (tensor(13.7906, device='cuda:0'))\n",
      "     | > current_lr: 3.7499999999999997e-06 \n",
      "     | > step_time: 1.2944  (0.6979331056836627)\n",
      "     | > loader_time: 0.0188  (0.013125253059494663)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:20:26 -- STEP: 380/406 -- GLOBAL_STEP: 29200\u001b[0m\n",
      "     | > loss: 0.026175975799560547  (0.026247578035844)\n",
      "     | > log_mle: -0.21985626220703125  (-0.21163159451986613)\n",
      "     | > loss_dur: 0.2460322380065918  (0.23787917255571014)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(17.5385, device='cuda:0')  (tensor(14.3545, device='cuda:0'))\n",
      "     | > current_lr: 3.7499999999999997e-06 \n",
      "     | > step_time: 0.9508  (0.714009647620352)\n",
      "     | > loader_time: 0.046  (0.01344073822623805)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:20:43 -- STEP: 405/406 -- GLOBAL_STEP: 29225\u001b[0m\n",
      "     | > loss: 0.02789534628391266  (0.02611976115056026)\n",
      "     | > log_mle: -0.22025132179260254  (-0.21236377910331444)\n",
      "     | > loss_dur: 0.2481466680765152  (0.2384835402538747)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(32.1990, device='cuda:0')  (tensor(14.8899, device='cuda:0'))\n",
      "     | > current_lr: 3.7499999999999997e-06 \n",
      "     | > step_time: 0.2719  (0.7109198105188066)\n",
      "     | > loader_time: 0.0051  (0.01317267182432575)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: 0.030100062489509583  (0.030100062489509583)\n",
      "     | > log_mle: -0.19548535346984863  (-0.19548535346984863)\n",
      "     | > loss_dur: 0.22558541595935822  (0.22558541595935822)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: -0.039857253432273865  (-0.039857253432273865)\n",
      "     | > log_mle: -0.2340148687362671  (-0.2340148687362671)\n",
      "     | > loss_dur: 0.19415761530399323  (0.19415761530399323)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: -0.0042837560176849365  (-0.0220705047249794)\n",
      "     | > log_mle: -0.19214797019958496  (-0.21308141946792603)\n",
      "     | > loss_dur: 0.18786421418190002  (0.19101091474294662)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: 0.0023327767848968506  (-0.01393607755502065)\n",
      "     | > log_mle: -0.20756566524505615  (-0.2112428347269694)\n",
      "     | > loss_dur: 0.209898442029953  (0.19730675717194876)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: -0.004793897271156311  (-0.011650532484054565)\n",
      "     | > log_mle: -0.235198974609375  (-0.2172318696975708)\n",
      "     | > loss_dur: 0.2304050773382187  (0.20558133721351624)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: -0.0064313411712646484  (-0.010606694221496581)\n",
      "     | > log_mle: -0.23207557201385498  (-0.22020061016082765)\n",
      "     | > loss_dur: 0.22564423084259033  (0.20959391593933105)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: 0.0105532705783844  (-0.0070800334215164185)\n",
      "     | > log_mle: -0.24562180042266846  (-0.22443747520446777)\n",
      "     | > loss_dur: 0.25617507100105286  (0.21735744178295135)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: -0.000813603401184082  (-0.0061848291328975135)\n",
      "     | > log_mle: -0.20876944065093994  (-0.22219918455396379)\n",
      "     | > loss_dur: 0.20795583724975586  (0.21601435542106628)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: -0.006430283188819885  (-0.00621551088988781)\n",
      "     | > log_mle: -0.2167515754699707  (-0.22151823341846466)\n",
      "     | > loss_dur: 0.21032129228115082  (0.21530272252857685)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: 0.018279507756233215  (-0.003493842151429918)\n",
      "     | > log_mle: -0.2289423942565918  (-0.22234314017825657)\n",
      "     | > loss_dur: 0.247221902012825  (0.21884929802682665)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: 0.023549318313598633  (-0.0007895261049270629)\n",
      "     | > log_mle: -0.21529841423034668  (-0.22163866758346557)\n",
      "     | > loss_dur: 0.2388477325439453  (0.2208491414785385)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: 0.004967644810676575  (-0.0002661469307812777)\n",
      "     | > log_mle: -0.23168349266052246  (-0.22255183349956165)\n",
      "     | > loss_dur: 0.23665113747119904  (0.22228568656878037)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: -0.017111286520957947  (-0.0016699085632960002)\n",
      "     | > log_mle: -0.21895158290863037  (-0.22225181261698404)\n",
      "     | > loss_dur: 0.20184029638767242  (0.22058190405368805)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: -0.04398123919963837  (-0.0049246263045531055)\n",
      "     | > log_mle: -0.23832237720489502  (-0.2234880098929772)\n",
      "     | > loss_dur: 0.19434113800525665  (0.2185633835884241)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: 0.0030668824911117554  (-0.004353804247719901)\n",
      "     | > log_mle: -0.23206400871276855  (-0.22410058123724802)\n",
      "     | > loss_dur: 0.2351308912038803  (0.2197467769895281)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: -0.006548553705215454  (-0.0045001208782196045)\n",
      "     | > log_mle: -0.22531116008758545  (-0.22418128649393718)\n",
      "     | > loss_dur: 0.21876260638237  (0.21968116561571757)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: 0.014956384897232056  (-0.0032840892672538757)\n",
      "     | > log_mle: -0.22244036197662354  (-0.22407247871160507)\n",
      "     | > loss_dur: 0.2373967468738556  (0.2207883894443512)\n",
      "\n",
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.00305330753326416 \u001b[0m(-0.0005867630243301392)\n",
      "     | > avg_loss:\u001b[92m -0.0032840892672538757 \u001b[0m(-0.002003561705350876)\n",
      "     | > avg_log_mle:\u001b[92m -0.22407247871160507 \u001b[0m(-0.0010598227381706238)\n",
      "     | > avg_loss_dur:\u001b[92m 0.2207883894443512 \u001b[0m(-0.0009437389671802521)\n",
      "\n",
      " > BEST MODEL : train/run-February-22-2025_10+59PM-fa84af3/best_model_29226.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 16/100\u001b[0m\n",
      " --> train/run-February-22-2025_10+59PM-fa84af3\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-23 00:21:01) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:21:16 -- STEP: 24/406 -- GLOBAL_STEP: 29250\u001b[0m\n",
      "     | > loss: 0.021318137645721436  (0.016422429432471592)\n",
      "     | > log_mle: -0.1934274435043335  (-0.19240817924340567)\n",
      "     | > loss_dur: 0.21474558115005493  (0.20883060867587724)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(7.1691, device='cuda:0')  (tensor(10.0167, device='cuda:0'))\n",
      "     | > current_lr: 4e-06 \n",
      "     | > step_time: 0.4179  (0.511147956053416)\n",
      "     | > loader_time: 0.004  (0.009865979353586832)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:21:31 -- STEP: 49/406 -- GLOBAL_STEP: 29275\u001b[0m\n",
      "     | > loss: 0.02434183657169342  (0.022857355219977237)\n",
      "     | > log_mle: -0.19393622875213623  (-0.19254750621562106)\n",
      "     | > loss_dur: 0.21827806532382965  (0.21540486143559825)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(4.3227, device='cuda:0')  (tensor(8.8259, device='cuda:0'))\n",
      "     | > current_lr: 4e-06 \n",
      "     | > step_time: 0.6531  (0.5549593507027141)\n",
      "     | > loader_time: 0.005  (0.009500197001865935)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:21:48 -- STEP: 74/406 -- GLOBAL_STEP: 29300\u001b[0m\n",
      "     | > loss: 0.015006139874458313  (0.023792751737543055)\n",
      "     | > log_mle: -0.2245030403137207  (-0.19575095337790413)\n",
      "     | > loss_dur: 0.23950918018817902  (0.21954370511544719)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(14.2923, device='cuda:0')  (tensor(8.2523, device='cuda:0'))\n",
      "     | > current_lr: 4e-06 \n",
      "     | > step_time: 0.6378  (0.5878684842908707)\n",
      "     | > loader_time: 0.0048  (0.010212907920012605)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:22:05 -- STEP: 99/406 -- GLOBAL_STEP: 29325\u001b[0m\n",
      "     | > loss: 0.04197773337364197  (0.024407414173839067)\n",
      "     | > log_mle: -0.20003783702850342  (-0.19831465229843603)\n",
      "     | > loss_dur: 0.24201557040214539  (0.22272206647227508)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(13.9938, device='cuda:0')  (tensor(9.9752, device='cuda:0'))\n",
      "     | > current_lr: 4e-06 \n",
      "     | > step_time: 0.8799  (0.6126443906263871)\n",
      "     | > loader_time: 0.0094  (0.010247632710620612)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:22:24 -- STEP: 124/406 -- GLOBAL_STEP: 29350\u001b[0m\n",
      "     | > loss: 0.021600931882858276  (0.02413659194304097)\n",
      "     | > log_mle: -0.21392035484313965  (-0.20089327904485887)\n",
      "     | > loss_dur: 0.23552128672599792  (0.22502987098789984)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(6.8236, device='cuda:0')  (tensor(10.2796, device='cuda:0'))\n",
      "     | > current_lr: 4e-06 \n",
      "     | > step_time: 0.7843  (0.6402474276481136)\n",
      "     | > loader_time: 0.0201  (0.010872758203937164)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:22:42 -- STEP: 149/406 -- GLOBAL_STEP: 29375\u001b[0m\n",
      "     | > loss: 0.01151573657989502  (0.024274674938029095)\n",
      "     | > log_mle: -0.21945512294769287  (-0.20299974143905128)\n",
      "     | > loss_dur: 0.2309708595275879  (0.22727441637708037)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(13.9930, device='cuda:0')  (tensor(10.2762, device='cuda:0'))\n",
      "     | > current_lr: 4e-06 \n",
      "     | > step_time: 0.5832  (0.6464612836005704)\n",
      "     | > loader_time: 0.0066  (0.010640990814106579)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:22:59 -- STEP: 174/406 -- GLOBAL_STEP: 29400\u001b[0m\n",
      "     | > loss: 0.00720803439617157  (0.02445914133869369)\n",
      "     | > log_mle: -0.21238481998443604  (-0.2043466691313119)\n",
      "     | > loss_dur: 0.2195928543806076  (0.22880581047000556)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(20.0986, device='cuda:0')  (tensor(12.0473, device='cuda:0'))\n",
      "     | > current_lr: 4e-06 \n",
      "     | > step_time: 0.5573  (0.651914589706509)\n",
      "     | > loader_time: 0.0235  (0.010772076146355994)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:23:20 -- STEP: 199/406 -- GLOBAL_STEP: 29425\u001b[0m\n",
      "     | > loss: 0.016694262623786926  (0.02438246267824317)\n",
      "     | > log_mle: -0.21367299556732178  (-0.20581992307500024)\n",
      "     | > loss_dur: 0.2303672581911087  (0.23020238575324342)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(23.3025, device='cuda:0')  (tensor(13.3466, device='cuda:0'))\n",
      "     | > current_lr: 4e-06 \n",
      "     | > step_time: 0.6  (0.66921294035025)\n",
      "     | > loader_time: 0.0072  (0.011465330219748037)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:23:42 -- STEP: 224/406 -- GLOBAL_STEP: 29450\u001b[0m\n",
      "     | > loss: 0.02428339421749115  (0.02451908255794219)\n",
      "     | > log_mle: -0.2101074457168579  (-0.20710471591779164)\n",
      "     | > loss_dur: 0.23439083993434906  (0.23162379847573383)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(7.1615, device='cuda:0')  (tensor(14.3823, device='cuda:0'))\n",
      "     | > current_lr: 4e-06 \n",
      "     | > step_time: 0.6662  (0.6903555457081116)\n",
      "     | > loader_time: 0.0069  (0.012154121484075278)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:24:00 -- STEP: 249/406 -- GLOBAL_STEP: 29475\u001b[0m\n",
      "     | > loss: 0.039847224950790405  (0.02459325022008046)\n",
      "     | > log_mle: -0.2114260196685791  (-0.2082882971169958)\n",
      "     | > loss_dur: 0.2512732446193695  (0.23288154733707628)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(34.5672, device='cuda:0')  (tensor(15.1164, device='cuda:0'))\n",
      "     | > current_lr: 4e-06 \n",
      "     | > step_time: 0.7637  (0.6939993153614215)\n",
      "     | > loader_time: 0.0054  (0.012179697373784694)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:24:19 -- STEP: 274/406 -- GLOBAL_STEP: 29500\u001b[0m\n",
      "     | > loss: 0.02530752122402191  (0.024189489818837524)\n",
      "     | > log_mle: -0.22117722034454346  (-0.2093990036170848)\n",
      "     | > loss_dur: 0.24648474156856537  (0.23358849343592233)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(36.1646, device='cuda:0')  (tensor(16.5288, device='cuda:0'))\n",
      "     | > current_lr: 4e-06 \n",
      "     | > step_time: 0.6445  (0.6961129051055354)\n",
      "     | > loader_time: 0.006  (0.012206714518748933)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:24:40 -- STEP: 299/406 -- GLOBAL_STEP: 29525\u001b[0m\n",
      "     | > loss: 0.0073685795068740845  (0.024184202569782935)\n",
      "     | > log_mle: -0.23747408390045166  (-0.21019058402964105)\n",
      "     | > loss_dur: 0.24484266340732574  (0.23437478659942398)\n",
      "     | > amp_scaler: 8192.0  (8274.193979933107)\n",
      "     | > grad_norm: tensor(36.9213, device='cuda:0')  (tensor(16.9736, device='cuda:0'))\n",
      "     | > current_lr: 4e-06 \n",
      "     | > step_time: 0.9712  (0.7084788494684225)\n",
      "     | > loader_time: 0.0076  (0.012528103729554244)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:25:01 -- STEP: 324/406 -- GLOBAL_STEP: 29550\u001b[0m\n",
      "     | > loss: 0.023543357849121094  (0.024203558578903297)\n",
      "     | > log_mle: -0.22241878509521484  (-0.21093014655289827)\n",
      "     | > loss_dur: 0.24596214294433594  (0.23513370513180157)\n",
      "     | > amp_scaler: 8192.0  (8267.851851851847)\n",
      "     | > grad_norm: tensor(32.7697, device='cuda:0')  (tensor(17.6881, device='cuda:0'))\n",
      "     | > current_lr: 4e-06 \n",
      "     | > step_time: 0.8781  (0.7170036744188379)\n",
      "     | > loader_time: 0.0391  (0.013024689974608246)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:25:23 -- STEP: 349/406 -- GLOBAL_STEP: 29575\u001b[0m\n",
      "     | > loss: 0.03914794325828552  (0.02444843038446925)\n",
      "     | > log_mle: -0.21432733535766602  (-0.211628362920701)\n",
      "     | > loss_dur: 0.25347527861595154  (0.23607679330517023)\n",
      "     | > amp_scaler: 8192.0  (8262.418338108877)\n",
      "     | > grad_norm: tensor(12.7084, device='cuda:0')  (tensor(18.1449, device='cuda:0'))\n",
      "     | > current_lr: 4e-06 \n",
      "     | > step_time: 0.799  (0.7254698030586573)\n",
      "     | > loader_time: 0.0296  (0.013567667635942257)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:25:46 -- STEP: 374/406 -- GLOBAL_STEP: 29600\u001b[0m\n",
      "     | > loss: 0.02295975387096405  (0.02423404722927727)\n",
      "     | > log_mle: -0.2200695276260376  (-0.21247468052063395)\n",
      "     | > loss_dur: 0.24302928149700165  (0.23670872774991122)\n",
      "     | > amp_scaler: 8192.0  (8257.71122994652)\n",
      "     | > grad_norm: tensor(13.3718, device='cuda:0')  (tensor(17.7720, device='cuda:0'))\n",
      "     | > current_lr: 4e-06 \n",
      "     | > step_time: 0.8151  (0.7358099222183231)\n",
      "     | > loader_time: 0.0077  (0.014143741067080575)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:26:06 -- STEP: 399/406 -- GLOBAL_STEP: 29625\u001b[0m\n",
      "     | > loss: 0.02883094549179077  (0.024242256742372258)\n",
      "     | > log_mle: -0.22454822063446045  (-0.21323031500766151)\n",
      "     | > loss_dur: 0.2533791661262512  (0.23747257175003378)\n",
      "     | > amp_scaler: 8192.0  (8253.5939849624)\n",
      "     | > grad_norm: tensor(11.9660, device='cuda:0')  (tensor(17.5030, device='cuda:0'))\n",
      "     | > current_lr: 4e-06 \n",
      "     | > step_time: 0.6325  (0.7394554154914725)\n",
      "     | > loader_time: 0.011  (0.014257038446297323)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: 0.03547869622707367  (0.03547869622707367)\n",
      "     | > log_mle: -0.19632601737976074  (-0.19632601737976074)\n",
      "     | > loss_dur: 0.2318047136068344  (0.2318047136068344)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: -0.04874175786972046  (-0.04874175786972046)\n",
      "     | > log_mle: -0.23404550552368164  (-0.23404550552368164)\n",
      "     | > loss_dur: 0.18530374765396118  (0.18530374765396118)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: -0.006445944309234619  (-0.02759385108947754)\n",
      "     | > log_mle: -0.1931091547012329  (-0.21357733011245728)\n",
      "     | > loss_dur: 0.1866632103919983  (0.18598347902297974)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: -0.0003317892551422119  (-0.018506497144699097)\n",
      "     | > log_mle: -0.20770537853240967  (-0.21162001291910806)\n",
      "     | > loss_dur: 0.20737358927726746  (0.19311351577440897)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: -0.011793717741966248  (-0.016828302294015884)\n",
      "     | > log_mle: -0.23463690280914307  (-0.21737423539161682)\n",
      "     | > loss_dur: 0.22284318506717682  (0.20054593309760094)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: -0.0021005570888519287  (-0.013882753252983094)\n",
      "     | > log_mle: -0.23124992847442627  (-0.22014937400817872)\n",
      "     | > loss_dur: 0.22914937138557434  (0.2062666207551956)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: 0.010130584239959717  (-0.009880530337492624)\n",
      "     | > log_mle: -0.243857741355896  (-0.2241007685661316)\n",
      "     | > loss_dur: 0.2539883255958557  (0.21422023822863898)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: -0.002574428915977478  (-0.008836801562990462)\n",
      "     | > log_mle: -0.20891380310058594  (-0.22193120207105363)\n",
      "     | > loss_dur: 0.20633937418460846  (0.2130944005080632)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: 0.001889839768409729  (-0.007495971396565437)\n",
      "     | > log_mle: -0.21689915657043457  (-0.22130219638347626)\n",
      "     | > loss_dur: 0.2187889963388443  (0.21380622498691082)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: 0.015125498175621033  (-0.004982474777433608)\n",
      "     | > log_mle: -0.22812581062316895  (-0.22206037574344212)\n",
      "     | > loss_dur: 0.24325130879878998  (0.2170779009660085)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: 0.018651217222213745  (-0.0026191055774688722)\n",
      "     | > log_mle: -0.21542108058929443  (-0.22139644622802734)\n",
      "     | > loss_dur: 0.23407229781150818  (0.21877734065055848)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: 0.008653402328491211  (-0.0015943321314725008)\n",
      "     | > log_mle: -0.2312941551208496  (-0.22229623794555664)\n",
      "     | > loss_dur: 0.23994755744934082  (0.22070190581408414)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: -0.02338188886642456  (-0.0034099618593851724)\n",
      "     | > log_mle: -0.21910977363586426  (-0.22203069925308228)\n",
      "     | > loss_dur: 0.1957278847694397  (0.2186207373936971)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: -0.04525722563266754  (-0.006628982149637663)\n",
      "     | > log_mle: -0.23835480213165283  (-0.2232863994745108)\n",
      "     | > loss_dur: 0.1930975764989853  (0.21665741732487312)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: 0.004507720470428467  (-0.005833503391061511)\n",
      "     | > log_mle: -0.23146271705627441  (-0.22387042215892247)\n",
      "     | > loss_dur: 0.23597043752670288  (0.21803691876786097)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: -0.0054479241371154785  (-0.005807798107465108)\n",
      "     | > log_mle: -0.2249521017074585  (-0.22394253412882487)\n",
      "     | > loss_dur: 0.21950417757034302  (0.21813473602135977)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: 0.013425946235656738  (-0.004605689086019993)\n",
      "     | > log_mle: -0.2219916582107544  (-0.22382060438394547)\n",
      "     | > loss_dur: 0.23541760444641113  (0.21921491529792547)\n",
      "\n",
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[91m 0.0036182552576065063 \u001b[0m(+0.0005649477243423462)\n",
      "     | > avg_loss:\u001b[92m -0.004605689086019993 \u001b[0m(-0.001321599818766117)\n",
      "     | > avg_log_mle:\u001b[91m -0.22382060438394547 \u001b[0m(+0.00025187432765960693)\n",
      "     | > avg_loss_dur:\u001b[92m 0.21921491529792547 \u001b[0m(-0.001573474146425724)\n",
      "\n",
      " > BEST MODEL : train/run-February-22-2025_10+59PM-fa84af3/best_model_29632.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 17/100\u001b[0m\n",
      " --> train/run-February-22-2025_10+59PM-fa84af3\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-23 00:26:27) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:26:40 -- STEP: 18/406 -- GLOBAL_STEP: 29650\u001b[0m\n",
      "     | > loss: 0.01894696056842804  (0.014070185522238413)\n",
      "     | > log_mle: -0.1885772943496704  (-0.19563723935021293)\n",
      "     | > loss_dur: 0.20752425491809845  (0.20970742487245136)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(5.1295, device='cuda:0')  (tensor(5.8374, device='cuda:0'))\n",
      "     | > current_lr: 4.25e-06 \n",
      "     | > step_time: 0.3567  (0.5136038727230496)\n",
      "     | > loader_time: 0.0032  (0.0074420107735527884)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:26:56 -- STEP: 43/406 -- GLOBAL_STEP: 29675\u001b[0m\n",
      "     | > loss: 0.01493951678276062  (0.01991796424222547)\n",
      "     | > log_mle: -0.1854485273361206  (-0.19353864082070285)\n",
      "     | > loss_dur: 0.20038804411888123  (0.21345660506292832)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(8.2805, device='cuda:0')  (tensor(5.7983, device='cuda:0'))\n",
      "     | > current_lr: 4.25e-06 \n",
      "     | > step_time: 0.5663  (0.590725255566974)\n",
      "     | > loader_time: 0.0157  (0.00915083219838697)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:27:14 -- STEP: 68/406 -- GLOBAL_STEP: 29700\u001b[0m\n",
      "     | > loss: 0.03036801517009735  (0.021847599569488976)\n",
      "     | > log_mle: -0.2053380012512207  (-0.1962923039408291)\n",
      "     | > loss_dur: 0.23570601642131805  (0.2181399035103181)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(14.0544, device='cuda:0')  (tensor(7.8003, device='cuda:0'))\n",
      "     | > current_lr: 4.25e-06 \n",
      "     | > step_time: 0.9672  (0.6362469932612251)\n",
      "     | > loader_time: 0.0065  (0.01031575132818783)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:27:32 -- STEP: 93/406 -- GLOBAL_STEP: 29725\u001b[0m\n",
      "     | > loss: 0.021639153361320496  (0.02174885699184992)\n",
      "     | > log_mle: -0.22471392154693604  (-0.19955361017616846)\n",
      "     | > loss_dur: 0.24635307490825653  (0.22130246716801838)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(7.7816, device='cuda:0')  (tensor(8.9633, device='cuda:0'))\n",
      "     | > current_lr: 4.25e-06 \n",
      "     | > step_time: 0.7282  (0.6474843204662363)\n",
      "     | > loader_time: 0.0051  (0.010537973014257285)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:27:50 -- STEP: 118/406 -- GLOBAL_STEP: 29750\u001b[0m\n",
      "     | > loss: 0.021408870816230774  (0.02131827125104807)\n",
      "     | > log_mle: -0.2187964916229248  (-0.2020305789123147)\n",
      "     | > loss_dur: 0.24020536243915558  (0.22334885016336278)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(15.7218, device='cuda:0')  (tensor(9.2012, device='cuda:0'))\n",
      "     | > current_lr: 4.25e-06 \n",
      "     | > step_time: 0.9224  (0.6603970709493605)\n",
      "     | > loader_time: 0.0051  (0.010599679866079554)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:28:07 -- STEP: 143/406 -- GLOBAL_STEP: 29775\u001b[0m\n",
      "     | > loss: 0.02741989493370056  (0.021678486799860334)\n",
      "     | > log_mle: -0.2175452709197998  (-0.2042745518517661)\n",
      "     | > loss_dur: 0.24496516585350037  (0.22595303865162641)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(24.0178, device='cuda:0')  (tensor(9.6539, device='cuda:0'))\n",
      "     | > current_lr: 4.25e-06 \n",
      "     | > step_time: 0.3703  (0.6642548887879698)\n",
      "     | > loader_time: 0.0053  (0.011206326784787475)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:28:26 -- STEP: 168/406 -- GLOBAL_STEP: 29800\u001b[0m\n",
      "     | > loss: 0.0268000066280365  (0.022275187873414586)\n",
      "     | > log_mle: -0.20582187175750732  (-0.20553264660494672)\n",
      "     | > loss_dur: 0.23262187838554382  (0.22780783447836125)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(11.7475, device='cuda:0')  (tensor(10.8893, device='cuda:0'))\n",
      "     | > current_lr: 4.25e-06 \n",
      "     | > step_time: 0.7332  (0.6742010670048849)\n",
      "     | > loader_time: 0.0388  (0.01150367231596084)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:28:45 -- STEP: 193/406 -- GLOBAL_STEP: 29825\u001b[0m\n",
      "     | > loss: 0.029281556606292725  (0.022090901750974706)\n",
      "     | > log_mle: -0.21877789497375488  (-0.2070688441627384)\n",
      "     | > loss_dur: 0.2480594515800476  (0.2291597459137131)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(12.2462, device='cuda:0')  (tensor(10.9969, device='cuda:0'))\n",
      "     | > current_lr: 4.25e-06 \n",
      "     | > step_time: 0.9703  (0.6819927025335439)\n",
      "     | > loader_time: 0.031  (0.011803134117719423)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:29:04 -- STEP: 218/406 -- GLOBAL_STEP: 29850\u001b[0m\n",
      "     | > loss: 0.026571571826934814  (0.02202101919902574)\n",
      "     | > log_mle: -0.2173302173614502  (-0.20832345409130834)\n",
      "     | > loss_dur: 0.243901789188385  (0.23034447329033406)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(17.1079, device='cuda:0')  (tensor(11.3698, device='cuda:0'))\n",
      "     | > current_lr: 4.25e-06 \n",
      "     | > step_time: 0.5577  (0.6870671127914287)\n",
      "     | > loader_time: 0.0201  (0.011776948193891332)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:29:26 -- STEP: 243/406 -- GLOBAL_STEP: 29875\u001b[0m\n",
      "     | > loss: 0.024435192346572876  (0.021982175393850223)\n",
      "     | > log_mle: -0.23544049263000488  (-0.209733955163524)\n",
      "     | > loss_dur: 0.25987568497657776  (0.2317161305573742)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(15.6656, device='cuda:0')  (tensor(11.6552, device='cuda:0'))\n",
      "     | > current_lr: 4.25e-06 \n",
      "     | > step_time: 0.9931  (0.7060870398219229)\n",
      "     | > loader_time: 0.0441  (0.012394247722233274)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:29:46 -- STEP: 268/406 -- GLOBAL_STEP: 29900\u001b[0m\n",
      "     | > loss: 0.009577065706253052  (0.021606634079075572)\n",
      "     | > log_mle: -0.23031842708587646  (-0.21074622068832172)\n",
      "     | > loss_dur: 0.23989549279212952  (0.23235285476739728)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(12.4913, device='cuda:0')  (tensor(11.8567, device='cuda:0'))\n",
      "     | > current_lr: 4.25e-06 \n",
      "     | > step_time: 0.7626  (0.7145456120149412)\n",
      "     | > loader_time: 0.0098  (0.012921318189421696)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:30:06 -- STEP: 293/406 -- GLOBAL_STEP: 29925\u001b[0m\n",
      "     | > loss: 0.014351904392242432  (0.021247084637143913)\n",
      "     | > log_mle: -0.2255096435546875  (-0.21168256619684525)\n",
      "     | > loss_dur: 0.23986154794692993  (0.23292965083398917)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(18.3417, device='cuda:0')  (tensor(12.0122, device='cuda:0'))\n",
      "     | > current_lr: 4.25e-06 \n",
      "     | > step_time: 0.8663  (0.7201412399474264)\n",
      "     | > loader_time: 0.0105  (0.013007576555115368)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:30:29 -- STEP: 318/406 -- GLOBAL_STEP: 29950\u001b[0m\n",
      "     | > loss: 0.028126642107963562  (0.02110694822087978)\n",
      "     | > log_mle: -0.2141207456588745  (-0.2125789223227111)\n",
      "     | > loss_dur: 0.24224738776683807  (0.23368587054359088)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(10.7256, device='cuda:0')  (tensor(12.1756, device='cuda:0'))\n",
      "     | > current_lr: 4.25e-06 \n",
      "     | > step_time: 0.6851  (0.7312850179912157)\n",
      "     | > loader_time: 0.0171  (0.013259976914843673)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:30:50 -- STEP: 343/406 -- GLOBAL_STEP: 29975\u001b[0m\n",
      "     | > loss: 0.0252874493598938  (0.02119271574493052)\n",
      "     | > log_mle: -0.2341926097869873  (-0.2133377700088323)\n",
      "     | > loss_dur: 0.2594800591468811  (0.2345304857537628)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(14.2985, device='cuda:0')  (tensor(12.3279, device='cuda:0'))\n",
      "     | > current_lr: 4.25e-06 \n",
      "     | > step_time: 0.7393  (0.7382939848885937)\n",
      "     | > loader_time: 0.0136  (0.013647678642161733)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:31:11 -- STEP: 368/406 -- GLOBAL_STEP: 30000\u001b[0m\n",
      "     | > loss: 0.014323592185974121  (0.021020456905598207)\n",
      "     | > log_mle: -0.22145390510559082  (-0.21414889233267825)\n",
      "     | > loss_dur: 0.23577749729156494  (0.23516934923827648)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(11.7905, device='cuda:0')  (tensor(12.5266, device='cuda:0'))\n",
      "     | > current_lr: 4.25e-06 \n",
      "     | > step_time: 0.6607  (0.744639222388682)\n",
      "     | > loader_time: 0.0174  (0.014026904883592026)\n",
      "\n",
      "\n",
      " > CHECKPOINT : train/run-February-22-2025_10+59PM-fa84af3/checkpoint_30000.pth\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:31:38 -- STEP: 393/406 -- GLOBAL_STEP: 30025\u001b[0m\n",
      "     | > loss: 0.02696436643600464  (0.02096029854457795)\n",
      "     | > log_mle: -0.2305135726928711  (-0.21491066372121564)\n",
      "     | > loss_dur: 0.25747793912887573  (0.2358709622657936)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(20.9452, device='cuda:0')  (tensor(12.7180, device='cuda:0'))\n",
      "     | > current_lr: 4.25e-06 \n",
      "     | > step_time: 0.5526  (0.7485753440371602)\n",
      "     | > loader_time: 0.0063  (0.01425962351054029)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: 0.03429622948169708  (0.03429622948169708)\n",
      "     | > log_mle: -0.19775915145874023  (-0.19775915145874023)\n",
      "     | > loss_dur: 0.23205538094043732  (0.23205538094043732)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: -0.04830199480056763  (-0.04830199480056763)\n",
      "     | > log_mle: -0.23492038249969482  (-0.23492038249969482)\n",
      "     | > loss_dur: 0.1866183876991272  (0.1866183876991272)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: -0.00500623881816864  (-0.026654116809368134)\n",
      "     | > log_mle: -0.19411814212799072  (-0.21451926231384277)\n",
      "     | > loss_dur: 0.18911190330982208  (0.18786514550447464)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: 0.0015041977167129517  (-0.017268011967341106)\n",
      "     | > log_mle: -0.2077195644378662  (-0.21225269635518393)\n",
      "     | > loss_dur: 0.20922376215457916  (0.1949846843878428)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: -0.01059560477733612  (-0.015599910169839859)\n",
      "     | > log_mle: -0.23453938961029053  (-0.21782436966896057)\n",
      "     | > loss_dur: 0.2239437848329544  (0.2022244594991207)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: -0.0061828941106796265  (-0.013716506958007812)\n",
      "     | > log_mle: -0.22827816009521484  (-0.21991512775421143)\n",
      "     | > loss_dur: 0.22209526598453522  (0.2061986207962036)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: 0.010972440242767334  (-0.009601682424545288)\n",
      "     | > log_mle: -0.24123120307922363  (-0.22346780697504678)\n",
      "     | > loss_dur: 0.25220364332199097  (0.2138661245505015)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: -0.0020148009061813354  (-0.008517842207636152)\n",
      "     | > log_mle: -0.20824074745178223  (-0.22129251275743758)\n",
      "     | > loss_dur: 0.2062259465456009  (0.21277467054980143)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: -0.0066967010498046875  (-0.008290199562907219)\n",
      "     | > log_mle: -0.2175450325012207  (-0.22082407772541046)\n",
      "     | > loss_dur: 0.21084833145141602  (0.21253387816250324)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: 0.012677580118179321  (-0.005960446265008714)\n",
      "     | > log_mle: -0.22740578651428223  (-0.22155537870195177)\n",
      "     | > loss_dur: 0.24008336663246155  (0.21559493243694305)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: 0.02233421802520752  (-0.003130979835987091)\n",
      "     | > log_mle: -0.21471548080444336  (-0.22087138891220093)\n",
      "     | > loss_dur: 0.23704969882965088  (0.21774040907621384)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: 0.006028488278388977  (-0.0022983009164983578)\n",
      "     | > log_mle: -0.23070549964904785  (-0.221765398979187)\n",
      "     | > loss_dur: 0.23673398792743683  (0.21946709806268866)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: -0.023090019822120667  (-0.00403094415863355)\n",
      "     | > log_mle: -0.2196507453918457  (-0.22158917784690857)\n",
      "     | > loss_dur: 0.19656072556972504  (0.217558233688275)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: -0.04243174195289612  (-0.0069848516812691325)\n",
      "     | > log_mle: -0.23596203327178955  (-0.22269478211036095)\n",
      "     | > loss_dur: 0.19353029131889343  (0.2157099304290918)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: -0.0016657710075378418  (-0.006604917347431183)\n",
      "     | > log_mle: -0.23130345344543457  (-0.22330968720572336)\n",
      "     | > loss_dur: 0.22963768243789673  (0.21670476985829218)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: -0.008273884654045105  (-0.006716181834538777)\n",
      "     | > log_mle: -0.2250441312789917  (-0.2234253168106079)\n",
      "     | > loss_dur: 0.2167702466249466  (0.21670913497606914)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: 0.015521243214607239  (-0.005326342768967152)\n",
      "     | > log_mle: -0.22090363502502441  (-0.22326771169900894)\n",
      "     | > loss_dur: 0.23642487823963165  (0.2179413689300418)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: audio amplitude out of range, auto clipped.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.0032906383275985718 \u001b[0m(-0.00032761693000793457)\n",
      "     | > avg_loss:\u001b[92m -0.005326342768967152 \u001b[0m(-0.0007206536829471588)\n",
      "     | > avg_log_mle:\u001b[91m -0.22326771169900894 \u001b[0m(+0.0005528926849365234)\n",
      "     | > avg_loss_dur:\u001b[92m 0.2179413689300418 \u001b[0m(-0.0012735463678836823)\n",
      "\n",
      " > BEST MODEL : train/run-February-22-2025_10+59PM-fa84af3/best_model_30038.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 18/100\u001b[0m\n",
      " --> train/run-February-22-2025_10+59PM-fa84af3\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-23 00:32:01) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:32:08 -- STEP: 12/406 -- GLOBAL_STEP: 30050\u001b[0m\n",
      "     | > loss: 0.016749680042266846  (0.009250263373057047)\n",
      "     | > log_mle: -0.20702111721038818  (-0.19670350352923074)\n",
      "     | > loss_dur: 0.22377079725265503  (0.2059537669022878)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(9.5191, device='cuda:0')  (tensor(7.7704, device='cuda:0'))\n",
      "     | > current_lr: 4.5e-06 \n",
      "     | > step_time: 0.2888  (0.3865705728530884)\n",
      "     | > loader_time: 0.0047  (0.004701197147369385)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:32:23 -- STEP: 37/406 -- GLOBAL_STEP: 30075\u001b[0m\n",
      "     | > loss: 0.019084453582763672  (0.01650935532273473)\n",
      "     | > log_mle: -0.19245362281799316  (-0.19600085632221118)\n",
      "     | > loss_dur: 0.21153807640075684  (0.2125102116449459)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(10.0392, device='cuda:0')  (tensor(6.6520, device='cuda:0'))\n",
      "     | > current_lr: 4.5e-06 \n",
      "     | > step_time: 0.8409  (0.5241278506614067)\n",
      "     | > loader_time: 0.0215  (0.009507437010069151)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:32:37 -- STEP: 62/406 -- GLOBAL_STEP: 30100\u001b[0m\n",
      "     | > loss: 0.02638585865497589  (0.020027640846467788)\n",
      "     | > log_mle: -0.19544851779937744  (-0.19752610114312938)\n",
      "     | > loss_dur: 0.22183437645435333  (0.2175537419895972)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(4.1333, device='cuda:0')  (tensor(7.1863, device='cuda:0'))\n",
      "     | > current_lr: 4.5e-06 \n",
      "     | > step_time: 0.4047  (0.5397851890133271)\n",
      "     | > loader_time: 0.0043  (0.009142221943024666)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:32:53 -- STEP: 87/406 -- GLOBAL_STEP: 30125\u001b[0m\n",
      "     | > loss: 0.019863039255142212  (0.019907656072200026)\n",
      "     | > log_mle: -0.22453594207763672  (-0.2004883289337158)\n",
      "     | > loss_dur: 0.24439898133277893  (0.22039598500591584)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(23.5067, device='cuda:0')  (tensor(7.8666, device='cuda:0'))\n",
      "     | > current_lr: 4.5e-06 \n",
      "     | > step_time: 0.724  (0.5576317173311081)\n",
      "     | > loader_time: 0.0192  (0.010067419074047573)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:33:10 -- STEP: 112/406 -- GLOBAL_STEP: 30150\u001b[0m\n",
      "     | > loss: 0.016477778553962708  (0.019409719056316777)\n",
      "     | > log_mle: -0.21653461456298828  (-0.20321001112461087)\n",
      "     | > loss_dur: 0.233012393116951  (0.22261973018092768)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(8.7364, device='cuda:0')  (tensor(8.8809, device='cuda:0'))\n",
      "     | > current_lr: 4.5e-06 \n",
      "     | > step_time: 0.6392  (0.583173102566174)\n",
      "     | > loader_time: 0.0055  (0.010740614363125392)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:33:27 -- STEP: 137/406 -- GLOBAL_STEP: 30175\u001b[0m\n",
      "     | > loss: 0.030661091208457947  (0.019349441584879463)\n",
      "     | > log_mle: -0.2151123285293579  (-0.205476160467106)\n",
      "     | > loss_dur: 0.24577341973781586  (0.2248256020519855)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(19.9964, device='cuda:0')  (tensor(9.4433, device='cuda:0'))\n",
      "     | > current_lr: 4.5e-06 \n",
      "     | > step_time: 0.8817  (0.5963143641061156)\n",
      "     | > loader_time: 0.0192  (0.01054680260428547)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:33:44 -- STEP: 162/406 -- GLOBAL_STEP: 30200\u001b[0m\n",
      "     | > loss: 0.023825332522392273  (0.019984406177644378)\n",
      "     | > log_mle: -0.2174062728881836  (-0.20707117922512097)\n",
      "     | > loss_dur: 0.24123160541057587  (0.22705558540276538)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(11.1159, device='cuda:0')  (tensor(9.9601, device='cuda:0'))\n",
      "     | > current_lr: 4.5e-06 \n",
      "     | > step_time: 0.3902  (0.6101767575299301)\n",
      "     | > loader_time: 0.0056  (0.010624080528447663)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:34:03 -- STEP: 187/406 -- GLOBAL_STEP: 30225\u001b[0m\n",
      "     | > loss: 0.013121694326400757  (0.019647805846948686)\n",
      "     | > log_mle: -0.22095215320587158  (-0.20861206398928225)\n",
      "     | > loss_dur: 0.23407384753227234  (0.22825986983623098)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(20.4898, device='cuda:0')  (tensor(10.5789, device='cuda:0'))\n",
      "     | > current_lr: 4.5e-06 \n",
      "     | > step_time: 0.7722  (0.626055677944326)\n",
      "     | > loader_time: 0.0055  (0.011009625572571785)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:34:24 -- STEP: 212/406 -- GLOBAL_STEP: 30250\u001b[0m\n",
      "     | > loss: 0.023205846548080444  (0.019377242141174828)\n",
      "     | > log_mle: -0.23139429092407227  (-0.2099125059145801)\n",
      "     | > loss_dur: 0.2546001374721527  (0.22928974805575497)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(22.6170, device='cuda:0')  (tensor(10.9888, device='cuda:0'))\n",
      "     | > current_lr: 4.5e-06 \n",
      "     | > step_time: 0.523  (0.6482172968252653)\n",
      "     | > loader_time: 0.0049  (0.011561295896206266)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:34:44 -- STEP: 237/406 -- GLOBAL_STEP: 30275\u001b[0m\n",
      "     | > loss: 0.0246543288230896  (0.019310908415649516)\n",
      "     | > log_mle: -0.23645508289337158  (-0.21131839983573944)\n",
      "     | > loss_dur: 0.2611094117164612  (0.23062930825138897)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(18.2763, device='cuda:0')  (tensor(11.5050, device='cuda:0'))\n",
      "     | > current_lr: 4.5e-06 \n",
      "     | > step_time: 0.852  (0.6633370254613179)\n",
      "     | > loader_time: 0.009  (0.011617481457030223)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:35:03 -- STEP: 262/406 -- GLOBAL_STEP: 30300\u001b[0m\n",
      "     | > loss: 0.023308858275413513  (0.018992812408290753)\n",
      "     | > log_mle: -0.20425724983215332  (-0.21246861865502276)\n",
      "     | > loss_dur: 0.22756610810756683  (0.23146143106331352)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(12.7476, device='cuda:0')  (tensor(11.8772, device='cuda:0'))\n",
      "     | > current_lr: 4.5e-06 \n",
      "     | > step_time: 0.9988  (0.671175359769632)\n",
      "     | > loader_time: 0.0175  (0.01185578244333049)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:35:24 -- STEP: 287/406 -- GLOBAL_STEP: 30325\u001b[0m\n",
      "     | > loss: 0.01973871886730194  (0.018507144228921957)\n",
      "     | > log_mle: -0.2205803394317627  (-0.21350134540517982)\n",
      "     | > loss_dur: 0.24031905829906464  (0.2320084896341018)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(12.8491, device='cuda:0')  (tensor(12.2915, device='cuda:0'))\n",
      "     | > current_lr: 4.5e-06 \n",
      "     | > step_time: 0.9758  (0.6843513296040925)\n",
      "     | > loader_time: 0.0099  (0.011933658181167237)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:35:45 -- STEP: 312/406 -- GLOBAL_STEP: 30350\u001b[0m\n",
      "     | > loss: 0.01026327908039093  (0.01832658921678861)\n",
      "     | > log_mle: -0.22713613510131836  (-0.21433689235112602)\n",
      "     | > loss_dur: 0.2373994141817093  (0.23266348156791467)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(28.7867, device='cuda:0')  (tensor(12.6173, device='cuda:0'))\n",
      "     | > current_lr: 4.5e-06 \n",
      "     | > step_time: 0.7895  (0.6927381020325883)\n",
      "     | > loader_time: 0.021  (0.012437854821865381)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:36:06 -- STEP: 337/406 -- GLOBAL_STEP: 30375\u001b[0m\n",
      "     | > loss: 0.03494420647621155  (0.018412409753757)\n",
      "     | > log_mle: -0.21954035758972168  (-0.21501659710258683)\n",
      "     | > loss_dur: 0.2544845640659332  (0.23342900685634388)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(12.5568, device='cuda:0')  (tensor(13.3596, device='cuda:0'))\n",
      "     | > current_lr: 4.5e-06 \n",
      "     | > step_time: 0.9487  (0.7026711069157996)\n",
      "     | > loader_time: 0.0269  (0.012284538512413871)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:36:28 -- STEP: 362/406 -- GLOBAL_STEP: 30400\u001b[0m\n",
      "     | > loss: 0.000615537166595459  (0.018377662240141677)\n",
      "     | > log_mle: -0.23472380638122559  (-0.21586054464730106)\n",
      "     | > loss_dur: 0.23533934354782104  (0.23423820688744276)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(19.0056, device='cuda:0')  (tensor(13.4494, device='cuda:0'))\n",
      "     | > current_lr: 4.5e-06 \n",
      "     | > step_time: 1.0336  (0.7141076339542543)\n",
      "     | > loader_time: 0.0106  (0.012497461303162977)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:36:50 -- STEP: 387/406 -- GLOBAL_STEP: 30425\u001b[0m\n",
      "     | > loss: 0.014703407883644104  (0.01826354010314598)\n",
      "     | > log_mle: -0.2290208339691162  (-0.21657407129765785)\n",
      "     | > loss_dur: 0.24372424185276031  (0.23483761140080386)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(18.6358, device='cuda:0')  (tensor(13.3380, device='cuda:0'))\n",
      "     | > current_lr: 4.5e-06 \n",
      "     | > step_time: 0.7351  (0.7220940540619296)\n",
      "     | > loader_time: 0.0076  (0.012713809346043794)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: 0.03198496997356415  (0.03198496997356415)\n",
      "     | > log_mle: -0.19954609870910645  (-0.19954609870910645)\n",
      "     | > loss_dur: 0.2315310686826706  (0.2315310686826706)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: -0.05078369379043579  (-0.05078369379043579)\n",
      "     | > log_mle: -0.23659610748291016  (-0.23659610748291016)\n",
      "     | > loss_dur: 0.18581241369247437  (0.18581241369247437)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: -0.011256292462348938  (-0.031019993126392365)\n",
      "     | > log_mle: -0.1958754062652588  (-0.21623575687408447)\n",
      "     | > loss_dur: 0.18461911380290985  (0.1852157637476921)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: 0.0002693086862564087  (-0.02059022585550944)\n",
      "     | > log_mle: -0.20912444591522217  (-0.21386531988779703)\n",
      "     | > loss_dur: 0.20939375460147858  (0.1932750940322876)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: -0.012578889727592468  (-0.018587391823530197)\n",
      "     | > log_mle: -0.23600637912750244  (-0.2194005846977234)\n",
      "     | > loss_dur: 0.22342748939990997  (0.2008131928741932)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: -0.010186702013015747  (-0.01690725386142731)\n",
      "     | > log_mle: -0.2287691831588745  (-0.2212743043899536)\n",
      "     | > loss_dur: 0.21858248114585876  (0.2043670505285263)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: 0.011344850063323975  (-0.01219856987396876)\n",
      "     | > log_mle: -0.24228692054748535  (-0.22477640708287558)\n",
      "     | > loss_dur: 0.2536317706108093  (0.2125778372089068)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: -0.006017521023750305  (-0.011315562895366124)\n",
      "     | > log_mle: -0.20961296558380127  (-0.2226102011544364)\n",
      "     | > loss_dur: 0.20359544456005096  (0.21129463825907027)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: -0.008722156286239624  (-0.010991387069225311)\n",
      "     | > log_mle: -0.21896147727966309  (-0.22215411067008972)\n",
      "     | > loss_dur: 0.21023932099342346  (0.2111627236008644)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: 0.012779995799064636  (-0.008350122306081984)\n",
      "     | > log_mle: -0.22866523265838623  (-0.22287756866878933)\n",
      "     | > loss_dur: 0.24144522845745087  (0.21452744636270735)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: 0.01787295937538147  (-0.005727814137935638)\n",
      "     | > log_mle: -0.21626007556915283  (-0.22221581935882567)\n",
      "     | > loss_dur: 0.2341330349445343  (0.21648800522089004)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: 0.001706629991531372  (-0.005051955580711365)\n",
      "     | > log_mle: -0.23183786869049072  (-0.22309055111624979)\n",
      "     | > loss_dur: 0.2335444986820221  (0.21803859553553842)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: -0.02782990038394928  (-0.006950117647647858)\n",
      "     | > log_mle: -0.22118604183197021  (-0.22293184200922647)\n",
      "     | > loss_dur: 0.19335614144802094  (0.21598172436157861)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: -0.04294835031032562  (-0.00971921246785384)\n",
      "     | > log_mle: -0.23653924465179443  (-0.223978565289424)\n",
      "     | > loss_dur: 0.1935908943414688  (0.2142593528215702)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: -0.003225862979888916  (-0.00925540179014206)\n",
      "     | > log_mle: -0.23271715641021729  (-0.22460275036948069)\n",
      "     | > loss_dur: 0.22949129343032837  (0.21534734857933863)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: -0.008974835276603699  (-0.00923669735590617)\n",
      "     | > log_mle: -0.22630977630615234  (-0.22471655209859212)\n",
      "     | > loss_dur: 0.21733494102954865  (0.21547985474268597)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: 0.012810349464416504  (-0.007858756929636002)\n",
      "     | > log_mle: -0.22213172912597656  (-0.22455500066280365)\n",
      "     | > loss_dur: 0.23494207859039307  (0.21669624373316765)\n",
      "\n",
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[91m 0.003939032554626464 \u001b[0m(+0.0006483942270278922)\n",
      "     | > avg_loss:\u001b[92m -0.007858756929636002 \u001b[0m(-0.00253241416066885)\n",
      "     | > avg_log_mle:\u001b[92m -0.22455500066280365 \u001b[0m(-0.0012872889637947083)\n",
      "     | > avg_loss_dur:\u001b[92m 0.21669624373316765 \u001b[0m(-0.0012451251968741417)\n",
      "\n",
      " > BEST MODEL : train/run-February-22-2025_10+59PM-fa84af3/best_model_30444.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 19/100\u001b[0m\n",
      " --> train/run-February-22-2025_10+59PM-fa84af3\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-23 00:37:18) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:37:22 -- STEP: 6/406 -- GLOBAL_STEP: 30450\u001b[0m\n",
      "     | > loss: -0.019664660096168518  (0.005703332523504893)\n",
      "     | > log_mle: -0.19797587394714355  (-0.19613617658615112)\n",
      "     | > loss_dur: 0.17831121385097504  (0.201839509109656)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(5.6817, device='cuda:0')  (tensor(5.3762, device='cuda:0'))\n",
      "     | > current_lr: 4.749999999999999e-06 \n",
      "     | > step_time: 0.3112  (0.4482600688934326)\n",
      "     | > loader_time: 0.0038  (0.005292336146036784)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:37:37 -- STEP: 31/406 -- GLOBAL_STEP: 30475\u001b[0m\n",
      "     | > loss: 0.008481338620185852  (0.010765748639260568)\n",
      "     | > log_mle: -0.191552996635437  (-0.19788674769863004)\n",
      "     | > loss_dur: 0.20003433525562286  (0.20865249633789062)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(15.5997, device='cuda:0')  (tensor(13.9171, device='cuda:0'))\n",
      "     | > current_lr: 4.749999999999999e-06 \n",
      "     | > step_time: 0.7633  (0.555310949202507)\n",
      "     | > loader_time: 0.0112  (0.006201036514774445)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:37:53 -- STEP: 56/406 -- GLOBAL_STEP: 30500\u001b[0m\n",
      "     | > loss: 0.015588074922561646  (0.016949191955583434)\n",
      "     | > log_mle: -0.20512259006500244  (-0.19918447307177953)\n",
      "     | > loss_dur: 0.2207106649875641  (0.21613366502736295)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(13.1959, device='cuda:0')  (tensor(12.4316, device='cuda:0'))\n",
      "     | > current_lr: 4.749999999999999e-06 \n",
      "     | > step_time: 0.9614  (0.5875504229749952)\n",
      "     | > loader_time: 0.0045  (0.007193190710885184)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:38:11 -- STEP: 81/406 -- GLOBAL_STEP: 30525\u001b[0m\n",
      "     | > loss: 0.008103027939796448  (0.016996613991113362)\n",
      "     | > log_mle: -0.21379399299621582  (-0.20145920470908837)\n",
      "     | > loss_dur: 0.22189702093601227  (0.21845581870020173)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(6.8060, device='cuda:0')  (tensor(11.7377, device='cuda:0'))\n",
      "     | > current_lr: 4.749999999999999e-06 \n",
      "     | > step_time: 1.3411  (0.622471120622423)\n",
      "     | > loader_time: 0.0111  (0.007465447908566322)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:38:27 -- STEP: 106/406 -- GLOBAL_STEP: 30550\u001b[0m\n",
      "     | > loss: 0.02176991105079651  (0.01658043799535284)\n",
      "     | > log_mle: -0.20311272144317627  (-0.2041737898340765)\n",
      "     | > loss_dur: 0.22488263249397278  (0.22075422782942933)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(22.1091, device='cuda:0')  (tensor(12.0927, device='cuda:0'))\n",
      "     | > current_lr: 4.749999999999999e-06 \n",
      "     | > step_time: 0.3374  (0.6249170910637334)\n",
      "     | > loader_time: 0.0049  (0.008589888518711307)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:38:46 -- STEP: 131/406 -- GLOBAL_STEP: 30575\u001b[0m\n",
      "     | > loss: -0.0093507319688797  (0.01648263189628834)\n",
      "     | > log_mle: -0.2166581153869629  (-0.20664357866039712)\n",
      "     | > loss_dur: 0.2073073834180832  (0.22312621055668547)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(15.1062, device='cuda:0')  (tensor(13.6647, device='cuda:0'))\n",
      "     | > current_lr: 4.749999999999999e-06 \n",
      "     | > step_time: 0.6154  (0.6427624917212333)\n",
      "     | > loader_time: 0.0335  (0.009522911246496303)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:39:04 -- STEP: 156/406 -- GLOBAL_STEP: 30600\u001b[0m\n",
      "     | > loss: 0.02890080213546753  (0.016988527698394585)\n",
      "     | > log_mle: -0.22400856018066406  (-0.20844402221532968)\n",
      "     | > loss_dur: 0.2529093623161316  (0.22543254991372427)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(13.1674, device='cuda:0')  (tensor(13.4767, device='cuda:0'))\n",
      "     | > current_lr: 4.749999999999999e-06 \n",
      "     | > step_time: 0.5376  (0.6539197304309943)\n",
      "     | > loader_time: 0.0188  (0.009994383041675273)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:39:24 -- STEP: 181/406 -- GLOBAL_STEP: 30625\u001b[0m\n",
      "     | > loss: 0.042015790939331055  (0.016944614645525893)\n",
      "     | > log_mle: -0.21771025657653809  (-0.20993177337541105)\n",
      "     | > loss_dur: 0.25972604751586914  (0.22687638802093696)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(14.8878, device='cuda:0')  (tensor(13.7102, device='cuda:0'))\n",
      "     | > current_lr: 4.749999999999999e-06 \n",
      "     | > step_time: 0.6933  (0.6720267672565099)\n",
      "     | > loader_time: 0.0541  (0.011445916160035523)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:39:44 -- STEP: 206/406 -- GLOBAL_STEP: 30650\u001b[0m\n",
      "     | > loss: 0.025848612189292908  (0.016914490863536167)\n",
      "     | > log_mle: -0.218500018119812  (-0.21133765491467077)\n",
      "     | > loss_dur: 0.24434863030910492  (0.22825214577820693)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(16.6877, device='cuda:0')  (tensor(13.8978, device='cuda:0'))\n",
      "     | > current_lr: 4.749999999999999e-06 \n",
      "     | > step_time: 0.9574  (0.681211552573639)\n",
      "     | > loader_time: 0.0061  (0.011436684617718443)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:40:04 -- STEP: 231/406 -- GLOBAL_STEP: 30675\u001b[0m\n",
      "     | > loss: 0.021874070167541504  (0.016721571807737475)\n",
      "     | > log_mle: -0.2330303192138672  (-0.2127927846206731)\n",
      "     | > loss_dur: 0.2549043893814087  (0.2295143564284106)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(19.0584, device='cuda:0')  (tensor(14.1403, device='cuda:0'))\n",
      "     | > current_lr: 4.749999999999999e-06 \n",
      "     | > step_time: 0.7455  (0.691944073805045)\n",
      "     | > loader_time: 0.0076  (0.011567666933134001)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:40:23 -- STEP: 256/406 -- GLOBAL_STEP: 30700\u001b[0m\n",
      "     | > loss: 0.01692582666873932  (0.016540109354536987)\n",
      "     | > log_mle: -0.22592175006866455  (-0.21405102824792266)\n",
      "     | > loss_dur: 0.24284757673740387  (0.23059113760245964)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(12.2150, device='cuda:0')  (tensor(14.3237, device='cuda:0'))\n",
      "     | > current_lr: 4.749999999999999e-06 \n",
      "     | > step_time: 0.5285  (0.6986720440909264)\n",
      "     | > loader_time: 0.0207  (0.011956823989748951)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:40:46 -- STEP: 281/406 -- GLOBAL_STEP: 30725\u001b[0m\n",
      "     | > loss: -0.006435126066207886  (0.01605060182220147)\n",
      "     | > log_mle: -0.2283940315246582  (-0.21508735100145443)\n",
      "     | > loss_dur: 0.22195890545845032  (0.23113795282365587)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(16.6878, device='cuda:0')  (tensor(14.4065, device='cuda:0'))\n",
      "     | > current_lr: 4.749999999999999e-06 \n",
      "     | > step_time: 0.8934  (0.7157375532537168)\n",
      "     | > loader_time: 0.009  (0.012223325165989557)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:41:13 -- STEP: 306/406 -- GLOBAL_STEP: 30750\u001b[0m\n",
      "     | > loss: 0.03258705139160156  (0.01590929063511829)\n",
      "     | > log_mle: -0.2180417776107788  (-0.21599124342787496)\n",
      "     | > loss_dur: 0.25062882900238037  (0.2319005340629933)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(20.6255, device='cuda:0')  (tensor(14.5332, device='cuda:0'))\n",
      "     | > current_lr: 4.749999999999999e-06 \n",
      "     | > step_time: 0.9214  (0.7436921799104979)\n",
      "     | > loader_time: 0.0314  (0.013002778969559007)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:41:36 -- STEP: 331/406 -- GLOBAL_STEP: 30775\u001b[0m\n",
      "     | > loss: 0.026596561074256897  (0.01579714343627053)\n",
      "     | > log_mle: -0.22249531745910645  (-0.21668437420421494)\n",
      "     | > loss_dur: 0.24909187853336334  (0.2324815176404855)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(20.4725, device='cuda:0')  (tensor(14.6391, device='cuda:0'))\n",
      "     | > current_lr: 4.749999999999999e-06 \n",
      "     | > step_time: 0.8483  (0.7560574050396234)\n",
      "     | > loader_time: 0.0483  (0.013512631557499169)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:41:58 -- STEP: 356/406 -- GLOBAL_STEP: 30800\u001b[0m\n",
      "     | > loss: 0.017237991094589233  (0.01579719555846759)\n",
      "     | > log_mle: -0.23294806480407715  (-0.21752830670121007)\n",
      "     | > loss_dur: 0.2501860558986664  (0.23332550225967771)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(32.0526, device='cuda:0')  (tensor(14.6109, device='cuda:0'))\n",
      "     | > current_lr: 4.749999999999999e-06 \n",
      "     | > step_time: 0.8567  (0.7619736603136816)\n",
      "     | > loader_time: 0.0223  (0.013697308770726231)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:42:22 -- STEP: 381/406 -- GLOBAL_STEP: 30825\u001b[0m\n",
      "     | > loss: 0.03373536467552185  (0.015610285122876391)\n",
      "     | > log_mle: -0.21674466133117676  (-0.2182736340470201)\n",
      "     | > loss_dur: 0.2504800260066986  (0.23388391916989654)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(12.0217, device='cuda:0')  (tensor(14.8118, device='cuda:0'))\n",
      "     | > current_lr: 4.749999999999999e-06 \n",
      "     | > step_time: 0.8745  (0.7746446257814025)\n",
      "     | > loader_time: 0.0412  (0.014015692112639816)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: 0.030090108513832092  (0.030090108513832092)\n",
      "     | > log_mle: -0.20129287242889404  (-0.20129287242889404)\n",
      "     | > loss_dur: 0.23138298094272614  (0.23138298094272614)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: -0.051252856850624084  (-0.051252856850624084)\n",
      "     | > log_mle: -0.2388526201248169  (-0.2388526201248169)\n",
      "     | > loss_dur: 0.1875997632741928  (0.1875997632741928)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: -0.01308351755142212  (-0.0321681872010231)\n",
      "     | > log_mle: -0.19823145866394043  (-0.21854203939437866)\n",
      "     | > loss_dur: 0.1851479411125183  (0.18637385219335556)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: -0.0009362399578094482  (-0.021757538119951885)\n",
      "     | > log_mle: -0.21189463138580322  (-0.21632623672485352)\n",
      "     | > loss_dur: 0.21095839142799377  (0.19456869860490164)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: -0.015576332807540894  (-0.020212236791849136)\n",
      "     | > log_mle: -0.23864614963531494  (-0.22190621495246887)\n",
      "     | > loss_dur: 0.22306981682777405  (0.20169397816061974)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: -0.014747127890586853  (-0.01911921501159668)\n",
      "     | > log_mle: -0.2344576120376587  (-0.22441649436950684)\n",
      "     | > loss_dur: 0.21971048414707184  (0.20529727935791015)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: 0.006204843521118164  (-0.014898538589477539)\n",
      "     | > log_mle: -0.2467104196548462  (-0.22813214858373007)\n",
      "     | > loss_dur: 0.25291526317596436  (0.21323360999425253)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: -0.007668823003768921  (-0.013865722077233451)\n",
      "     | > log_mle: -0.21272492408752441  (-0.22593111651284353)\n",
      "     | > loss_dur: 0.2050561010837555  (0.2120653944356101)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: -0.014245808124542236  (-0.013913232833147049)\n",
      "     | > log_mle: -0.22169816493988037  (-0.22540199756622314)\n",
      "     | > loss_dur: 0.20745235681533813  (0.2114887647330761)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: 0.00804196298122406  (-0.01147376663155026)\n",
      "     | > log_mle: -0.23232817649841309  (-0.22617157300313315)\n",
      "     | > loss_dur: 0.24037013947963715  (0.21469780637158287)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: 0.013850897550582886  (-0.008941300213336945)\n",
      "     | > log_mle: -0.21920239925384521  (-0.22547465562820435)\n",
      "     | > loss_dur: 0.2330532968044281  (0.2165333554148674)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: -0.00013218820095062256  (-0.008140471848574552)\n",
      "     | > log_mle: -0.23520565032958984  (-0.22635929151014847)\n",
      "     | > loss_dur: 0.23507346212863922  (0.21821881966157394)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: -0.028734982013702393  (-0.009856681029001873)\n",
      "     | > log_mle: -0.22398507595062256  (-0.22616144021352133)\n",
      "     | > loss_dur: 0.19525009393692017  (0.21630475918451944)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: -0.048638224601745605  (-0.012839876688443698)\n",
      "     | > log_mle: -0.24197518825531006  (-0.22737788237058199)\n",
      "     | > loss_dur: 0.19333696365356445  (0.2145380056821383)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: -0.0018196851015090942  (-0.012052720146519797)\n",
      "     | > log_mle: -0.23560643196105957  (-0.22796563591275895)\n",
      "     | > loss_dur: 0.23378674685955048  (0.21591291576623917)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: -0.010289683938026428  (-0.011935184399286905)\n",
      "     | > log_mle: -0.22944927215576172  (-0.2280645449956258)\n",
      "     | > loss_dur: 0.2191595882177353  (0.21612936059633892)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: -0.006336957216262817  (-0.0115852952003479)\n",
      "     | > log_mle: -0.22644615173339844  (-0.2279633954167366)\n",
      "     | > loss_dur: 0.22010919451713562  (0.2163781002163887)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: audio amplitude out of range, auto clipped.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.00309617817401886 \u001b[0m(-0.0008428543806076041)\n",
      "     | > avg_loss:\u001b[92m -0.0115852952003479 \u001b[0m(-0.003726538270711899)\n",
      "     | > avg_log_mle:\u001b[92m -0.2279633954167366 \u001b[0m(-0.003408394753932953)\n",
      "     | > avg_loss_dur:\u001b[92m 0.2163781002163887 \u001b[0m(-0.0003181435167789459)\n",
      "\n",
      " > BEST MODEL : train/run-February-22-2025_10+59PM-fa84af3/best_model_30850.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 20/100\u001b[0m\n",
      " --> train/run-February-22-2025_10+59PM-fa84af3\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-23 00:42:57) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:42:59 -- STEP: 0/406 -- GLOBAL_STEP: 30850\u001b[0m\n",
      "     | > loss: 0.003916293382644653  (0.003916293382644653)\n",
      "     | > log_mle: -0.19055068492889404  (-0.19055068492889404)\n",
      "     | > loss_dur: 0.1944669783115387  (0.1944669783115387)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(2.6573, device='cuda:0')  (tensor(2.6573, device='cuda:0'))\n",
      "     | > current_lr: 4.9999999999999996e-06 \n",
      "     | > step_time: 0.9261  (0.9261095523834229)\n",
      "     | > loader_time: 1.0036  (1.0035886764526367)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:43:12 -- STEP: 25/406 -- GLOBAL_STEP: 30875\u001b[0m\n",
      "     | > loss: 0.011069461703300476  (0.0054222124814987185)\n",
      "     | > log_mle: -0.20465445518493652  (-0.19969837188720704)\n",
      "     | > loss_dur: 0.215723916888237  (0.20512058436870576)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(6.1265, device='cuda:0')  (tensor(8.0943, device='cuda:0'))\n",
      "     | > current_lr: 4.9999999999999996e-06 \n",
      "     | > step_time: 0.3013  (0.5071198368072509)\n",
      "     | > loader_time: 0.0046  (0.0072688102722167965)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:43:28 -- STEP: 50/406 -- GLOBAL_STEP: 30900\u001b[0m\n",
      "     | > loss: 0.009878471493721008  (0.01147312432527542)\n",
      "     | > log_mle: -0.22608113288879395  (-0.19995667219161986)\n",
      "     | > loss_dur: 0.23595960438251495  (0.2114297965168953)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(10.2366, device='cuda:0')  (tensor(8.2325, device='cuda:0'))\n",
      "     | > current_lr: 4.9999999999999996e-06 \n",
      "     | > step_time: 0.6361  (0.5577514791488645)\n",
      "     | > loader_time: 0.0205  (0.00907665252685547)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:43:44 -- STEP: 75/406 -- GLOBAL_STEP: 30925\u001b[0m\n",
      "     | > loss: 0.008587151765823364  (0.012509830594062805)\n",
      "     | > log_mle: -0.21497535705566406  (-0.20273123264312742)\n",
      "     | > loss_dur: 0.22356250882148743  (0.21524106323719025)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(17.8661, device='cuda:0')  (tensor(10.8063, device='cuda:0'))\n",
      "     | > current_lr: 4.9999999999999996e-06 \n",
      "     | > step_time: 0.3322  (0.5804041639963783)\n",
      "     | > loader_time: 0.0161  (0.010347051620483397)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:44:00 -- STEP: 100/406 -- GLOBAL_STEP: 30950\u001b[0m\n",
      "     | > loss: 0.0239059180021286  (0.013163274824619294)\n",
      "     | > log_mle: -0.2161322832107544  (-0.2054063832759857)\n",
      "     | > loss_dur: 0.240038201212883  (0.21856965810060502)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(44.8930, device='cuda:0')  (tensor(11.3505, device='cuda:0'))\n",
      "     | > current_lr: 4.9999999999999996e-06 \n",
      "     | > step_time: 0.6799  (0.594972710609436)\n",
      "     | > loader_time: 0.0059  (0.010077760219573972)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:44:17 -- STEP: 125/406 -- GLOBAL_STEP: 30975\u001b[0m\n",
      "     | > loss: 0.02123120427131653  (0.012794131755828858)\n",
      "     | > log_mle: -0.22625446319580078  (-0.2080576229095459)\n",
      "     | > loss_dur: 0.2474856674671173  (0.22085175466537477)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(15.5791, device='cuda:0')  (tensor(12.9901, device='cuda:0'))\n",
      "     | > current_lr: 4.9999999999999996e-06 \n",
      "     | > step_time: 1.0091  (0.6106298103332519)\n",
      "     | > loader_time: 0.007  (0.010007486343383788)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:44:34 -- STEP: 150/406 -- GLOBAL_STEP: 31000\u001b[0m\n",
      "     | > loss: 0.00846301019191742  (0.013231374919414519)\n",
      "     | > log_mle: -0.2181403636932373  (-0.2101488439242045)\n",
      "     | > loss_dur: 0.22660337388515472  (0.22338021884361903)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(19.0626, device='cuda:0')  (tensor(13.3760, device='cuda:0'))\n",
      "     | > current_lr: 4.9999999999999996e-06 \n",
      "     | > step_time: 0.7936  (0.6186297448476156)\n",
      "     | > loader_time: 0.0053  (0.01088462829589844)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:44:52 -- STEP: 175/406 -- GLOBAL_STEP: 31025\u001b[0m\n",
      "     | > loss: 0.0023849010467529297  (0.013101984007017953)\n",
      "     | > log_mle: -0.22506427764892578  (-0.21163866315569194)\n",
      "     | > loss_dur: 0.2274491786956787  (0.22474064716270992)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(12.6855, device='cuda:0')  (tensor(13.5098, device='cuda:0'))\n",
      "     | > current_lr: 4.9999999999999996e-06 \n",
      "     | > step_time: 0.7408  (0.6307415076664519)\n",
      "     | > loader_time: 0.0056  (0.010980882644653326)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:45:12 -- STEP: 200/406 -- GLOBAL_STEP: 31050\u001b[0m\n",
      "     | > loss: 0.015567094087600708  (0.013087053820490836)\n",
      "     | > log_mle: -0.2223285436630249  (-0.2131262147426605)\n",
      "     | > loss_dur: 0.2378956377506256  (0.22621326856315135)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(19.5336, device='cuda:0')  (tensor(14.4378, device='cuda:0'))\n",
      "     | > current_lr: 4.9999999999999996e-06 \n",
      "     | > step_time: 0.8883  (0.6478860628604889)\n",
      "     | > loader_time: 0.0061  (0.011123038530349738)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:45:30 -- STEP: 225/406 -- GLOBAL_STEP: 31075\u001b[0m\n",
      "     | > loss: 0.013160094618797302  (0.013018645379278396)\n",
      "     | > log_mle: -0.22551345825195312  (-0.2144794548882378)\n",
      "     | > loss_dur: 0.23867355287075043  (0.22749810026751624)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(12.9870, device='cuda:0')  (tensor(14.6971, device='cuda:0'))\n",
      "     | > current_lr: 4.9999999999999996e-06 \n",
      "     | > step_time: 0.7411  (0.6529879675971137)\n",
      "     | > loader_time: 0.0218  (0.011623602973090284)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:45:49 -- STEP: 250/406 -- GLOBAL_STEP: 31100\u001b[0m\n",
      "     | > loss: -0.002762719988822937  (0.012849999606609345)\n",
      "     | > log_mle: -0.2370206117630005  (-0.21574639272689816)\n",
      "     | > loss_dur: 0.23425789177417755  (0.22859639233350754)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(16.3096, device='cuda:0')  (tensor(14.9525, device='cuda:0'))\n",
      "     | > current_lr: 4.9999999999999996e-06 \n",
      "     | > step_time: 0.7842  (0.6626938047409058)\n",
      "     | > loader_time: 0.0314  (0.012316703796386724)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:46:08 -- STEP: 275/406 -- GLOBAL_STEP: 31125\u001b[0m\n",
      "     | > loss: 0.013053059577941895  (0.012380167029120705)\n",
      "     | > log_mle: -0.22285079956054688  (-0.21689497600902208)\n",
      "     | > loss_dur: 0.23590385913848877  (0.2292751430381428)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(14.4242, device='cuda:0')  (tensor(15.1218, device='cuda:0'))\n",
      "     | > current_lr: 4.9999999999999996e-06 \n",
      "     | > step_time: 0.862  (0.6687510897896508)\n",
      "     | > loader_time: 0.0181  (0.012577589208429515)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:46:28 -- STEP: 300/406 -- GLOBAL_STEP: 31150\u001b[0m\n",
      "     | > loss: 0.019860848784446716  (0.012185339232285819)\n",
      "     | > log_mle: -0.21448242664337158  (-0.217724517583847)\n",
      "     | > loss_dur: 0.2343432754278183  (0.22990985681613285)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(20.1735, device='cuda:0')  (tensor(15.3517, device='cuda:0'))\n",
      "     | > current_lr: 4.9999999999999996e-06 \n",
      "     | > step_time: 0.825  (0.6794076832135519)\n",
      "     | > loader_time: 0.0081  (0.012718058427174892)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:46:48 -- STEP: 325/406 -- GLOBAL_STEP: 31175\u001b[0m\n",
      "     | > loss: 0.016083449125289917  (0.01209769537815681)\n",
      "     | > log_mle: -0.21889972686767578  (-0.21852443988506606)\n",
      "     | > loss_dur: 0.2349831759929657  (0.23062213526322292)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(23.2072, device='cuda:0')  (tensor(15.9492, device='cuda:0'))\n",
      "     | > current_lr: 4.9999999999999996e-06 \n",
      "     | > step_time: 0.8249  (0.6859303195659929)\n",
      "     | > loader_time: 0.027  (0.013086946193988511)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:47:08 -- STEP: 350/406 -- GLOBAL_STEP: 31200\u001b[0m\n",
      "     | > loss: 0.0151652991771698  (0.01223532114710127)\n",
      "     | > log_mle: -0.23370850086212158  (-0.219276750087738)\n",
      "     | > loss_dur: 0.24887380003929138  (0.2315120712348393)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(11.9491, device='cuda:0')  (tensor(16.6576, device='cuda:0'))\n",
      "     | > current_lr: 4.9999999999999996e-06 \n",
      "     | > step_time: 0.8379  (0.6932558114188058)\n",
      "     | > loader_time: 0.0302  (0.01353206906999861)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:47:30 -- STEP: 375/406 -- GLOBAL_STEP: 31225\u001b[0m\n",
      "     | > loss: 0.002554193139076233  (0.01204766174157461)\n",
      "     | > log_mle: -0.23843073844909668  (-0.22013864231109614)\n",
      "     | > loss_dur: 0.2409849315881729  (0.2321863040526708)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(22.2046, device='cuda:0')  (tensor(16.7162, device='cuda:0'))\n",
      "     | > current_lr: 4.9999999999999996e-06 \n",
      "     | > step_time: 1.0934  (0.7027617568969726)\n",
      "     | > loader_time: 0.0357  (0.013813803990681972)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:47:49 -- STEP: 400/406 -- GLOBAL_STEP: 31250\u001b[0m\n",
      "     | > loss: 0.024595588445663452  (0.012023170553147798)\n",
      "     | > log_mle: -0.23428678512573242  (-0.22090491056442257)\n",
      "     | > loss_dur: 0.2588823735713959  (0.2329280811175704)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(26.8513, device='cuda:0')  (tensor(16.8477, device='cuda:0'))\n",
      "     | > current_lr: 4.9999999999999996e-06 \n",
      "     | > step_time: 0.5628  (0.7067477494478226)\n",
      "     | > loader_time: 0.0068  (0.01385938167572022)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: 0.018335625529289246  (0.018335625529289246)\n",
      "     | > log_mle: -0.20346128940582275  (-0.20346128940582275)\n",
      "     | > loss_dur: 0.221796914935112  (0.221796914935112)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: -0.058227941393852234  (-0.058227941393852234)\n",
      "     | > log_mle: -0.24170160293579102  (-0.24170160293579102)\n",
      "     | > loss_dur: 0.18347366154193878  (0.18347366154193878)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: -0.018166959285736084  (-0.03819745033979416)\n",
      "     | > log_mle: -0.2003166675567627  (-0.22100913524627686)\n",
      "     | > loss_dur: 0.1821497082710266  (0.1828116849064827)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: -0.0009223520755767822  (-0.025772417585055035)\n",
      "     | > log_mle: -0.2146700620651245  (-0.21889611085255942)\n",
      "     | > loss_dur: 0.21374770998954773  (0.19312369326750436)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: -0.019470930099487305  (-0.0241970457136631)\n",
      "     | > log_mle: -0.24198126792907715  (-0.22466740012168884)\n",
      "     | > loss_dur: 0.22251033782958984  (0.20047035440802574)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: -0.019664183259010315  (-0.023290473222732543)\n",
      "     | > log_mle: -0.23715317249298096  (-0.22716455459594725)\n",
      "     | > loss_dur: 0.21748898923397064  (0.20387408137321472)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: -0.001815885305404663  (-0.01971137523651123)\n",
      "     | > log_mle: -0.2502248287200928  (-0.23100793361663818)\n",
      "     | > loss_dur: 0.2484089434146881  (0.21129655838012695)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: -0.009225055575370789  (-0.018213329570634023)\n",
      "     | > log_mle: -0.2153555154800415  (-0.22877187388283865)\n",
      "     | > loss_dur: 0.20613045990467072  (0.21055854431220464)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: -0.013302698731422424  (-0.017599500715732574)\n",
      "     | > log_mle: -0.22434675693511963  (-0.22821873426437378)\n",
      "     | > loss_dur: 0.2110440582036972  (0.2106192335486412)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: -0.0003652423620223999  (-0.015684583120875888)\n",
      "     | > log_mle: -0.23562562465667725  (-0.22904172208574083)\n",
      "     | > loss_dur: 0.23526038229465485  (0.21335713896486494)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: 0.01186959445476532  (-0.012929165363311767)\n",
      "     | > log_mle: -0.22196578979492188  (-0.22833412885665894)\n",
      "     | > loss_dur: 0.2338353842496872  (0.21540496349334717)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: -0.004258096218109131  (-0.012140886350111528)\n",
      "     | > log_mle: -0.2384488582611084  (-0.2292536497116089)\n",
      "     | > loss_dur: 0.23419076204299927  (0.21711276336149735)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: -0.03265358507633209  (-0.013850277910629908)\n",
      "     | > log_mle: -0.22671329975128174  (-0.22904195388158163)\n",
      "     | > loss_dur: 0.19405971467494965  (0.2151916759709517)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: -0.05169723927974701  (-0.016761582631331224)\n",
      "     | > log_mle: -0.24425816535949707  (-0.23021243168757513)\n",
      "     | > loss_dur: 0.19256092607975006  (0.2134508490562439)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: -0.01052151620388031  (-0.016315863600799015)\n",
      "     | > log_mle: -0.23875069618225098  (-0.2308223077229091)\n",
      "     | > loss_dur: 0.22822917997837067  (0.2145064441221101)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: -0.013607293367385864  (-0.016135292251904805)\n",
      "     | > log_mle: -0.2322988510131836  (-0.23092074394226075)\n",
      "     | > loss_dur: 0.21869155764579773  (0.21478545169035593)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: -0.010851532220840454  (-0.015805057249963284)\n",
      "     | > log_mle: -0.2293146848678589  (-0.23082036525011063)\n",
      "     | > loss_dur: 0.21846315264701843  (0.21501530800014734)\n",
      "\n",
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[91m 0.005070477724075317 \u001b[0m(+0.0019742995500564575)\n",
      "     | > avg_loss:\u001b[92m -0.015805057249963284 \u001b[0m(-0.004219762049615383)\n",
      "     | > avg_log_mle:\u001b[92m -0.23082036525011063 \u001b[0m(-0.0028569698333740234)\n",
      "     | > avg_loss_dur:\u001b[92m 0.21501530800014734 \u001b[0m(-0.0013627922162413597)\n",
      "\n",
      " > BEST MODEL : train/run-February-22-2025_10+59PM-fa84af3/best_model_31256.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 21/100\u001b[0m\n",
      " --> train/run-February-22-2025_10+59PM-fa84af3\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-23 00:48:07) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:48:17 -- STEP: 19/406 -- GLOBAL_STEP: 31275\u001b[0m\n",
      "     | > loss: 0.0294245183467865  (0.0028214940899296812)\n",
      "     | > log_mle: -0.1884669065475464  (-0.2028297687831678)\n",
      "     | > loss_dur: 0.21789142489433289  (0.20565126287309746)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(12.5274, device='cuda:0')  (tensor(7.5813, device='cuda:0'))\n",
      "     | > current_lr: 5.25e-06 \n",
      "     | > step_time: 0.3077  (0.4004923418948525)\n",
      "     | > loader_time: 0.0139  (0.007629959206832082)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:48:31 -- STEP: 44/406 -- GLOBAL_STEP: 31300\u001b[0m\n",
      "     | > loss: 0.028713837265968323  (0.009064626287330279)\n",
      "     | > log_mle: -0.2059270143508911  (-0.20143219828605652)\n",
      "     | > loss_dur: 0.23464085161685944  (0.2104968245733868)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(11.5083, device='cuda:0')  (tensor(8.8812, device='cuda:0'))\n",
      "     | > current_lr: 5.25e-06 \n",
      "     | > step_time: 0.6528  (0.482046820900657)\n",
      "     | > loader_time: 0.0083  (0.008558533408425072)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:48:44 -- STEP: 69/406 -- GLOBAL_STEP: 31325\u001b[0m\n",
      "     | > loss: 0.01489904522895813  (0.010272127130757206)\n",
      "     | > log_mle: -0.21383380889892578  (-0.20417523038560065)\n",
      "     | > loss_dur: 0.2287328541278839  (0.21444735751635785)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(5.3738, device='cuda:0')  (tensor(9.5902, device='cuda:0'))\n",
      "     | > current_lr: 5.25e-06 \n",
      "     | > step_time: 0.5726  (0.49474633949390356)\n",
      "     | > loader_time: 0.0136  (0.008813464123269787)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:48:58 -- STEP: 94/406 -- GLOBAL_STEP: 31350\u001b[0m\n",
      "     | > loss: 0.0039703696966171265  (0.009955685189429749)\n",
      "     | > log_mle: -0.21756303310394287  (-0.20731590783342402)\n",
      "     | > loss_dur: 0.22153340280056  (0.21727159302285376)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(23.9882, device='cuda:0')  (tensor(12.5889, device='cuda:0'))\n",
      "     | > current_lr: 5.25e-06 \n",
      "     | > step_time: 0.3794  (0.508506896648001)\n",
      "     | > loader_time: 0.0053  (0.008905129229768794)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:49:15 -- STEP: 119/406 -- GLOBAL_STEP: 31375\u001b[0m\n",
      "     | > loss: 0.007653400301933289  (0.009771828891850319)\n",
      "     | > log_mle: -0.2282576560974121  (-0.20976948838274018)\n",
      "     | > loss_dur: 0.2359110563993454  (0.2195413172745905)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(25.1482, device='cuda:0')  (tensor(13.3527, device='cuda:0'))\n",
      "     | > current_lr: 5.25e-06 \n",
      "     | > step_time: 0.8102  (0.538563630160163)\n",
      "     | > loader_time: 0.0094  (0.009111396404875426)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:49:31 -- STEP: 144/406 -- GLOBAL_STEP: 31400\u001b[0m\n",
      "     | > loss: 0.004807502031326294  (0.01003346685320139)\n",
      "     | > log_mle: -0.2210381031036377  (-0.21195294128523934)\n",
      "     | > loss_dur: 0.225845605134964  (0.2219864081384407)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(12.9718, device='cuda:0')  (tensor(13.1637, device='cuda:0'))\n",
      "     | > current_lr: 5.25e-06 \n",
      "     | > step_time: 0.6704  (0.5525650762849379)\n",
      "     | > loader_time: 0.0063  (0.009423121809959412)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:49:49 -- STEP: 169/406 -- GLOBAL_STEP: 31425\u001b[0m\n",
      "     | > loss: 0.015645354986190796  (0.010348218079854749)\n",
      "     | > log_mle: -0.22407054901123047  (-0.21335715443424924)\n",
      "     | > loss_dur: 0.23971590399742126  (0.223705372514104)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(7.0415, device='cuda:0')  (tensor(13.5268, device='cuda:0'))\n",
      "     | > current_lr: 5.25e-06 \n",
      "     | > step_time: 0.81  (0.5756450715149646)\n",
      "     | > loader_time: 0.0065  (0.009545869375827047)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:50:07 -- STEP: 194/406 -- GLOBAL_STEP: 31450\u001b[0m\n",
      "     | > loss: 0.00907871127128601  (0.01023711348624574)\n",
      "     | > log_mle: -0.22513985633850098  (-0.21487953122129144)\n",
      "     | > loss_dur: 0.234218567609787  (0.2251166447075372)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(7.9455, device='cuda:0')  (tensor(13.9902, device='cuda:0'))\n",
      "     | > current_lr: 5.25e-06 \n",
      "     | > step_time: 0.7828  (0.5944227520952515)\n",
      "     | > loader_time: 0.0062  (0.010610827465647274)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:50:25 -- STEP: 219/406 -- GLOBAL_STEP: 31475\u001b[0m\n",
      "     | > loss: -0.005049556493759155  (0.010137402575854302)\n",
      "     | > log_mle: -0.22466254234313965  (-0.21607377267863653)\n",
      "     | > loss_dur: 0.2196129858493805  (0.22621117525449083)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(17.7105, device='cuda:0')  (tensor(14.1389, device='cuda:0'))\n",
      "     | > current_lr: 5.25e-06 \n",
      "     | > step_time: 0.6976  (0.6063805453853516)\n",
      "     | > loader_time: 0.0354  (0.010926024554526969)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:50:45 -- STEP: 244/406 -- GLOBAL_STEP: 31500\u001b[0m\n",
      "     | > loss: 5.7056546211242676e-05  (0.010085793364731995)\n",
      "     | > log_mle: -0.22932302951812744  (-0.21747696253119922)\n",
      "     | > loss_dur: 0.22938008606433868  (0.22756275589593122)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(19.2350, device='cuda:0')  (tensor(14.5556, device='cuda:0'))\n",
      "     | > current_lr: 5.25e-06 \n",
      "     | > step_time: 0.546  (0.6234749770555337)\n",
      "     | > loader_time: 0.0069  (0.011234479849455787)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:51:05 -- STEP: 269/406 -- GLOBAL_STEP: 31525\u001b[0m\n",
      "     | > loss: 0.003062114119529724  (0.009733749698972173)\n",
      "     | > log_mle: -0.2288053035736084  (-0.21847490838912337)\n",
      "     | > loss_dur: 0.23186741769313812  (0.22820865808809557)\n",
      "     | > amp_scaler: 16384.0  (8496.53531598513)\n",
      "     | > grad_norm: tensor(17.5115, device='cuda:0')  (tensor(14.8068, device='cuda:0'))\n",
      "     | > current_lr: 5.25e-06 \n",
      "     | > step_time: 0.951  (0.6362408767402391)\n",
      "     | > loader_time: 0.0333  (0.011766821921536472)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:51:25 -- STEP: 294/406 -- GLOBAL_STEP: 31550\u001b[0m\n",
      "     | > loss: 0.011039584875106812  (0.009513935010854895)\n",
      "     | > log_mle: -0.23432934284210205  (-0.21940238094654213)\n",
      "     | > loss_dur: 0.24536892771720886  (0.22891631595739703)\n",
      "     | > amp_scaler: 16384.0  (9167.238095238097)\n",
      "     | > grad_norm: tensor(17.4337, device='cuda:0')  (tensor(15.0568, device='cuda:0'))\n",
      "     | > current_lr: 5.25e-06 \n",
      "     | > step_time: 0.8817  (0.6498002251800227)\n",
      "     | > loader_time: 0.0206  (0.011967990674129151)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:51:48 -- STEP: 319/406 -- GLOBAL_STEP: 31575\u001b[0m\n",
      "     | > loss: 0.013894379138946533  (0.009289450359568704)\n",
      "     | > log_mle: -0.2292492389678955  (-0.22025257816135324)\n",
      "     | > loss_dur: 0.24314361810684204  (0.22954202852092193)\n",
      "     | > amp_scaler: 16384.0  (9732.81504702195)\n",
      "     | > grad_norm: tensor(13.1455, device='cuda:0')  (tensor(15.3027, device='cuda:0'))\n",
      "     | > current_lr: 5.25e-06 \n",
      "     | > step_time: 0.54  (0.6689387571101653)\n",
      "     | > loader_time: 0.0072  (0.012372149942810638)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:52:09 -- STEP: 344/406 -- GLOBAL_STEP: 31600\u001b[0m\n",
      "     | > loss: 0.011828646063804626  (0.009355368265925456)\n",
      "     | > log_mle: -0.22237825393676758  (-0.22097594169683235)\n",
      "     | > loss_dur: 0.2342069000005722  (0.2303313099627578)\n",
      "     | > amp_scaler: 16384.0  (10216.186046511633)\n",
      "     | > grad_norm: tensor(24.5700, device='cuda:0')  (tensor(15.4801, device='cuda:0'))\n",
      "     | > current_lr: 5.25e-06 \n",
      "     | > step_time: 0.5987  (0.679382713728173)\n",
      "     | > loader_time: 0.0092  (0.012735330781271297)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:52:30 -- STEP: 369/406 -- GLOBAL_STEP: 31625\u001b[0m\n",
      "     | > loss: 0.013100460171699524  (0.00935539041915884)\n",
      "     | > log_mle: -0.2280055284500122  (-0.22178633070896633)\n",
      "     | > loss_dur: 0.24110598862171173  (0.23114172112812517)\n",
      "     | > amp_scaler: 8192.0  (10567.457994579947)\n",
      "     | > grad_norm: tensor(38.8055, device='cuda:0')  (tensor(15.4810, device='cuda:0'))\n",
      "     | > current_lr: 5.25e-06 \n",
      "     | > step_time: 0.6073  (0.689893797484194)\n",
      "     | > loader_time: 0.0096  (0.013194615278786764)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:52:51 -- STEP: 394/406 -- GLOBAL_STEP: 31650\u001b[0m\n",
      "     | > loss: 0.007194235920906067  (0.009346451477956052)\n",
      "     | > log_mle: -0.2347710132598877  (-0.22251876386894187)\n",
      "     | > loss_dur: 0.24196524918079376  (0.2318652153468979)\n",
      "     | > amp_scaler: 8192.0  (10416.73096446701)\n",
      "     | > grad_norm: tensor(12.3549, device='cuda:0')  (tensor(16.0883, device='cuda:0'))\n",
      "     | > current_lr: 5.25e-06 \n",
      "     | > step_time: 0.5851  (0.6978154842018479)\n",
      "     | > loader_time: 0.0105  (0.013248979137633662)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: 0.021840333938598633  (0.021840333938598633)\n",
      "     | > log_mle: -0.20499646663665771  (-0.20499646663665771)\n",
      "     | > loss_dur: 0.22683680057525635  (0.22683680057525635)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: -0.06495450437068939  (-0.06495450437068939)\n",
      "     | > log_mle: -0.2428981065750122  (-0.2428981065750122)\n",
      "     | > loss_dur: 0.17794360220432281  (0.17794360220432281)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: -0.01942439377307892  (-0.042189449071884155)\n",
      "     | > log_mle: -0.2021312713623047  (-0.22251468896865845)\n",
      "     | > loss_dur: 0.18270687758922577  (0.1803252398967743)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: -0.013100296258926392  (-0.03249306480089823)\n",
      "     | > log_mle: -0.21618878841400146  (-0.22040605545043945)\n",
      "     | > loss_dur: 0.20308849215507507  (0.18791299064954123)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: -0.02240021526813507  (-0.029969852417707443)\n",
      "     | > log_mle: -0.24316847324371338  (-0.22609665989875793)\n",
      "     | > loss_dur: 0.2207682579755783  (0.1961268074810505)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: -0.022168174386024475  (-0.028409516811370848)\n",
      "     | > log_mle: -0.23844778537750244  (-0.22856688499450684)\n",
      "     | > loss_dur: 0.21627961099147797  (0.20015736818313598)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: -0.003638938069343567  (-0.02428108702103297)\n",
      "     | > log_mle: -0.2504580020904541  (-0.23221540451049805)\n",
      "     | > loss_dur: 0.24681906402111053  (0.2079343174894651)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: -0.01011192798614502  (-0.022256921444620405)\n",
      "     | > log_mle: -0.21661102771759033  (-0.22998620782579696)\n",
      "     | > loss_dur: 0.2064990997314453  (0.20772928638117655)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: -0.01643534004688263  (-0.021529223769903183)\n",
      "     | > log_mle: -0.22575855255126953  (-0.22945775091648102)\n",
      "     | > loss_dur: 0.2093232125043869  (0.20792852714657784)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: -0.0016278773546218872  (-0.01931796305709415)\n",
      "     | > log_mle: -0.23660147190093994  (-0.230251497692532)\n",
      "     | > loss_dur: 0.23497359454631805  (0.21093353463543785)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: 0.007891908288002014  (-0.016596975922584533)\n",
      "     | > log_mle: -0.22316253185272217  (-0.22954260110855101)\n",
      "     | > loss_dur: 0.23105444014072418  (0.2129456251859665)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: -0.0007409155368804932  (-0.01515551588752053)\n",
      "     | > log_mle: -0.2398909330368042  (-0.23048335855657404)\n",
      "     | > loss_dur: 0.2391500174999237  (0.2153278426690535)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: -0.0374278724193573  (-0.017011545598506927)\n",
      "     | > log_mle: -0.22834539413452148  (-0.23030519485473633)\n",
      "     | > loss_dur: 0.19091752171516418  (0.2132936492562294)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: -0.051801830530166626  (-0.019687721362480752)\n",
      "     | > log_mle: -0.24661767482757568  (-0.2315600010064932)\n",
      "     | > loss_dur: 0.19481584429740906  (0.21187227964401245)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: -0.011992394924163818  (-0.019138055188315257)\n",
      "     | > log_mle: -0.23950934410095215  (-0.232127811227526)\n",
      "     | > loss_dur: 0.22751694917678833  (0.21298975603921072)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: -0.02251332998275757  (-0.019363073507944743)\n",
      "     | > log_mle: -0.23333072662353516  (-0.23220800558725993)\n",
      "     | > loss_dur: 0.2108173966407776  (0.21284493207931518)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: -0.011699333786964417  (-0.018884089775383472)\n",
      "     | > log_mle: -0.2305983304977417  (-0.23210740089416504)\n",
      "     | > loss_dur: 0.21889899671077728  (0.21322331111878157)\n",
      "\n",
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[91m 0.006666302680969238 \u001b[0m(+0.001595824956893921)\n",
      "     | > avg_loss:\u001b[92m -0.018884089775383472 \u001b[0m(-0.003079032525420189)\n",
      "     | > avg_log_mle:\u001b[92m -0.23210740089416504 \u001b[0m(-0.0012870356440544128)\n",
      "     | > avg_loss_dur:\u001b[92m 0.21322331111878157 \u001b[0m(-0.001791996881365776)\n",
      "\n",
      " > BEST MODEL : train/run-February-22-2025_10+59PM-fa84af3/best_model_31662.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 22/100\u001b[0m\n",
      " --> train/run-February-22-2025_10+59PM-fa84af3\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-23 00:53:13) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:53:21 -- STEP: 13/406 -- GLOBAL_STEP: 31675\u001b[0m\n",
      "     | > loss: -0.0034554749727249146  (-0.004087858475171602)\n",
      "     | > log_mle: -0.20958268642425537  (-0.20509221920600304)\n",
      "     | > loss_dur: 0.20612721145153046  (0.20100436073083144)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(8.6653, device='cuda:0')  (tensor(5.8574, device='cuda:0'))\n",
      "     | > current_lr: 5.5e-06 \n",
      "     | > step_time: 0.3003  (0.363063225379357)\n",
      "     | > loader_time: 0.0022  (0.0050384814922626205)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:53:35 -- STEP: 38/406 -- GLOBAL_STEP: 31700\u001b[0m\n",
      "     | > loss: 0.028971269726753235  (0.00502758159449226)\n",
      "     | > log_mle: -0.21160709857940674  (-0.20371368056849426)\n",
      "     | > loss_dur: 0.24057836830615997  (0.20874126216298655)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(6.4437, device='cuda:0')  (tensor(8.2867, device='cuda:0'))\n",
      "     | > current_lr: 5.5e-06 \n",
      "     | > step_time: 0.691  (0.49644679772226435)\n",
      "     | > loader_time: 0.0044  (0.007327838947898463)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:53:55 -- STEP: 63/406 -- GLOBAL_STEP: 31725\u001b[0m\n",
      "     | > loss: 0.012477383017539978  (0.0079749006600607)\n",
      "     | > log_mle: -0.20733916759490967  (-0.2051218577793666)\n",
      "     | > loss_dur: 0.21981655061244965  (0.21309675843942733)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(15.9026, device='cuda:0')  (tensor(9.1045, device='cuda:0'))\n",
      "     | > current_lr: 5.5e-06 \n",
      "     | > step_time: 0.8301  (0.6080394056108261)\n",
      "     | > loader_time: 0.0156  (0.008638064066569012)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:54:12 -- STEP: 88/406 -- GLOBAL_STEP: 31750\u001b[0m\n",
      "     | > loss: 0.020993858575820923  (0.008228924294764347)\n",
      "     | > log_mle: -0.20128154754638672  (-0.20793580331585623)\n",
      "     | > loss_dur: 0.22227540612220764  (0.21616472761062058)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(15.0708, device='cuda:0')  (tensor(10.7731, device='cuda:0'))\n",
      "     | > current_lr: 5.5e-06 \n",
      "     | > step_time: 0.8989  (0.6175880269570785)\n",
      "     | > loader_time: 0.0098  (0.009536816315217455)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:54:28 -- STEP: 113/406 -- GLOBAL_STEP: 31775\u001b[0m\n",
      "     | > loss: 0.01685124635696411  (0.007941139878424928)\n",
      "     | > log_mle: -0.21550166606903076  (-0.2107968773462076)\n",
      "     | > loss_dur: 0.23235291242599487  (0.21873801722463254)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(18.7678, device='cuda:0')  (tensor(11.9392, device='cuda:0'))\n",
      "     | > current_lr: 5.5e-06 \n",
      "     | > step_time: 0.694  (0.6185715029724933)\n",
      "     | > loader_time: 0.0079  (0.010074794819924683)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:54:45 -- STEP: 138/406 -- GLOBAL_STEP: 31800\u001b[0m\n",
      "     | > loss: 0.04282408952713013  (0.008070086547430015)\n",
      "     | > log_mle: -0.225624680519104  (-0.2130656337392503)\n",
      "     | > loss_dur: 0.26844877004623413  (0.22113572028668033)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(29.7180, device='cuda:0')  (tensor(12.0654, device='cuda:0'))\n",
      "     | > current_lr: 5.5e-06 \n",
      "     | > step_time: 0.5408  (0.6277589106905289)\n",
      "     | > loader_time: 0.0064  (0.010463267132855844)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:55:03 -- STEP: 163/406 -- GLOBAL_STEP: 31825\u001b[0m\n",
      "     | > loss: 0.016954123973846436  (0.008490304731152542)\n",
      "     | > log_mle: -0.23657524585723877  (-0.2146807594533347)\n",
      "     | > loss_dur: 0.2535293698310852  (0.22317106418448723)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(20.9879, device='cuda:0')  (tensor(12.6645, device='cuda:0'))\n",
      "     | > current_lr: 5.5e-06 \n",
      "     | > step_time: 0.8113  (0.6395778773021112)\n",
      "     | > loader_time: 0.0052  (0.010646170633702184)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:55:21 -- STEP: 188/406 -- GLOBAL_STEP: 31850\u001b[0m\n",
      "     | > loss: 0.008772745728492737  (0.008194210126678998)\n",
      "     | > log_mle: -0.23530912399291992  (-0.21617276998276405)\n",
      "     | > loss_dur: 0.24408186972141266  (0.22436698010944306)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(24.4242, device='cuda:0')  (tensor(14.1645, device='cuda:0'))\n",
      "     | > current_lr: 5.5e-06 \n",
      "     | > step_time: 1.138  (0.6492443160807829)\n",
      "     | > loader_time: 0.0342  (0.010988574078742487)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:55:40 -- STEP: 213/406 -- GLOBAL_STEP: 31875\u001b[0m\n",
      "     | > loss: 0.0014333575963974  (0.008083361135402195)\n",
      "     | > log_mle: -0.23390066623687744  (-0.2174682382126929)\n",
      "     | > loss_dur: 0.23533402383327484  (0.2255515993480951)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(12.5260, device='cuda:0')  (tensor(14.7485, device='cuda:0'))\n",
      "     | > current_lr: 5.5e-06 \n",
      "     | > step_time: 0.51  (0.6597298221409038)\n",
      "     | > loader_time: 0.0082  (0.01118838619178449)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:55:59 -- STEP: 238/406 -- GLOBAL_STEP: 31900\u001b[0m\n",
      "     | > loss: 0.00943484902381897  (0.008075553516880801)\n",
      "     | > log_mle: -0.23796093463897705  (-0.21885027705120438)\n",
      "     | > loss_dur: 0.24739578366279602  (0.22692583056808519)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(13.6584, device='cuda:0')  (tensor(15.1731, device='cuda:0'))\n",
      "     | > current_lr: 5.5e-06 \n",
      "     | > step_time: 0.7076  (0.668939890981722)\n",
      "     | > loader_time: 0.0066  (0.011928950037275036)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:56:18 -- STEP: 263/406 -- GLOBAL_STEP: 31925\u001b[0m\n",
      "     | > loss: -0.004196763038635254  (0.007813529653240968)\n",
      "     | > log_mle: -0.2369009256362915  (-0.21994265132077293)\n",
      "     | > loss_dur: 0.23270416259765625  (0.2277561809740139)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(31.7185, device='cuda:0')  (tensor(15.6722, device='cuda:0'))\n",
      "     | > current_lr: 5.5e-06 \n",
      "     | > step_time: 0.5621  (0.6741324024055392)\n",
      "     | > loader_time: 0.0207  (0.011989400414006333)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:56:40 -- STEP: 288/406 -- GLOBAL_STEP: 31950\u001b[0m\n",
      "     | > loss: -0.011525347828865051  (0.0073837879527774075)\n",
      "     | > log_mle: -0.22674715518951416  (-0.22089533052510685)\n",
      "     | > loss_dur: 0.2152218073606491  (0.22827911847788426)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(34.6078, device='cuda:0')  (tensor(16.1628, device='cuda:0'))\n",
      "     | > current_lr: 5.5e-06 \n",
      "     | > step_time: 0.5639  (0.6916598727305728)\n",
      "     | > loader_time: 0.0393  (0.01297195255756378)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:57:00 -- STEP: 313/406 -- GLOBAL_STEP: 31975\u001b[0m\n",
      "     | > loss: 0.010446369647979736  (0.007128541461956763)\n",
      "     | > log_mle: -0.2268441915512085  (-0.22173451691770707)\n",
      "     | > loss_dur: 0.23729056119918823  (0.22886305837966384)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(15.5500, device='cuda:0')  (tensor(16.6665, device='cuda:0'))\n",
      "     | > current_lr: 5.5e-06 \n",
      "     | > step_time: 1.2908  (0.6966544759159273)\n",
      "     | > loader_time: 0.0171  (0.0135041296291656)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:57:19 -- STEP: 338/406 -- GLOBAL_STEP: 32000\u001b[0m\n",
      "     | > loss: 0.0068383365869522095  (0.007105051016313786)\n",
      "     | > log_mle: -0.2346433401107788  (-0.22245929156534772)\n",
      "     | > loss_dur: 0.24148167669773102  (0.2295643425816615)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(14.3210, device='cuda:0')  (tensor(16.7452, device='cuda:0'))\n",
      "     | > current_lr: 5.5e-06 \n",
      "     | > step_time: 0.6005  (0.7000887732534017)\n",
      "     | > loader_time: 0.0071  (0.013610563334628675)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:57:40 -- STEP: 363/406 -- GLOBAL_STEP: 32025\u001b[0m\n",
      "     | > loss: 2.7358531951904297e-05  (0.006974224873482356)\n",
      "     | > log_mle: -0.23779559135437012  (-0.22333483656575856)\n",
      "     | > loss_dur: 0.23782294988632202  (0.23030906143924093)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(17.5411, device='cuda:0')  (tensor(16.8470, device='cuda:0'))\n",
      "     | > current_lr: 5.5e-06 \n",
      "     | > step_time: 0.7168  (0.7079660761126477)\n",
      "     | > loader_time: 0.0075  (0.013782136039628799)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:58:02 -- STEP: 388/406 -- GLOBAL_STEP: 32050\u001b[0m\n",
      "     | > loss: 0.010338440537452698  (0.00680521360992156)\n",
      "     | > log_mle: -0.23891210556030273  (-0.22407404448568208)\n",
      "     | > loss_dur: 0.24925054609775543  (0.23087925809560364)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(20.8737, device='cuda:0')  (tensor(16.9863, device='cuda:0'))\n",
      "     | > current_lr: 5.5e-06 \n",
      "     | > step_time: 1.3399  (0.7168941350327328)\n",
      "     | > loader_time: 0.0084  (0.01405470887410272)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: 0.014980107545852661  (0.014980107545852661)\n",
      "     | > log_mle: -0.20696306228637695  (-0.20696306228637695)\n",
      "     | > loss_dur: 0.22194316983222961  (0.22194316983222961)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: -0.06636860966682434  (-0.06636860966682434)\n",
      "     | > log_mle: -0.24508428573608398  (-0.24508428573608398)\n",
      "     | > loss_dur: 0.17871567606925964  (0.17871567606925964)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: -0.02224832773208618  (-0.04430846869945526)\n",
      "     | > log_mle: -0.2042539119720459  (-0.22466909885406494)\n",
      "     | > loss_dur: 0.18200558423995972  (0.18036063015460968)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: -0.005850628018379211  (-0.03148918847242991)\n",
      "     | > log_mle: -0.21812570095062256  (-0.22248796621958414)\n",
      "     | > loss_dur: 0.21227507293224335  (0.19099877774715424)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: -0.02110840380191803  (-0.02889399230480194)\n",
      "     | > log_mle: -0.24514412879943848  (-0.22815200686454773)\n",
      "     | > loss_dur: 0.22403572499752045  (0.1992580145597458)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: -0.02900862693786621  (-0.028916919231414796)\n",
      "     | > log_mle: -0.24089694023132324  (-0.23070099353790283)\n",
      "     | > loss_dur: 0.21188831329345703  (0.20178407430648804)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: -0.002244412899017334  (-0.024471501509348553)\n",
      "     | > log_mle: -0.2526259422302246  (-0.2343551516532898)\n",
      "     | > loss_dur: 0.2503815293312073  (0.20988365014394125)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: -0.012825429439544678  (-0.022807776927947998)\n",
      "     | > log_mle: -0.21847844123840332  (-0.23208705016544887)\n",
      "     | > loss_dur: 0.20565301179885864  (0.20927927323750087)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: -0.021854296326637268  (-0.022688591852784157)\n",
      "     | > log_mle: -0.2277764081954956  (-0.2315482199192047)\n",
      "     | > loss_dur: 0.20592211186885834  (0.20885962806642056)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: -0.0028851181268692017  (-0.02048820588323805)\n",
      "     | > log_mle: -0.2386237382888794  (-0.23233438862694633)\n",
      "     | > loss_dur: 0.2357386201620102  (0.21184618274370828)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: 0.006339207291603088  (-0.017805464565753937)\n",
      "     | > log_mle: -0.2253667116165161  (-0.23163762092590331)\n",
      "     | > loss_dur: 0.2317059189081192  (0.21383215636014938)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: -0.006871074438095093  (-0.016811429099603134)\n",
      "     | > log_mle: -0.2417280673980713  (-0.23255493424155496)\n",
      "     | > loss_dur: 0.2348569929599762  (0.2157435051419518)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: -0.04458524286746979  (-0.019125913580258686)\n",
      "     | > log_mle: -0.23034489154815674  (-0.2323707640171051)\n",
      "     | > loss_dur: 0.18575964868068695  (0.2132448504368464)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: -0.053611963987350464  (-0.021778686688496515)\n",
      "     | > log_mle: -0.24851059913635254  (-0.23361228979550874)\n",
      "     | > loss_dur: 0.19489863514900208  (0.21183360310701224)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: -0.014636501669883728  (-0.02126853061573846)\n",
      "     | > log_mle: -0.24186837673187256  (-0.2342020102909633)\n",
      "     | > loss_dur: 0.22723187506198883  (0.21293347967522486)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: -0.02318929135799408  (-0.021396581331888834)\n",
      "     | > log_mle: -0.23548877239227295  (-0.2342877944310506)\n",
      "     | > loss_dur: 0.21229948103427887  (0.21289121309916179)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: -0.011171460151672363  (-0.020757511258125305)\n",
      "     | > log_mle: -0.23290801048278809  (-0.2342015579342842)\n",
      "     | > loss_dur: 0.22173655033111572  (0.2134440466761589)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: audio amplitude out of range, auto clipped.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.004880979657173157 \u001b[0m(-0.0017853230237960815)\n",
      "     | > avg_loss:\u001b[92m -0.020757511258125305 \u001b[0m(-0.0018734214827418327)\n",
      "     | > avg_log_mle:\u001b[92m -0.2342015579342842 \u001b[0m(-0.002094157040119171)\n",
      "     | > avg_loss_dur:\u001b[91m 0.2134440466761589 \u001b[0m(+0.0002207355573773384)\n",
      "\n",
      " > BEST MODEL : train/run-February-22-2025_10+59PM-fa84af3/best_model_32068.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 23/100\u001b[0m\n",
      " --> train/run-February-22-2025_10+59PM-fa84af3\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-23 00:58:29) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:58:34 -- STEP: 7/406 -- GLOBAL_STEP: 32075\u001b[0m\n",
      "     | > loss: 0.0048448145389556885  (-0.0017382694142205374)\n",
      "     | > log_mle: -0.19839203357696533  (-0.20300938401903426)\n",
      "     | > loss_dur: 0.20323684811592102  (0.2012711146048137)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(6.5163, device='cuda:0')  (tensor(6.0754, device='cuda:0'))\n",
      "     | > current_lr: 5.75e-06 \n",
      "     | > step_time: 0.3555  (0.4451970032283238)\n",
      "     | > loader_time: 0.0067  (0.006273576191493443)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:58:48 -- STEP: 32/406 -- GLOBAL_STEP: 32100\u001b[0m\n",
      "     | > loss: 1.3262033462524414e-06  (-0.0014291466213762762)\n",
      "     | > log_mle: -0.20740187168121338  (-0.20535626262426376)\n",
      "     | > loss_dur: 0.20740319788455963  (0.2039271160028875)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(12.7315, device='cuda:0')  (tensor(8.7683, device='cuda:0'))\n",
      "     | > current_lr: 5.75e-06 \n",
      "     | > step_time: 0.6258  (0.5034228041768074)\n",
      "     | > loader_time: 0.0043  (0.008628547191619873)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:59:04 -- STEP: 57/406 -- GLOBAL_STEP: 32125\u001b[0m\n",
      "     | > loss: 0.015936553478240967  (0.004067442134806983)\n",
      "     | > log_mle: -0.20402753353118896  (-0.20631280279996103)\n",
      "     | > loss_dur: 0.21996408700942993  (0.210380244934768)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(12.4843, device='cuda:0')  (tensor(10.0157, device='cuda:0'))\n",
      "     | > current_lr: 5.75e-06 \n",
      "     | > step_time: 0.4073  (0.56016374889173)\n",
      "     | > loader_time: 0.0143  (0.00978776864838182)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:59:19 -- STEP: 82/406 -- GLOBAL_STEP: 32150\u001b[0m\n",
      "     | > loss: 0.001489296555519104  (0.004622938065994076)\n",
      "     | > log_mle: -0.21867132186889648  (-0.20868867926481297)\n",
      "     | > loss_dur: 0.2201606184244156  (0.213311617330807)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(17.6729, device='cuda:0')  (tensor(10.9909, device='cuda:0'))\n",
      "     | > current_lr: 5.75e-06 \n",
      "     | > step_time: 0.5222  (0.5720822113316234)\n",
      "     | > loader_time: 0.0046  (0.010251786650680916)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:59:36 -- STEP: 107/406 -- GLOBAL_STEP: 32175\u001b[0m\n",
      "     | > loss: -0.004492893815040588  (0.004524746509355919)\n",
      "     | > log_mle: -0.22535443305969238  (-0.21144423752187572)\n",
      "     | > loss_dur: 0.2208615392446518  (0.2159689840312316)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(21.4845, device='cuda:0')  (tensor(11.7658, device='cuda:0'))\n",
      "     | > current_lr: 5.75e-06 \n",
      "     | > step_time: 1.0492  (0.5860421457023264)\n",
      "     | > loader_time: 0.0195  (0.010861376735651606)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 00:59:53 -- STEP: 132/406 -- GLOBAL_STEP: 32200\u001b[0m\n",
      "     | > loss: -0.005649685859680176  (0.0043420256538824606)\n",
      "     | > log_mle: -0.2400578260421753  (-0.21407658584190137)\n",
      "     | > loss_dur: 0.23440814018249512  (0.21841861149578384)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(17.2914, device='cuda:0')  (tensor(12.4910, device='cuda:0'))\n",
      "     | > current_lr: 5.75e-06 \n",
      "     | > step_time: 0.702  (0.6036205960042549)\n",
      "     | > loader_time: 0.0062  (0.010859803719954058)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:00:09 -- STEP: 157/406 -- GLOBAL_STEP: 32225\u001b[0m\n",
      "     | > loss: -0.0025129765272140503  (0.004767111437335898)\n",
      "     | > log_mle: -0.21636855602264404  (-0.2157359495284451)\n",
      "     | > loss_dur: 0.21385557949543  (0.220503060965781)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(16.9051, device='cuda:0')  (tensor(13.3352, device='cuda:0'))\n",
      "     | > current_lr: 5.75e-06 \n",
      "     | > step_time: 0.3909  (0.6079769848258633)\n",
      "     | > loader_time: 0.0048  (0.011125526610453419)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:00:27 -- STEP: 182/406 -- GLOBAL_STEP: 32250\u001b[0m\n",
      "     | > loss: -7.496774196624756e-05  (0.004590831287614593)\n",
      "     | > log_mle: -0.2275862693786621  (-0.2172984304008903)\n",
      "     | > loss_dur: 0.22751130163669586  (0.2218892616885049)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(12.5913, device='cuda:0')  (tensor(13.8792, device='cuda:0'))\n",
      "     | > current_lr: 5.75e-06 \n",
      "     | > step_time: 0.8393  (0.6187198109679168)\n",
      "     | > loader_time: 0.0191  (0.011475517199589657)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:00:44 -- STEP: 207/406 -- GLOBAL_STEP: 32275\u001b[0m\n",
      "     | > loss: 0.007333993911743164  (0.004615640510683476)\n",
      "     | > log_mle: -0.2240372896194458  (-0.2186743798463241)\n",
      "     | > loss_dur: 0.23137128353118896  (0.22329002035700757)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(18.0936, device='cuda:0')  (tensor(14.3892, device='cuda:0'))\n",
      "     | > current_lr: 5.75e-06 \n",
      "     | > step_time: 0.6112  (0.6260393967375087)\n",
      "     | > loader_time: 0.0248  (0.011699880378833715)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:01:02 -- STEP: 232/406 -- GLOBAL_STEP: 32300\u001b[0m\n",
      "     | > loss: 0.013783499598503113  (0.004382537099821816)\n",
      "     | > log_mle: -0.2321453094482422  (-0.22016665647769795)\n",
      "     | > loss_dur: 0.2459288090467453  (0.2245491935775198)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(18.9095, device='cuda:0')  (tensor(14.5413, device='cuda:0'))\n",
      "     | > current_lr: 5.75e-06 \n",
      "     | > step_time: 0.6855  (0.6324580938651644)\n",
      "     | > loader_time: 0.0147  (0.012002840124327561)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:01:21 -- STEP: 257/406 -- GLOBAL_STEP: 32325\u001b[0m\n",
      "     | > loss: -0.00942094624042511  (0.004224808125644344)\n",
      "     | > log_mle: -0.23519384860992432  (-0.22140706002944174)\n",
      "     | > loss_dur: 0.2257729023694992  (0.2256318681550861)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(11.0912, device='cuda:0')  (tensor(14.5652, device='cuda:0'))\n",
      "     | > current_lr: 5.75e-06 \n",
      "     | > step_time: 0.8604  (0.6433445637328151)\n",
      "     | > loader_time: 0.0192  (0.012208298486494368)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:01:40 -- STEP: 282/406 -- GLOBAL_STEP: 32350\u001b[0m\n",
      "     | > loss: -0.0158388614654541  (0.003872462039720929)\n",
      "     | > log_mle: -0.24681568145751953  (-0.22246437842118824)\n",
      "     | > loss_dur: 0.23097681999206543  (0.2263368404609092)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(18.4423, device='cuda:0')  (tensor(14.6292, device='cuda:0'))\n",
      "     | > current_lr: 5.75e-06 \n",
      "     | > step_time: 0.6024  (0.6522543683965155)\n",
      "     | > loader_time: 0.0112  (0.012661876407920889)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:02:03 -- STEP: 307/406 -- GLOBAL_STEP: 32375\u001b[0m\n",
      "     | > loss: -0.00931432843208313  (0.003747967244747797)\n",
      "     | > log_mle: -0.23031997680664062  (-0.22332516982423367)\n",
      "     | > loss_dur: 0.2210056483745575  (0.22707313706898147)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(19.1019, device='cuda:0')  (tensor(15.0118, device='cuda:0'))\n",
      "     | > current_lr: 5.75e-06 \n",
      "     | > step_time: 0.8152  (0.6723700944297863)\n",
      "     | > loader_time: 0.0124  (0.0131266598592752)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:02:24 -- STEP: 332/406 -- GLOBAL_STEP: 32400\u001b[0m\n",
      "     | > loss: 0.00885908305644989  (0.0037755656942545664)\n",
      "     | > log_mle: -0.22755134105682373  (-0.22403966051986418)\n",
      "     | > loss_dur: 0.23641042411327362  (0.22781522621411876)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(17.4292, device='cuda:0')  (tensor(15.2173, device='cuda:0'))\n",
      "     | > current_lr: 5.75e-06 \n",
      "     | > step_time: 0.7144  (0.6836352714573044)\n",
      "     | > loader_time: 0.0077  (0.013241071298897988)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:02:48 -- STEP: 357/406 -- GLOBAL_STEP: 32425\u001b[0m\n",
      "     | > loss: 0.011855199933052063  (0.003736323168297777)\n",
      "     | > log_mle: -0.2298736572265625  (-0.2248874912742807)\n",
      "     | > loss_dur: 0.24172885715961456  (0.22862381444257848)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(38.9190, device='cuda:0')  (tensor(15.5492, device='cuda:0'))\n",
      "     | > current_lr: 5.75e-06 \n",
      "     | > step_time: 0.8787  (0.700172448358616)\n",
      "     | > loader_time: 0.0076  (0.013577733053212743)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:03:11 -- STEP: 382/406 -- GLOBAL_STEP: 32450\u001b[0m\n",
      "     | > loss: 0.008768945932388306  (0.0035316491236237345)\n",
      "     | > log_mle: -0.237959623336792  (-0.2256501014320014)\n",
      "     | > loss_dur: 0.2467285692691803  (0.22918175055562515)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(24.2158, device='cuda:0')  (tensor(15.8989, device='cuda:0'))\n",
      "     | > current_lr: 5.75e-06 \n",
      "     | > step_time: 1.0111  (0.7132883221691194)\n",
      "     | > loader_time: 0.0088  (0.013968000237230233)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: 0.011634528636932373  (0.011634528636932373)\n",
      "     | > log_mle: -0.2087996006011963  (-0.2087996006011963)\n",
      "     | > loss_dur: 0.22043412923812866  (0.22043412923812866)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: -0.0714324563741684  (-0.0714324563741684)\n",
      "     | > log_mle: -0.24725127220153809  (-0.24725127220153809)\n",
      "     | > loss_dur: 0.1758188158273697  (0.1758188158273697)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: -0.02448830008506775  (-0.04796037822961807)\n",
      "     | > log_mle: -0.20625662803649902  (-0.22675395011901855)\n",
      "     | > loss_dur: 0.18176832795143127  (0.17879357188940048)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: -0.011940762400627136  (-0.03595383961995443)\n",
      "     | > log_mle: -0.22082483768463135  (-0.22477757930755615)\n",
      "     | > loss_dur: 0.2088840752840042  (0.18882373968760172)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: -0.020545944571495056  (-0.032101865857839584)\n",
      "     | > log_mle: -0.24786102771759033  (-0.2305484414100647)\n",
      "     | > loss_dur: 0.22731508314609528  (0.1984465755522251)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: -0.03406919538974762  (-0.03249533176422119)\n",
      "     | > log_mle: -0.2449742555618286  (-0.23343360424041748)\n",
      "     | > loss_dur: 0.210905060172081  (0.20093827247619628)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: -0.0117262601852417  (-0.029033819834391277)\n",
      "     | > log_mle: -0.2566748857498169  (-0.23730715115865073)\n",
      "     | > loss_dur: 0.2449486255645752  (0.20827333132425943)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: -0.01789790391921997  (-0.027442974703652517)\n",
      "     | > log_mle: -0.22162187099456787  (-0.235066396849496)\n",
      "     | > loss_dur: 0.2037239670753479  (0.2076234221458435)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: -0.02462153136730194  (-0.027090294286608696)\n",
      "     | > log_mle: -0.23025202751159668  (-0.2344646006822586)\n",
      "     | > loss_dur: 0.20563049614429474  (0.2073743063956499)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: -0.007014542818069458  (-0.02485965523454878)\n",
      "     | > log_mle: -0.24176299571990967  (-0.23527553346421984)\n",
      "     | > loss_dur: 0.2347484529018402  (0.21041587822967106)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: 0.0017300546169281006  (-0.022200684249401092)\n",
      "     | > log_mle: -0.228357195854187  (-0.23458369970321655)\n",
      "     | > loss_dur: 0.2300872504711151  (0.21238301545381547)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: -0.014606073498725891  (-0.021510265090248802)\n",
      "     | > log_mle: -0.24502718448638916  (-0.2355331074107777)\n",
      "     | > loss_dur: 0.23042111098766327  (0.2140228423205289)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: -0.04688200354576111  (-0.02362457662820816)\n",
      "     | > log_mle: -0.2329026460647583  (-0.2353139022986094)\n",
      "     | > loss_dur: 0.1860206425189972  (0.21168932567040125)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: -0.05785675346851349  (-0.02625782100053934)\n",
      "     | > log_mle: -0.25241756439208984  (-0.23662956861349252)\n",
      "     | > loss_dur: 0.19456081092357635  (0.21037174761295319)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: -0.014658629894256592  (-0.025429307350090573)\n",
      "     | > log_mle: -0.24435269832611084  (-0.2371812207358224)\n",
      "     | > loss_dur: 0.22969406843185425  (0.21175191338573182)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: -0.022852569818496704  (-0.025257524847984315)\n",
      "     | > log_mle: -0.23821592330932617  (-0.23725020090738932)\n",
      "     | > loss_dur: 0.21536335349082947  (0.211992676059405)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: -0.01533837616443634  (-0.024637578055262566)\n",
      "     | > log_mle: -0.23620986938476562  (-0.23718518018722534)\n",
      "     | > loss_dur: 0.22087149322032928  (0.21254760213196278)\n",
      "\n",
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.003973275423049927 \u001b[0m(-0.00090770423412323)\n",
      "     | > avg_loss:\u001b[92m -0.024637578055262566 \u001b[0m(-0.0038800667971372604)\n",
      "     | > avg_log_mle:\u001b[92m -0.23718518018722534 \u001b[0m(-0.0029836222529411316)\n",
      "     | > avg_loss_dur:\u001b[92m 0.21254760213196278 \u001b[0m(-0.0008964445441961288)\n",
      "\n",
      " > BEST MODEL : train/run-February-22-2025_10+59PM-fa84af3/best_model_32474.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 24/100\u001b[0m\n",
      " --> train/run-February-22-2025_10+59PM-fa84af3\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-23 01:03:45) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:03:50 -- STEP: 1/406 -- GLOBAL_STEP: 32475\u001b[0m\n",
      "     | > loss: -0.02432018518447876  (-0.02432018518447876)\n",
      "     | > log_mle: -0.20573842525482178  (-0.20573842525482178)\n",
      "     | > loss_dur: 0.18141824007034302  (0.18141824007034302)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(3.5991, device='cuda:0')  (tensor(3.5991, device='cuda:0'))\n",
      "     | > current_lr: 6e-06 \n",
      "     | > step_time: 1.1699  (1.169938087463379)\n",
      "     | > loader_time: 0.0134  (0.013428449630737305)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:04:06 -- STEP: 26/406 -- GLOBAL_STEP: 32500\u001b[0m\n",
      "     | > loss: 0.0004354417324066162  (-0.006519106718210073)\n",
      "     | > log_mle: -0.20873773097991943  (-0.20778514788700983)\n",
      "     | > loss_dur: 0.20917317271232605  (0.20126604116879976)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(12.6695, device='cuda:0')  (tensor(7.9392, device='cuda:0'))\n",
      "     | > current_lr: 6e-06 \n",
      "     | > step_time: 1.2719  (0.6669053847973162)\n",
      "     | > loader_time: 0.0166  (0.008819919366102952)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:04:25 -- STEP: 51/406 -- GLOBAL_STEP: 32525\u001b[0m\n",
      "     | > loss: 0.006657317280769348  (-0.0004659400266759535)\n",
      "     | > log_mle: -0.2241830825805664  (-0.20825739000357835)\n",
      "     | > loss_dur: 0.23084039986133575  (0.20779144997690238)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(14.2619, device='cuda:0')  (tensor(9.1596, device='cuda:0'))\n",
      "     | > current_lr: 6e-06 \n",
      "     | > step_time: 0.6722  (0.6877012907289991)\n",
      "     | > loader_time: 0.0143  (0.013901144850487802)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:04:41 -- STEP: 76/406 -- GLOBAL_STEP: 32550\u001b[0m\n",
      "     | > loss: 0.023135557770729065  (0.0010606234795168827)\n",
      "     | > log_mle: -0.21215951442718506  (-0.21059151229105497)\n",
      "     | > loss_dur: 0.23529507219791412  (0.21165213577057185)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(9.7072, device='cuda:0')  (tensor(10.1571, device='cuda:0'))\n",
      "     | > current_lr: 6e-06 \n",
      "     | > step_time: 0.6229  (0.6676254868507385)\n",
      "     | > loader_time: 0.0283  (0.013305638965807463)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:04:59 -- STEP: 101/406 -- GLOBAL_STEP: 32575\u001b[0m\n",
      "     | > loss: 0.018000081181526184  (0.0015018812500604312)\n",
      "     | > log_mle: -0.21866655349731445  (-0.21311588452594116)\n",
      "     | > loss_dur: 0.23666663467884064  (0.21461776577600158)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(23.7502, device='cuda:0')  (tensor(12.9694, device='cuda:0'))\n",
      "     | > current_lr: 6e-06 \n",
      "     | > step_time: 0.4766  (0.6788888260869697)\n",
      "     | > loader_time: 0.046  (0.013243125216795666)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:05:18 -- STEP: 126/406 -- GLOBAL_STEP: 32600\u001b[0m\n",
      "     | > loss: -0.000306740403175354  (0.0010818641573663741)\n",
      "     | > log_mle: -0.22171425819396973  (-0.2156984361391219)\n",
      "     | > loss_dur: 0.22140751779079437  (0.21678030029648826)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(33.7668, device='cuda:0')  (tensor(15.2736, device='cuda:0'))\n",
      "     | > current_lr: 6e-06 \n",
      "     | > step_time: 0.6633  (0.6935660366028075)\n",
      "     | > loader_time: 0.0214  (0.01305820828392392)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:05:39 -- STEP: 151/406 -- GLOBAL_STEP: 32625\u001b[0m\n",
      "     | > loss: 0.013126254081726074  (0.0014242296976758947)\n",
      "     | > log_mle: -0.21894407272338867  (-0.21764299411647367)\n",
      "     | > loss_dur: 0.23207032680511475  (0.21906722381414956)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(19.8516, device='cuda:0')  (tensor(16.9264, device='cuda:0'))\n",
      "     | > current_lr: 6e-06 \n",
      "     | > step_time: 0.483  (0.7113828374850039)\n",
      "     | > loader_time: 0.0053  (0.013412216641255562)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:05:58 -- STEP: 176/406 -- GLOBAL_STEP: 32650\u001b[0m\n",
      "     | > loss: 0.013175532221794128  (0.0015800253234126357)\n",
      "     | > log_mle: -0.2236020565032959  (-0.21905946325172077)\n",
      "     | > loss_dur: 0.23677758872509003  (0.2206394885751334)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(23.8099, device='cuda:0')  (tensor(18.0299, device='cuda:0'))\n",
      "     | > current_lr: 6e-06 \n",
      "     | > step_time: 0.6442  (0.7188598486510188)\n",
      "     | > loader_time: 0.0079  (0.013257368044419722)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:06:18 -- STEP: 201/406 -- GLOBAL_STEP: 32675\u001b[0m\n",
      "     | > loss: -0.0013072490692138672  (0.0016128019017366633)\n",
      "     | > log_mle: -0.22042298316955566  (-0.22049283566166514)\n",
      "     | > loss_dur: 0.2191157341003418  (0.2221056375634018)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(30.1595, device='cuda:0')  (tensor(18.9171, device='cuda:0'))\n",
      "     | > current_lr: 6e-06 \n",
      "     | > step_time: 0.9238  (0.7238718953298691)\n",
      "     | > loader_time: 0.0052  (0.013512858110873853)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:06:39 -- STEP: 226/406 -- GLOBAL_STEP: 32700\u001b[0m\n",
      "     | > loss: -0.009834244847297668  (0.0014718522408367263)\n",
      "     | > log_mle: -0.2378218173980713  (-0.22188737276381096)\n",
      "     | > loss_dur: 0.22798757255077362  (0.2233592250046477)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(16.2316, device='cuda:0')  (tensor(19.6421, device='cuda:0'))\n",
      "     | > current_lr: 6e-06 \n",
      "     | > step_time: 0.8829  (0.7327251381578698)\n",
      "     | > loader_time: 0.0066  (0.013690985409559401)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:07:01 -- STEP: 251/406 -- GLOBAL_STEP: 32725\u001b[0m\n",
      "     | > loss: -0.00045020878314971924  (0.0014622599123958577)\n",
      "     | > log_mle: -0.23495113849639893  (-0.22313864202613376)\n",
      "     | > loss_dur: 0.2345009297132492  (0.2246009019385296)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(27.0843, device='cuda:0')  (tensor(20.2578, device='cuda:0'))\n",
      "     | > current_lr: 6e-06 \n",
      "     | > step_time: 1.55  (0.7483570290751665)\n",
      "     | > loader_time: 0.0396  (0.013803539998027909)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:07:22 -- STEP: 276/406 -- GLOBAL_STEP: 32750\u001b[0m\n",
      "     | > loss: 0.010035470128059387  (0.0011571921624135284)\n",
      "     | > log_mle: -0.23207342624664307  (-0.22425281828728275)\n",
      "     | > loss_dur: 0.24210889637470245  (0.22541001044969625)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(14.3466, device='cuda:0')  (tensor(20.1714, device='cuda:0'))\n",
      "     | > current_lr: 6e-06 \n",
      "     | > step_time: 0.6324  (0.7537333032359248)\n",
      "     | > loader_time: 0.0308  (0.014113498770672342)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:07:43 -- STEP: 301/406 -- GLOBAL_STEP: 32775\u001b[0m\n",
      "     | > loss: -0.005314290523529053  (0.0009174846929569185)\n",
      "     | > log_mle: -0.2488175630569458  (-0.22510059608573532)\n",
      "     | > loss_dur: 0.24350327253341675  (0.22601808077869226)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(40.9393, device='cuda:0')  (tensor(20.1000, device='cuda:0'))\n",
      "     | > current_lr: 6e-06 \n",
      "     | > step_time: 0.7818  (0.7599149756257322)\n",
      "     | > loader_time: 0.0346  (0.014476391960220084)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:08:07 -- STEP: 326/406 -- GLOBAL_STEP: 32800\u001b[0m\n",
      "     | > loss: -0.001254841685295105  (0.0006868337835270938)\n",
      "     | > log_mle: -0.22606146335601807  (-0.22576020795143456)\n",
      "     | > loss_dur: 0.22480662167072296  (0.22644704173496163)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(11.4415, device='cuda:0')  (tensor(20.3693, device='cuda:0'))\n",
      "     | > current_lr: 6e-06 \n",
      "     | > step_time: 1.2075  (0.7733254937306506)\n",
      "     | > loader_time: 0.0123  (0.01498099850730662)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:08:34 -- STEP: 351/406 -- GLOBAL_STEP: 32825\u001b[0m\n",
      "     | > loss: 0.015284717082977295  (0.0007724806114479351)\n",
      "     | > log_mle: -0.22894048690795898  (-0.2265428294483413)\n",
      "     | > loss_dur: 0.24422520399093628  (0.22731531005978925)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(17.0758, device='cuda:0')  (tensor(20.1324, device='cuda:0'))\n",
      "     | > current_lr: 6e-06 \n",
      "     | > step_time: 1.1177  (0.7909964557386874)\n",
      "     | > loader_time: 0.0179  (0.015375780583786488)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:08:57 -- STEP: 376/406 -- GLOBAL_STEP: 32850\u001b[0m\n",
      "     | > loss: 0.0006366074085235596  (0.00047134168129018037)\n",
      "     | > log_mle: -0.24056732654571533  (-0.2274534375743663)\n",
      "     | > loss_dur: 0.2412039339542389  (0.2279247792556565)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(18.4824, device='cuda:0')  (tensor(20.1045, device='cuda:0'))\n",
      "     | > current_lr: 6e-06 \n",
      "     | > step_time: 0.9863  (0.7986108692402538)\n",
      "     | > loader_time: 0.0106  (0.015731887614473382)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:09:16 -- STEP: 401/406 -- GLOBAL_STEP: 32875\u001b[0m\n",
      "     | > loss: -0.010643884539604187  (0.0004288761544405969)\n",
      "     | > log_mle: -0.2423795461654663  (-0.2282485367354015)\n",
      "     | > loss_dur: 0.23173566162586212  (0.22867741288984209)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(21.1675, device='cuda:0')  (tensor(20.1211, device='cuda:0'))\n",
      "     | > current_lr: 6e-06 \n",
      "     | > step_time: 0.5636  (0.7952381286240578)\n",
      "     | > loader_time: 0.0068  (0.0156308689022302)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: 0.01711893081665039  (0.01711893081665039)\n",
      "     | > log_mle: -0.2113204002380371  (-0.2113204002380371)\n",
      "     | > loss_dur: 0.2284393310546875  (0.2284393310546875)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: -0.07276257872581482  (-0.07276257872581482)\n",
      "     | > log_mle: -0.24995458126068115  (-0.24995458126068115)\n",
      "     | > loss_dur: 0.17719200253486633  (0.17719200253486633)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: -0.028110966086387634  (-0.05043677240610123)\n",
      "     | > log_mle: -0.2090318202972412  (-0.22949320077896118)\n",
      "     | > loss_dur: 0.18092085421085358  (0.17905642837285995)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: -0.014442697167396545  (-0.038438747326533)\n",
      "     | > log_mle: -0.2229853868484497  (-0.22732392946879068)\n",
      "     | > loss_dur: 0.20854268968105316  (0.1888851821422577)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: -0.02412635087966919  (-0.03486064821481705)\n",
      "     | > log_mle: -0.25030481815338135  (-0.23306915163993835)\n",
      "     | > loss_dur: 0.22617846727371216  (0.1982085034251213)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: -0.0409182608127594  (-0.036072170734405516)\n",
      "     | > log_mle: -0.24805891513824463  (-0.2360671043395996)\n",
      "     | > loss_dur: 0.20714065432548523  (0.1999949336051941)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: -0.014757364988327026  (-0.032519703110059105)\n",
      "     | > log_mle: -0.2598165273666382  (-0.2400253415107727)\n",
      "     | > loss_dur: 0.24505916237831116  (0.2075056384007136)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: -0.019921138882637024  (-0.03071990822042738)\n",
      "     | > log_mle: -0.22362375259399414  (-0.23768225737980433)\n",
      "     | > loss_dur: 0.20370261371135712  (0.20696234915937697)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: -0.029385894536972046  (-0.03055315650999546)\n",
      "     | > log_mle: -0.2330775260925293  (-0.23710666596889496)\n",
      "     | > loss_dur: 0.20369163155555725  (0.2065535094588995)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: -0.012664794921875  (-0.028565560777982075)\n",
      "     | > log_mle: -0.24473249912261963  (-0.23795398076375326)\n",
      "     | > loss_dur: 0.23206770420074463  (0.20938841998577118)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: -0.004152044653892517  (-0.02612420916557312)\n",
      "     | > log_mle: -0.23065078258514404  (-0.23722366094589234)\n",
      "     | > loss_dur: 0.22649873793125153  (0.21109945178031922)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: -0.015324801206588745  (-0.02514244480566545)\n",
      "     | > log_mle: -0.2474377155303955  (-0.23815221136266534)\n",
      "     | > loss_dur: 0.23211291432380676  (0.2130097665569999)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: -0.050511136651039124  (-0.02725650245944659)\n",
      "     | > log_mle: -0.23517072200775146  (-0.23790375391642252)\n",
      "     | > loss_dur: 0.18465958535671234  (0.21064725145697594)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: -0.060142770409584045  (-0.029786215378687933)\n",
      "     | > log_mle: -0.2553309202194214  (-0.23924430517049936)\n",
      "     | > loss_dur: 0.19518814980983734  (0.20945808979181144)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: -0.02070888876914978  (-0.029137834906578064)\n",
      "     | > log_mle: -0.24745094776153564  (-0.23983049392700195)\n",
      "     | > loss_dur: 0.22674205899238586  (0.2106926590204239)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: -0.024756476283073425  (-0.028845744331677754)\n",
      "     | > log_mle: -0.24092841148376465  (-0.23990368843078613)\n",
      "     | > loss_dur: 0.21617193520069122  (0.21105794409910839)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: -0.016015291213989258  (-0.028043841011822224)\n",
      "     | > log_mle: -0.23886990547180176  (-0.2398390769958496)\n",
      "     | > loss_dur: 0.2228546142578125  (0.21179523598402739)\n",
      "\n",
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[91m 0.006279751658439636 \u001b[0m(+0.0023064762353897095)\n",
      "     | > avg_loss:\u001b[92m -0.028043841011822224 \u001b[0m(-0.003406262956559658)\n",
      "     | > avg_log_mle:\u001b[92m -0.2398390769958496 \u001b[0m(-0.0026538968086242676)\n",
      "     | > avg_loss_dur:\u001b[92m 0.21179523598402739 \u001b[0m(-0.0007523661479353905)\n",
      "\n",
      " > BEST MODEL : train/run-February-22-2025_10+59PM-fa84af3/best_model_32880.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 25/100\u001b[0m\n",
      " --> train/run-February-22-2025_10+59PM-fa84af3\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-23 01:09:34) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:09:46 -- STEP: 20/406 -- GLOBAL_STEP: 32900\u001b[0m\n",
      "     | > loss: -0.0020735859870910645  (-0.01106780841946602)\n",
      "     | > log_mle: -0.19183599948883057  (-0.20953229069709778)\n",
      "     | > loss_dur: 0.1897624135017395  (0.19846448227763175)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(9.8839, device='cuda:0')  (tensor(9.2078, device='cuda:0'))\n",
      "     | > current_lr: 6.2499999999999995e-06 \n",
      "     | > step_time: 0.7824  (0.47878029346466067)\n",
      "     | > loader_time: 0.007  (0.006494534015655517)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:10:01 -- STEP: 45/406 -- GLOBAL_STEP: 32925\u001b[0m\n",
      "     | > loss: -0.002493619918823242  (-0.005373545487721761)\n",
      "     | > log_mle: -0.21016240119934082  (-0.2088768243789673)\n",
      "     | > loss_dur: 0.20766878128051758  (0.20350327889124553)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(22.6118, device='cuda:0')  (tensor(13.2510, device='cuda:0'))\n",
      "     | > current_lr: 6.2499999999999995e-06 \n",
      "     | > step_time: 0.4021  (0.530541510052151)\n",
      "     | > loader_time: 0.0046  (0.008018212848239475)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:10:17 -- STEP: 70/406 -- GLOBAL_STEP: 32950\u001b[0m\n",
      "     | > loss: -0.026966124773025513  (-0.0034798562526702874)\n",
      "     | > log_mle: -0.2217576503753662  (-0.2116456389427185)\n",
      "     | > loss_dur: 0.1947915256023407  (0.2081657826900482)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(8.4219, device='cuda:0')  (tensor(14.4811, device='cuda:0'))\n",
      "     | > current_lr: 6.2499999999999995e-06 \n",
      "     | > step_time: 0.5643  (0.5635445696966986)\n",
      "     | > loader_time: 0.0053  (0.009967919758387974)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:10:33 -- STEP: 95/406 -- GLOBAL_STEP: 32975\u001b[0m\n",
      "     | > loss: -0.0008883178234100342  (-0.002911973940698724)\n",
      "     | > log_mle: -0.2217956781387329  (-0.2147701250879388)\n",
      "     | > loss_dur: 0.22090736031532288  (0.21185815114724008)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(6.9846, device='cuda:0')  (tensor(14.3581, device='cuda:0'))\n",
      "     | > current_lr: 6.2499999999999995e-06 \n",
      "     | > step_time: 0.572  (0.58553103647734)\n",
      "     | > loader_time: 0.0049  (0.009996333875154194)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:10:51 -- STEP: 120/406 -- GLOBAL_STEP: 33000\u001b[0m\n",
      "     | > loss: 0.0053194016218185425  (-0.0029788460582494737)\n",
      "     | > log_mle: -0.2249380350112915  (-0.21722765962282817)\n",
      "     | > loss_dur: 0.23025743663311005  (0.2142488135645787)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(18.2241, device='cuda:0')  (tensor(15.1857, device='cuda:0'))\n",
      "     | > current_lr: 6.2499999999999995e-06 \n",
      "     | > step_time: 0.8626  (0.6051173607508342)\n",
      "     | > loader_time: 0.0154  (0.010124868154525757)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:11:07 -- STEP: 145/406 -- GLOBAL_STEP: 33025\u001b[0m\n",
      "     | > loss: 0.004103511571884155  (-0.0024503921640330346)\n",
      "     | > log_mle: -0.21182453632354736  (-0.2193182920587474)\n",
      "     | > loss_dur: 0.21592804789543152  (0.21686789989471436)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(16.1536, device='cuda:0')  (tensor(15.3722, device='cuda:0'))\n",
      "     | > current_lr: 6.2499999999999995e-06 \n",
      "     | > step_time: 0.5318  (0.6137060527143808)\n",
      "     | > loader_time: 0.0134  (0.009985540653097218)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:11:25 -- STEP: 170/406 -- GLOBAL_STEP: 33050\u001b[0m\n",
      "     | > loss: -0.01244121789932251  (-0.0019194980754571806)\n",
      "     | > log_mle: -0.2252335548400879  (-0.22078936310375438)\n",
      "     | > loss_dur: 0.21279233694076538  (0.2188698650282972)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(8.3118, device='cuda:0')  (tensor(15.5273, device='cuda:0'))\n",
      "     | > current_lr: 6.2499999999999995e-06 \n",
      "     | > step_time: 0.5861  (0.6233572777579814)\n",
      "     | > loader_time: 0.0337  (0.010656913589028752)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:11:47 -- STEP: 195/406 -- GLOBAL_STEP: 33075\u001b[0m\n",
      "     | > loss: 0.010572195053100586  (-0.0019346740001287218)\n",
      "     | > log_mle: -0.22194671630859375  (-0.22226454967107528)\n",
      "     | > loss_dur: 0.23251891136169434  (0.22032987567094656)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(6.7877, device='cuda:0')  (tensor(15.4285, device='cuda:0'))\n",
      "     | > current_lr: 6.2499999999999995e-06 \n",
      "     | > step_time: 0.416  (0.6520107574951952)\n",
      "     | > loader_time: 0.0056  (0.011377245340591825)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:12:06 -- STEP: 220/406 -- GLOBAL_STEP: 33100\u001b[0m\n",
      "     | > loss: -0.005663260817527771  (-0.0021245537833734)\n",
      "     | > log_mle: -0.2540459632873535  (-0.22365855195305565)\n",
      "     | > loss_dur: 0.24838270246982574  (0.22153399816968225)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(19.2384, device='cuda:0')  (tensor(15.6940, device='cuda:0'))\n",
      "     | > current_lr: 6.2499999999999995e-06 \n",
      "     | > step_time: 0.638  (0.6635243990204548)\n",
      "     | > loader_time: 0.0052  (0.011486193266781896)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:12:27 -- STEP: 245/406 -- GLOBAL_STEP: 33125\u001b[0m\n",
      "     | > loss: 0.0034746676683425903  (-0.002016753079939863)\n",
      "     | > log_mle: -0.23299956321716309  (-0.2249541185340103)\n",
      "     | > loss_dur: 0.23647423088550568  (0.22293736545407042)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(16.6146, device='cuda:0')  (tensor(16.4046, device='cuda:0'))\n",
      "     | > current_lr: 6.2499999999999995e-06 \n",
      "     | > step_time: 0.9015  (0.6811804489213591)\n",
      "     | > loader_time: 0.0205  (0.011640162370642838)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:12:51 -- STEP: 270/406 -- GLOBAL_STEP: 33150\u001b[0m\n",
      "     | > loss: -0.014459222555160522  (-0.002372557531904292)\n",
      "     | > log_mle: -0.24227750301361084  (-0.22597064751165885)\n",
      "     | > loss_dur: 0.22781828045845032  (0.22359808997975456)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(44.7286, device='cuda:0')  (tensor(17.2305, device='cuda:0'))\n",
      "     | > current_lr: 6.2499999999999995e-06 \n",
      "     | > step_time: 0.8296  (0.7037126355701021)\n",
      "     | > loader_time: 0.0155  (0.012204700929147227)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:13:13 -- STEP: 295/406 -- GLOBAL_STEP: 33175\u001b[0m\n",
      "     | > loss: -0.003409743309020996  (-0.002669422606290396)\n",
      "     | > log_mle: -0.23549485206604004  (-0.22687881679858188)\n",
      "     | > loss_dur: 0.23208510875701904  (0.22420939419229152)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(24.0159, device='cuda:0')  (tensor(17.9894, device='cuda:0'))\n",
      "     | > current_lr: 6.2499999999999995e-06 \n",
      "     | > step_time: 1.1169  (0.718630012415223)\n",
      "     | > loader_time: 0.0072  (0.01250202938661737)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:13:34 -- STEP: 320/406 -- GLOBAL_STEP: 33200\u001b[0m\n",
      "     | > loss: 0.014936402440071106  (-0.0027850823476910586)\n",
      "     | > log_mle: -0.22950303554534912  (-0.22774265110492703)\n",
      "     | > loss_dur: 0.24443943798542023  (0.224957568757236)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(27.7395, device='cuda:0')  (tensor(17.9861, device='cuda:0'))\n",
      "     | > current_lr: 6.2499999999999995e-06 \n",
      "     | > step_time: 0.973  (0.7253180667757986)\n",
      "     | > loader_time: 0.0315  (0.012642354518175126)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:13:55 -- STEP: 345/406 -- GLOBAL_STEP: 33225\u001b[0m\n",
      "     | > loss: -0.0003052949905395508  (-0.002772508928741235)\n",
      "     | > log_mle: -0.241784930229187  (-0.22849105199178055)\n",
      "     | > loss_dur: 0.24147963523864746  (0.22571854306303937)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(20.5218, device='cuda:0')  (tensor(18.2686, device='cuda:0'))\n",
      "     | > current_lr: 6.2499999999999995e-06 \n",
      "     | > step_time: 0.6149  (0.7330200831095378)\n",
      "     | > loader_time: 0.0075  (0.013173245692598647)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:14:16 -- STEP: 370/406 -- GLOBAL_STEP: 33250\u001b[0m\n",
      "     | > loss: -0.013175234198570251  (-0.0028588950634002696)\n",
      "     | > log_mle: -0.25991225242614746  (-0.22931292508099527)\n",
      "     | > loss_dur: 0.2467370182275772  (0.22645403001759504)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(27.4999, device='cuda:0')  (tensor(18.9307, device='cuda:0'))\n",
      "     | > current_lr: 6.2499999999999995e-06 \n",
      "     | > step_time: 0.6153  (0.7387989334157995)\n",
      "     | > loader_time: 0.0085  (0.013363706743395007)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:14:36 -- STEP: 395/406 -- GLOBAL_STEP: 33275\u001b[0m\n",
      "     | > loss: -0.010860458016395569  (-0.002978865519354616)\n",
      "     | > log_mle: -0.24654579162597656  (-0.2300105031532577)\n",
      "     | > loss_dur: 0.235685333609581  (0.2270316376339031)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(32.9017, device='cuda:0')  (tensor(18.8976, device='cuda:0'))\n",
      "     | > current_lr: 6.2499999999999995e-06 \n",
      "     | > step_time: 0.5415  (0.7407363312153876)\n",
      "     | > loader_time: 0.007  (0.013674941847595988)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: 0.0004570186138153076  (0.0004570186138153076)\n",
      "     | > log_mle: -0.21312260627746582  (-0.21312260627746582)\n",
      "     | > loss_dur: 0.21357962489128113  (0.21357962489128113)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: -0.07248081266880035  (-0.07248081266880035)\n",
      "     | > log_mle: -0.252111554145813  (-0.252111554145813)\n",
      "     | > loss_dur: 0.17963074147701263  (0.17963074147701263)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: -0.037556663155555725  (-0.05501873791217804)\n",
      "     | > log_mle: -0.21119201183319092  (-0.23165178298950195)\n",
      "     | > loss_dur: 0.1736353486776352  (0.1766330450773239)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: -0.02195487916469574  (-0.04399745166301727)\n",
      "     | > log_mle: -0.22603940963745117  (-0.2297809918721517)\n",
      "     | > loss_dur: 0.20408453047275543  (0.18578354020913443)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: -0.026891276240348816  (-0.03972090780735016)\n",
      "     | > log_mle: -0.2531849145889282  (-0.23563197255134583)\n",
      "     | > loss_dur: 0.2262936383485794  (0.19591106474399567)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: -0.047337934374809265  (-0.04124431312084198)\n",
      "     | > log_mle: -0.25059354305267334  (-0.23862428665161134)\n",
      "     | > loss_dur: 0.20325560867786407  (0.19737997353076936)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: -0.01995992660522461  (-0.03769691536823908)\n",
      "     | > log_mle: -0.26279282569885254  (-0.2426523764928182)\n",
      "     | > loss_dur: 0.24283289909362793  (0.2049554611245791)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: -0.02362769842147827  (-0.03568702723298754)\n",
      "     | > log_mle: -0.2262483835220337  (-0.24030894892556326)\n",
      "     | > loss_dur: 0.20262068510055542  (0.20462192169257573)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: -0.030434250831604004  (-0.0350304301828146)\n",
      "     | > log_mle: -0.23539626598358154  (-0.23969486355781555)\n",
      "     | > loss_dur: 0.20496201515197754  (0.20466443337500095)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: -0.02224726974964142  (-0.03361007902357313)\n",
      "     | > log_mle: -0.24720072746276855  (-0.24052884843614367)\n",
      "     | > loss_dur: 0.22495345771312714  (0.20691876941257054)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: -0.00887821614742279  (-0.0311368927359581)\n",
      "     | > log_mle: -0.23362398147583008  (-0.2398383617401123)\n",
      "     | > loss_dur: 0.2247457653284073  (0.2087014690041542)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: -0.024433597922325134  (-0.030527502298355103)\n",
      "     | > log_mle: -0.25037217140197754  (-0.24079598080028186)\n",
      "     | > loss_dur: 0.2259385734796524  (0.21026847850192676)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: -0.055787354707717896  (-0.03263248999913534)\n",
      "     | > log_mle: -0.23760676383972168  (-0.2405302127202352)\n",
      "     | > loss_dur: 0.18181940913200378  (0.20789772272109985)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: -0.06387220323085785  (-0.03503554486311399)\n",
      "     | > log_mle: -0.2579420804977417  (-0.24186958716465876)\n",
      "     | > loss_dur: 0.19406987726688385  (0.20683404230154478)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: -0.034183815121650696  (-0.03497470702443804)\n",
      "     | > log_mle: -0.24971473217010498  (-0.24242995466504777)\n",
      "     | > loss_dur: 0.21553091704845428  (0.20745524764060974)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: -0.029537543654441833  (-0.03461222946643829)\n",
      "     | > log_mle: -0.2431730031967163  (-0.24247949123382567)\n",
      "     | > loss_dur: 0.21363545954227448  (0.2078672617673874)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: -0.021243706345558167  (-0.033776696771383286)\n",
      "     | > log_mle: -0.24141108989715576  (-0.2424127161502838)\n",
      "     | > loss_dur: 0.2201673835515976  (0.20863601937890053)\n",
      "\n",
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.003625348210334778 \u001b[0m(-0.0026544034481048584)\n",
      "     | > avg_loss:\u001b[92m -0.033776696771383286 \u001b[0m(-0.005732855759561062)\n",
      "     | > avg_log_mle:\u001b[92m -0.2424127161502838 \u001b[0m(-0.002573639154434204)\n",
      "     | > avg_loss_dur:\u001b[92m 0.20863601937890053 \u001b[0m(-0.0031592166051268578)\n",
      "\n",
      " > BEST MODEL : train/run-February-22-2025_10+59PM-fa84af3/best_model_33286.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 26/100\u001b[0m\n",
      " --> train/run-February-22-2025_10+59PM-fa84af3\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-23 01:14:57) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:15:06 -- STEP: 14/406 -- GLOBAL_STEP: 33300\u001b[0m\n",
      "     | > loss: -0.0014759451150894165  (-0.02050786784717015)\n",
      "     | > log_mle: -0.2220158576965332  (-0.2134121826716832)\n",
      "     | > loss_dur: 0.2205399125814438  (0.19290431482451303)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(27.0337, device='cuda:0')  (tensor(10.1054, device='cuda:0'))\n",
      "     | > current_lr: 6.5e-06 \n",
      "     | > step_time: 0.8192  (0.43648666994912283)\n",
      "     | > loader_time: 0.0063  (0.006384117262704032)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:15:21 -- STEP: 39/406 -- GLOBAL_STEP: 33325\u001b[0m\n",
      "     | > loss: 0.007552608847618103  (-0.01019928012138758)\n",
      "     | > log_mle: -0.20615530014038086  (-0.21102807460687098)\n",
      "     | > loss_dur: 0.21370790898799896  (0.20082879448548338)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(12.4615, device='cuda:0')  (tensor(10.0574, device='cuda:0'))\n",
      "     | > current_lr: 6.5e-06 \n",
      "     | > step_time: 0.3423  (0.520393750606439)\n",
      "     | > loader_time: 0.0041  (0.006879690365913587)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:15:40 -- STEP: 64/406 -- GLOBAL_STEP: 33350\u001b[0m\n",
      "     | > loss: -0.014395952224731445  (-0.006877110106870534)\n",
      "     | > log_mle: -0.22299516201019287  (-0.21259939670562744)\n",
      "     | > loss_dur: 0.20859920978546143  (0.2057222865987569)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(17.2876, device='cuda:0')  (tensor(11.7730, device='cuda:0'))\n",
      "     | > current_lr: 6.5e-06 \n",
      "     | > step_time: 0.4602  (0.6081295013427733)\n",
      "     | > loader_time: 0.0166  (0.008172404021024704)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:15:57 -- STEP: 89/406 -- GLOBAL_STEP: 33375\u001b[0m\n",
      "     | > loss: -0.00239504873752594  (-0.00533352474148354)\n",
      "     | > log_mle: -0.21860289573669434  (-0.21523829524436694)\n",
      "     | > loss_dur: 0.2162078469991684  (0.20990477050288336)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(16.3758, device='cuda:0')  (tensor(12.9458, device='cuda:0'))\n",
      "     | > current_lr: 6.5e-06 \n",
      "     | > step_time: 0.7662  (0.6276043559728041)\n",
      "     | > loader_time: 0.0048  (0.00999250840604975)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:16:14 -- STEP: 114/406 -- GLOBAL_STEP: 33400\u001b[0m\n",
      "     | > loss: -0.03243982791900635  (-0.005852588305347845)\n",
      "     | > log_mle: -0.2546952962875366  (-0.21835466539650633)\n",
      "     | > loss_dur: 0.22225546836853027  (0.21250207709115845)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(15.9033, device='cuda:0')  (tensor(14.6370, device='cuda:0'))\n",
      "     | > current_lr: 6.5e-06 \n",
      "     | > step_time: 0.3923  (0.638546125930652)\n",
      "     | > loader_time: 0.0066  (0.010685531716597703)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:16:32 -- STEP: 139/406 -- GLOBAL_STEP: 33425\u001b[0m\n",
      "     | > loss: -0.00018762052059173584  (-0.005161841460269133)\n",
      "     | > log_mle: -0.22752666473388672  (-0.22036499857044908)\n",
      "     | > loss_dur: 0.22733904421329498  (0.21520315711017993)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(17.1061, device='cuda:0')  (tensor(15.8864, device='cuda:0'))\n",
      "     | > current_lr: 6.5e-06 \n",
      "     | > step_time: 0.6186  (0.6482898279917323)\n",
      "     | > loader_time: 0.0137  (0.010752573287744312)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:16:52 -- STEP: 164/406 -- GLOBAL_STEP: 33450\u001b[0m\n",
      "     | > loss: 0.004695907235145569  (-0.004910618793673633)\n",
      "     | > log_mle: -0.21898043155670166  (-0.22189420679720437)\n",
      "     | > loss_dur: 0.22367633879184723  (0.21698358800353074)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(21.2363, device='cuda:0')  (tensor(17.0983, device='cuda:0'))\n",
      "     | > current_lr: 6.5e-06 \n",
      "     | > step_time: 0.9047  (0.665921859624909)\n",
      "     | > loader_time: 0.0226  (0.011244635756422833)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:17:12 -- STEP: 189/406 -- GLOBAL_STEP: 33475\u001b[0m\n",
      "     | > loss: -0.010302811861038208  (-0.005211460054236115)\n",
      "     | > log_mle: -0.2351323366165161  (-0.22348062323514747)\n",
      "     | > loss_dur: 0.2248295247554779  (0.21826916318091136)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(29.7862, device='cuda:0')  (tensor(17.1240, device='cuda:0'))\n",
      "     | > current_lr: 6.5e-06 \n",
      "     | > step_time: 0.7404  (0.682653819442426)\n",
      "     | > loader_time: 0.0208  (0.011468000512905223)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:17:31 -- STEP: 214/406 -- GLOBAL_STEP: 33500\u001b[0m\n",
      "     | > loss: -0.009606778621673584  (-0.005323914723975636)\n",
      "     | > log_mle: -0.2404841184616089  (-0.22475976921687615)\n",
      "     | > loss_dur: 0.2308773398399353  (0.21943585449290054)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(13.2190, device='cuda:0')  (tensor(16.9178, device='cuda:0'))\n",
      "     | > current_lr: 6.5e-06 \n",
      "     | > step_time: 0.5994  (0.6877469737953114)\n",
      "     | > loader_time: 0.0132  (0.011943077372613355)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:17:53 -- STEP: 239/406 -- GLOBAL_STEP: 33525\u001b[0m\n",
      "     | > loss: -0.002752631902694702  (-0.00530712057107662)\n",
      "     | > log_mle: -0.2319575548171997  (-0.2260530209441564)\n",
      "     | > loss_dur: 0.229204922914505  (0.22074590037307978)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(37.8208, device='cuda:0')  (tensor(17.1521, device='cuda:0'))\n",
      "     | > current_lr: 6.5e-06 \n",
      "     | > step_time: 0.9719  (0.7080204546700959)\n",
      "     | > loader_time: 0.0184  (0.012362056197481675)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:18:15 -- STEP: 264/406 -- GLOBAL_STEP: 33550\u001b[0m\n",
      "     | > loss: -0.0045731812715530396  (-0.005650043826211582)\n",
      "     | > log_mle: -0.22923505306243896  (-0.22707987689610684)\n",
      "     | > loss_dur: 0.22466187179088593  (0.22142983306989525)\n",
      "     | > amp_scaler: 4096.0  (7850.666666666667)\n",
      "     | > grad_norm: tensor(48.4702, device='cuda:0')  (tensor(19.0874, device='cuda:0'))\n",
      "     | > current_lr: 6.5e-06 \n",
      "     | > step_time: 0.7483  (0.7203997969627379)\n",
      "     | > loader_time: 0.0074  (0.012803911259680084)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:18:34 -- STEP: 289/406 -- GLOBAL_STEP: 33575\u001b[0m\n",
      "     | > loss: -0.00027939677238464355  (-0.0059030007016700045)\n",
      "     | > log_mle: -0.22473692893981934  (-0.2279825210571289)\n",
      "     | > loss_dur: 0.2244575321674347  (0.22207952035545891)\n",
      "     | > amp_scaler: 4096.0  (7525.868512110726)\n",
      "     | > grad_norm: tensor(27.1405, device='cuda:0')  (tensor(20.4347, device='cuda:0'))\n",
      "     | > current_lr: 6.5e-06 \n",
      "     | > step_time: 0.4707  (0.7223011275888724)\n",
      "     | > loader_time: 0.0205  (0.013031866311201996)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:18:57 -- STEP: 314/406 -- GLOBAL_STEP: 33600\u001b[0m\n",
      "     | > loss: -0.015475794672966003  (-0.006165823644133889)\n",
      "     | > log_mle: -0.24642837047576904  (-0.2289119385609961)\n",
      "     | > loss_dur: 0.23095257580280304  (0.2227461149168622)\n",
      "     | > amp_scaler: 4096.0  (7252.789808917198)\n",
      "     | > grad_norm: tensor(26.5646, device='cuda:0')  (tensor(20.3569, device='cuda:0'))\n",
      "     | > current_lr: 6.5e-06 \n",
      "     | > step_time: 0.6737  (0.7366045880469548)\n",
      "     | > loader_time: 0.0297  (0.01350289165594016)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:19:20 -- STEP: 339/406 -- GLOBAL_STEP: 33625\u001b[0m\n",
      "     | > loss: -0.00972774624824524  (-0.0060126403879627015)\n",
      "     | > log_mle: -0.24285638332366943  (-0.22963189340270726)\n",
      "     | > loss_dur: 0.2331286370754242  (0.22361925301474456)\n",
      "     | > amp_scaler: 4096.0  (7019.988200589971)\n",
      "     | > grad_norm: tensor(15.0566, device='cuda:0')  (tensor(20.4063, device='cuda:0'))\n",
      "     | > current_lr: 6.5e-06 \n",
      "     | > step_time: 1.1014  (0.7492303377055843)\n",
      "     | > loader_time: 0.0064  (0.013595521977517457)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:19:42 -- STEP: 364/406 -- GLOBAL_STEP: 33650\u001b[0m\n",
      "     | > loss: -0.007714956998825073  (-0.005962290606655918)\n",
      "     | > log_mle: -0.2360999584197998  (-0.2304175276677687)\n",
      "     | > loss_dur: 0.22838500142097473  (0.22445523706111278)\n",
      "     | > amp_scaler: 4096.0  (6819.1648351648355)\n",
      "     | > grad_norm: tensor(20.7941, device='cuda:0')  (tensor(20.9592, device='cuda:0'))\n",
      "     | > current_lr: 6.5e-06 \n",
      "     | > step_time: 0.8049  (0.7558250021148517)\n",
      "     | > loader_time: 0.007  (0.013572423667698116)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:20:05 -- STEP: 389/406 -- GLOBAL_STEP: 33675\u001b[0m\n",
      "     | > loss: -0.014175459742546082  (-0.00593591789813152)\n",
      "     | > log_mle: -0.23909986019134521  (-0.2310868305534814)\n",
      "     | > loss_dur: 0.22492440044879913  (0.22515091265534987)\n",
      "     | > amp_scaler: 4096.0  (6644.154241645244)\n",
      "     | > grad_norm: tensor(13.1625, device='cuda:0')  (tensor(21.2768, device='cuda:0'))\n",
      "     | > current_lr: 6.5e-06 \n",
      "     | > step_time: 1.0087  (0.7653874652244748)\n",
      "     | > loader_time: 0.0135  (0.013632077484326988)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: -0.00577177107334137  (-0.00577177107334137)\n",
      "     | > log_mle: -0.21482133865356445  (-0.21482133865356445)\n",
      "     | > loss_dur: 0.20904956758022308  (0.20904956758022308)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: -0.0776013433933258  (-0.0776013433933258)\n",
      "     | > log_mle: -0.2538754940032959  (-0.2538754940032959)\n",
      "     | > loss_dur: 0.1762741506099701  (0.1762741506099701)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: -0.03496928513050079  (-0.0562853142619133)\n",
      "     | > log_mle: -0.2129439115524292  (-0.23340970277786255)\n",
      "     | > loss_dur: 0.1779746264219284  (0.17712438851594925)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: -0.015675276517868042  (-0.042748635013898216)\n",
      "     | > log_mle: -0.22760295867919922  (-0.23147412141164145)\n",
      "     | > loss_dur: 0.21192768216133118  (0.18872548639774323)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: -0.03937850892543793  (-0.04190610349178314)\n",
      "     | > log_mle: -0.2550375461578369  (-0.2373649775981903)\n",
      "     | > loss_dur: 0.215659037232399  (0.19545887410640717)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: -0.04669158160686493  (-0.0428631991147995)\n",
      "     | > log_mle: -0.25277185440063477  (-0.2404463529586792)\n",
      "     | > loss_dur: 0.20608027279376984  (0.1975831538438797)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: -0.019414544105529785  (-0.03895508994658788)\n",
      "     | > log_mle: -0.2645760774612427  (-0.24446797370910645)\n",
      "     | > loss_dur: 0.2451615333557129  (0.20551288376251856)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: -0.024489358067512512  (-0.03688855682100568)\n",
      "     | > log_mle: -0.2278677225112915  (-0.24209650925227574)\n",
      "     | > loss_dur: 0.203378364443779  (0.20520795243127005)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: -0.034319281578063965  (-0.03656739741563797)\n",
      "     | > log_mle: -0.2371976375579834  (-0.2414841502904892)\n",
      "     | > loss_dur: 0.20287835597991943  (0.20491675287485123)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: -0.02061237394809723  (-0.03479461703035566)\n",
      "     | > log_mle: -0.24966907501220703  (-0.24239358637068006)\n",
      "     | > loss_dur: 0.2290567010641098  (0.2075989693403244)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: -0.014080658555030823  (-0.032723221182823184)\n",
      "     | > log_mle: -0.23567605018615723  (-0.24172183275222778)\n",
      "     | > loss_dur: 0.2215953916311264  (0.2089986115694046)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: -0.029953598976135254  (-0.032471437345851555)\n",
      "     | > log_mle: -0.2519652843475342  (-0.24265305562452835)\n",
      "     | > loss_dur: 0.22201168537139893  (0.21018161827867682)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: -0.055728793144226074  (-0.03440955032904943)\n",
      "     | > log_mle: -0.23963117599487305  (-0.2424012323220571)\n",
      "     | > loss_dur: 0.18390238285064697  (0.20799168199300766)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: -0.06836962699890137  (-0.03702186391903804)\n",
      "     | > log_mle: -0.2595248222351074  (-0.24371843154613787)\n",
      "     | > loss_dur: 0.19115519523620605  (0.20669656762709984)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: -0.03246261179447174  (-0.03669620305299759)\n",
      "     | > log_mle: -0.2519214153289795  (-0.244304358959198)\n",
      "     | > loss_dur: 0.21945880353450775  (0.2076081559062004)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: -0.037203818559646606  (-0.03673004408677419)\n",
      "     | > log_mle: -0.24535632133483887  (-0.24437448978424073)\n",
      "     | > loss_dur: 0.20815250277519226  (0.20764444569746654)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: -0.024532154202461243  (-0.03596767596900463)\n",
      "     | > log_mle: -0.24346017837524414  (-0.24431734532117844)\n",
      "     | > loss_dur: 0.2189280241727829  (0.2083496693521738)\n",
      "\n",
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[91m 0.00414624810218811 \u001b[0m(+0.0005208998918533325)\n",
      "     | > avg_loss:\u001b[92m -0.03596767596900463 \u001b[0m(-0.0021909791976213455)\n",
      "     | > avg_log_mle:\u001b[92m -0.24431734532117844 \u001b[0m(-0.0019046291708946228)\n",
      "     | > avg_loss_dur:\u001b[92m 0.2083496693521738 \u001b[0m(-0.0002863500267267227)\n",
      "\n",
      " > BEST MODEL : train/run-February-22-2025_10+59PM-fa84af3/best_model_33692.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 27/100\u001b[0m\n",
      " --> train/run-February-22-2025_10+59PM-fa84af3\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-23 01:20:31) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:20:37 -- STEP: 8/406 -- GLOBAL_STEP: 33700\u001b[0m\n",
      "     | > loss: -0.04811745882034302  (-0.024463530629873276)\n",
      "     | > log_mle: -0.22244560718536377  (-0.21295006573200226)\n",
      "     | > loss_dur: 0.17432814836502075  (0.18848653510212898)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(2.3587, device='cuda:0')  (tensor(8.7495, device='cuda:0'))\n",
      "     | > current_lr: 6.75e-06 \n",
      "     | > step_time: 0.2704  (0.3932614326477051)\n",
      "     | > loader_time: 0.0038  (0.006319880485534668)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:20:51 -- STEP: 33/406 -- GLOBAL_STEP: 33725\u001b[0m\n",
      "     | > loss: 0.007111281156539917  (-0.014838280099810974)\n",
      "     | > log_mle: -0.2059231996536255  (-0.2131824674028339)\n",
      "     | > loss_dur: 0.2130344808101654  (0.19834418730302292)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(12.8336, device='cuda:0')  (tensor(9.6956, device='cuda:0'))\n",
      "     | > current_lr: 6.75e-06 \n",
      "     | > step_time: 0.2573  (0.5048646637887666)\n",
      "     | > loader_time: 0.0042  (0.007451389775131688)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:21:07 -- STEP: 58/406 -- GLOBAL_STEP: 33750\u001b[0m\n",
      "     | > loss: -0.010421156883239746  (-0.00872310045464285)\n",
      "     | > log_mle: -0.219832181930542  (-0.2142384360576498)\n",
      "     | > loss_dur: 0.20941102504730225  (0.20551533560300694)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(24.2934, device='cuda:0')  (tensor(12.9132, device='cuda:0'))\n",
      "     | > current_lr: 6.75e-06 \n",
      "     | > step_time: 0.4684  (0.551817347263468)\n",
      "     | > loader_time: 0.0293  (0.008968694456692395)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:21:22 -- STEP: 83/406 -- GLOBAL_STEP: 33775\u001b[0m\n",
      "     | > loss: -0.007120534777641296  (-0.00832240588693733)\n",
      "     | > log_mle: -0.2294853925704956  (-0.21672846035784984)\n",
      "     | > loss_dur: 0.2223648577928543  (0.2084060544709125)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(15.3208, device='cuda:0')  (tensor(15.5259, device='cuda:0'))\n",
      "     | > current_lr: 6.75e-06 \n",
      "     | > step_time: 0.5785  (0.5706576439271492)\n",
      "     | > loader_time: 0.0147  (0.009251494005501985)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:21:39 -- STEP: 108/406 -- GLOBAL_STEP: 33800\u001b[0m\n",
      "     | > loss: -0.015239939093589783  (-0.008591207365194956)\n",
      "     | > log_mle: -0.22280657291412354  (-0.21939009648782234)\n",
      "     | > loss_dur: 0.20756663382053375  (0.2107988891226274)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(13.5300, device='cuda:0')  (tensor(16.0138, device='cuda:0'))\n",
      "     | > current_lr: 6.75e-06 \n",
      "     | > step_time: 0.6298  (0.5894263982772829)\n",
      "     | > loader_time: 0.0057  (0.009122108971631087)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:21:57 -- STEP: 133/406 -- GLOBAL_STEP: 33825\u001b[0m\n",
      "     | > loss: -0.013291627168655396  (-0.00872643448804554)\n",
      "     | > log_mle: -0.23670578002929688  (-0.2220342401275061)\n",
      "     | > loss_dur: 0.22341415286064148  (0.21330780563946056)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(12.4592, device='cuda:0')  (tensor(16.1032, device='cuda:0'))\n",
      "     | > current_lr: 6.75e-06 \n",
      "     | > step_time: 0.6685  (0.6075537419856942)\n",
      "     | > loader_time: 0.0089  (0.009592196098843911)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:22:15 -- STEP: 158/406 -- GLOBAL_STEP: 33850\u001b[0m\n",
      "     | > loss: -0.005108699202537537  (-0.007794903520541857)\n",
      "     | > log_mle: -0.23830246925354004  (-0.22362648761725124)\n",
      "     | > loss_dur: 0.2331937700510025  (0.21583158409670933)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(26.1154, device='cuda:0')  (tensor(16.0431, device='cuda:0'))\n",
      "     | > current_lr: 6.75e-06 \n",
      "     | > step_time: 0.4365  (0.6226587446430065)\n",
      "     | > loader_time: 0.0064  (0.009878682184822954)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:22:37 -- STEP: 183/406 -- GLOBAL_STEP: 33875\u001b[0m\n",
      "     | > loss: -0.016552716493606567  (-0.007856695704121406)\n",
      "     | > log_mle: -0.24014997482299805  (-0.22503694549935763)\n",
      "     | > loss_dur: 0.22359725832939148  (0.21718024979523617)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(22.3744, device='cuda:0')  (tensor(16.3594, device='cuda:0'))\n",
      "     | > current_lr: 6.75e-06 \n",
      "     | > step_time: 0.7355  (0.6555226357256785)\n",
      "     | > loader_time: 0.0217  (0.010831138475345127)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:22:57 -- STEP: 208/406 -- GLOBAL_STEP: 33900\u001b[0m\n",
      "     | > loss: -0.028413161635398865  (-0.007853396666737707)\n",
      "     | > log_mle: -0.2415989637374878  (-0.22632270879470384)\n",
      "     | > loss_dur: 0.21318580210208893  (0.2184693121279661)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(20.7251, device='cuda:0')  (tensor(16.5904, device='cuda:0'))\n",
      "     | > current_lr: 6.75e-06 \n",
      "     | > step_time: 1.1626  (0.6705167110149681)\n",
      "     | > loader_time: 0.0102  (0.010897440405992359)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:23:15 -- STEP: 233/406 -- GLOBAL_STEP: 33925\u001b[0m\n",
      "     | > loss: -0.009206727147102356  (-0.008087783987941665)\n",
      "     | > log_mle: -0.24290573596954346  (-0.22774152233876896)\n",
      "     | > loss_dur: 0.2336990088224411  (0.21965373835082727)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(27.7882, device='cuda:0')  (tensor(16.9677, device='cuda:0'))\n",
      "     | > current_lr: 6.75e-06 \n",
      "     | > step_time: 0.7604  (0.6764380461156628)\n",
      "     | > loader_time: 0.0161  (0.01128670790676395)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:23:36 -- STEP: 258/406 -- GLOBAL_STEP: 33950\u001b[0m\n",
      "     | > loss: 0.006512582302093506  (-0.008162231697130576)\n",
      "     | > log_mle: -0.22533607482910156  (-0.2288298861000889)\n",
      "     | > loss_dur: 0.23184865713119507  (0.2206676544029583)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(14.3976, device='cuda:0')  (tensor(17.1482, device='cuda:0'))\n",
      "     | > current_lr: 6.75e-06 \n",
      "     | > step_time: 0.7026  (0.68753970870676)\n",
      "     | > loader_time: 0.0059  (0.01190131486848343)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:23:55 -- STEP: 283/406 -- GLOBAL_STEP: 33975\u001b[0m\n",
      "     | > loss: -0.0006814152002334595  (-0.008515065160741237)\n",
      "     | > log_mle: -0.2389587163925171  (-0.22992549346950786)\n",
      "     | > loss_dur: 0.23827730119228363  (0.22141042830876662)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(17.8286, device='cuda:0')  (tensor(16.9101, device='cuda:0'))\n",
      "     | > current_lr: 6.75e-06 \n",
      "     | > step_time: 0.8098  (0.6920971819874258)\n",
      "     | > loader_time: 0.0052  (0.012265699912297008)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:24:15 -- STEP: 308/406 -- GLOBAL_STEP: 34000\u001b[0m\n",
      "     | > loss: -0.009675770998001099  (-0.008591700151756216)\n",
      "     | > log_mle: -0.24224865436553955  (-0.2307541130425094)\n",
      "     | > loss_dur: 0.23257288336753845  (0.2221624128907532)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(21.0224, device='cuda:0')  (tensor(16.9857, device='cuda:0'))\n",
      "     | > current_lr: 6.75e-06 \n",
      "     | > step_time: 0.837  (0.699239170396483)\n",
      "     | > loader_time: 0.0078  (0.012401878059684457)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:24:40 -- STEP: 333/406 -- GLOBAL_STEP: 34025\u001b[0m\n",
      "     | > loss: -0.019431665539741516  (-0.008597105965242016)\n",
      "     | > log_mle: -0.2511146068572998  (-0.23145211673713662)\n",
      "     | > loss_dur: 0.2316829413175583  (0.2228550107718946)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(10.7768, device='cuda:0')  (tensor(17.3789, device='cuda:0'))\n",
      "     | > current_lr: 6.75e-06 \n",
      "     | > step_time: 0.5138  (0.7201846970452206)\n",
      "     | > loader_time: 0.0089  (0.01324442843417148)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:25:05 -- STEP: 358/406 -- GLOBAL_STEP: 34050\u001b[0m\n",
      "     | > loss: -0.02913406491279602  (-0.00857144852257308)\n",
      "     | > log_mle: -0.25849950313568115  (-0.23229071980748098)\n",
      "     | > loss_dur: 0.22936543822288513  (0.2237192712849079)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(9.2273, device='cuda:0')  (tensor(17.5325, device='cuda:0'))\n",
      "     | > current_lr: 6.75e-06 \n",
      "     | > step_time: 0.6345  (0.7389481527179317)\n",
      "     | > loader_time: 0.0208  (0.01358703128452408)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:25:29 -- STEP: 383/406 -- GLOBAL_STEP: 34075\u001b[0m\n",
      "     | > loss: -0.008472934365272522  (-0.008694198750951582)\n",
      "     | > log_mle: -0.23621690273284912  (-0.23298343790417864)\n",
      "     | > loss_dur: 0.2277439683675766  (0.22428923915322704)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(20.1778, device='cuda:0')  (tensor(18.0574, device='cuda:0'))\n",
      "     | > current_lr: 6.75e-06 \n",
      "     | > step_time: 1.0626  (0.7516776257955688)\n",
      "     | > loader_time: 0.0314  (0.013885155047822563)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: -0.006991863250732422  (-0.006991863250732422)\n",
      "     | > log_mle: -0.21565186977386475  (-0.21565186977386475)\n",
      "     | > loss_dur: 0.20866000652313232  (0.20866000652313232)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: -0.07880882918834686  (-0.07880882918834686)\n",
      "     | > log_mle: -0.25420284271240234  (-0.25420284271240234)\n",
      "     | > loss_dur: 0.17539401352405548  (0.17539401352405548)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: -0.038708776235580444  (-0.058758802711963654)\n",
      "     | > log_mle: -0.2144298553466797  (-0.23431634902954102)\n",
      "     | > loss_dur: 0.17572107911109924  (0.17555754631757736)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: -0.027246728539466858  (-0.04825477798779806)\n",
      "     | > log_mle: -0.22835028171539307  (-0.23232765992482504)\n",
      "     | > loss_dur: 0.2011035531759262  (0.18407288193702698)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: -0.041469573974609375  (-0.046558476984500885)\n",
      "     | > log_mle: -0.2546966075897217  (-0.2379198968410492)\n",
      "     | > loss_dur: 0.2132270336151123  (0.1913614198565483)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: -0.046925485134124756  (-0.04663187861442566)\n",
      "     | > log_mle: -0.253658652305603  (-0.24106764793395996)\n",
      "     | > loss_dur: 0.20673316717147827  (0.1944357693195343)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: -0.020934075117111206  (-0.04234891136487325)\n",
      "     | > log_mle: -0.2648235559463501  (-0.245026965936025)\n",
      "     | > loss_dur: 0.2438894808292389  (0.20267805457115173)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: -0.030915334820747375  (-0.040715543287140984)\n",
      "     | > log_mle: -0.22903668880462646  (-0.24274264063153947)\n",
      "     | > loss_dur: 0.1981213539838791  (0.2020270973443985)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: -0.04123280942440033  (-0.0407802015542984)\n",
      "     | > log_mle: -0.23764312267303467  (-0.24210520088672638)\n",
      "     | > loss_dur: 0.19641031324863434  (0.20132499933242798)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: -0.027121350169181824  (-0.039262551400396556)\n",
      "     | > log_mle: -0.25005507469177246  (-0.24298852019839817)\n",
      "     | > loss_dur: 0.22293372452259064  (0.20372596879800162)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: -0.01523447036743164  (-0.03685974329710007)\n",
      "     | > log_mle: -0.2362959384918213  (-0.24231926202774048)\n",
      "     | > loss_dur: 0.22106146812438965  (0.20545951873064042)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: -0.03321555256843567  (-0.03652845323085785)\n",
      "     | > log_mle: -0.2521522045135498  (-0.2432131658900868)\n",
      "     | > loss_dur: 0.21893665194511414  (0.20668471265922894)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: -0.05539505183696747  (-0.03810066978136698)\n",
      "     | > log_mle: -0.24041509628295898  (-0.24297999342282614)\n",
      "     | > loss_dur: 0.18502004444599152  (0.20487932364145914)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: -0.07097859680652618  (-0.04062974109099461)\n",
      "     | > log_mle: -0.2605701684951782  (-0.24433308381300706)\n",
      "     | > loss_dur: 0.18959157168865204  (0.20370334272201246)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: -0.03350698947906494  (-0.040120973118713925)\n",
      "     | > log_mle: -0.25210368633270264  (-0.24488812685012817)\n",
      "     | > loss_dur: 0.2185966968536377  (0.20476715373141424)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: -0.035875290632247925  (-0.039837927619616194)\n",
      "     | > log_mle: -0.24621808528900146  (-0.24497679074605305)\n",
      "     | > loss_dur: 0.21034279465675354  (0.20513886312643687)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: -0.03076930344104767  (-0.03927113860845566)\n",
      "     | > log_mle: -0.24460792541503906  (-0.24495373666286469)\n",
      "     | > loss_dur: 0.2138386219739914  (0.20568259805440903)\n",
      "\n",
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.0036232173442840576 \u001b[0m(-0.0005230307579040527)\n",
      "     | > avg_loss:\u001b[92m -0.03927113860845566 \u001b[0m(-0.003303462639451027)\n",
      "     | > avg_log_mle:\u001b[92m -0.24495373666286469 \u001b[0m(-0.0006363913416862488)\n",
      "     | > avg_loss_dur:\u001b[92m 0.20568259805440903 \u001b[0m(-0.002667071297764778)\n",
      "\n",
      " > BEST MODEL : train/run-February-22-2025_10+59PM-fa84af3/best_model_34098.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 28/100\u001b[0m\n",
      " --> train/run-February-22-2025_10+59PM-fa84af3\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-23 01:26:02) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:26:05 -- STEP: 2/406 -- GLOBAL_STEP: 34100\u001b[0m\n",
      "     | > loss: -0.04110805690288544  (-0.03671542555093765)\n",
      "     | > log_mle: -0.22904491424560547  (-0.22173726558685303)\n",
      "     | > loss_dur: 0.18793685734272003  (0.18502184003591537)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(12.5441, device='cuda:0')  (tensor(7.2592, device='cuda:0'))\n",
      "     | > current_lr: 7e-06 \n",
      "     | > step_time: 0.3389  (0.7819076776504517)\n",
      "     | > loader_time: 0.0063  (0.01496875286102295)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:26:23 -- STEP: 27/406 -- GLOBAL_STEP: 34125\u001b[0m\n",
      "     | > loss: -0.011518865823745728  (-0.01775305856157232)\n",
      "     | > log_mle: -0.21092987060546875  (-0.21494664969267668)\n",
      "     | > loss_dur: 0.19941100478172302  (0.19719359113110435)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(4.6476, device='cuda:0')  (tensor(8.9564, device='cuda:0'))\n",
      "     | > current_lr: 7e-06 \n",
      "     | > step_time: 1.1173  (0.7092380611984818)\n",
      "     | > loader_time: 0.0056  (0.010053970195628977)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:26:42 -- STEP: 52/406 -- GLOBAL_STEP: 34150\u001b[0m\n",
      "     | > loss: 0.0268317312002182  (-0.012787688523530957)\n",
      "     | > log_mle: -0.21544992923736572  (-0.2156409346140348)\n",
      "     | > loss_dur: 0.24228166043758392  (0.20285324609050384)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(29.2724, device='cuda:0')  (tensor(11.2583, device='cuda:0'))\n",
      "     | > current_lr: 7e-06 \n",
      "     | > step_time: 0.9969  (0.7269253180577204)\n",
      "     | > loader_time: 0.0076  (0.012014370698195238)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:27:00 -- STEP: 77/406 -- GLOBAL_STEP: 34175\u001b[0m\n",
      "     | > loss: 0.013810977339744568  (-0.011495953643476805)\n",
      "     | > log_mle: -0.2146977186203003  (-0.21779570177003935)\n",
      "     | > loss_dur: 0.22850869596004486  (0.2062997481265626)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(14.2187, device='cuda:0')  (tensor(15.0802, device='cuda:0'))\n",
      "     | > current_lr: 7e-06 \n",
      "     | > step_time: 0.6931  (0.7166873417891465)\n",
      "     | > loader_time: 0.0085  (0.0118326676356328)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:27:17 -- STEP: 102/406 -- GLOBAL_STEP: 34200\u001b[0m\n",
      "     | > loss: -0.033680886030197144  (-0.011278623605475702)\n",
      "     | > log_mle: -0.2401031255722046  (-0.22073734040353812)\n",
      "     | > loss_dur: 0.20642223954200745  (0.2094587167980625)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(28.8975, device='cuda:0')  (tensor(15.4425, device='cuda:0'))\n",
      "     | > current_lr: 7e-06 \n",
      "     | > step_time: 0.7016  (0.6977085552963556)\n",
      "     | > loader_time: 0.0072  (0.011984072479547239)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:27:33 -- STEP: 127/406 -- GLOBAL_STEP: 34225\u001b[0m\n",
      "     | > loss: -0.0012607276439666748  (-0.011414323266096938)\n",
      "     | > log_mle: -0.23508894443511963  (-0.22325878537545993)\n",
      "     | > loss_dur: 0.23382821679115295  (0.21184446210936303)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(27.9088, device='cuda:0')  (tensor(17.5865, device='cuda:0'))\n",
      "     | > current_lr: 7e-06 \n",
      "     | > step_time: 0.3906  (0.68788248159754)\n",
      "     | > loader_time: 0.0056  (0.01255593149680791)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:27:51 -- STEP: 152/406 -- GLOBAL_STEP: 34250\u001b[0m\n",
      "     | > loss: 0.005936384201049805  (-0.010998876177166637)\n",
      "     | > log_mle: -0.23185980319976807  (-0.22519830261406146)\n",
      "     | > loss_dur: 0.23779618740081787  (0.2141994264368949)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(16.2140, device='cuda:0')  (tensor(18.2294, device='cuda:0'))\n",
      "     | > current_lr: 7e-06 \n",
      "     | > step_time: 0.404  (0.6851631026518971)\n",
      "     | > loader_time: 0.0057  (0.012301358737443624)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:28:10 -- STEP: 177/406 -- GLOBAL_STEP: 34275\u001b[0m\n",
      "     | > loss: -0.023505836725234985  (-0.011100712553255973)\n",
      "     | > log_mle: -0.2376720905303955  (-0.22664568653214448)\n",
      "     | > loss_dur: 0.21416625380516052  (0.2155449739788886)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(16.9540, device='cuda:0')  (tensor(18.3853, device='cuda:0'))\n",
      "     | > current_lr: 7e-06 \n",
      "     | > step_time: 0.4254  (0.6936885960358009)\n",
      "     | > loader_time: 0.0242  (0.01249924756712833)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:28:28 -- STEP: 202/406 -- GLOBAL_STEP: 34300\u001b[0m\n",
      "     | > loss: 0.0017653703689575195  (-0.011045512070160097)\n",
      "     | > log_mle: -0.22735297679901123  (-0.2280305045666081)\n",
      "     | > loss_dur: 0.22911834716796875  (0.21698499249644806)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(18.2733, device='cuda:0')  (tensor(18.4235, device='cuda:0'))\n",
      "     | > current_lr: 7e-06 \n",
      "     | > step_time: 0.5759  (0.6975972770464304)\n",
      "     | > loader_time: 0.0065  (0.012324946941715658)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:28:48 -- STEP: 227/406 -- GLOBAL_STEP: 34325\u001b[0m\n",
      "     | > loss: -0.0036315619945526123  (-0.011227147957301871)\n",
      "     | > log_mle: -0.23559296131134033  (-0.22944196100276998)\n",
      "     | > loss_dur: 0.23196139931678772  (0.21821481304546816)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(17.8715, device='cuda:0')  (tensor(18.4914, device='cuda:0'))\n",
      "     | > current_lr: 7e-06 \n",
      "     | > step_time: 1.1632  (0.7053761408717623)\n",
      "     | > loader_time: 0.0064  (0.012445464533331112)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:29:06 -- STEP: 252/406 -- GLOBAL_STEP: 34350\u001b[0m\n",
      "     | > loss: -0.0039669424295425415  (-0.011381525841970289)\n",
      "     | > log_mle: -0.23789286613464355  (-0.23070462497453842)\n",
      "     | > loss_dur: 0.233925923705101  (0.21932309913256817)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(34.2423, device='cuda:0')  (tensor(18.8659, device='cuda:0'))\n",
      "     | > current_lr: 7e-06 \n",
      "     | > step_time: 0.6184  (0.7078506520816259)\n",
      "     | > loader_time: 0.0072  (0.01246853101821173)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:29:25 -- STEP: 277/406 -- GLOBAL_STEP: 34375\u001b[0m\n",
      "     | > loss: -0.024823740124702454  (-0.011807008932213486)\n",
      "     | > log_mle: -0.23897230625152588  (-0.23177871850423434)\n",
      "     | > loss_dur: 0.21414856612682343  (0.2199717095720209)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(20.4090, device='cuda:0')  (tensor(19.7580, device='cuda:0'))\n",
      "     | > current_lr: 7e-06 \n",
      "     | > step_time: 0.6143  (0.7103732501556727)\n",
      "     | > loader_time: 0.0062  (0.01274463329934902)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:29:45 -- STEP: 302/406 -- GLOBAL_STEP: 34400\u001b[0m\n",
      "     | > loss: -0.00467507541179657  (-0.011973531583681795)\n",
      "     | > log_mle: -0.24661993980407715  (-0.2326942930947866)\n",
      "     | > loss_dur: 0.24194486439228058  (0.22072076151110487)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(23.0490, device='cuda:0')  (tensor(19.6890, device='cuda:0'))\n",
      "     | > current_lr: 7e-06 \n",
      "     | > step_time: 0.5522  (0.7146170226153948)\n",
      "     | > loader_time: 0.0069  (0.012804587155777886)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:30:05 -- STEP: 327/406 -- GLOBAL_STEP: 34425\u001b[0m\n",
      "     | > loss: -0.0026335716247558594  (-0.012169458815081762)\n",
      "     | > log_mle: -0.24003982543945312  (-0.23343985780663445)\n",
      "     | > loss_dur: 0.23740625381469727  (0.2212703989915528)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(11.4236, device='cuda:0')  (tensor(19.6536, device='cuda:0'))\n",
      "     | > current_lr: 7e-06 \n",
      "     | > step_time: 0.6529  (0.7193188557931045)\n",
      "     | > loader_time: 0.0209  (0.013110331439096996)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:30:25 -- STEP: 352/406 -- GLOBAL_STEP: 34450\u001b[0m\n",
      "     | > loss: -0.012271642684936523  (-0.011987131131304925)\n",
      "     | > log_mle: -0.24010682106018066  (-0.23425691608678212)\n",
      "     | > loss_dur: 0.22783517837524414  (0.22226978495547725)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(15.5666, device='cuda:0')  (tensor(19.6807, device='cuda:0'))\n",
      "     | > current_lr: 7e-06 \n",
      "     | > step_time: 0.5903  (0.7236817221749915)\n",
      "     | > loader_time: 0.0076  (0.013380311429500582)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:30:47 -- STEP: 377/406 -- GLOBAL_STEP: 34475\u001b[0m\n",
      "     | > loss: -0.002916201949119568  (-0.01218944040944784)\n",
      "     | > log_mle: -0.24411225318908691  (-0.23517285322953282)\n",
      "     | > loss_dur: 0.24119605123996735  (0.22298341282008505)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(18.4642, device='cuda:0')  (tensor(19.9154, device='cuda:0'))\n",
      "     | > current_lr: 7e-06 \n",
      "     | > step_time: 0.7399  (0.732729582950987)\n",
      "     | > loader_time: 0.0415  (0.013554619225013796)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:31:06 -- STEP: 402/406 -- GLOBAL_STEP: 34500\u001b[0m\n",
      "     | > loss: -0.013776123523712158  (-0.012319969337674506)\n",
      "     | > log_mle: -0.25392377376556396  (-0.2359691398653818)\n",
      "     | > loss_dur: 0.2401476502418518  (0.22364917052770736)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(30.7409, device='cuda:0')  (tensor(20.1069, device='cuda:0'))\n",
      "     | > current_lr: 7e-06 \n",
      "     | > step_time: 0.5232  (0.7332466378140808)\n",
      "     | > loader_time: 0.0077  (0.0135134191655401)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: -0.0030421316623687744  (-0.0030421316623687744)\n",
      "     | > log_mle: -0.21653735637664795  (-0.21653735637664795)\n",
      "     | > loss_dur: 0.21349522471427917  (0.21349522471427917)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: -0.07699136435985565  (-0.07699136435985565)\n",
      "     | > log_mle: -0.25417351722717285  (-0.25417351722717285)\n",
      "     | > loss_dur: 0.1771821528673172  (0.1771821528673172)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: -0.03517262637615204  (-0.056081995368003845)\n",
      "     | > log_mle: -0.21509015560150146  (-0.23463183641433716)\n",
      "     | > loss_dur: 0.17991752922534943  (0.1785498410463333)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: -0.03965833783149719  (-0.05060744285583496)\n",
      "     | > log_mle: -0.22792530059814453  (-0.2323963244756063)\n",
      "     | > loss_dur: 0.18826696276664734  (0.18178888161977133)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: -0.035918086767196655  (-0.046935103833675385)\n",
      "     | > log_mle: -0.2540038824081421  (-0.23779821395874023)\n",
      "     | > loss_dur: 0.21808579564094543  (0.19086311012506485)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: -0.04541657865047455  (-0.04663139879703522)\n",
      "     | > log_mle: -0.2504624128341675  (-0.24033105373382568)\n",
      "     | > loss_dur: 0.20504583418369293  (0.19369965493679048)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: -0.018590718507766724  (-0.041957952082157135)\n",
      "     | > log_mle: -0.2606889009475708  (-0.24372402826944986)\n",
      "     | > loss_dur: 0.24209818243980408  (0.20176607618729273)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: -0.026924341917037964  (-0.03981029348714011)\n",
      "     | > log_mle: -0.22812259197235107  (-0.2414952516555786)\n",
      "     | > loss_dur: 0.2011982500553131  (0.2016849581684385)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: -0.04467286169528961  (-0.0404181145131588)\n",
      "     | > log_mle: -0.23706114292144775  (-0.24094098806381226)\n",
      "     | > loss_dur: 0.19238828122615814  (0.20052287355065346)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: -0.023175179958343506  (-0.0385022328959571)\n",
      "     | > log_mle: -0.24795269966125488  (-0.24172006713019478)\n",
      "     | > loss_dur: 0.22477751970291138  (0.20321783423423767)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: -0.012137621641159058  (-0.0358657717704773)\n",
      "     | > log_mle: -0.23556959629058838  (-0.24110502004623413)\n",
      "     | > loss_dur: 0.22343197464942932  (0.20523924827575685)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: -0.032284557819366455  (-0.035540206865830856)\n",
      "     | > log_mle: -0.2508072853088379  (-0.2419870441610163)\n",
      "     | > loss_dur: 0.21852272748947144  (0.20644683729518543)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: -0.05842280387878418  (-0.03744708995024363)\n",
      "     | > log_mle: -0.24043893814086914  (-0.24185803532600403)\n",
      "     | > loss_dur: 0.18201613426208496  (0.2044109453757604)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: -0.06677381694316864  (-0.03970299202662248)\n",
      "     | > log_mle: -0.2580993175506592  (-0.24310736472790057)\n",
      "     | > loss_dur: 0.19132550060749054  (0.2034043727012781)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: -0.034852489829063416  (-0.03935652758393969)\n",
      "     | > log_mle: -0.2509801387786865  (-0.24366970573152816)\n",
      "     | > loss_dur: 0.2161276489496231  (0.20431317814758845)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: -0.03444145619869232  (-0.039028856158256534)\n",
      "     | > log_mle: -0.24549198150634766  (-0.2437911907831828)\n",
      "     | > loss_dur: 0.21105052530765533  (0.20476233462492624)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: -0.025975152850151062  (-0.03821299970149994)\n",
      "     | > log_mle: -0.24321234226226807  (-0.2437550127506256)\n",
      "     | > loss_dur: 0.217237189412117  (0.20554201304912567)\n",
      "\n",
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[91m 0.00637364387512207 \u001b[0m(+0.0027504265308380127)\n",
      "     | > avg_loss:\u001b[91m -0.03821299970149994 \u001b[0m(+0.001058138906955719)\n",
      "     | > avg_log_mle:\u001b[91m -0.2437550127506256 \u001b[0m(+0.0011987239122390747)\n",
      "     | > avg_loss_dur:\u001b[92m 0.20554201304912567 \u001b[0m(-0.0001405850052833557)\n",
      "\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 29/100\u001b[0m\n",
      " --> train/run-February-22-2025_10+59PM-fa84af3\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-23 01:31:22) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:31:35 -- STEP: 21/406 -- GLOBAL_STEP: 34525\u001b[0m\n",
      "     | > loss: -0.03146003186702728  (-0.027689724451019644)\n",
      "     | > log_mle: -0.21994471549987793  (-0.21798790068853469)\n",
      "     | > loss_dur: 0.18848468363285065  (0.19029817623751505)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(5.0047, device='cuda:0')  (tensor(9.5291, device='cuda:0'))\n",
      "     | > current_lr: 7.25e-06 \n",
      "     | > step_time: 0.7499  (0.4802172524588449)\n",
      "     | > loader_time: 0.0179  (0.006379513513474237)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:31:50 -- STEP: 46/406 -- GLOBAL_STEP: 34550\u001b[0m\n",
      "     | > loss: -0.005387857556343079  (-0.017800277018028755)\n",
      "     | > log_mle: -0.21201550960540771  (-0.21652340111525162)\n",
      "     | > loss_dur: 0.20662765204906464  (0.19872312409722287)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(12.8552, device='cuda:0')  (tensor(12.6210, device='cuda:0'))\n",
      "     | > current_lr: 7.25e-06 \n",
      "     | > step_time: 0.7228  (0.543169617652893)\n",
      "     | > loader_time: 0.0047  (0.009117287138234011)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:32:05 -- STEP: 71/406 -- GLOBAL_STEP: 34575\u001b[0m\n",
      "     | > loss: -0.007448181509971619  (-0.01618871323659386)\n",
      "     | > log_mle: -0.23399567604064941  (-0.2194470183950075)\n",
      "     | > loss_dur: 0.2265474945306778  (0.20325830515841364)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(22.8294, device='cuda:0')  (tensor(15.4261, device='cuda:0'))\n",
      "     | > current_lr: 7.25e-06 \n",
      "     | > step_time: 0.5513  (0.5539110882181517)\n",
      "     | > loader_time: 0.0049  (0.008671438190299018)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:32:23 -- STEP: 96/406 -- GLOBAL_STEP: 34600\u001b[0m\n",
      "     | > loss: 0.0005370974540710449  (-0.015534968581050634)\n",
      "     | > log_mle: -0.2332679033279419  (-0.22244721775253615)\n",
      "     | > loss_dur: 0.23380500078201294  (0.2069122491714855)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(20.2433, device='cuda:0')  (tensor(15.1466, device='cuda:0'))\n",
      "     | > current_lr: 7.25e-06 \n",
      "     | > step_time: 0.5195  (0.5971436351537703)\n",
      "     | > loader_time: 0.0054  (0.009403737882773076)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:32:43 -- STEP: 121/406 -- GLOBAL_STEP: 34625\u001b[0m\n",
      "     | > loss: -0.023197218775749207  (-0.015351855680962239)\n",
      "     | > log_mle: -0.231986403465271  (-0.22487551220192398)\n",
      "     | > loss_dur: 0.2087891846895218  (0.20952365652096172)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(18.1698, device='cuda:0')  (tensor(15.1292, device='cuda:0'))\n",
      "     | > current_lr: 7.25e-06 \n",
      "     | > step_time: 0.7546  (0.6401692875160657)\n",
      "     | > loader_time: 0.0045  (0.009735456182936988)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:33:05 -- STEP: 146/406 -- GLOBAL_STEP: 34650\u001b[0m\n",
      "     | > loss: -0.015718892216682434  (-0.014966825508091548)\n",
      "     | > log_mle: -0.23174595832824707  (-0.22698180397895917)\n",
      "     | > loss_dur: 0.21602706611156464  (0.21201497847086767)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(22.9771, device='cuda:0')  (tensor(15.8829, device='cuda:0'))\n",
      "     | > current_lr: 7.25e-06 \n",
      "     | > step_time: 0.5904  (0.6775352922204423)\n",
      "     | > loader_time: 0.005  (0.01107647157695195)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:33:29 -- STEP: 171/406 -- GLOBAL_STEP: 34675\u001b[0m\n",
      "     | > loss: -0.02342800796031952  (-0.014539246932107803)\n",
      "     | > log_mle: -0.24341583251953125  (-0.2285210863191482)\n",
      "     | > loss_dur: 0.21998782455921173  (0.21398183938704043)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(5.9514, device='cuda:0')  (tensor(16.5830, device='cuda:0'))\n",
      "     | > current_lr: 7.25e-06 \n",
      "     | > step_time: 0.9654  (0.7142732213115138)\n",
      "     | > loader_time: 0.0965  (0.012727153231525973)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:33:54 -- STEP: 196/406 -- GLOBAL_STEP: 34700\u001b[0m\n",
      "     | > loss: -0.017231464385986328  (-0.014278152007229475)\n",
      "     | > log_mle: -0.24012625217437744  (-0.2299706631777238)\n",
      "     | > loss_dur: 0.2228947877883911  (0.21569251117049434)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(13.6678, device='cuda:0')  (tensor(16.7129, device='cuda:0'))\n",
      "     | > current_lr: 7.25e-06 \n",
      "     | > step_time: 1.3698  (0.7448295658948475)\n",
      "     | > loader_time: 0.0345  (0.013180321576643958)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:34:18 -- STEP: 221/406 -- GLOBAL_STEP: 34725\u001b[0m\n",
      "     | > loss: 0.000604286789894104  (-0.014316318059399117)\n",
      "     | > log_mle: -0.2403104305267334  (-0.23128176220941327)\n",
      "     | > loss_dur: 0.2409147173166275  (0.2169654441500142)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(14.5511, device='cuda:0')  (tensor(17.1816, device='cuda:0'))\n",
      "     | > current_lr: 7.25e-06 \n",
      "     | > step_time: 0.7723  (0.7662553851960475)\n",
      "     | > loader_time: 0.007  (0.013674186905045311)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:34:41 -- STEP: 246/406 -- GLOBAL_STEP: 34750\u001b[0m\n",
      "     | > loss: -0.02224820852279663  (-0.014309693582174255)\n",
      "     | > log_mle: -0.23880958557128906  (-0.23259331104232045)\n",
      "     | > loss_dur: 0.21656137704849243  (0.2182836174601462)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(16.1244, device='cuda:0')  (tensor(17.7739, device='cuda:0'))\n",
      "     | > current_lr: 7.25e-06 \n",
      "     | > step_time: 0.8591  (0.7815335746703113)\n",
      "     | > loader_time: 0.0163  (0.013665866076461664)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:35:04 -- STEP: 271/406 -- GLOBAL_STEP: 34775\u001b[0m\n",
      "     | > loss: -0.030265629291534424  (-0.014779524389668144)\n",
      "     | > log_mle: -0.25415563583374023  (-0.2337064901401196)\n",
      "     | > loss_dur: 0.2238900065422058  (0.21892696575045148)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(22.9841, device='cuda:0')  (tensor(18.1623, device='cuda:0'))\n",
      "     | > current_lr: 7.25e-06 \n",
      "     | > step_time: 1.2522  (0.7917390723070099)\n",
      "     | > loader_time: 0.0333  (0.01382733798994789)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:35:27 -- STEP: 296/406 -- GLOBAL_STEP: 34800\u001b[0m\n",
      "     | > loss: -0.011174127459526062  (-0.014966301418639518)\n",
      "     | > log_mle: -0.24938976764678955  (-0.2345808857196086)\n",
      "     | > loss_dur: 0.2382156401872635  (0.21961458430096908)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(30.0078, device='cuda:0')  (tensor(19.1273, device='cuda:0'))\n",
      "     | > current_lr: 7.25e-06 \n",
      "     | > step_time: 1.2008  (0.8022614387241572)\n",
      "     | > loader_time: 0.0148  (0.014128760711566818)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:35:49 -- STEP: 321/406 -- GLOBAL_STEP: 34825\u001b[0m\n",
      "     | > loss: -0.01198500394821167  (-0.015218042231794458)\n",
      "     | > log_mle: -0.240858793258667  (-0.23539521612482278)\n",
      "     | > loss_dur: 0.22887378931045532  (0.22017717389302832)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(16.0646, device='cuda:0')  (tensor(19.4879, device='cuda:0'))\n",
      "     | > current_lr: 7.25e-06 \n",
      "     | > step_time: 0.6305  (0.8055654723324881)\n",
      "     | > loader_time: 0.0081  (0.01451893536101249)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:36:10 -- STEP: 346/406 -- GLOBAL_STEP: 34850\u001b[0m\n",
      "     | > loss: -0.029493242502212524  (-0.015251776171212941)\n",
      "     | > log_mle: -0.2531334161758423  (-0.23621632322410627)\n",
      "     | > loss_dur: 0.22364017367362976  (0.22096454705289334)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(19.4907, device='cuda:0')  (tensor(19.6059, device='cuda:0'))\n",
      "     | > current_lr: 7.25e-06 \n",
      "     | > step_time: 1.0241  (0.8050010969184039)\n",
      "     | > loader_time: 0.0074  (0.014913896604769489)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:36:31 -- STEP: 371/406 -- GLOBAL_STEP: 34875\u001b[0m\n",
      "     | > loss: -0.014590322971343994  (-0.015304756172583752)\n",
      "     | > log_mle: -0.2476567029953003  (-0.23703698199392972)\n",
      "     | > loss_dur: 0.2330663800239563  (0.22173222582134597)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(35.0902, device='cuda:0')  (tensor(20.5364, device='cuda:0'))\n",
      "     | > current_lr: 7.25e-06 \n",
      "     | > step_time: 0.8652  (0.8059282784834706)\n",
      "     | > loader_time: 0.0328  (0.01520853415332393)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:36:51 -- STEP: 396/406 -- GLOBAL_STEP: 34900\u001b[0m\n",
      "     | > loss: -0.01845906674861908  (-0.015466695557339023)\n",
      "     | > log_mle: -0.25406360626220703  (-0.23777142076781302)\n",
      "     | > loss_dur: 0.23560453951358795  (0.222304725210474)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(21.7264, device='cuda:0')  (tensor(21.2438, device='cuda:0'))\n",
      "     | > current_lr: 7.25e-06 \n",
      "     | > step_time: 0.5211  (0.8060683481621022)\n",
      "     | > loader_time: 0.0079  (0.01517575316958957)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: -0.014713406562805176  (-0.014713406562805176)\n",
      "     | > log_mle: -0.22023725509643555  (-0.22023725509643555)\n",
      "     | > loss_dur: 0.20552384853363037  (0.20552384853363037)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: -0.08249928057193756  (-0.08249928057193756)\n",
      "     | > log_mle: -0.25905537605285645  (-0.25905537605285645)\n",
      "     | > loss_dur: 0.17655609548091888  (0.17655609548091888)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: -0.044587522745132446  (-0.063543401658535)\n",
      "     | > log_mle: -0.21866273880004883  (-0.23885905742645264)\n",
      "     | > loss_dur: 0.17407521605491638  (0.17531565576791763)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: -0.04437398910522461  (-0.057153597474098206)\n",
      "     | > log_mle: -0.23274099826812744  (-0.23681970437367758)\n",
      "     | > loss_dur: 0.18836700916290283  (0.17966610689957938)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: -0.04675455391407013  (-0.054553836584091187)\n",
      "     | > log_mle: -0.2594994306564331  (-0.24248963594436646)\n",
      "     | > loss_dur: 0.21274487674236298  (0.18793579936027527)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: -0.05302371084690094  (-0.05424781143665314)\n",
      "     | > log_mle: -0.25675415992736816  (-0.24534254074096679)\n",
      "     | > loss_dur: 0.20373044908046722  (0.19109472930431365)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: -0.03065033257007599  (-0.05031489829222361)\n",
      "     | > log_mle: -0.26771080493927  (-0.24907058477401733)\n",
      "     | > loss_dur: 0.23706047236919403  (0.19875568648179373)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: -0.032562777400016785  (-0.04777888102190835)\n",
      "     | > log_mle: -0.232452392578125  (-0.2466965573174613)\n",
      "     | > loss_dur: 0.19988961517810822  (0.19891767629555293)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: -0.050171494483947754  (-0.04807795770466328)\n",
      "     | > log_mle: -0.2420893907546997  (-0.2461206614971161)\n",
      "     | > loss_dur: 0.19191789627075195  (0.1980427037924528)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: -0.02912139892578125  (-0.04597167339589861)\n",
      "     | > log_mle: -0.25352728366851807  (-0.24694361951616076)\n",
      "     | > loss_dur: 0.22440588474273682  (0.20097194612026215)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: -0.01876792311668396  (-0.04325129836797714)\n",
      "     | > log_mle: -0.24073433876037598  (-0.24632269144058228)\n",
      "     | > loss_dur: 0.22196641564369202  (0.20307139307260513)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: -0.040781185030937195  (-0.04302674261006442)\n",
      "     | > log_mle: -0.2564481496810913  (-0.24724318764426492)\n",
      "     | > loss_dur: 0.2156669646501541  (0.2042164450342005)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: -0.06255793571472168  (-0.04465434203545252)\n",
      "     | > log_mle: -0.2448115348815918  (-0.24704054991404215)\n",
      "     | > loss_dur: 0.18225359916687012  (0.20238620787858963)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: -0.07548950612545013  (-0.04702627773468311)\n",
      "     | > log_mle: -0.2636162042617798  (-0.2483156002484835)\n",
      "     | > loss_dur: 0.18812669813632965  (0.2012893225138004)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: -0.04758647084236145  (-0.04706629152808871)\n",
      "     | > log_mle: -0.25635743141174316  (-0.2488900167601449)\n",
      "     | > loss_dur: 0.2087709605693817  (0.20182372523205622)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: -0.036967933177948  (-0.04639306763807933)\n",
      "     | > log_mle: -0.2500823736190796  (-0.24896950721740724)\n",
      "     | > loss_dur: 0.2131144404411316  (0.2025764395793279)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: -0.03212997317314148  (-0.04550162423402071)\n",
      "     | > log_mle: -0.2481461763381958  (-0.2489180490374565)\n",
      "     | > loss_dur: 0.21601620316505432  (0.2034164248034358)\n",
      "\n",
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.0037218332290649414 \u001b[0m(-0.002651810646057129)\n",
      "     | > avg_loss:\u001b[92m -0.04550162423402071 \u001b[0m(-0.007288624532520771)\n",
      "     | > avg_log_mle:\u001b[92m -0.2489180490374565 \u001b[0m(-0.005163036286830902)\n",
      "     | > avg_loss_dur:\u001b[92m 0.2034164248034358 \u001b[0m(-0.002125588245689869)\n",
      "\n",
      " > BEST MODEL : train/run-February-22-2025_10+59PM-fa84af3/best_model_34910.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 30/100\u001b[0m\n",
      " --> train/run-February-22-2025_10+59PM-fa84af3\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-23 01:37:14) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:37:24 -- STEP: 15/406 -- GLOBAL_STEP: 34925\u001b[0m\n",
      "     | > loss: -0.0173598974943161  (-0.03035899301369985)\n",
      "     | > log_mle: -0.22245144844055176  (-0.22218948205312092)\n",
      "     | > loss_dur: 0.20509155094623566  (0.19183048903942107)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(10.1579, device='cuda:0')  (tensor(13.5608, device='cuda:0'))\n",
      "     | > current_lr: 7.499999999999999e-06 \n",
      "     | > step_time: 0.9784  (0.5072353839874267)\n",
      "     | > loader_time: 0.0331  (0.008516867955525717)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:37:42 -- STEP: 40/406 -- GLOBAL_STEP: 34950\u001b[0m\n",
      "     | > loss: -0.0012618005275726318  (-0.02188911885023117)\n",
      "     | > log_mle: -0.20022499561309814  (-0.21910813450813293)\n",
      "     | > loss_dur: 0.1989631950855255  (0.19721901565790176)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(10.9556, device='cuda:0')  (tensor(10.9661, device='cuda:0'))\n",
      "     | > current_lr: 7.499999999999999e-06 \n",
      "     | > step_time: 0.4238  (0.6100457429885864)\n",
      "     | > loader_time: 0.0061  (0.009990417957305908)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:38:00 -- STEP: 65/406 -- GLOBAL_STEP: 34975\u001b[0m\n",
      "     | > loss: -0.012416541576385498  (-0.01871795058250427)\n",
      "     | > log_mle: -0.21645498275756836  (-0.22078501627995417)\n",
      "     | > loss_dur: 0.20403844118118286  (0.2020670656974499)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(10.0194, device='cuda:0')  (tensor(11.5080, device='cuda:0'))\n",
      "     | > current_lr: 7.499999999999999e-06 \n",
      "     | > step_time: 0.8082  (0.6589655839479888)\n",
      "     | > loader_time: 0.0055  (0.009385640804584209)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:38:19 -- STEP: 90/406 -- GLOBAL_STEP: 35000\u001b[0m\n",
      "     | > loss: -0.027728378772735596  (-0.017661596503522663)\n",
      "     | > log_mle: -0.23807203769683838  (-0.2234324349297417)\n",
      "     | > loss_dur: 0.21034365892410278  (0.2057708384262191)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(18.3717, device='cuda:0')  (tensor(14.5247, device='cuda:0'))\n",
      "     | > current_lr: 7.499999999999999e-06 \n",
      "     | > step_time: 1.0689  (0.6799238628811308)\n",
      "     | > loader_time: 0.0043  (0.010070586204528803)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:38:42 -- STEP: 115/406 -- GLOBAL_STEP: 35025\u001b[0m\n",
      "     | > loss: -0.004721879959106445  (-0.017935281603232673)\n",
      "     | > log_mle: -0.22111940383911133  (-0.22626766951187793)\n",
      "     | > loss_dur: 0.21639752388000488  (0.2083323879086453)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(11.2304, device='cuda:0')  (tensor(16.1322, device='cuda:0'))\n",
      "     | > current_lr: 7.499999999999999e-06 \n",
      "     | > step_time: 0.8494  (0.7240725807521656)\n",
      "     | > loader_time: 0.0137  (0.011633360904196028)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:39:00 -- STEP: 140/406 -- GLOBAL_STEP: 35050\u001b[0m\n",
      "     | > loss: -0.014090389013290405  (-0.017011744529008867)\n",
      "     | > log_mle: -0.2456190586090088  (-0.22837305154119217)\n",
      "     | > loss_dur: 0.23152866959571838  (0.21136130701218334)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(18.1762, device='cuda:0')  (tensor(16.3259, device='cuda:0'))\n",
      "     | > current_lr: 7.499999999999999e-06 \n",
      "     | > step_time: 0.4411  (0.717924886090415)\n",
      "     | > loader_time: 0.0151  (0.011564137254442483)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:39:18 -- STEP: 165/406 -- GLOBAL_STEP: 35075\u001b[0m\n",
      "     | > loss: -0.04548750817775726  (-0.01675750721584667)\n",
      "     | > log_mle: -0.25974810123443604  (-0.23000433444976806)\n",
      "     | > loss_dur: 0.21426059305667877  (0.2132468272339214)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(28.0879, device='cuda:0')  (tensor(16.7302, device='cuda:0'))\n",
      "     | > current_lr: 7.499999999999999e-06 \n",
      "     | > step_time: 0.791  (0.7163929693626637)\n",
      "     | > loader_time: 0.0105  (0.01191048477635238)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:39:37 -- STEP: 190/406 -- GLOBAL_STEP: 35100\u001b[0m\n",
      "     | > loss: -0.015264034271240234  (-0.016930554650331796)\n",
      "     | > log_mle: -0.25117385387420654  (-0.23158016644026103)\n",
      "     | > loss_dur: 0.2359098196029663  (0.21464961178992925)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(16.9999, device='cuda:0')  (tensor(17.1373, device='cuda:0'))\n",
      "     | > current_lr: 7.499999999999999e-06 \n",
      "     | > step_time: 1.0107  (0.7207323877434981)\n",
      "     | > loader_time: 0.0081  (0.012082229162517338)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:39:56 -- STEP: 215/406 -- GLOBAL_STEP: 35125\u001b[0m\n",
      "     | > loss: -0.015833169221878052  (-0.01712226597375647)\n",
      "     | > log_mle: -0.23851025104522705  (-0.23280556312827178)\n",
      "     | > loss_dur: 0.222677081823349  (0.21568329715451529)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(18.6342, device='cuda:0')  (tensor(17.6152, device='cuda:0'))\n",
      "     | > current_lr: 7.499999999999999e-06 \n",
      "     | > step_time: 0.7816  (0.725538297032201)\n",
      "     | > loader_time: 0.0243  (0.01222057342529296)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:40:19 -- STEP: 240/406 -- GLOBAL_STEP: 35150\u001b[0m\n",
      "     | > loss: -0.03786982595920563  (-0.017032077535986886)\n",
      "     | > log_mle: -0.254703164100647  (-0.2341938053568204)\n",
      "     | > loss_dur: 0.21683333814144135  (0.2171617278208335)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(17.7713, device='cuda:0')  (tensor(17.7360, device='cuda:0'))\n",
      "     | > current_lr: 7.499999999999999e-06 \n",
      "     | > step_time: 1.5728  (0.7395966907342275)\n",
      "     | > loader_time: 0.0064  (0.012803435325622552)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:40:42 -- STEP: 265/406 -- GLOBAL_STEP: 35175\u001b[0m\n",
      "     | > loss: -0.022155404090881348  (-0.01732459118906056)\n",
      "     | > log_mle: -0.24916434288024902  (-0.23526400889990465)\n",
      "     | > loss_dur: 0.22700893878936768  (0.21793941771084407)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(31.0585, device='cuda:0')  (tensor(17.7418, device='cuda:0'))\n",
      "     | > current_lr: 7.499999999999999e-06 \n",
      "     | > step_time: 1.1001  (0.7576216652708233)\n",
      "     | > loader_time: 0.0279  (0.01307701074852133)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:41:03 -- STEP: 290/406 -- GLOBAL_STEP: 35200\u001b[0m\n",
      "     | > loss: -0.030518457293510437  (-0.01767306846791299)\n",
      "     | > log_mle: -0.2577381134033203  (-0.23623782807383045)\n",
      "     | > loss_dur: 0.22721965610980988  (0.21856475960591742)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(29.0021, device='cuda:0')  (tensor(18.2566, device='cuda:0'))\n",
      "     | > current_lr: 7.499999999999999e-06 \n",
      "     | > step_time: 0.7919  (0.7615201473236084)\n",
      "     | > loader_time: 0.0231  (0.013389830753721037)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:41:24 -- STEP: 315/406 -- GLOBAL_STEP: 35225\u001b[0m\n",
      "     | > loss: -0.017042577266693115  (-0.017886670667027656)\n",
      "     | > log_mle: -0.24678552150726318  (-0.23712272303444998)\n",
      "     | > loss_dur: 0.22974294424057007  (0.21923605236742233)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(20.3530, device='cuda:0')  (tensor(18.6388, device='cuda:0'))\n",
      "     | > current_lr: 7.499999999999999e-06 \n",
      "     | > step_time: 0.6855  (0.7670378790961369)\n",
      "     | > loader_time: 0.0074  (0.01353845293559725)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:41:48 -- STEP: 340/406 -- GLOBAL_STEP: 35250\u001b[0m\n",
      "     | > loss: -0.011300161480903625  (-0.017942494942861424)\n",
      "     | > log_mle: -0.2394428253173828  (-0.23783859820926892)\n",
      "     | > loss_dur: 0.2281426638364792  (0.21989610326640746)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(19.8955, device='cuda:0')  (tensor(18.9416, device='cuda:0'))\n",
      "     | > current_lr: 7.499999999999999e-06 \n",
      "     | > step_time: 0.832  (0.7794384381350349)\n",
      "     | > loader_time: 0.0109  (0.01395526002435123)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:42:10 -- STEP: 365/406 -- GLOBAL_STEP: 35275\u001b[0m\n",
      "     | > loss: -0.019147709012031555  (-0.018098789453506455)\n",
      "     | > log_mle: -0.2524230480194092  (-0.2387444306726325)\n",
      "     | > loss_dur: 0.23327533900737762  (0.22064564121912603)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(28.1092, device='cuda:0')  (tensor(19.3354, device='cuda:0'))\n",
      "     | > current_lr: 7.499999999999999e-06 \n",
      "     | > step_time: 0.6373  (0.7828172768632027)\n",
      "     | > loader_time: 0.0294  (0.014230517818503182)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:42:33 -- STEP: 390/406 -- GLOBAL_STEP: 35300\u001b[0m\n",
      "     | > loss: -0.033959925174713135  (-0.018237198851047406)\n",
      "     | > log_mle: -0.26296722888946533  (-0.23950871015206363)\n",
      "     | > loss_dur: 0.2290073037147522  (0.2212715113010162)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(23.5052, device='cuda:0')  (tensor(19.6624, device='cuda:0'))\n",
      "     | > current_lr: 7.499999999999999e-06 \n",
      "     | > step_time: 1.2329  (0.7902149114853296)\n",
      "     | > loader_time: 0.0062  (0.014525007590269428)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: -0.01088792085647583  (-0.01088792085647583)\n",
      "     | > log_mle: -0.22222411632537842  (-0.22222411632537842)\n",
      "     | > loss_dur: 0.2113361954689026  (0.2113361954689026)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: -0.08462412655353546  (-0.08462412655353546)\n",
      "     | > log_mle: -0.2610208988189697  (-0.2610208988189697)\n",
      "     | > loss_dur: 0.17639677226543427  (0.17639677226543427)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: -0.04680390655994415  (-0.06571401655673981)\n",
      "     | > log_mle: -0.220863938331604  (-0.24094241857528687)\n",
      "     | > loss_dur: 0.17406003177165985  (0.17522840201854706)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: -0.043419986963272095  (-0.058282673358917236)\n",
      "     | > log_mle: -0.2344517707824707  (-0.2387788693110148)\n",
      "     | > loss_dur: 0.1910317838191986  (0.18049619595209757)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: -0.05515079200267792  (-0.05749970301985741)\n",
      "     | > log_mle: -0.26151013374328613  (-0.24446168541908264)\n",
      "     | > loss_dur: 0.20635934174060822  (0.18696198239922523)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: -0.05582110583782196  (-0.05716398358345032)\n",
      "     | > log_mle: -0.2579817771911621  (-0.24716570377349853)\n",
      "     | > loss_dur: 0.20216067135334015  (0.1900017201900482)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: -0.030635863542556763  (-0.05274263024330139)\n",
      "     | > log_mle: -0.2687267065048218  (-0.25075920422871906)\n",
      "     | > loss_dur: 0.23809084296226501  (0.1980165739854177)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: -0.03866986930370331  (-0.050732235823358805)\n",
      "     | > log_mle: -0.2340259552001953  (-0.2483687400817871)\n",
      "     | > loss_dur: 0.195356085896492  (0.1976365042584283)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: -0.05333016812801361  (-0.05105697736144066)\n",
      "     | > log_mle: -0.244012713432312  (-0.24782423675060272)\n",
      "     | > loss_dur: 0.1906825453042984  (0.19676725938916206)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: -0.03055281937122345  (-0.048778737584749855)\n",
      "     | > log_mle: -0.2553532123565674  (-0.24866078959570992)\n",
      "     | > loss_dur: 0.22480039298534393  (0.19988205201096004)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: -0.021533936262130737  (-0.046054257452487944)\n",
      "     | > log_mle: -0.2423079013824463  (-0.24802550077438354)\n",
      "     | > loss_dur: 0.22077396512031555  (0.2019712433218956)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: -0.04545895755290985  (-0.04600013927979903)\n",
      "     | > log_mle: -0.2580045461654663  (-0.24893268671902744)\n",
      "     | > loss_dur: 0.21254558861255646  (0.2029325474392284)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: -0.06371913850307465  (-0.04747672254840533)\n",
      "     | > log_mle: -0.2468653917312622  (-0.24876041213671365)\n",
      "     | > loss_dur: 0.18314625322818756  (0.20128368958830833)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: -0.07870057225227356  (-0.049878557141010575)\n",
      "     | > log_mle: -0.265012264251709  (-0.2500105546070979)\n",
      "     | > loss_dur: 0.18631169199943542  (0.20013199746608734)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: -0.04458460211753845  (-0.04950041749647686)\n",
      "     | > log_mle: -0.258242130279541  (-0.25059852429798674)\n",
      "     | > loss_dur: 0.21365752816200256  (0.20109810680150986)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: -0.04298114776611328  (-0.04906579951445262)\n",
      "     | > log_mle: -0.2518833875656128  (-0.2506841818491618)\n",
      "     | > loss_dur: 0.2089022397994995  (0.20161838233470916)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: -0.03445476293563843  (-0.04815260972827673)\n",
      "     | > log_mle: -0.2500370740890503  (-0.2506437376141548)\n",
      "     | > loss_dur: 0.21558231115341187  (0.20249112788587809)\n",
      "\n",
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.0034272074699401855 \u001b[0m(-0.00029462575912475586)\n",
      "     | > avg_loss:\u001b[92m -0.04815260972827673 \u001b[0m(-0.0026509854942560196)\n",
      "     | > avg_log_mle:\u001b[92m -0.2506437376141548 \u001b[0m(-0.0017256885766983032)\n",
      "     | > avg_loss_dur:\u001b[92m 0.20249112788587809 \u001b[0m(-0.0009252969175577164)\n",
      "\n",
      " > BEST MODEL : train/run-February-22-2025_10+59PM-fa84af3/best_model_35316.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 31/100\u001b[0m\n",
      " --> train/run-February-22-2025_10+59PM-fa84af3\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-23 01:42:58) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:43:04 -- STEP: 9/406 -- GLOBAL_STEP: 35325\u001b[0m\n",
      "     | > loss: -0.009168431162834167  (-0.03149683276812235)\n",
      "     | > log_mle: -0.22797346115112305  (-0.22196127308739555)\n",
      "     | > loss_dur: 0.21880502998828888  (0.1904644403192732)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(19.2651, device='cuda:0')  (tensor(10.3613, device='cuda:0'))\n",
      "     | > current_lr: 7.75e-06 \n",
      "     | > step_time: 0.4105  (0.3742594189114041)\n",
      "     | > loader_time: 0.004  (0.004169967439439561)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:43:18 -- STEP: 34/406 -- GLOBAL_STEP: 35350\u001b[0m\n",
      "     | > loss: -0.008582517504692078  (-0.025199094677672666)\n",
      "     | > log_mle: -0.21643030643463135  (-0.2210897873429691)\n",
      "     | > loss_dur: 0.20784778892993927  (0.19589069266529643)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(15.7812, device='cuda:0')  (tensor(11.3091, device='cuda:0'))\n",
      "     | > current_lr: 7.75e-06 \n",
      "     | > step_time: 0.8582  (0.5096072028664983)\n",
      "     | > loader_time: 0.0252  (0.011726133963641)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:43:35 -- STEP: 59/406 -- GLOBAL_STEP: 35375\u001b[0m\n",
      "     | > loss: -0.028886452317237854  (-0.020681726730475993)\n",
      "     | > log_mle: -0.22611474990844727  (-0.22214768498630846)\n",
      "     | > loss_dur: 0.1972282975912094  (0.20146595825583247)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(11.4787, device='cuda:0')  (tensor(13.9323, device='cuda:0'))\n",
      "     | > current_lr: 7.75e-06 \n",
      "     | > step_time: 0.7019  (0.5734992552611785)\n",
      "     | > loader_time: 0.0053  (0.011574320873971715)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:43:55 -- STEP: 84/406 -- GLOBAL_STEP: 35400\u001b[0m\n",
      "     | > loss: -0.014850139617919922  (-0.019656525481314885)\n",
      "     | > log_mle: -0.23675251007080078  (-0.22464215471631005)\n",
      "     | > loss_dur: 0.22190237045288086  (0.20498562923499516)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(22.5456, device='cuda:0')  (tensor(16.5370, device='cuda:0'))\n",
      "     | > current_lr: 7.75e-06 \n",
      "     | > step_time: 0.711  (0.6255736975442796)\n",
      "     | > loader_time: 0.0213  (0.01212218545732044)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:44:17 -- STEP: 109/406 -- GLOBAL_STEP: 35425\u001b[0m\n",
      "     | > loss: -0.032911449670791626  (-0.020026608891443375)\n",
      "     | > log_mle: -0.24723589420318604  (-0.22739478644974734)\n",
      "     | > loss_dur: 0.2143244445323944  (0.20736817755830397)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(8.1312, device='cuda:0')  (tensor(16.2410, device='cuda:0'))\n",
      "     | > current_lr: 7.75e-06 \n",
      "     | > step_time: 0.5583  (0.6803827788851676)\n",
      "     | > loader_time: 0.0051  (0.01455937613041029)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:44:37 -- STEP: 134/406 -- GLOBAL_STEP: 35450\u001b[0m\n",
      "     | > loss: -0.0029238611459732056  (-0.01975254202956584)\n",
      "     | > log_mle: -0.23196053504943848  (-0.22987766319246433)\n",
      "     | > loss_dur: 0.22903667390346527  (0.2101251211628985)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(21.2062, device='cuda:0')  (tensor(15.8261, device='cuda:0'))\n",
      "     | > current_lr: 7.75e-06 \n",
      "     | > step_time: 0.6594  (0.6978311752205464)\n",
      "     | > loader_time: 0.0095  (0.014738757218887557)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:44:56 -- STEP: 159/406 -- GLOBAL_STEP: 35475\u001b[0m\n",
      "     | > loss: -0.014604493975639343  (-0.019167803181042473)\n",
      "     | > log_mle: -0.24170923233032227  (-0.23155523171214937)\n",
      "     | > loss_dur: 0.22710473835468292  (0.21238742853110693)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(25.0434, device='cuda:0')  (tensor(15.8517, device='cuda:0'))\n",
      "     | > current_lr: 7.75e-06 \n",
      "     | > step_time: 0.586  (0.7093357470050548)\n",
      "     | > loader_time: 0.0072  (0.014185163210023125)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:45:17 -- STEP: 184/406 -- GLOBAL_STEP: 35500\u001b[0m\n",
      "     | > loss: -0.005267411470413208  (-0.019037390127778057)\n",
      "     | > log_mle: -0.24902117252349854  (-0.232992691838223)\n",
      "     | > loss_dur: 0.24375376105308533  (0.21395530171044494)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(26.0723, device='cuda:0')  (tensor(16.4731, device='cuda:0'))\n",
      "     | > current_lr: 7.75e-06 \n",
      "     | > step_time: 0.5542  (0.7193702964679057)\n",
      "     | > loader_time: 0.0061  (0.013959301554638407)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:45:36 -- STEP: 209/406 -- GLOBAL_STEP: 35525\u001b[0m\n",
      "     | > loss: -0.034415796399116516  (-0.019175604128381284)\n",
      "     | > log_mle: -0.24861431121826172  (-0.2343715081374611)\n",
      "     | > loss_dur: 0.2141985148191452  (0.2151959040090798)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(24.4522, device='cuda:0')  (tensor(17.2642, device='cuda:0'))\n",
      "     | > current_lr: 7.75e-06 \n",
      "     | > step_time: 0.6445  (0.722869717903685)\n",
      "     | > loader_time: 0.0065  (0.01427569571864662)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:45:55 -- STEP: 234/406 -- GLOBAL_STEP: 35550\u001b[0m\n",
      "     | > loss: -0.011708050966262817  (-0.0194121388416005)\n",
      "     | > log_mle: -0.256272554397583  (-0.23590123551523584)\n",
      "     | > loss_dur: 0.2445645034313202  (0.21648909667363533)\n",
      "     | > amp_scaler: 8192.0  (4481.094017094019)\n",
      "     | > grad_norm: tensor(34.0637, device='cuda:0')  (tensor(18.0625, device='cuda:0'))\n",
      "     | > current_lr: 7.75e-06 \n",
      "     | > step_time: 0.8437  (0.7246329488917296)\n",
      "     | > loader_time: 0.0167  (0.014270672431358924)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:46:14 -- STEP: 259/406 -- GLOBAL_STEP: 35575\u001b[0m\n",
      "     | > loss: -0.029748693108558655  (-0.019884115940815694)\n",
      "     | > log_mle: -0.26457202434539795  (-0.2371149155163857)\n",
      "     | > loss_dur: 0.2348233312368393  (0.21723079957557)\n",
      "     | > amp_scaler: 8192.0  (4839.289575289577)\n",
      "     | > grad_norm: tensor(14.0088, device='cuda:0')  (tensor(18.6255, device='cuda:0'))\n",
      "     | > current_lr: 7.75e-06 \n",
      "     | > step_time: 0.6777  (0.7276745569751992)\n",
      "     | > loader_time: 0.0062  (0.014286122266850417)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:46:34 -- STEP: 284/406 -- GLOBAL_STEP: 35600\u001b[0m\n",
      "     | > loss: -0.01311473548412323  (-0.0201868126824708)\n",
      "     | > log_mle: -0.2541719675064087  (-0.2381567081934969)\n",
      "     | > loss_dur: 0.24105723202228546  (0.2179698955110261)\n",
      "     | > amp_scaler: 8192.0  (5134.422535211268)\n",
      "     | > grad_norm: tensor(13.6496, device='cuda:0')  (tensor(19.2386, device='cuda:0'))\n",
      "     | > current_lr: 7.75e-06 \n",
      "     | > step_time: 0.9707  (0.7319612973172902)\n",
      "     | > loader_time: 0.0082  (0.014537727329092967)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:46:54 -- STEP: 309/406 -- GLOBAL_STEP: 35625\u001b[0m\n",
      "     | > loss: -0.03832253813743591  (-0.020455922461250452)\n",
      "     | > log_mle: -0.24909913539886475  (-0.23897075537338996)\n",
      "     | > loss_dur: 0.21077659726142883  (0.21851483291213952)\n",
      "     | > amp_scaler: 8192.0  (5381.79935275081)\n",
      "     | > grad_norm: tensor(19.1890, device='cuda:0')  (tensor(19.6376, device='cuda:0'))\n",
      "     | > current_lr: 7.75e-06 \n",
      "     | > step_time: 0.7098  (0.7352690264630862)\n",
      "     | > loader_time: 0.0281  (0.014961706396059697)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:47:15 -- STEP: 334/406 -- GLOBAL_STEP: 35650\u001b[0m\n",
      "     | > loss: -0.024329453706741333  (-0.02051900237977148)\n",
      "     | > log_mle: -0.25754380226135254  (-0.23968222648083806)\n",
      "     | > loss_dur: 0.2332143485546112  (0.2191632241010666)\n",
      "     | > amp_scaler: 4096.0  (5359.137724550897)\n",
      "     | > grad_norm: tensor(35.1980, device='cuda:0')  (tensor(20.4953, device='cuda:0'))\n",
      "     | > current_lr: 7.75e-06 \n",
      "     | > step_time: 0.6698  (0.7421227115356996)\n",
      "     | > loader_time: 0.0085  (0.014850898417170176)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:47:36 -- STEP: 359/406 -- GLOBAL_STEP: 35675\u001b[0m\n",
      "     | > loss: -0.01733684539794922  (-0.02053383918359752)\n",
      "     | > log_mle: -0.24183166027069092  (-0.24049691403476642)\n",
      "     | > loss_dur: 0.2244948148727417  (0.2199630748511689)\n",
      "     | > amp_scaler: 4096.0  (5271.175487465181)\n",
      "     | > grad_norm: tensor(29.0802, device='cuda:0')  (tensor(20.9607, device='cuda:0'))\n",
      "     | > current_lr: 7.75e-06 \n",
      "     | > step_time: 1.0925  (0.7467680256346809)\n",
      "     | > loader_time: 0.0087  (0.014902512675208302)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:47:58 -- STEP: 384/406 -- GLOBAL_STEP: 35700\u001b[0m\n",
      "     | > loss: -0.0160081684589386  (-0.02077228242220979)\n",
      "     | > log_mle: -0.2551969289779663  (-0.24125521164387465)\n",
      "     | > loss_dur: 0.2391887605190277  (0.22048292922166488)\n",
      "     | > amp_scaler: 4096.0  (5194.666666666666)\n",
      "     | > grad_norm: tensor(26.4084, device='cuda:0')  (tensor(21.1572, device='cuda:0'))\n",
      "     | > current_lr: 7.75e-06 \n",
      "     | > step_time: 0.9213  (0.7549466937780384)\n",
      "     | > loader_time: 0.0195  (0.015071914220849672)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: -0.007163137197494507  (-0.007163137197494507)\n",
      "     | > log_mle: -0.22416794300079346  (-0.22416794300079346)\n",
      "     | > loss_dur: 0.21700480580329895  (0.21700480580329895)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: -0.08723410964012146  (-0.08723410964012146)\n",
      "     | > log_mle: -0.26199257373809814  (-0.26199257373809814)\n",
      "     | > loss_dur: 0.17475846409797668  (0.17475846409797668)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: -0.05609530210494995  (-0.0716647058725357)\n",
      "     | > log_mle: -0.22275495529174805  (-0.2423737645149231)\n",
      "     | > loss_dur: 0.1666596531867981  (0.1707090586423874)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: -0.044461071491241455  (-0.06259682774543762)\n",
      "     | > log_mle: -0.23525023460388184  (-0.23999925454457602)\n",
      "     | > loss_dur: 0.19078916311264038  (0.1774024267991384)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: -0.06324498355388641  (-0.06275886669754982)\n",
      "     | > log_mle: -0.26172709465026855  (-0.24543121457099915)\n",
      "     | > loss_dur: 0.19848211109638214  (0.18267234787344933)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: -0.05761633813381195  (-0.061730360984802245)\n",
      "     | > log_mle: -0.2599189281463623  (-0.2483287572860718)\n",
      "     | > loss_dur: 0.20230259001255035  (0.18659839630126954)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: -0.026573091745376587  (-0.055870816111564636)\n",
      "     | > log_mle: -0.27062368392944336  (-0.25204457839330036)\n",
      "     | > loss_dur: 0.24405059218406677  (0.19617376228173575)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: -0.04301770031452179  (-0.05403465671198709)\n",
      "     | > log_mle: -0.23571956157684326  (-0.2497124331338065)\n",
      "     | > loss_dur: 0.19270186126232147  (0.1956777764218194)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: -0.05674472451210022  (-0.05437341518700123)\n",
      "     | > log_mle: -0.24563276767730713  (-0.24920247495174408)\n",
      "     | > loss_dur: 0.1888880431652069  (0.19482905976474285)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: -0.02970913052558899  (-0.05163293911351098)\n",
      "     | > log_mle: -0.2570614814758301  (-0.25007569789886475)\n",
      "     | > loss_dur: 0.2273523509502411  (0.19844275878535378)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: -0.018354937434196472  (-0.04830513894557953)\n",
      "     | > log_mle: -0.24332678318023682  (-0.24940080642700196)\n",
      "     | > loss_dur: 0.22497184574604034  (0.20109566748142244)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: -0.05012771487236023  (-0.048470827666195954)\n",
      "     | > log_mle: -0.25957536697387695  (-0.25032576647671784)\n",
      "     | > loss_dur: 0.20944765210151672  (0.2018549388105219)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: -0.0638505071401596  (-0.049752467622359596)\n",
      "     | > log_mle: -0.24812912940979004  (-0.2501427133878072)\n",
      "     | > loss_dur: 0.18427862226963043  (0.20039024576544762)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: -0.08425261080265045  (-0.052406324790074274)\n",
      "     | > log_mle: -0.2674858570098877  (-0.25147680135873646)\n",
      "     | > loss_dur: 0.18323324620723724  (0.1990704765686622)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: -0.04764193296432495  (-0.05206601108823504)\n",
      "     | > log_mle: -0.25910091400146484  (-0.25202138083321707)\n",
      "     | > loss_dur: 0.2114589810371399  (0.19995536974498204)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: -0.042683348059654236  (-0.05144050021966298)\n",
      "     | > log_mle: -0.2528867721557617  (-0.25207907358805337)\n",
      "     | > loss_dur: 0.21020342409610748  (0.2006385733683904)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: -0.03564910590648651  (-0.050453538075089455)\n",
      "     | > log_mle: -0.25116801261901855  (-0.2520221322774887)\n",
      "     | > loss_dur: 0.21551890671253204  (0.20156859420239925)\n",
      "\n",
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[91m 0.004530414938926697 \u001b[0m(+0.0011032074689865112)\n",
      "     | > avg_loss:\u001b[92m -0.050453538075089455 \u001b[0m(-0.002300928346812725)\n",
      "     | > avg_log_mle:\u001b[92m -0.2520221322774887 \u001b[0m(-0.0013783946633338928)\n",
      "     | > avg_loss_dur:\u001b[92m 0.20156859420239925 \u001b[0m(-0.0009225336834788322)\n",
      "\n",
      " > BEST MODEL : train/run-February-22-2025_10+59PM-fa84af3/best_model_35722.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 32/100\u001b[0m\n",
      " --> train/run-February-22-2025_10+59PM-fa84af3\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-23 01:48:29) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:48:33 -- STEP: 3/406 -- GLOBAL_STEP: 35725\u001b[0m\n",
      "     | > loss: -0.03183971345424652  (-0.050343289971351624)\n",
      "     | > log_mle: -0.22935867309570312  (-0.23016107082366943)\n",
      "     | > loss_dur: 0.1975189596414566  (0.1798177808523178)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(11.6388, device='cuda:0')  (tensor(11.0913, device='cuda:0'))\n",
      "     | > current_lr: 8e-06 \n",
      "     | > step_time: 0.3796  (0.5466354688008627)\n",
      "     | > loader_time: 0.0041  (0.01005713144938151)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:48:46 -- STEP: 28/406 -- GLOBAL_STEP: 35750\u001b[0m\n",
      "     | > loss: -0.013759732246398926  (-0.03236228600144387)\n",
      "     | > log_mle: -0.2235637903213501  (-0.22352429372923716)\n",
      "     | > loss_dur: 0.20980405807495117  (0.1911620077277933)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(10.4833, device='cuda:0')  (tensor(14.3919, device='cuda:0'))\n",
      "     | > current_lr: 8e-06 \n",
      "     | > step_time: 0.6879  (0.5072325042315892)\n",
      "     | > loader_time: 0.0179  (0.007097687040056501)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:49:02 -- STEP: 53/406 -- GLOBAL_STEP: 35775\u001b[0m\n",
      "     | > loss: -0.026085585355758667  (-0.026077553629875183)\n",
      "     | > log_mle: -0.22151756286621094  (-0.2239845023964936)\n",
      "     | > loss_dur: 0.19543197751045227  (0.1979069487666184)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(8.7071, device='cuda:0')  (tensor(13.2182, device='cuda:0'))\n",
      "     | > current_lr: 8e-06 \n",
      "     | > step_time: 0.2743  (0.5574865566109712)\n",
      "     | > loader_time: 0.0058  (0.008834514977797022)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:49:18 -- STEP: 78/406 -- GLOBAL_STEP: 35800\u001b[0m\n",
      "     | > loss: -0.026654139161109924  (-0.02414762591704344)\n",
      "     | > log_mle: -0.22895526885986328  (-0.22642333843769172)\n",
      "     | > loss_dur: 0.20230112969875336  (0.2022757125206483)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(16.7604, device='cuda:0')  (tensor(13.8691, device='cuda:0'))\n",
      "     | > current_lr: 8e-06 \n",
      "     | > step_time: 0.4933  (0.5838265632971739)\n",
      "     | > loader_time: 0.0051  (0.008686533341040978)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:49:35 -- STEP: 103/406 -- GLOBAL_STEP: 35825\u001b[0m\n",
      "     | > loss: -0.03831477463245392  (-0.024133608468527933)\n",
      "     | > log_mle: -0.24668872356414795  (-0.22943130627419184)\n",
      "     | > loss_dur: 0.20837394893169403  (0.20529769780566393)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(21.0898, device='cuda:0')  (tensor(14.8603, device='cuda:0'))\n",
      "     | > current_lr: 8e-06 \n",
      "     | > step_time: 0.6281  (0.5989785356429017)\n",
      "     | > loader_time: 0.0093  (0.00965522793890203)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:49:51 -- STEP: 128/406 -- GLOBAL_STEP: 35850\u001b[0m\n",
      "     | > loss: -0.03486885130405426  (-0.024452126352116466)\n",
      "     | > log_mle: -0.23932862281799316  (-0.23186287004500628)\n",
      "     | > loss_dur: 0.2044597715139389  (0.2074107436928898)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(18.9590, device='cuda:0')  (tensor(15.8435, device='cuda:0'))\n",
      "     | > current_lr: 8e-06 \n",
      "     | > step_time: 0.7723  (0.6079893577843904)\n",
      "     | > loader_time: 0.0324  (0.009900644421577454)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:50:09 -- STEP: 153/406 -- GLOBAL_STEP: 35875\u001b[0m\n",
      "     | > loss: -0.03785187005996704  (-0.024198951090083402)\n",
      "     | > log_mle: -0.24947035312652588  (-0.2338139418683021)\n",
      "     | > loss_dur: 0.21161848306655884  (0.20961499077821868)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(36.6138, device='cuda:0')  (tensor(16.5443, device='cuda:0'))\n",
      "     | > current_lr: 8e-06 \n",
      "     | > step_time: 0.5202  (0.6220604983809728)\n",
      "     | > loader_time: 0.0264  (0.01022808692034553)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:50:28 -- STEP: 178/406 -- GLOBAL_STEP: 35900\u001b[0m\n",
      "     | > loss: -0.014491468667984009  (-0.024079588189553677)\n",
      "     | > log_mle: -0.23195230960845947  (-0.23516104864270498)\n",
      "     | > loss_dur: 0.21746084094047546  (0.21108146045315132)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(9.6769, device='cuda:0')  (tensor(17.0225, device='cuda:0'))\n",
      "     | > current_lr: 8e-06 \n",
      "     | > step_time: 0.7908  (0.6362300695997947)\n",
      "     | > loader_time: 0.0265  (0.010738029908598134)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:50:49 -- STEP: 203/406 -- GLOBAL_STEP: 35925\u001b[0m\n",
      "     | > loss: -0.007261693477630615  (-0.02390470770485883)\n",
      "     | > log_mle: -0.2418590784072876  (-0.23652146015261194)\n",
      "     | > loss_dur: 0.23459738492965698  (0.2126167524477531)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(20.9041, device='cuda:0')  (tensor(17.7128, device='cuda:0'))\n",
      "     | > current_lr: 8e-06 \n",
      "     | > step_time: 0.8733  (0.6600454898890604)\n",
      "     | > loader_time: 0.0099  (0.011649271537517675)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:51:09 -- STEP: 228/406 -- GLOBAL_STEP: 35950\u001b[0m\n",
      "     | > loss: -0.03407977521419525  (-0.024138213249675015)\n",
      "     | > log_mle: -0.2478797435760498  (-0.23791713725056565)\n",
      "     | > loss_dur: 0.21379996836185455  (0.21377892400089063)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(18.6724, device='cuda:0')  (tensor(18.0688, device='cuda:0'))\n",
      "     | > current_lr: 8e-06 \n",
      "     | > step_time: 1.3757  (0.674261768658956)\n",
      "     | > loader_time: 0.0118  (0.012266955877605233)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:51:32 -- STEP: 253/406 -- GLOBAL_STEP: 35975\u001b[0m\n",
      "     | > loss: -0.038715749979019165  (-0.02422752352100116)\n",
      "     | > log_mle: -0.26482701301574707  (-0.23921724741637942)\n",
      "     | > loss_dur: 0.2261112630367279  (0.21498972389537827)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(26.1110, device='cuda:0')  (tensor(18.3761, device='cuda:0'))\n",
      "     | > current_lr: 8e-06 \n",
      "     | > step_time: 0.4985  (0.6954356248199706)\n",
      "     | > loader_time: 0.0053  (0.013092606435180178)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:51:55 -- STEP: 278/406 -- GLOBAL_STEP: 36000\u001b[0m\n",
      "     | > loss: -0.02195863425731659  (-0.024631048653194373)\n",
      "     | > log_mle: -0.24156272411346436  (-0.2402424353489773)\n",
      "     | > loss_dur: 0.21960408985614777  (0.21561138669578292)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(22.4760, device='cuda:0')  (tensor(18.7958, device='cuda:0'))\n",
      "     | > current_lr: 8e-06 \n",
      "     | > step_time: 1.1749  (0.7111942450777232)\n",
      "     | > loader_time: 0.0085  (0.013205236668209375)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:52:15 -- STEP: 303/406 -- GLOBAL_STEP: 36025\u001b[0m\n",
      "     | > loss: -0.014071822166442871  (-0.024719682807969576)\n",
      "     | > log_mle: -0.25166749954223633  (-0.2411975848792803)\n",
      "     | > loss_dur: 0.23759567737579346  (0.21647790207131073)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(22.9701, device='cuda:0')  (tensor(19.1149, device='cuda:0'))\n",
      "     | > current_lr: 8e-06 \n",
      "     | > step_time: 1.4197  (0.719085256652077)\n",
      "     | > loader_time: 0.0097  (0.01327976928685758)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:52:36 -- STEP: 328/406 -- GLOBAL_STEP: 36050\u001b[0m\n",
      "     | > loss: -0.013122215867042542  (-0.024792707593339246)\n",
      "     | > log_mle: -0.2612253427505493  (-0.24189626988841267)\n",
      "     | > loss_dur: 0.24810312688350677  (0.2171035622950734)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(19.8621, device='cuda:0')  (tensor(19.4352, device='cuda:0'))\n",
      "     | > current_lr: 8e-06 \n",
      "     | > step_time: 0.8839  (0.7270087003707892)\n",
      "     | > loader_time: 0.0237  (0.013364158752487927)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:52:58 -- STEP: 353/406 -- GLOBAL_STEP: 36075\u001b[0m\n",
      "     | > loss: -0.022961661219596863  (-0.024726136547985562)\n",
      "     | > log_mle: -0.26512396335601807  (-0.24267560361802748)\n",
      "     | > loss_dur: 0.2421623021364212  (0.2179494670700419)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(26.7923, device='cuda:0')  (tensor(19.7739, device='cuda:0'))\n",
      "     | > current_lr: 8e-06 \n",
      "     | > step_time: 0.791  (0.7352274517837398)\n",
      "     | > loader_time: 0.0077  (0.013830250450977185)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:53:23 -- STEP: 378/406 -- GLOBAL_STEP: 36100\u001b[0m\n",
      "     | > loss: -0.01894405484199524  (-0.024932890420868284)\n",
      "     | > log_mle: -0.25256597995758057  (-0.24354675648704407)\n",
      "     | > loss_dur: 0.23362192511558533  (0.2186138660661758)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(24.8160, device='cuda:0')  (tensor(20.0890, device='cuda:0'))\n",
      "     | > current_lr: 8e-06 \n",
      "     | > step_time: 0.8036  (0.7502367628945248)\n",
      "     | > loader_time: 0.0077  (0.014066177070456208)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:53:42 -- STEP: 403/406 -- GLOBAL_STEP: 36125\u001b[0m\n",
      "     | > loss: -0.03890451788902283  (-0.025013591900061142)\n",
      "     | > log_mle: -0.24896228313446045  (-0.24431899197344153)\n",
      "     | > loss_dur: 0.21005776524543762  (0.2193054000733804)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(20.5367, device='cuda:0')  (tensor(20.3144, device='cuda:0'))\n",
      "     | > current_lr: 8e-06 \n",
      "     | > step_time: 0.5228  (0.7497726113861314)\n",
      "     | > loader_time: 0.0096  (0.014168869472910689)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: -0.014402031898498535  (-0.014402031898498535)\n",
      "     | > log_mle: -0.22648394107818604  (-0.22648394107818604)\n",
      "     | > loss_dur: 0.2120819091796875  (0.2120819091796875)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: -0.08990956842899323  (-0.08990956842899323)\n",
      "     | > log_mle: -0.2654191255569458  (-0.2654191255569458)\n",
      "     | > loss_dur: 0.17550955712795258  (0.17550955712795258)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: -0.06026315689086914  (-0.07508636265993118)\n",
      "     | > log_mle: -0.22551310062408447  (-0.24546611309051514)\n",
      "     | > loss_dur: 0.16524994373321533  (0.17037975043058395)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: -0.049853190779685974  (-0.06667530536651611)\n",
      "     | > log_mle: -0.23863577842712402  (-0.24318933486938477)\n",
      "     | > loss_dur: 0.18878258764743805  (0.17651402950286865)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: -0.06883558630943298  (-0.06721537560224533)\n",
      "     | > log_mle: -0.2655761241912842  (-0.24878603219985962)\n",
      "     | > loss_dur: 0.1967405378818512  (0.1815706565976143)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: -0.06360012292861938  (-0.06649232506752015)\n",
      "     | > log_mle: -0.26431798934936523  (-0.2518924236297607)\n",
      "     | > loss_dur: 0.20071786642074585  (0.1854000985622406)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: -0.03162375092506409  (-0.060680896043777466)\n",
      "     | > log_mle: -0.27550172805786133  (-0.25582730770111084)\n",
      "     | > loss_dur: 0.24387797713279724  (0.19514641165733337)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: -0.04684245586395264  (-0.0587039760180882)\n",
      "     | > log_mle: -0.23913228511810303  (-0.25344230447496685)\n",
      "     | > loss_dur: 0.1922898292541504  (0.19473832845687866)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: -0.0635790079832077  (-0.05931335501372814)\n",
      "     | > log_mle: -0.24907660484313965  (-0.25289659202098846)\n",
      "     | > loss_dur: 0.18549759685993195  (0.19358323700726032)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: -0.036265671253204346  (-0.05675250126255883)\n",
      "     | > log_mle: -0.26131927967071533  (-0.25383244620429146)\n",
      "     | > loss_dur: 0.225053608417511  (0.19707994494173262)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: -0.026223108172416687  (-0.05369956195354462)\n",
      "     | > log_mle: -0.2470937967300415  (-0.25315858125686647)\n",
      "     | > loss_dur: 0.22087068855762482  (0.19945901930332183)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: -0.05332694947719574  (-0.05366568809205836)\n",
      "     | > log_mle: -0.2633167505264282  (-0.25408205119046295)\n",
      "     | > loss_dur: 0.20998980104923248  (0.20041636309840463)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: -0.06619308888912201  (-0.054709638158480324)\n",
      "     | > log_mle: -0.2516000270843506  (-0.25387521584828693)\n",
      "     | > loss_dur: 0.18540693819522858  (0.1991655776898066)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: -0.09094889461994171  (-0.057497273270900436)\n",
      "     | > log_mle: -0.2713778018951416  (-0.25522156862112194)\n",
      "     | > loss_dur: 0.1804289072751999  (0.19772429535022149)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: -0.054835572838783264  (-0.057307151811463494)\n",
      "     | > log_mle: -0.26309847831726074  (-0.255784205027989)\n",
      "     | > loss_dur: 0.20826290547847748  (0.19847705321652548)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: -0.04880806803703308  (-0.056740546226501466)\n",
      "     | > log_mle: -0.25658750534057617  (-0.25583775838216144)\n",
      "     | > loss_dur: 0.2077794373035431  (0.19909721215565998)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: -0.03690069913864136  (-0.05550055578351021)\n",
      "     | > log_mle: -0.2552086114883423  (-0.25579843670129776)\n",
      "     | > loss_dur: 0.21830791234970093  (0.20029788091778755)\n",
      "\n",
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.00399412214756012 \u001b[0m(-0.0005362927913665771)\n",
      "     | > avg_loss:\u001b[92m -0.05550055578351021 \u001b[0m(-0.0050470177084207535)\n",
      "     | > avg_log_mle:\u001b[92m -0.25579843670129776 \u001b[0m(-0.0037763044238090515)\n",
      "     | > avg_loss_dur:\u001b[92m 0.20029788091778755 \u001b[0m(-0.001270713284611702)\n",
      "\n",
      " > BEST MODEL : train/run-February-22-2025_10+59PM-fa84af3/best_model_36128.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 33/100\u001b[0m\n",
      " --> train/run-February-22-2025_10+59PM-fa84af3\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-23 01:53:59) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:54:13 -- STEP: 22/406 -- GLOBAL_STEP: 36150\u001b[0m\n",
      "     | > loss: -0.020489603281021118  (-0.03740030865777622)\n",
      "     | > log_mle: -0.2146846055984497  (-0.22519309954209762)\n",
      "     | > loss_dur: 0.1941950023174286  (0.18779279088432138)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(14.4632, device='cuda:0')  (tensor(12.3533, device='cuda:0'))\n",
      "     | > current_lr: 8.25e-06 \n",
      "     | > step_time: 0.8328  (0.4890804507515647)\n",
      "     | > loader_time: 0.0038  (0.004340713674371894)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:54:28 -- STEP: 47/406 -- GLOBAL_STEP: 36175\u001b[0m\n",
      "     | > loss: -0.015273451805114746  (-0.029696219779075456)\n",
      "     | > log_mle: -0.24822866916656494  (-0.22506505377749178)\n",
      "     | > loss_dur: 0.2329552173614502  (0.19536883399841634)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(15.5606, device='cuda:0')  (tensor(12.0391, device='cuda:0'))\n",
      "     | > current_lr: 8.25e-06 \n",
      "     | > step_time: 0.7611  (0.5473718491006406)\n",
      "     | > loader_time: 0.0148  (0.006714212133529339)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:54:44 -- STEP: 72/406 -- GLOBAL_STEP: 36200\u001b[0m\n",
      "     | > loss: -0.031598448753356934  (-0.027800521295931604)\n",
      "     | > log_mle: -0.2201012372970581  (-0.22745307286580405)\n",
      "     | > loss_dur: 0.18850278854370117  (0.19965255156987244)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(12.9924, device='cuda:0')  (tensor(12.9668, device='cuda:0'))\n",
      "     | > current_lr: 8.25e-06 \n",
      "     | > step_time: 0.5568  (0.5730541348457336)\n",
      "     | > loader_time: 0.0313  (0.008562280072106255)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:55:01 -- STEP: 97/406 -- GLOBAL_STEP: 36225\u001b[0m\n",
      "     | > loss: -0.01674070954322815  (-0.02712032260354032)\n",
      "     | > log_mle: -0.23750901222229004  (-0.2307674380921826)\n",
      "     | > loss_dur: 0.2207683026790619  (0.20364711548864228)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(19.2611, device='cuda:0')  (tensor(14.3954, device='cuda:0'))\n",
      "     | > current_lr: 8.25e-06 \n",
      "     | > step_time: 0.4857  (0.6002707235591925)\n",
      "     | > loader_time: 0.0047  (0.009497782618729111)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:55:18 -- STEP: 122/406 -- GLOBAL_STEP: 36250\u001b[0m\n",
      "     | > loss: -0.025367140769958496  (-0.027514270827418467)\n",
      "     | > log_mle: -0.23101091384887695  (-0.23321766540652417)\n",
      "     | > loss_dur: 0.20564377307891846  (0.2057033945791057)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(7.5193, device='cuda:0')  (tensor(15.0508, device='cuda:0'))\n",
      "     | > current_lr: 8.25e-06 \n",
      "     | > step_time: 0.719  (0.6115934379765243)\n",
      "     | > loader_time: 0.016  (0.00993004783255155)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:55:35 -- STEP: 147/406 -- GLOBAL_STEP: 36275\u001b[0m\n",
      "     | > loss: -0.019039303064346313  (-0.027166752284075946)\n",
      "     | > log_mle: -0.2424449920654297  (-0.23537294313210208)\n",
      "     | > loss_dur: 0.22340568900108337  (0.20820619084802613)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(15.0496, device='cuda:0')  (tensor(15.1786, device='cuda:0'))\n",
      "     | > current_lr: 8.25e-06 \n",
      "     | > step_time: 0.9473  (0.6182043309114416)\n",
      "     | > loader_time: 0.0119  (0.010268892560686384)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:55:52 -- STEP: 172/406 -- GLOBAL_STEP: 36300\u001b[0m\n",
      "     | > loss: -0.023534879088401794  (-0.02688650093799414)\n",
      "     | > log_mle: -0.2456510066986084  (-0.23692280677861946)\n",
      "     | > loss_dur: 0.2221161276102066  (0.21003630584062533)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(40.4695, device='cuda:0')  (tensor(16.4769, device='cuda:0'))\n",
      "     | > current_lr: 8.25e-06 \n",
      "     | > step_time: 0.8561  (0.6272982497547946)\n",
      "     | > loader_time: 0.0169  (0.011204991229744844)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:56:09 -- STEP: 197/406 -- GLOBAL_STEP: 36325\u001b[0m\n",
      "     | > loss: -0.03874775767326355  (-0.02697528119619728)\n",
      "     | > log_mle: -0.24487805366516113  (-0.23838105722127226)\n",
      "     | > loss_dur: 0.20613029599189758  (0.211405776025075)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(33.8786, device='cuda:0')  (tensor(17.8789, device='cuda:0'))\n",
      "     | > current_lr: 8.25e-06 \n",
      "     | > step_time: 0.5144  (0.6326932810284767)\n",
      "     | > loader_time: 0.0053  (0.011509803345965856)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:56:27 -- STEP: 222/406 -- GLOBAL_STEP: 36350\u001b[0m\n",
      "     | > loss: -0.03502647578716278  (-0.026898611638997056)\n",
      "     | > log_mle: -0.24871611595153809  (-0.23970777923996384)\n",
      "     | > loss_dur: 0.2136896401643753  (0.2128091676009668)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(13.9694, device='cuda:0')  (tensor(18.1090, device='cuda:0'))\n",
      "     | > current_lr: 8.25e-06 \n",
      "     | > step_time: 0.9157  (0.640428342260756)\n",
      "     | > loader_time: 0.0217  (0.01153744448412646)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:56:47 -- STEP: 247/406 -- GLOBAL_STEP: 36375\u001b[0m\n",
      "     | > loss: -0.02076198160648346  (-0.026884955071244648)\n",
      "     | > log_mle: -0.23887133598327637  (-0.2408628251388488)\n",
      "     | > loss_dur: 0.2181093543767929  (0.21397787006760416)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(16.8905, device='cuda:0')  (tensor(18.4689, device='cuda:0'))\n",
      "     | > current_lr: 8.25e-06 \n",
      "     | > step_time: 1.0109  (0.653214204649211)\n",
      "     | > loader_time: 0.0221  (0.01160316235623379)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:57:06 -- STEP: 272/406 -- GLOBAL_STEP: 36400\u001b[0m\n",
      "     | > loss: -0.037295565009117126  (-0.027398736873532045)\n",
      "     | > log_mle: -0.2627284526824951  (-0.24198023054529638)\n",
      "     | > loss_dur: 0.225432887673378  (0.21458149367176435)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(25.8173, device='cuda:0')  (tensor(18.5967, device='cuda:0'))\n",
      "     | > current_lr: 8.25e-06 \n",
      "     | > step_time: 0.5825  (0.6608151854837642)\n",
      "     | > loader_time: 0.0085  (0.011559857165112215)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:57:26 -- STEP: 297/406 -- GLOBAL_STEP: 36425\u001b[0m\n",
      "     | > loss: -0.03127013146877289  (-0.02754596362410973)\n",
      "     | > log_mle: -0.2528672218322754  (-0.24283534268337467)\n",
      "     | > loss_dur: 0.2215970903635025  (0.215289379059265)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(32.8707, device='cuda:0')  (tensor(19.0642, device='cuda:0'))\n",
      "     | > current_lr: 8.25e-06 \n",
      "     | > step_time: 0.931  (0.6713525502368658)\n",
      "     | > loader_time: 0.0063  (0.011995129312329022)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:57:45 -- STEP: 322/406 -- GLOBAL_STEP: 36450\u001b[0m\n",
      "     | > loss: -0.045964762568473816  (-0.027736536556889558)\n",
      "     | > log_mle: -0.25540077686309814  (-0.24362690848593385)\n",
      "     | > loss_dur: 0.20943601429462433  (0.21589037192904437)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(28.6346, device='cuda:0')  (tensor(19.4895, device='cuda:0'))\n",
      "     | > current_lr: 8.25e-06 \n",
      "     | > step_time: 0.6775  (0.6759333388405558)\n",
      "     | > loader_time: 0.0202  (0.01218397943129451)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:58:10 -- STEP: 347/406 -- GLOBAL_STEP: 36475\u001b[0m\n",
      "     | > loss: -0.03154553472995758  (-0.0277282757958349)\n",
      "     | > log_mle: -0.2519484758377075  (-0.24439876017721654)\n",
      "     | > loss_dur: 0.22040294110774994  (0.2166704843813817)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(23.2143, device='cuda:0')  (tensor(19.4277, device='cuda:0'))\n",
      "     | > current_lr: 8.25e-06 \n",
      "     | > step_time: 0.6149  (0.6969941555594849)\n",
      "     | > loader_time: 0.0456  (0.01272965989126596)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:58:32 -- STEP: 372/406 -- GLOBAL_STEP: 36500\u001b[0m\n",
      "     | > loss: -0.02556602656841278  (-0.02781879965977003)\n",
      "     | > log_mle: -0.24803614616394043  (-0.24525661654369804)\n",
      "     | > loss_dur: 0.22247011959552765  (0.21743781688392808)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(42.3234, device='cuda:0')  (tensor(19.9999, device='cuda:0'))\n",
      "     | > current_lr: 8.25e-06 \n",
      "     | > step_time: 0.9029  (0.7086105474861716)\n",
      "     | > loader_time: 0.0278  (0.013048933398339058)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:58:53 -- STEP: 397/406 -- GLOBAL_STEP: 36525\u001b[0m\n",
      "     | > loss: -0.03477314114570618  (-0.027953599089339042)\n",
      "     | > log_mle: -0.2668691873550415  (-0.24605280866550858)\n",
      "     | > loss_dur: 0.23209604620933533  (0.21809920957616957)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(41.6647, device='cuda:0')  (tensor(20.1822, device='cuda:0'))\n",
      "     | > current_lr: 8.25e-06 \n",
      "     | > step_time: 0.5255  (0.7169242739977701)\n",
      "     | > loader_time: 0.0063  (0.013293709502712607)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: -0.021079719066619873  (-0.021079719066619873)\n",
      "     | > log_mle: -0.22865629196166992  (-0.22865629196166992)\n",
      "     | > loss_dur: 0.20757657289505005  (0.20757657289505005)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: -0.09389761090278625  (-0.09389761090278625)\n",
      "     | > log_mle: -0.26732945442199707  (-0.26732945442199707)\n",
      "     | > loss_dur: 0.17343184351921082  (0.17343184351921082)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: -0.06194154918193817  (-0.07791958004236221)\n",
      "     | > log_mle: -0.227380633354187  (-0.24735504388809204)\n",
      "     | > loss_dur: 0.16543908417224884  (0.16943546384572983)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: -0.05327075719833374  (-0.0697033057610194)\n",
      "     | > log_mle: -0.24101102352142334  (-0.2452403704325358)\n",
      "     | > loss_dur: 0.1877402663230896  (0.17553706467151642)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: -0.07366026937961578  (-0.07069254666566849)\n",
      "     | > log_mle: -0.2676112651824951  (-0.25083309412002563)\n",
      "     | > loss_dur: 0.19395099580287933  (0.18014054745435715)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: -0.06151577830314636  (-0.06885719299316406)\n",
      "     | > log_mle: -0.264801025390625  (-0.2536266803741455)\n",
      "     | > loss_dur: 0.20328524708747864  (0.18476948738098145)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: -0.0361449271440506  (-0.06340514868497849)\n",
      "     | > log_mle: -0.27483177185058594  (-0.25716086228688556)\n",
      "     | > loss_dur: 0.23868684470653534  (0.1937557136019071)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: -0.04697304964065552  (-0.06105770596436092)\n",
      "     | > log_mle: -0.24022555351257324  (-0.25474153246198383)\n",
      "     | > loss_dur: 0.19325250387191772  (0.1936838264976229)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: -0.06576381623744965  (-0.06164596974849701)\n",
      "     | > log_mle: -0.2506439685821533  (-0.254229336977005)\n",
      "     | > loss_dur: 0.18488015234470367  (0.192583367228508)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: -0.03768308460712433  (-0.05898342695501116)\n",
      "     | > log_mle: -0.26217949390411377  (-0.2551126877466838)\n",
      "     | > loss_dur: 0.22449640929698944  (0.1961292607916726)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: -0.030170083045959473  (-0.05610209256410599)\n",
      "     | > log_mle: -0.24822425842285156  (-0.2544238448143005)\n",
      "     | > loss_dur: 0.2180541753768921  (0.19832175225019455)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: -0.05544084310531616  (-0.056041978976943276)\n",
      "     | > log_mle: -0.26494574546813965  (-0.25538038123737683)\n",
      "     | > loss_dur: 0.2095049023628235  (0.19933840226043353)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: -0.06901393830776215  (-0.05712297558784485)\n",
      "     | > log_mle: -0.2533388137817383  (-0.2552102506160736)\n",
      "     | > loss_dur: 0.18432487547397614  (0.19808727502822876)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: -0.08886873722076416  (-0.059564957251915567)\n",
      "     | > log_mle: -0.2723221778869629  (-0.25652655271383434)\n",
      "     | > loss_dur: 0.18345344066619873  (0.19696159546191877)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: -0.055945977568626404  (-0.059306458703109195)\n",
      "     | > log_mle: -0.2641479969024658  (-0.2570709415844509)\n",
      "     | > loss_dur: 0.20820201933383942  (0.19776448288134166)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: -0.05483384430408478  (-0.0590082844098409)\n",
      "     | > log_mle: -0.2578878402709961  (-0.25712540149688723)\n",
      "     | > loss_dur: 0.20305399596691132  (0.1981171170870463)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: -0.044479697942733765  (-0.058100247755646706)\n",
      "     | > log_mle: -0.256402850151062  (-0.25708024203777313)\n",
      "     | > loss_dur: 0.21192315220832825  (0.19897999428212643)\n",
      "\n",
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[91m 0.005804196000099182 \u001b[0m(+0.0018100738525390625)\n",
      "     | > avg_loss:\u001b[92m -0.058100247755646706 \u001b[0m(-0.0025996919721364975)\n",
      "     | > avg_log_mle:\u001b[92m -0.25708024203777313 \u001b[0m(-0.0012818053364753723)\n",
      "     | > avg_loss_dur:\u001b[92m 0.19897999428212643 \u001b[0m(-0.0013178866356611252)\n",
      "\n",
      " > BEST MODEL : train/run-February-22-2025_10+59PM-fa84af3/best_model_36534.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 34/100\u001b[0m\n",
      " --> train/run-February-22-2025_10+59PM-fa84af3\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-23 01:59:14) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:59:26 -- STEP: 16/406 -- GLOBAL_STEP: 36550\u001b[0m\n",
      "     | > loss: -0.027676627039909363  (-0.03873490355908871)\n",
      "     | > log_mle: -0.23091459274291992  (-0.2303202971816063)\n",
      "     | > loss_dur: 0.20323796570301056  (0.19158539362251759)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(20.2640, device='cuda:0')  (tensor(14.5825, device='cuda:0'))\n",
      "     | > current_lr: 8.5e-06 \n",
      "     | > step_time: 0.9389  (0.47499382495880127)\n",
      "     | > loader_time: 0.0111  (0.0062421709299087524)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:59:42 -- STEP: 41/406 -- GLOBAL_STEP: 36575\u001b[0m\n",
      "     | > loss: -0.023153066635131836  (-0.03253185131200929)\n",
      "     | > log_mle: -0.22443759441375732  (-0.22725847000029029)\n",
      "     | > loss_dur: 0.2012845277786255  (0.19472661868828098)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(11.8696, device='cuda:0')  (tensor(15.3131, device='cuda:0'))\n",
      "     | > current_lr: 8.5e-06 \n",
      "     | > step_time: 0.6523  (0.5677811692400676)\n",
      "     | > loader_time: 0.0084  (0.006725439211217369)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 01:59:59 -- STEP: 66/406 -- GLOBAL_STEP: 36600\u001b[0m\n",
      "     | > loss: -0.013633877038955688  (-0.030131468944477307)\n",
      "     | > log_mle: -0.23397040367126465  (-0.22908587166757294)\n",
      "     | > loss_dur: 0.22033652663230896  (0.19895440272309564)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(21.6417, device='cuda:0')  (tensor(14.1937, device='cuda:0'))\n",
      "     | > current_lr: 8.5e-06 \n",
      "     | > step_time: 0.5541  (0.6048139080856786)\n",
      "     | > loader_time: 0.0263  (0.009085272297714695)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:00:18 -- STEP: 91/406 -- GLOBAL_STEP: 36625\u001b[0m\n",
      "     | > loss: -0.03851059079170227  (-0.029611022262782834)\n",
      "     | > log_mle: -0.2475491762161255  (-0.23192319634196523)\n",
      "     | > loss_dur: 0.20903858542442322  (0.2023121740791824)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(19.8415, device='cuda:0')  (tensor(14.3685, device='cuda:0'))\n",
      "     | > current_lr: 8.5e-06 \n",
      "     | > step_time: 0.6336  (0.6444591349297828)\n",
      "     | > loader_time: 0.0141  (0.010149180234133541)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:00:36 -- STEP: 116/406 -- GLOBAL_STEP: 36650\u001b[0m\n",
      "     | > loss: -0.01078861951828003  (-0.029828891286562225)\n",
      "     | > log_mle: -0.23332750797271729  (-0.23462022995126658)\n",
      "     | > loss_dur: 0.22253888845443726  (0.20479133866470436)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(21.7014, device='cuda:0')  (tensor(15.5838, device='cuda:0'))\n",
      "     | > current_lr: 8.5e-06 \n",
      "     | > step_time: 0.4445  (0.6615456877083615)\n",
      "     | > loader_time: 0.0091  (0.009880602359771727)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:00:55 -- STEP: 141/406 -- GLOBAL_STEP: 36675\u001b[0m\n",
      "     | > loss: -0.026560276746749878  (-0.029552682600122816)\n",
      "     | > log_mle: -0.25261998176574707  (-0.23696184158325195)\n",
      "     | > loss_dur: 0.2260597050189972  (0.20740915898312912)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(34.5790, device='cuda:0')  (tensor(16.8419, device='cuda:0'))\n",
      "     | > current_lr: 8.5e-06 \n",
      "     | > step_time: 0.3481  (0.6732887105738864)\n",
      "     | > loader_time: 0.007  (0.01080785237305553)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:01:15 -- STEP: 166/406 -- GLOBAL_STEP: 36700\u001b[0m\n",
      "     | > loss: -0.03521791100502014  (-0.029562718089086462)\n",
      "     | > log_mle: -0.25381696224212646  (-0.23856317637914634)\n",
      "     | > loss_dur: 0.21859905123710632  (0.2090004582900599)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(23.9680, device='cuda:0')  (tensor(17.6180, device='cuda:0'))\n",
      "     | > current_lr: 8.5e-06 \n",
      "     | > step_time: 0.6028  (0.6885693303073745)\n",
      "     | > loader_time: 0.0066  (0.010905538696840583)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:01:34 -- STEP: 191/406 -- GLOBAL_STEP: 36725\u001b[0m\n",
      "     | > loss: -0.037298306822776794  (-0.02990051003962911)\n",
      "     | > log_mle: -0.24537599086761475  (-0.24009111976124228)\n",
      "     | > loss_dur: 0.20807768404483795  (0.2101906097216132)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(24.0174, device='cuda:0')  (tensor(18.2085, device='cuda:0'))\n",
      "     | > current_lr: 8.5e-06 \n",
      "     | > step_time: 1.0111  (0.6986604673076053)\n",
      "     | > loader_time: 0.0072  (0.011476160968161373)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:01:55 -- STEP: 216/406 -- GLOBAL_STEP: 36750\u001b[0m\n",
      "     | > loss: -0.031762853264808655  (-0.029940806812158337)\n",
      "     | > log_mle: -0.26119136810302734  (-0.24139453139570025)\n",
      "     | > loss_dur: 0.2294285148382187  (0.21145372458354192)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(18.3744, device='cuda:0')  (tensor(18.5819, device='cuda:0'))\n",
      "     | > current_lr: 8.5e-06 \n",
      "     | > step_time: 0.431  (0.7123920807132017)\n",
      "     | > loader_time: 0.0071  (0.01179394788212246)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:02:16 -- STEP: 241/406 -- GLOBAL_STEP: 36775\u001b[0m\n",
      "     | > loss: -0.02462369203567505  (-0.030012193000662872)\n",
      "     | > log_mle: -0.248801589012146  (-0.242746176066735)\n",
      "     | > loss_dur: 0.22417789697647095  (0.2127339830660721)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(20.7126, device='cuda:0')  (tensor(19.0245, device='cuda:0'))\n",
      "     | > current_lr: 8.5e-06 \n",
      "     | > step_time: 0.7889  (0.7212617080735965)\n",
      "     | > loader_time: 0.0148  (0.012204041619518482)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:02:38 -- STEP: 266/406 -- GLOBAL_STEP: 36800\u001b[0m\n",
      "     | > loss: -0.03946833312511444  (-0.030456302029297763)\n",
      "     | > log_mle: -0.25557518005371094  (-0.24384562996097078)\n",
      "     | > loss_dur: 0.2161068469285965  (0.213389327931673)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(18.6273, device='cuda:0')  (tensor(19.4843, device='cuda:0'))\n",
      "     | > current_lr: 8.5e-06 \n",
      "     | > step_time: 1.1711  (0.7330168010596945)\n",
      "     | > loader_time: 0.0159  (0.012791811971736131)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:03:02 -- STEP: 291/406 -- GLOBAL_STEP: 36825\u001b[0m\n",
      "     | > loss: -0.02923998236656189  (-0.030815352330502775)\n",
      "     | > log_mle: -0.24926817417144775  (-0.24480928752020872)\n",
      "     | > loss_dur: 0.22002819180488586  (0.21399393518970602)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(16.6293, device='cuda:0')  (tensor(19.7876, device='cuda:0'))\n",
      "     | > current_lr: 8.5e-06 \n",
      "     | > step_time: 1.6167  (0.7502892877637728)\n",
      "     | > loader_time: 0.0496  (0.01305778985170974)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:03:25 -- STEP: 316/406 -- GLOBAL_STEP: 36850\u001b[0m\n",
      "     | > loss: -0.03828933835029602  (-0.030973688192382644)\n",
      "     | > log_mle: -0.2628117799758911  (-0.24573337579075294)\n",
      "     | > loss_dur: 0.2245224416255951  (0.21475968759837039)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(22.2060, device='cuda:0')  (tensor(20.0756, device='cuda:0'))\n",
      "     | > current_lr: 8.5e-06 \n",
      "     | > step_time: 0.775  (0.762290838398511)\n",
      "     | > loader_time: 0.0371  (0.013590049140061004)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:03:48 -- STEP: 341/406 -- GLOBAL_STEP: 36875\u001b[0m\n",
      "     | > loss: -0.03733900189399719  (-0.03089523455264631)\n",
      "     | > log_mle: -0.2570607662200928  (-0.2463981552907099)\n",
      "     | > loss_dur: 0.21972176432609558  (0.21550292073806368)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(23.4131, device='cuda:0')  (tensor(20.2430, device='cuda:0'))\n",
      "     | > current_lr: 8.5e-06 \n",
      "     | > step_time: 0.7828  (0.7719587028201375)\n",
      "     | > loader_time: 0.0067  (0.013883597689989376)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:04:11 -- STEP: 366/406 -- GLOBAL_STEP: 36900\u001b[0m\n",
      "     | > loss: -0.039485394954681396  (-0.03096403576474372)\n",
      "     | > log_mle: -0.2631427049636841  (-0.24729887188458052)\n",
      "     | > loss_dur: 0.22365731000900269  (0.21633483611983687)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(26.2669, device='cuda:0')  (tensor(20.4838, device='cuda:0'))\n",
      "     | > current_lr: 8.5e-06 \n",
      "     | > step_time: 0.9115  (0.7810813481690454)\n",
      "     | > loader_time: 0.0058  (0.014133354353774441)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:04:35 -- STEP: 391/406 -- GLOBAL_STEP: 36925\u001b[0m\n",
      "     | > loss: -0.0323413610458374  (-0.031126198523184833)\n",
      "     | > log_mle: -0.2660336494445801  (-0.24805404127711225)\n",
      "     | > loss_dur: 0.23369228839874268  (0.21692784275392749)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(25.5102, device='cuda:0')  (tensor(20.4500, device='cuda:0'))\n",
      "     | > current_lr: 8.5e-06 \n",
      "     | > step_time: 0.9703  (0.7924250556379938)\n",
      "     | > loader_time: 0.0229  (0.014167361857031312)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: -0.02108687162399292  (-0.02108687162399292)\n",
      "     | > log_mle: -0.22963571548461914  (-0.22963571548461914)\n",
      "     | > loss_dur: 0.20854884386062622  (0.20854884386062622)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: -0.09503398835659027  (-0.09503398835659027)\n",
      "     | > log_mle: -0.2670501470565796  (-0.2670501470565796)\n",
      "     | > loss_dur: 0.17201615869998932  (0.17201615869998932)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: -0.0596744567155838  (-0.07735422253608704)\n",
      "     | > log_mle: -0.22833633422851562  (-0.2476932406425476)\n",
      "     | > loss_dur: 0.16866187751293182  (0.17033901810646057)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: -0.05328294634819031  (-0.06933046380678813)\n",
      "     | > log_mle: -0.23939692974090576  (-0.24492780367533365)\n",
      "     | > loss_dur: 0.18611398339271545  (0.17559733986854553)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: -0.07017821073532104  (-0.06954240053892136)\n",
      "     | > log_mle: -0.2656437158584595  (-0.2501067817211151)\n",
      "     | > loss_dur: 0.19546550512313843  (0.18056438118219376)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: -0.06575575470924377  (-0.06878507137298584)\n",
      "     | > log_mle: -0.26205480098724365  (-0.25249638557434084)\n",
      "     | > loss_dur: 0.19629904627799988  (0.18371131420135497)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: -0.02489122748374939  (-0.06146943072477976)\n",
      "     | > log_mle: -0.27252113819122314  (-0.2558338443438212)\n",
      "     | > loss_dur: 0.24762991070747375  (0.19436441361904144)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: -0.052741169929504395  (-0.06022253632545471)\n",
      "     | > log_mle: -0.23974454402923584  (-0.25353537287030903)\n",
      "     | > loss_dur: 0.18700337409973145  (0.1933128365448543)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: -0.07167483866214752  (-0.06165407411754131)\n",
      "     | > log_mle: -0.2502620220184326  (-0.25312620401382446)\n",
      "     | > loss_dur: 0.1785871833562851  (0.19147212989628315)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: -0.03774702548980713  (-0.058997735381126404)\n",
      "     | > log_mle: -0.26109957695007324  (-0.2540121343400743)\n",
      "     | > loss_dur: 0.2233525514602661  (0.19501439895894793)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: -0.02952386438846588  (-0.056050348281860354)\n",
      "     | > log_mle: -0.24760937690734863  (-0.2533718585968018)\n",
      "     | > loss_dur: 0.21808551251888275  (0.1973215103149414)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: -0.05206555128097534  (-0.05568809400905262)\n",
      "     | > log_mle: -0.2633723020553589  (-0.25428098982030695)\n",
      "     | > loss_dur: 0.21130675077438354  (0.19859289581125433)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: -0.06591662764549255  (-0.05654047181208929)\n",
      "     | > log_mle: -0.2527899742126465  (-0.2541567385196686)\n",
      "     | > loss_dur: 0.18687334656715393  (0.19761626670757929)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: -0.08790354430675507  (-0.0589530158501405)\n",
      "     | > log_mle: -0.27064692974090576  (-0.25542521476745605)\n",
      "     | > loss_dur: 0.1827433854341507  (0.19647219891731554)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: -0.053035274147987366  (-0.05853032001427242)\n",
      "     | > log_mle: -0.2631741762161255  (-0.2559787120137896)\n",
      "     | > loss_dur: 0.21013890206813812  (0.19744839199951716)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: -0.05514441430568695  (-0.058304592967033386)\n",
      "     | > log_mle: -0.25713372230529785  (-0.25605571269989014)\n",
      "     | > loss_dur: 0.2019893079996109  (0.19775111973285675)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: -0.04051840305328369  (-0.05719295609742403)\n",
      "     | > log_mle: -0.2555738687515259  (-0.25602559745311737)\n",
      "     | > loss_dur: 0.2150554656982422  (0.19883264135569334)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: audio amplitude out of range, auto clipped.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.005126446485519409 \u001b[0m(-0.000677749514579773)\n",
      "     | > avg_loss:\u001b[91m -0.05719295609742403 \u001b[0m(+0.0009072916582226753)\n",
      "     | > avg_log_mle:\u001b[91m -0.25602559745311737 \u001b[0m(+0.0010546445846557617)\n",
      "     | > avg_loss_dur:\u001b[92m 0.19883264135569334 \u001b[0m(-0.0001473529264330864)\n",
      "\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 35/100\u001b[0m\n",
      " --> train/run-February-22-2025_10+59PM-fa84af3\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-23 02:04:59) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:05:06 -- STEP: 10/406 -- GLOBAL_STEP: 36950\u001b[0m\n",
      "     | > loss: -0.06513884663581848  (-0.047914940118789676)\n",
      "     | > log_mle: -0.23391449451446533  (-0.23076537847518921)\n",
      "     | > loss_dur: 0.16877564787864685  (0.18285043835639953)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(9.0089, device='cuda:0')  (tensor(12.9302, device='cuda:0'))\n",
      "     | > current_lr: 8.750000000000001e-06 \n",
      "     | > step_time: 0.434  (0.47193691730499265)\n",
      "     | > loader_time: 0.0027  (0.0048800230026245115)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:05:22 -- STEP: 35/406 -- GLOBAL_STEP: 36975\u001b[0m\n",
      "     | > loss: -0.0491175502538681  (-0.0394291456256594)\n",
      "     | > log_mle: -0.23996257781982422  (-0.2298085757664272)\n",
      "     | > loss_dur: 0.19084502756595612  (0.19037943014076777)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(42.5951, device='cuda:0')  (tensor(17.0358, device='cuda:0'))\n",
      "     | > current_lr: 8.750000000000001e-06 \n",
      "     | > step_time: 0.5817  (0.5962060587746757)\n",
      "     | > loader_time: 0.0036  (0.006851387023925781)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:05:38 -- STEP: 60/406 -- GLOBAL_STEP: 37000\u001b[0m\n",
      "     | > loss: -0.035319194197654724  (-0.03526150410374004)\n",
      "     | > log_mle: -0.23469436168670654  (-0.23084908326466877)\n",
      "     | > loss_dur: 0.19937516748905182  (0.19558757916092873)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(9.7477, device='cuda:0')  (tensor(15.3958, device='cuda:0'))\n",
      "     | > current_lr: 8.750000000000001e-06 \n",
      "     | > step_time: 0.8945  (0.6063416123390197)\n",
      "     | > loader_time: 0.0099  (0.008412683010101318)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:05:54 -- STEP: 85/406 -- GLOBAL_STEP: 37025\u001b[0m\n",
      "     | > loss: -0.055618226528167725  (-0.034229462287005234)\n",
      "     | > log_mle: -0.25354135036468506  (-0.23352929423837102)\n",
      "     | > loss_dur: 0.19792312383651733  (0.1992998319513658)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(27.7173, device='cuda:0')  (tensor(15.9082, device='cuda:0'))\n",
      "     | > current_lr: 8.750000000000001e-06 \n",
      "     | > step_time: 0.5983  (0.6042924235848819)\n",
      "     | > loader_time: 0.0115  (0.010521235185510977)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:06:10 -- STEP: 110/406 -- GLOBAL_STEP: 37050\u001b[0m\n",
      "     | > loss: -0.032265350222587585  (-0.03417764888568359)\n",
      "     | > log_mle: -0.2583991289138794  (-0.23624003583734685)\n",
      "     | > loss_dur: 0.2261337786912918  (0.20206238695166331)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(24.3768, device='cuda:0')  (tensor(16.6235, device='cuda:0'))\n",
      "     | > current_lr: 8.750000000000001e-06 \n",
      "     | > step_time: 0.6216  (0.6134193008596249)\n",
      "     | > loader_time: 0.006  (0.010560367324135527)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:06:29 -- STEP: 135/406 -- GLOBAL_STEP: 37075\u001b[0m\n",
      "     | > loss: -0.03333359956741333  (-0.03432842680701504)\n",
      "     | > log_mle: -0.2538870573043823  (-0.23872868131708216)\n",
      "     | > loss_dur: 0.220553457736969  (0.20440025451006716)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(22.8831, device='cuda:0')  (tensor(17.3371, device='cuda:0'))\n",
      "     | > current_lr: 8.750000000000001e-06 \n",
      "     | > step_time: 0.375  (0.6390044424268937)\n",
      "     | > loader_time: 0.0058  (0.011136969813594117)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:06:48 -- STEP: 160/406 -- GLOBAL_STEP: 37100\u001b[0m\n",
      "     | > loss: -0.02269349992275238  (-0.03341997601091863)\n",
      "     | > log_mle: -0.254061222076416  (-0.24041669964790344)\n",
      "     | > loss_dur: 0.23136772215366364  (0.20699672363698474)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(22.0993, device='cuda:0')  (tensor(17.8683, device='cuda:0'))\n",
      "     | > current_lr: 8.750000000000001e-06 \n",
      "     | > step_time: 0.379  (0.6521810039877896)\n",
      "     | > loader_time: 0.0062  (0.011289259791374216)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:07:07 -- STEP: 185/406 -- GLOBAL_STEP: 37125\u001b[0m\n",
      "     | > loss: -0.035577192902565  (-0.03352002622307957)\n",
      "     | > log_mle: -0.25858020782470703  (-0.24195691959278004)\n",
      "     | > loss_dur: 0.22300301492214203  (0.2084368933697004)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(20.4263, device='cuda:0')  (tensor(18.3920, device='cuda:0'))\n",
      "     | > current_lr: 8.750000000000001e-06 \n",
      "     | > step_time: 0.9712  (0.6629400433720769)\n",
      "     | > loader_time: 0.006  (0.011844484226123714)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:07:25 -- STEP: 210/406 -- GLOBAL_STEP: 37150\u001b[0m\n",
      "     | > loss: -0.04591746628284454  (-0.03349845664841789)\n",
      "     | > log_mle: -0.2539759874343872  (-0.2432245515641712)\n",
      "     | > loss_dur: 0.20805852115154266  (0.20972609491575325)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(15.5901, device='cuda:0')  (tensor(18.7115, device='cuda:0'))\n",
      "     | > current_lr: 8.750000000000001e-06 \n",
      "     | > step_time: 0.565  (0.671545300029573)\n",
      "     | > loader_time: 0.0059  (0.01211019811176119)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:07:44 -- STEP: 235/406 -- GLOBAL_STEP: 37175\u001b[0m\n",
      "     | > loss: -0.03407353162765503  (-0.03374521580148252)\n",
      "     | > log_mle: -0.25204789638519287  (-0.24471552321251402)\n",
      "     | > loss_dur: 0.21797436475753784  (0.21097030741103145)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(31.3302, device='cuda:0')  (tensor(19.1826, device='cuda:0'))\n",
      "     | > current_lr: 8.750000000000001e-06 \n",
      "     | > step_time: 0.5131  (0.6780856994872397)\n",
      "     | > loader_time: 0.0054  (0.012155666757137223)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:08:05 -- STEP: 260/406 -- GLOBAL_STEP: 37200\u001b[0m\n",
      "     | > loss: -0.040023207664489746  (-0.03408823431684422)\n",
      "     | > log_mle: -0.26463520526885986  (-0.24596511996709383)\n",
      "     | > loss_dur: 0.22461199760437012  (0.21187688565024956)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(32.7749, device='cuda:0')  (tensor(19.4073, device='cuda:0'))\n",
      "     | > current_lr: 8.750000000000001e-06 \n",
      "     | > step_time: 0.7906  (0.6923571898387029)\n",
      "     | > loader_time: 0.0061  (0.012454912295708295)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:08:25 -- STEP: 285/406 -- GLOBAL_STEP: 37225\u001b[0m\n",
      "     | > loss: -0.02477268874645233  (-0.034575840151100844)\n",
      "     | > log_mle: -0.24928414821624756  (-0.2469821294148763)\n",
      "     | > loss_dur: 0.22451145946979523  (0.21240628926377542)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(27.9014, device='cuda:0')  (tensor(19.8081, device='cuda:0'))\n",
      "     | > current_lr: 8.750000000000001e-06 \n",
      "     | > step_time: 0.7697  (0.6996293779005084)\n",
      "     | > loader_time: 0.0205  (0.01286412038301167)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:08:45 -- STEP: 310/406 -- GLOBAL_STEP: 37250\u001b[0m\n",
      "     | > loss: -0.034682467579841614  (-0.03464064021264356)\n",
      "     | > log_mle: -0.26004719734191895  (-0.24783808685118153)\n",
      "     | > loss_dur: 0.22536472976207733  (0.21319744663853799)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(10.9864, device='cuda:0')  (tensor(19.6742, device='cuda:0'))\n",
      "     | > current_lr: 8.750000000000001e-06 \n",
      "     | > step_time: 1.3491  (0.703865272768082)\n",
      "     | > loader_time: 0.0084  (0.01335841917222546)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:09:06 -- STEP: 335/406 -- GLOBAL_STEP: 37275\u001b[0m\n",
      "     | > loss: -0.017946287989616394  (-0.03451484072564255)\n",
      "     | > log_mle: -0.2583404779434204  (-0.24851258868601786)\n",
      "     | > loss_dur: 0.24039418995380402  (0.21399774796037532)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(15.5319, device='cuda:0')  (tensor(19.8840, device='cuda:0'))\n",
      "     | > current_lr: 8.750000000000001e-06 \n",
      "     | > step_time: 0.8068  (0.7114273092639978)\n",
      "     | > loader_time: 0.0059  (0.013744226142541687)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:09:27 -- STEP: 360/406 -- GLOBAL_STEP: 37300\u001b[0m\n",
      "     | > loss: -0.04396355152130127  (-0.034480682305163816)\n",
      "     | > log_mle: -0.2604407072067261  (-0.2493087311585744)\n",
      "     | > loss_dur: 0.2164771556854248  (0.2148280488534106)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(36.4892, device='cuda:0')  (tensor(20.2826, device='cuda:0'))\n",
      "     | > current_lr: 8.750000000000001e-06 \n",
      "     | > step_time: 1.2086  (0.7206536710262297)\n",
      "     | > loader_time: 0.0092  (0.013991773790783353)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:09:57 -- STEP: 385/406 -- GLOBAL_STEP: 37325\u001b[0m\n",
      "     | > loss: -0.03613065183162689  (-0.034626743507075626)\n",
      "     | > log_mle: -0.25415098667144775  (-0.2500601530075074)\n",
      "     | > loss_dur: 0.21802033483982086  (0.21543340950043172)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(18.9198, device='cuda:0')  (tensor(20.6487, device='cuda:0'))\n",
      "     | > current_lr: 8.750000000000001e-06 \n",
      "     | > step_time: 2.0214  (0.7493895456388397)\n",
      "     | > loader_time: 0.0397  (0.014486598349236823)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: -0.02912619709968567  (-0.02912619709968567)\n",
      "     | > log_mle: -0.23340630531311035  (-0.23340630531311035)\n",
      "     | > loss_dur: 0.20428010821342468  (0.20428010821342468)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: -0.09964078664779663  (-0.09964078664779663)\n",
      "     | > log_mle: -0.27185511589050293  (-0.27185511589050293)\n",
      "     | > loss_dur: 0.1722143292427063  (0.1722143292427063)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: -0.06281250715255737  (-0.081226646900177)\n",
      "     | > log_mle: -0.23256778717041016  (-0.25221145153045654)\n",
      "     | > loss_dur: 0.16975528001785278  (0.17098480463027954)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: -0.058682799339294434  (-0.07371203104654948)\n",
      "     | > log_mle: -0.24504506587982178  (-0.24982265631357828)\n",
      "     | > loss_dur: 0.18636226654052734  (0.1761106252670288)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: -0.07372398674488068  (-0.07371501997113228)\n",
      "     | > log_mle: -0.27184128761291504  (-0.2553273141384125)\n",
      "     | > loss_dur: 0.19811730086803436  (0.1816122941672802)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: -0.07330474257469177  (-0.07363296449184417)\n",
      "     | > log_mle: -0.2707451581954956  (-0.2584108829498291)\n",
      "     | > loss_dur: 0.19744041562080383  (0.1847779184579849)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: -0.04120263457298279  (-0.06822790950536728)\n",
      "     | > log_mle: -0.2808486223220825  (-0.262150506178538)\n",
      "     | > loss_dur: 0.23964598774909973  (0.19392259667317072)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: -0.058165088295936584  (-0.06679036361830575)\n",
      "     | > log_mle: -0.24514985084533691  (-0.2597218411309378)\n",
      "     | > loss_dur: 0.18698476254940033  (0.1929314775126321)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: -0.07809451222419739  (-0.0682033821940422)\n",
      "     | > log_mle: -0.25594258308410645  (-0.2592494338750839)\n",
      "     | > loss_dur: 0.17784807085990906  (0.19104605168104172)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: -0.043890610337257385  (-0.06550196309884389)\n",
      "     | > log_mle: -0.2680429220199585  (-0.2602264881134033)\n",
      "     | > loss_dur: 0.2241523116827011  (0.19472452501455942)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: -0.03804364800453186  (-0.06275613158941269)\n",
      "     | > log_mle: -0.25334620475769043  (-0.259538459777832)\n",
      "     | > loss_dur: 0.21530255675315857  (0.19678232818841934)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: -0.0626128613948822  (-0.06274310702627356)\n",
      "     | > log_mle: -0.27021145820617676  (-0.260508732362227)\n",
      "     | > loss_dur: 0.20759859681129456  (0.19776562533595346)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: -0.07627084851264954  (-0.06387041881680489)\n",
      "     | > log_mle: -0.2578928470611572  (-0.2602907419204712)\n",
      "     | > loss_dur: 0.1816219985485077  (0.1964203231036663)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: -0.09131674468517303  (-0.06598167465283321)\n",
      "     | > log_mle: -0.27824246883392334  (-0.2616716439907367)\n",
      "     | > loss_dur: 0.1869257241487503  (0.19568996933790353)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: -0.06220631301403046  (-0.0657120059643473)\n",
      "     | > log_mle: -0.2692418098449707  (-0.26221237012318205)\n",
      "     | > loss_dur: 0.20703549683094025  (0.19650036415883473)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: -0.06219524145126343  (-0.06547755499680838)\n",
      "     | > log_mle: -0.2629661560058594  (-0.26226262251536053)\n",
      "     | > loss_dur: 0.20077091455459595  (0.19678506751855215)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: -0.04790559411048889  (-0.0643793074414134)\n",
      "     | > log_mle: -0.2619032859802246  (-0.2622401639819145)\n",
      "     | > loss_dur: 0.21399769186973572  (0.19786085654050112)\n",
      "\n",
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.004272595047950745 \u001b[0m(-0.0008538514375686646)\n",
      "     | > avg_loss:\u001b[92m -0.0643793074414134 \u001b[0m(-0.007186351343989372)\n",
      "     | > avg_log_mle:\u001b[92m -0.2622401639819145 \u001b[0m(-0.00621456652879715)\n",
      "     | > avg_loss_dur:\u001b[92m 0.19786085654050112 \u001b[0m(-0.0009717848151922226)\n",
      "\n",
      " > BEST MODEL : train/run-February-22-2025_10+59PM-fa84af3/best_model_37346.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 36/100\u001b[0m\n",
      " --> train/run-February-22-2025_10+59PM-fa84af3\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-23 02:10:31) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:10:36 -- STEP: 4/406 -- GLOBAL_STEP: 37350\u001b[0m\n",
      "     | > loss: -0.03626014292240143  (-0.056827057152986526)\n",
      "     | > log_mle: -0.21568965911865234  (-0.23303118348121643)\n",
      "     | > loss_dur: 0.17942951619625092  (0.1762041263282299)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(7.6665, device='cuda:0')  (tensor(10.9540, device='cuda:0'))\n",
      "     | > current_lr: 9e-06 \n",
      "     | > step_time: 0.4064  (0.5593753457069397)\n",
      "     | > loader_time: 0.0029  (0.008407950401306152)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:10:50 -- STEP: 29/406 -- GLOBAL_STEP: 37375\u001b[0m\n",
      "     | > loss: -0.04063953459262848  (-0.04497469447810074)\n",
      "     | > log_mle: -0.23921668529510498  (-0.2322965695940215)\n",
      "     | > loss_dur: 0.1985771507024765  (0.18732187511592074)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(20.3486, device='cuda:0')  (tensor(17.7320, device='cuda:0'))\n",
      "     | > current_lr: 9e-06 \n",
      "     | > step_time: 0.6425  (0.5744413918462293)\n",
      "     | > loader_time: 0.006  (0.009499114135216022)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:11:07 -- STEP: 54/406 -- GLOBAL_STEP: 37400\u001b[0m\n",
      "     | > loss: -0.04479485750198364  (-0.03820094273046211)\n",
      "     | > log_mle: -0.23779022693634033  (-0.2321584180549339)\n",
      "     | > loss_dur: 0.1929953694343567  (0.1939574753244718)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(8.2999, device='cuda:0')  (tensor(15.3816, device='cuda:0'))\n",
      "     | > current_lr: 9e-06 \n",
      "     | > step_time: 0.5849  (0.6022575343096696)\n",
      "     | > loader_time: 0.006  (0.00963453451792399)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:11:22 -- STEP: 79/406 -- GLOBAL_STEP: 37425\u001b[0m\n",
      "     | > loss: -0.031979143619537354  (-0.03742814535581613)\n",
      "     | > log_mle: -0.2417229413986206  (-0.2345757107191448)\n",
      "     | > loss_dur: 0.20974379777908325  (0.19714756536332867)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(22.6886, device='cuda:0')  (tensor(15.5837, device='cuda:0'))\n",
      "     | > current_lr: 9e-06 \n",
      "     | > step_time: 0.3071  (0.5988541705698907)\n",
      "     | > loader_time: 0.0049  (0.010354796542397026)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:11:38 -- STEP: 104/406 -- GLOBAL_STEP: 37450\u001b[0m\n",
      "     | > loss: -0.03455324470996857  (-0.03723717724474577)\n",
      "     | > log_mle: -0.24158990383148193  (-0.23741610233600324)\n",
      "     | > loss_dur: 0.20703665912151337  (0.20017892509125745)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(17.5573, device='cuda:0')  (tensor(16.5155, device='cuda:0'))\n",
      "     | > current_lr: 9e-06 \n",
      "     | > step_time: 0.6596  (0.6098679074874288)\n",
      "     | > loader_time: 0.0041  (0.009943097829818722)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:11:58 -- STEP: 129/406 -- GLOBAL_STEP: 37475\u001b[0m\n",
      "     | > loss: -0.03455442190170288  (-0.03749050719793452)\n",
      "     | > log_mle: -0.25646746158599854  (-0.23993487043898235)\n",
      "     | > loss_dur: 0.22191303968429565  (0.2024443632410478)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(15.0066, device='cuda:0')  (tensor(16.4623, device='cuda:0'))\n",
      "     | > current_lr: 9e-06 \n",
      "     | > step_time: 0.4961  (0.6429985031601069)\n",
      "     | > loader_time: 0.0059  (0.010168508041736688)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:12:19 -- STEP: 154/406 -- GLOBAL_STEP: 37500\u001b[0m\n",
      "     | > loss: -0.013774141669273376  (-0.03695479838492032)\n",
      "     | > log_mle: -0.23216164112091064  (-0.24173960902474143)\n",
      "     | > loss_dur: 0.21838749945163727  (0.2047848106398211)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(18.0182, device='cuda:0')  (tensor(16.6322, device='cuda:0'))\n",
      "     | > current_lr: 9e-06 \n",
      "     | > step_time: 0.5775  (0.6696559066896314)\n",
      "     | > loader_time: 0.0366  (0.011431661519137293)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:12:37 -- STEP: 179/406 -- GLOBAL_STEP: 37525\u001b[0m\n",
      "     | > loss: -0.05886109173297882  (-0.03699377820145482)\n",
      "     | > log_mle: -0.264376163482666  (-0.2432502781212663)\n",
      "     | > loss_dur: 0.2055150717496872  (0.20625649991981143)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(25.3979, device='cuda:0')  (tensor(17.5410, device='cuda:0'))\n",
      "     | > current_lr: 9e-06 \n",
      "     | > step_time: 0.7436  (0.6741114568443937)\n",
      "     | > loader_time: 0.0312  (0.01207590502733625)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:12:57 -- STEP: 204/406 -- GLOBAL_STEP: 37550\u001b[0m\n",
      "     | > loss: -0.037052541971206665  (-0.03676558468563883)\n",
      "     | > log_mle: -0.2541799545288086  (-0.24463975371098987)\n",
      "     | > loss_dur: 0.21712741255760193  (0.20787416902535102)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(31.0498, device='cuda:0')  (tensor(17.9556, device='cuda:0'))\n",
      "     | > current_lr: 9e-06 \n",
      "     | > step_time: 0.6166  (0.6872969024321612)\n",
      "     | > loader_time: 0.0166  (0.011902451515197754)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:13:15 -- STEP: 229/406 -- GLOBAL_STEP: 37575\u001b[0m\n",
      "     | > loss: -0.035437509417533875  (-0.036842188200055234)\n",
      "     | > log_mle: -0.2530949115753174  (-0.24597701807730063)\n",
      "     | > loss_dur: 0.2176574021577835  (0.20913482987724538)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(21.0379, device='cuda:0')  (tensor(19.3230, device='cuda:0'))\n",
      "     | > current_lr: 9e-06 \n",
      "     | > step_time: 0.9361  (0.6876896958163732)\n",
      "     | > loader_time: 0.0186  (0.012357392165338108)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:13:33 -- STEP: 254/406 -- GLOBAL_STEP: 37600\u001b[0m\n",
      "     | > loss: -0.04931923747062683  (-0.037038500442748916)\n",
      "     | > log_mle: -0.2521630525588989  (-0.24731597515541737)\n",
      "     | > loss_dur: 0.2028438150882721  (0.21027747471266844)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(13.2556, device='cuda:0')  (tensor(19.4708, device='cuda:0'))\n",
      "     | > current_lr: 9e-06 \n",
      "     | > step_time: 0.7535  (0.690393110898536)\n",
      "     | > loader_time: 0.0202  (0.012459571905962126)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:13:52 -- STEP: 279/406 -- GLOBAL_STEP: 37625\u001b[0m\n",
      "     | > loss: -0.0027710795402526855  (-0.037345828922418695)\n",
      "     | > log_mle: -0.2442718744277954  (-0.24830237981666373)\n",
      "     | > loss_dur: 0.24150079488754272  (0.2109565508942451)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(11.9574, device='cuda:0')  (tensor(19.6090, device='cuda:0'))\n",
      "     | > current_lr: 9e-06 \n",
      "     | > step_time: 0.6757  (0.6943420569101969)\n",
      "     | > loader_time: 0.0065  (0.012615798622049309)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:14:11 -- STEP: 304/406 -- GLOBAL_STEP: 37650\u001b[0m\n",
      "     | > loss: -0.05415567755699158  (-0.03754922904466324)\n",
      "     | > log_mle: -0.260701060295105  (-0.24930811438121295)\n",
      "     | > loss_dur: 0.2065453827381134  (0.21175888533654974)\n",
      "     | > amp_scaler: 8192.0  (4351.999999999999)\n",
      "     | > grad_norm: tensor(23.4150, device='cuda:0')  (tensor(19.6534, device='cuda:0'))\n",
      "     | > current_lr: 9e-06 \n",
      "     | > step_time: 0.7093  (0.6981555592072636)\n",
      "     | > loader_time: 0.0078  (0.012823997359526778)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:14:31 -- STEP: 329/406 -- GLOBAL_STEP: 37675\u001b[0m\n",
      "     | > loss: -0.04190546274185181  (-0.03758770938521096)\n",
      "     | > log_mle: -0.24949336051940918  (-0.24995255071703787)\n",
      "     | > loss_dur: 0.20758789777755737  (0.21236484133182695)\n",
      "     | > amp_scaler: 4096.0  (4444.595744680848)\n",
      "     | > grad_norm: tensor(32.7550, device='cuda:0')  (tensor(20.5074, device='cuda:0'))\n",
      "     | > current_lr: 9e-06 \n",
      "     | > step_time: 0.8017  (0.7058249998237586)\n",
      "     | > loader_time: 0.0131  (0.013310706361811206)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:14:57 -- STEP: 354/406 -- GLOBAL_STEP: 37700\u001b[0m\n",
      "     | > loss: -0.02955096960067749  (-0.03743502400857579)\n",
      "     | > log_mle: -0.26063644886016846  (-0.2507549241437751)\n",
      "     | > loss_dur: 0.23108547925949097  (0.2133199001351993)\n",
      "     | > amp_scaler: 4096.0  (4419.9774011299405)\n",
      "     | > grad_norm: tensor(22.9188, device='cuda:0')  (tensor(21.3078, device='cuda:0'))\n",
      "     | > current_lr: 9e-06 \n",
      "     | > step_time: 1.8862  (0.7250319719314576)\n",
      "     | > loader_time: 0.0173  (0.013582683552456436)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:15:21 -- STEP: 379/406 -- GLOBAL_STEP: 37725\u001b[0m\n",
      "     | > loss: -0.04653310775756836  (-0.037684366303572234)\n",
      "     | > log_mle: -0.26258254051208496  (-0.2516408139608781)\n",
      "     | > loss_dur: 0.2160494327545166  (0.2139564476573059)\n",
      "     | > amp_scaler: 4096.0  (4398.606860158309)\n",
      "     | > grad_norm: tensor(17.1949, device='cuda:0')  (tensor(21.6671, device='cuda:0'))\n",
      "     | > current_lr: 9e-06 \n",
      "     | > step_time: 1.1099  (0.740299704206965)\n",
      "     | > loader_time: 0.0123  (0.013965166338515465)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:15:39 -- STEP: 404/406 -- GLOBAL_STEP: 37750\u001b[0m\n",
      "     | > loss: -0.04952980577945709  (-0.03783756520340937)\n",
      "     | > log_mle: -0.2618783712387085  (-0.25240857323797616)\n",
      "     | > loss_dur: 0.2123485654592514  (0.2145710080345669)\n",
      "     | > amp_scaler: 4096.0  (4379.881188118809)\n",
      "     | > grad_norm: tensor(37.5367, device='cuda:0')  (tensor(22.1290, device='cuda:0'))\n",
      "     | > current_lr: 9e-06 \n",
      "     | > step_time: 0.5664  (0.7374038891036914)\n",
      "     | > loader_time: 0.0108  (0.014077522967121385)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: -0.03391675651073456  (-0.03391675651073456)\n",
      "     | > log_mle: -0.23601388931274414  (-0.23601388931274414)\n",
      "     | > loss_dur: 0.20209713280200958  (0.20209713280200958)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: -0.10418082773685455  (-0.10418082773685455)\n",
      "     | > log_mle: -0.2746100425720215  (-0.2746100425720215)\n",
      "     | > loss_dur: 0.17042921483516693  (0.17042921483516693)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: -0.06924562156200409  (-0.08671322464942932)\n",
      "     | > log_mle: -0.23462986946105957  (-0.2546199560165405)\n",
      "     | > loss_dur: 0.16538424789905548  (0.1679067313671112)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: -0.06021031737327576  (-0.0778789222240448)\n",
      "     | > log_mle: -0.2484070062637329  (-0.2525489727656047)\n",
      "     | > loss_dur: 0.18819668889045715  (0.17467005054155985)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: -0.0793842077255249  (-0.07825524359941483)\n",
      "     | > log_mle: -0.27451956272125244  (-0.2580416202545166)\n",
      "     | > loss_dur: 0.19513535499572754  (0.17978637665510178)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: -0.06898669898509979  (-0.07640153467655182)\n",
      "     | > log_mle: -0.270305871963501  (-0.2604944705963135)\n",
      "     | > loss_dur: 0.20131917297840118  (0.18409293591976167)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: -0.044931650161743164  (-0.07115655392408371)\n",
      "     | > log_mle: -0.2799098491668701  (-0.26373036702473956)\n",
      "     | > loss_dur: 0.23497819900512695  (0.19257381310065588)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: -0.058444783091545105  (-0.06934058666229248)\n",
      "     | > log_mle: -0.24605071544647217  (-0.26120470251355854)\n",
      "     | > loss_dur: 0.18760593235492706  (0.19186411585126603)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: -0.0827411562204361  (-0.07101565785706043)\n",
      "     | > log_mle: -0.2578308582305908  (-0.26078297197818756)\n",
      "     | > loss_dur: 0.17508970201015472  (0.18976731412112713)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: -0.04252892732620239  (-0.06785046557585399)\n",
      "     | > log_mle: -0.2682797908782959  (-0.26161595185597736)\n",
      "     | > loss_dur: 0.2257508635520935  (0.19376548628012338)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: -0.037126392126083374  (-0.06477805823087693)\n",
      "     | > log_mle: -0.25529325008392334  (-0.26098368167877195)\n",
      "     | > loss_dur: 0.21816685795783997  (0.19620562344789505)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: -0.0616447776556015  (-0.06449321454221552)\n",
      "     | > log_mle: -0.27174127101898193  (-0.2619616443460638)\n",
      "     | > loss_dur: 0.21009649336338043  (0.19746842980384827)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: -0.07262527942657471  (-0.06517088661591212)\n",
      "     | > log_mle: -0.2599613666534424  (-0.26179495453834534)\n",
      "     | > loss_dur: 0.18733608722686768  (0.19662406792243323)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: -0.08904488384723663  (-0.06700734794139862)\n",
      "     | > log_mle: -0.2777670621871948  (-0.2630235782036415)\n",
      "     | > loss_dur: 0.1887221783399582  (0.19601623026224282)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: -0.06001219153404236  (-0.06650769391230174)\n",
      "     | > log_mle: -0.2706948518753052  (-0.26357152632304603)\n",
      "     | > loss_dur: 0.21068266034126282  (0.19706383241074427)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: -0.06741778552532196  (-0.0665683666865031)\n",
      "     | > log_mle: -0.2640500068664551  (-0.26360342502594)\n",
      "     | > loss_dur: 0.19663222134113312  (0.19703505833943685)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: -0.04896007478237152  (-0.06546784844249487)\n",
      "     | > log_mle: -0.2626146078109741  (-0.2635416239500046)\n",
      "     | > loss_dur: 0.2136545330286026  (0.1980737755075097)\n",
      "\n",
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.0035969167947769165 \u001b[0m(-0.0006756782531738281)\n",
      "     | > avg_loss:\u001b[92m -0.06546784844249487 \u001b[0m(-0.0010885410010814667)\n",
      "     | > avg_log_mle:\u001b[92m -0.2635416239500046 \u001b[0m(-0.0013014599680900574)\n",
      "     | > avg_loss_dur:\u001b[91m 0.1980737755075097 \u001b[0m(+0.0002129189670085907)\n",
      "\n",
      " > BEST MODEL : train/run-February-22-2025_10+59PM-fa84af3/best_model_37752.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 37/100\u001b[0m\n",
      " --> train/run-February-22-2025_10+59PM-fa84af3\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-23 02:15:56) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:16:10 -- STEP: 23/406 -- GLOBAL_STEP: 37775\u001b[0m\n",
      "     | > loss: -0.04207219183444977  (-0.04924270510673523)\n",
      "     | > log_mle: -0.23631668090820312  (-0.23460226473600967)\n",
      "     | > loss_dur: 0.19424448907375336  (0.18535955962927445)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(34.4127, device='cuda:0')  (tensor(19.0179, device='cuda:0'))\n",
      "     | > current_lr: 9.250000000000001e-06 \n",
      "     | > step_time: 0.5577  (0.5029066956561544)\n",
      "     | > loader_time: 0.0177  (0.00807928002398947)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:16:25 -- STEP: 48/406 -- GLOBAL_STEP: 37800\u001b[0m\n",
      "     | > loss: -0.011582016944885254  (-0.043147019731501736)\n",
      "     | > log_mle: -0.22588753700256348  (-0.234091783563296)\n",
      "     | > loss_dur: 0.21430552005767822  (0.19094476383179426)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(12.5656, device='cuda:0')  (tensor(17.6560, device='cuda:0'))\n",
      "     | > current_lr: 9.250000000000001e-06 \n",
      "     | > step_time: 0.3337  (0.564269368847211)\n",
      "     | > loader_time: 0.0044  (0.009373833735783897)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:16:41 -- STEP: 73/406 -- GLOBAL_STEP: 37825\u001b[0m\n",
      "     | > loss: -0.04795144498348236  (-0.042352917667937605)\n",
      "     | > log_mle: -0.2517986297607422  (-0.23671780710350976)\n",
      "     | > loss_dur: 0.20384718477725983  (0.19436488943557217)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(29.6005, device='cuda:0')  (tensor(16.0162, device='cuda:0'))\n",
      "     | > current_lr: 9.250000000000001e-06 \n",
      "     | > step_time: 0.6499  (0.5851223893361547)\n",
      "     | > loader_time: 0.0247  (0.010309252020430891)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:16:58 -- STEP: 98/406 -- GLOBAL_STEP: 37850\u001b[0m\n",
      "     | > loss: -0.022911444306373596  (-0.04064303940656233)\n",
      "     | > log_mle: -0.23535418510437012  (-0.23941076288417895)\n",
      "     | > loss_dur: 0.21244274079799652  (0.1987677234776166)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(21.8792, device='cuda:0')  (tensor(16.4171, device='cuda:0'))\n",
      "     | > current_lr: 9.250000000000001e-06 \n",
      "     | > step_time: 0.6698  (0.5979523439796601)\n",
      "     | > loader_time: 0.0169  (0.010256453436248154)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:17:14 -- STEP: 123/406 -- GLOBAL_STEP: 37875\u001b[0m\n",
      "     | > loss: -0.042719125747680664  (-0.040848062048113434)\n",
      "     | > log_mle: -0.2593446969985962  (-0.24193114575331773)\n",
      "     | > loss_dur: 0.21662557125091553  (0.20108308370520428)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(6.6410, device='cuda:0')  (tensor(16.7593, device='cuda:0'))\n",
      "     | > current_lr: 9.250000000000001e-06 \n",
      "     | > step_time: 0.4027  (0.6055053966801337)\n",
      "     | > loader_time: 0.0078  (0.010934465299776897)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:17:31 -- STEP: 148/406 -- GLOBAL_STEP: 37900\u001b[0m\n",
      "     | > loss: -0.03858993947505951  (-0.04025422147399669)\n",
      "     | > log_mle: -0.26219427585601807  (-0.24398166505066124)\n",
      "     | > loss_dur: 0.22360433638095856  (0.20372744357666456)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(34.0922, device='cuda:0')  (tensor(17.2511, device='cuda:0'))\n",
      "     | > current_lr: 9.250000000000001e-06 \n",
      "     | > step_time: 0.5896  (0.6170118708868281)\n",
      "     | > loader_time: 0.0073  (0.011286648544105321)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:17:48 -- STEP: 173/406 -- GLOBAL_STEP: 37925\u001b[0m\n",
      "     | > loss: -0.05014275014400482  (-0.040217190033438585)\n",
      "     | > log_mle: -0.2512176036834717  (-0.2454561146697557)\n",
      "     | > loss_dur: 0.20107485353946686  (0.20523892463631713)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(26.8149, device='cuda:0')  (tensor(18.2162, device='cuda:0'))\n",
      "     | > current_lr: 9.250000000000001e-06 \n",
      "     | > step_time: 0.7978  (0.622260813079128)\n",
      "     | > loader_time: 0.0273  (0.012116404627099894)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:18:05 -- STEP: 198/406 -- GLOBAL_STEP: 37950\u001b[0m\n",
      "     | > loss: -0.031777068972587585  (-0.04031106581290563)\n",
      "     | > log_mle: -0.2594200372695923  (-0.24699302935841108)\n",
      "     | > loss_dur: 0.2276429682970047  (0.20668196354550544)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(37.3961, device='cuda:0')  (tensor(18.6932, device='cuda:0'))\n",
      "     | > current_lr: 9.250000000000001e-06 \n",
      "     | > step_time: 0.5225  (0.6265644834499159)\n",
      "     | > loader_time: 0.0056  (0.011881303305577752)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:18:24 -- STEP: 223/406 -- GLOBAL_STEP: 37975\u001b[0m\n",
      "     | > loss: -0.04452425241470337  (-0.04022473203761695)\n",
      "     | > log_mle: -0.2587883472442627  (-0.2482749608600086)\n",
      "     | > loss_dur: 0.21426409482955933  (0.20805022882239166)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(26.8097, device='cuda:0')  (tensor(19.1206, device='cuda:0'))\n",
      "     | > current_lr: 9.250000000000001e-06 \n",
      "     | > step_time: 0.6776  (0.6387710026026835)\n",
      "     | > loader_time: 0.0066  (0.011584357830441053)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:18:46 -- STEP: 248/406 -- GLOBAL_STEP: 38000\u001b[0m\n",
      "     | > loss: -0.053968772292137146  (-0.04003574777274362)\n",
      "     | > log_mle: -0.2583726644515991  (-0.24939914961015025)\n",
      "     | > loss_dur: 0.20440389215946198  (0.20936340183740662)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(36.3726, device='cuda:0')  (tensor(20.5202, device='cuda:0'))\n",
      "     | > current_lr: 9.250000000000001e-06 \n",
      "     | > step_time: 0.9037  (0.664080300638752)\n",
      "     | > loader_time: 0.02  (0.012004469671557029)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:19:08 -- STEP: 273/406 -- GLOBAL_STEP: 38025\u001b[0m\n",
      "     | > loss: -0.05048398673534393  (-0.04047746039353884)\n",
      "     | > log_mle: -0.26251208782196045  (-0.25047729216215814)\n",
      "     | > loss_dur: 0.21202810108661652  (0.20999983176861928)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(15.1696, device='cuda:0')  (tensor(21.2585, device='cuda:0'))\n",
      "     | > current_lr: 9.250000000000001e-06 \n",
      "     | > step_time: 0.6563  (0.6796515843807117)\n",
      "     | > loader_time: 0.0233  (0.012133864692715936)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:19:27 -- STEP: 298/406 -- GLOBAL_STEP: 38050\u001b[0m\n",
      "     | > loss: -0.03483891487121582  (-0.04050796383979337)\n",
      "     | > log_mle: -0.2511998414993286  (-0.2512295934177886)\n",
      "     | > loss_dur: 0.2163609266281128  (0.21072162957799512)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(31.2428, device='cuda:0')  (tensor(21.7528, device='cuda:0'))\n",
      "     | > current_lr: 9.250000000000001e-06 \n",
      "     | > step_time: 0.6052  (0.6873799290433019)\n",
      "     | > loader_time: 0.0083  (0.012256711121373531)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:19:51 -- STEP: 323/406 -- GLOBAL_STEP: 38075\u001b[0m\n",
      "     | > loss: -0.05143287777900696  (-0.04066853165257458)\n",
      "     | > log_mle: -0.2662200927734375  (-0.2520365323813708)\n",
      "     | > loss_dur: 0.21478721499443054  (0.21136800072879613)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(24.5817, device='cuda:0')  (tensor(22.2413, device='cuda:0'))\n",
      "     | > current_lr: 9.250000000000001e-06 \n",
      "     | > step_time: 0.8039  (0.7054574541263162)\n",
      "     | > loader_time: 0.0293  (0.012645159712516858)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:20:16 -- STEP: 348/406 -- GLOBAL_STEP: 38100\u001b[0m\n",
      "     | > loss: -0.044774651527404785  (-0.04057468974898604)\n",
      "     | > log_mle: -0.2663377523422241  (-0.25277025432422245)\n",
      "     | > loss_dur: 0.22156310081481934  (0.21219556457523642)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(16.6872, device='cuda:0')  (tensor(22.4033, device='cuda:0'))\n",
      "     | > current_lr: 9.250000000000001e-06 \n",
      "     | > step_time: 0.7807  (0.7249675557531153)\n",
      "     | > loader_time: 0.0068  (0.013072799677136303)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:20:41 -- STEP: 373/406 -- GLOBAL_STEP: 38125\u001b[0m\n",
      "     | > loss: -0.06822538375854492  (-0.040623703487117586)\n",
      "     | > log_mle: -0.26881682872772217  (-0.2535711315937401)\n",
      "     | > loss_dur: 0.20059144496917725  (0.21294742810662246)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(38.1610, device='cuda:0')  (tensor(22.5886, device='cuda:0'))\n",
      "     | > current_lr: 9.250000000000001e-06 \n",
      "     | > step_time: 0.8055  (0.7423334121704096)\n",
      "     | > loader_time: 0.0326  (0.013449675915388258)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:21:03 -- STEP: 398/406 -- GLOBAL_STEP: 38150\u001b[0m\n",
      "     | > loss: -0.0443190336227417  (-0.040718250463356344)\n",
      "     | > log_mle: -0.2666792869567871  (-0.25427911419365257)\n",
      "     | > loss_dur: 0.2223602533340454  (0.21356086373029642)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(20.7202, device='cuda:0')  (tensor(23.2761, device='cuda:0'))\n",
      "     | > current_lr: 9.250000000000001e-06 \n",
      "     | > step_time: 0.6046  (0.7495651730340923)\n",
      "     | > loader_time: 0.0066  (0.013760830289754439)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: -0.036042019724845886  (-0.036042019724845886)\n",
      "     | > log_mle: -0.23853349685668945  (-0.23853349685668945)\n",
      "     | > loss_dur: 0.20249147713184357  (0.20249147713184357)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: -0.111356720328331  (-0.111356720328331)\n",
      "     | > log_mle: -0.27873027324676514  (-0.27873027324676514)\n",
      "     | > loss_dur: 0.16737355291843414  (0.16737355291843414)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: -0.07447272539138794  (-0.09291472285985947)\n",
      "     | > log_mle: -0.23849022388458252  (-0.25861024856567383)\n",
      "     | > loss_dur: 0.16401749849319458  (0.16569552570581436)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: -0.06978929042816162  (-0.08520624538262685)\n",
      "     | > log_mle: -0.2526731491088867  (-0.25663121541341144)\n",
      "     | > loss_dur: 0.1828838586807251  (0.1714249700307846)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: -0.08278083801269531  (-0.08459989354014397)\n",
      "     | > log_mle: -0.27983033657073975  (-0.26243099570274353)\n",
      "     | > loss_dur: 0.19704949855804443  (0.17783110216259956)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: -0.08572563529014587  (-0.08482504189014435)\n",
      "     | > log_mle: -0.27983105182647705  (-0.26591100692749026)\n",
      "     | > loss_dur: 0.19410541653633118  (0.1810859650373459)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: -0.05720975995063782  (-0.08022249490022659)\n",
      "     | > log_mle: -0.29047322273254395  (-0.27000470956166583)\n",
      "     | > loss_dur: 0.23326346278190613  (0.18978221466143927)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: -0.06664545834064484  (-0.07828291824885777)\n",
      "     | > log_mle: -0.25207197666168213  (-0.2674428905759539)\n",
      "     | > loss_dur: 0.1854265183210373  (0.1891599723270961)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: -0.08887407183647156  (-0.0796068124473095)\n",
      "     | > log_mle: -0.2627754211425781  (-0.2668594568967819)\n",
      "     | > loss_dur: 0.17390134930610657  (0.18725264444947243)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: -0.05508929491043091  (-0.07688264383210076)\n",
      "     | > log_mle: -0.2754915952682495  (-0.26781858338250053)\n",
      "     | > loss_dur: 0.2204023003578186  (0.19093593955039978)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: -0.04650656878948212  (-0.0738450363278389)\n",
      "     | > log_mle: -0.2610907554626465  (-0.2671458005905151)\n",
      "     | > loss_dur: 0.21458418667316437  (0.19330076426267623)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: -0.07111261785030365  (-0.07359663464806297)\n",
      "     | > log_mle: -0.2777513265609741  (-0.2681099393151023)\n",
      "     | > loss_dur: 0.20663870871067047  (0.19451330466703934)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: -0.07896117866039276  (-0.0740436799824238)\n",
      "     | > log_mle: -0.2647569179534912  (-0.2678305208683014)\n",
      "     | > loss_dur: 0.18579573929309845  (0.1937868408858776)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: -0.10057908296585083  (-0.0760848648273028)\n",
      "     | > log_mle: -0.28579914569854736  (-0.2692127227783203)\n",
      "     | > loss_dur: 0.18522006273269653  (0.19312785795101753)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: -0.07305409014225006  (-0.0758683809212276)\n",
      "     | > log_mle: -0.2768017053604126  (-0.26975479296275545)\n",
      "     | > loss_dur: 0.20374761521816254  (0.19388641204152787)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: -0.07033926248550415  (-0.0754997730255127)\n",
      "     | > log_mle: -0.2699471712112427  (-0.26976761817932127)\n",
      "     | > loss_dur: 0.19960790872573853  (0.1942678451538086)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: -0.05636787414550781  (-0.07430402934551239)\n",
      "     | > log_mle: -0.2693392038345337  (-0.26974084228277206)\n",
      "     | > loss_dur: 0.21297132968902588  (0.19543681293725967)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: audio amplitude out of range, auto clipped.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[91m 0.005266949534416199 \u001b[0m(+0.0016700327396392822)\n",
      "     | > avg_loss:\u001b[92m -0.07430402934551239 \u001b[0m(-0.008836180903017521)\n",
      "     | > avg_log_mle:\u001b[92m -0.26974084228277206 \u001b[0m(-0.006199218332767487)\n",
      "     | > avg_loss_dur:\u001b[92m 0.19543681293725967 \u001b[0m(-0.0026369625702500343)\n",
      "\n",
      " > BEST MODEL : train/run-February-22-2025_10+59PM-fa84af3/best_model_38158.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 38/100\u001b[0m\n",
      " --> train/run-February-22-2025_10+59PM-fa84af3\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-23 02:21:26) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:21:36 -- STEP: 17/406 -- GLOBAL_STEP: 38175\u001b[0m\n",
      "     | > loss: -0.051693692803382874  (-0.05635802886065315)\n",
      "     | > log_mle: -0.23795068264007568  (-0.23853862986845129)\n",
      "     | > loss_dur: 0.1862569898366928  (0.18218060100779815)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(15.7523, device='cuda:0')  (tensor(17.4260, device='cuda:0'))\n",
      "     | > current_lr: 9.499999999999999e-06 \n",
      "     | > step_time: 0.7411  (0.4622863460989559)\n",
      "     | > loader_time: 0.0043  (0.006643533706665039)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:21:51 -- STEP: 42/406 -- GLOBAL_STEP: 38200\u001b[0m\n",
      "     | > loss: -0.05080711841583252  (-0.04777824488424119)\n",
      "     | > log_mle: -0.24198853969573975  (-0.23546218020575388)\n",
      "     | > loss_dur: 0.19118142127990723  (0.18768393532151267)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(11.8688, device='cuda:0')  (tensor(16.6778, device='cuda:0'))\n",
      "     | > current_lr: 9.499999999999999e-06 \n",
      "     | > step_time: 0.7037  (0.5267640522548129)\n",
      "     | > loader_time: 0.0143  (0.008993228276570639)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:22:06 -- STEP: 67/406 -- GLOBAL_STEP: 38225\u001b[0m\n",
      "     | > loss: -0.03210878372192383  (-0.0438247467599698)\n",
      "     | > log_mle: -0.24778175354003906  (-0.2370758056640625)\n",
      "     | > loss_dur: 0.21567296981811523  (0.1932510589040927)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(7.9577, device='cuda:0')  (tensor(16.2153, device='cuda:0'))\n",
      "     | > current_lr: 9.499999999999999e-06 \n",
      "     | > step_time: 0.3245  (0.5454323149439114)\n",
      "     | > loader_time: 0.0131  (0.009518086020626237)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:22:22 -- STEP: 92/406 -- GLOBAL_STEP: 38250\u001b[0m\n",
      "     | > loss: -0.03988301753997803  (-0.04297017613830776)\n",
      "     | > log_mle: -0.26097822189331055  (-0.23980813829795175)\n",
      "     | > loss_dur: 0.22109520435333252  (0.196837962159644)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(33.2454, device='cuda:0')  (tensor(16.9206, device='cuda:0'))\n",
      "     | > current_lr: 9.499999999999999e-06 \n",
      "     | > step_time: 0.7817  (0.5694778380186659)\n",
      "     | > loader_time: 0.0191  (0.010788197102754016)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:22:41 -- STEP: 117/406 -- GLOBAL_STEP: 38275\u001b[0m\n",
      "     | > loss: -0.0495230108499527  (-0.042503562875283084)\n",
      "     | > log_mle: -0.24975359439849854  (-0.24212164247137868)\n",
      "     | > loss_dur: 0.20023058354854584  (0.19961807959609562)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(11.7231, device='cuda:0')  (tensor(17.1624, device='cuda:0'))\n",
      "     | > current_lr: 9.499999999999999e-06 \n",
      "     | > step_time: 0.4714  (0.6099377391684766)\n",
      "     | > loader_time: 0.0358  (0.011406107845469422)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:23:02 -- STEP: 142/406 -- GLOBAL_STEP: 38300\u001b[0m\n",
      "     | > loss: -0.051346346735954285  (-0.04191198661713535)\n",
      "     | > log_mle: -0.2619518041610718  (-0.24444234790936323)\n",
      "     | > loss_dur: 0.2106054574251175  (0.2025303612922279)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(30.6922, device='cuda:0')  (tensor(17.8477, device='cuda:0'))\n",
      "     | > current_lr: 9.499999999999999e-06 \n",
      "     | > step_time: 0.5018  (0.6410488276414467)\n",
      "     | > loader_time: 0.0367  (0.011862696056634607)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:23:19 -- STEP: 167/406 -- GLOBAL_STEP: 38325\u001b[0m\n",
      "     | > loss: -0.04471445083618164  (-0.041526346060330295)\n",
      "     | > log_mle: -0.2527369260787964  (-0.2459769034813978)\n",
      "     | > loss_dur: 0.20802247524261475  (0.20445055742106752)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(8.0287, device='cuda:0')  (tensor(19.0819, device='cuda:0'))\n",
      "     | > current_lr: 9.499999999999999e-06 \n",
      "     | > step_time: 0.4746  (0.6477876109277415)\n",
      "     | > loader_time: 0.0081  (0.012436182912952173)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:23:39 -- STEP: 192/406 -- GLOBAL_STEP: 38350\u001b[0m\n",
      "     | > loss: -0.05667485296726227  (-0.04180781038788456)\n",
      "     | > log_mle: -0.26105332374572754  (-0.2474956400692463)\n",
      "     | > loss_dur: 0.20437847077846527  (0.2056878296813617)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(23.9991, device='cuda:0')  (tensor(19.7300, device='cuda:0'))\n",
      "     | > current_lr: 9.499999999999999e-06 \n",
      "     | > step_time: 0.9848  (0.6616973131895064)\n",
      "     | > loader_time: 0.008  (0.012670382857322693)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:23:57 -- STEP: 217/406 -- GLOBAL_STEP: 38375\u001b[0m\n",
      "     | > loss: -0.048523783683776855  (-0.04193246309658348)\n",
      "     | > log_mle: -0.26503121852874756  (-0.24880653317622875)\n",
      "     | > loss_dur: 0.2165074348449707  (0.20687407007964526)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(17.5343, device='cuda:0')  (tensor(19.8877, device='cuda:0'))\n",
      "     | > current_lr: 9.499999999999999e-06 \n",
      "     | > step_time: 0.5444  (0.6675419532758299)\n",
      "     | > loader_time: 0.0059  (0.012937137058803014)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:24:16 -- STEP: 242/406 -- GLOBAL_STEP: 38400\u001b[0m\n",
      "     | > loss: -0.04993097484111786  (-0.04203812513223363)\n",
      "     | > log_mle: -0.26862406730651855  (-0.2502006390863214)\n",
      "     | > loss_dur: 0.2186930924654007  (0.20816251395408772)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(36.1098, device='cuda:0')  (tensor(20.3260, device='cuda:0'))\n",
      "     | > current_lr: 9.499999999999999e-06 \n",
      "     | > step_time: 1.0143  (0.6736962095765042)\n",
      "     | > loader_time: 0.017  (0.012990457952515152)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:24:35 -- STEP: 267/406 -- GLOBAL_STEP: 38425\u001b[0m\n",
      "     | > loss: -0.04189032316207886  (-0.042531927035988924)\n",
      "     | > log_mle: -0.25515031814575195  (-0.2513208460718506)\n",
      "     | > loss_dur: 0.2132599949836731  (0.2087889190358616)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(36.9663, device='cuda:0')  (tensor(20.5441, device='cuda:0'))\n",
      "     | > current_lr: 9.499999999999999e-06 \n",
      "     | > step_time: 0.9105  (0.6799007926540874)\n",
      "     | > loader_time: 0.0206  (0.013288148779994095)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:24:57 -- STEP: 292/406 -- GLOBAL_STEP: 38450\u001b[0m\n",
      "     | > loss: -0.02877853810787201  (-0.04291782395480429)\n",
      "     | > log_mle: -0.256819486618042  (-0.25232750463159126)\n",
      "     | > loss_dur: 0.22804094851016998  (0.20940968067678695)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(6.3784, device='cuda:0')  (tensor(20.6569, device='cuda:0'))\n",
      "     | > current_lr: 9.499999999999999e-06 \n",
      "     | > step_time: 0.8905  (0.696806380193527)\n",
      "     | > loader_time: 0.0249  (0.013673830522249825)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:25:18 -- STEP: 317/406 -- GLOBAL_STEP: 38475\u001b[0m\n",
      "     | > loss: -0.03508971631526947  (-0.04308927914697665)\n",
      "     | > log_mle: -0.2638561725616455  (-0.25327011012128486)\n",
      "     | > loss_dur: 0.22876645624637604  (0.21018083097430815)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(48.0370, device='cuda:0')  (tensor(21.1763, device='cuda:0'))\n",
      "     | > current_lr: 9.499999999999999e-06 \n",
      "     | > step_time: 0.783  (0.706722040657741)\n",
      "     | > loader_time: 0.0121  (0.014278228350618285)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:25:39 -- STEP: 342/406 -- GLOBAL_STEP: 38500\u001b[0m\n",
      "     | > loss: -0.05251595377922058  (-0.04291643973505286)\n",
      "     | > log_mle: -0.2771064043045044  (-0.25394892030292093)\n",
      "     | > loss_dur: 0.2245904505252838  (0.21103248056786802)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(70.9659, device='cuda:0')  (tensor(21.4796, device='cuda:0'))\n",
      "     | > current_lr: 9.499999999999999e-06 \n",
      "     | > step_time: 1.0153  (0.7135410246096158)\n",
      "     | > loader_time: 0.0081  (0.014217238677175422)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:26:00 -- STEP: 367/406 -- GLOBAL_STEP: 38525\u001b[0m\n",
      "     | > loss: -0.04881337285041809  (-0.04296599742664625)\n",
      "     | > log_mle: -0.2694380283355713  (-0.25480277401874757)\n",
      "     | > loss_dur: 0.2206246554851532  (0.21183677659210137)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(31.3159, device='cuda:0')  (tensor(22.7425, device='cuda:0'))\n",
      "     | > current_lr: 9.499999999999999e-06 \n",
      "     | > step_time: 0.7229  (0.7200539021141195)\n",
      "     | > loader_time: 0.0074  (0.014480479081904855)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:26:22 -- STEP: 392/406 -- GLOBAL_STEP: 38550\u001b[0m\n",
      "     | > loss: -0.05561739206314087  (-0.043069411677365374)\n",
      "     | > log_mle: -0.2627449035644531  (-0.2555398174694604)\n",
      "     | > loss_dur: 0.20712751150131226  (0.21247040579209525)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(25.7738, device='cuda:0')  (tensor(23.2431, device='cuda:0'))\n",
      "     | > current_lr: 9.499999999999999e-06 \n",
      "     | > step_time: 0.605  (0.728723549721192)\n",
      "     | > loader_time: 0.0096  (0.014633601417346877)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: -0.03695365786552429  (-0.03695365786552429)\n",
      "     | > log_mle: -0.23929262161254883  (-0.23929262161254883)\n",
      "     | > loss_dur: 0.20233896374702454  (0.20233896374702454)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: -0.10893675684928894  (-0.10893675684928894)\n",
      "     | > log_mle: -0.2781749963760376  (-0.2781749963760376)\n",
      "     | > loss_dur: 0.16923823952674866  (0.16923823952674866)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: -0.07738018035888672  (-0.09315846860408783)\n",
      "     | > log_mle: -0.23902642726898193  (-0.25860071182250977)\n",
      "     | > loss_dur: 0.16164624691009521  (0.16544224321842194)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: -0.07008185982704163  (-0.08546626567840576)\n",
      "     | > log_mle: -0.25221383571624756  (-0.25647175312042236)\n",
      "     | > loss_dur: 0.18213197588920593  (0.1710054874420166)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: -0.08513541519641876  (-0.08538355305790901)\n",
      "     | > log_mle: -0.27886199951171875  (-0.26206931471824646)\n",
      "     | > loss_dur: 0.1937265843153  (0.17668576166033745)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: -0.08442723751068115  (-0.08519228994846344)\n",
      "     | > log_mle: -0.27707552909851074  (-0.2650705575942993)\n",
      "     | > loss_dur: 0.1926482915878296  (0.17987826764583587)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: -0.044606760144233704  (-0.07842803498109181)\n",
      "     | > log_mle: -0.2874821424484253  (-0.2688058217366536)\n",
      "     | > loss_dur: 0.2428753823041916  (0.19037778675556183)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: -0.06717370450496674  (-0.07682027348450252)\n",
      "     | > log_mle: -0.2512381076812744  (-0.2662961483001709)\n",
      "     | > loss_dur: 0.18406440317630768  (0.18947587481566838)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: -0.08721449971199036  (-0.0781195517629385)\n",
      "     | > log_mle: -0.2619360685348511  (-0.2657511383295059)\n",
      "     | > loss_dur: 0.17472156882286072  (0.18763158656656742)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: -0.05267930030822754  (-0.0752928571568595)\n",
      "     | > log_mle: -0.2740901708602905  (-0.2666776974995931)\n",
      "     | > loss_dur: 0.221410870552063  (0.1913848403427336)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: -0.0439654141664505  (-0.0721601128578186)\n",
      "     | > log_mle: -0.260603666305542  (-0.266070294380188)\n",
      "     | > loss_dur: 0.2166382521390915  (0.19391018152236938)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: -0.0732659250497818  (-0.07226064123890617)\n",
      "     | > log_mle: -0.27635657787323  (-0.2670054110613736)\n",
      "     | > loss_dur: 0.20309065282344818  (0.19474476982246747)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: -0.07862824201583862  (-0.07279127463698389)\n",
      "     | > log_mle: -0.264279842376709  (-0.26677828033765155)\n",
      "     | > loss_dur: 0.18565160036087036  (0.1939870057006677)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: -0.0999876856803894  (-0.0748833062557074)\n",
      "     | > log_mle: -0.2839466333389282  (-0.2680989228762113)\n",
      "     | > loss_dur: 0.18395894765853882  (0.19321561662050393)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: -0.07164852321147919  (-0.07465225032397682)\n",
      "     | > log_mle: -0.27595317363739014  (-0.26865994078772404)\n",
      "     | > loss_dur: 0.20430465042591095  (0.1940076904637473)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: -0.06833340227603912  (-0.07423099378744764)\n",
      "     | > log_mle: -0.2692667245864868  (-0.26870039304097487)\n",
      "     | > loss_dur: 0.2009333223104477  (0.19446939925352733)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: -0.058152079582214355  (-0.07322606164962056)\n",
      "     | > log_mle: -0.2686573266983032  (-0.2686977013945579)\n",
      "     | > loss_dur: 0.21050524711608887  (0.19547163974493742)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: audio amplitude out of range, auto clipped.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.0042645931243896484 \u001b[0m(-0.0010023564100265503)\n",
      "     | > avg_loss:\u001b[91m -0.07322606164962056 \u001b[0m(+0.0010779676958918294)\n",
      "     | > avg_log_mle:\u001b[91m -0.2686977013945579 \u001b[0m(+0.0010431408882141668)\n",
      "     | > avg_loss_dur:\u001b[91m 0.19547163974493742 \u001b[0m(+3.482680767774582e-05)\n",
      "\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 39/100\u001b[0m\n",
      " --> train/run-February-22-2025_10+59PM-fa84af3\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-23 02:26:43) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:26:49 -- STEP: 11/406 -- GLOBAL_STEP: 38575\u001b[0m\n",
      "     | > loss: -0.07354700565338135  (-0.0620842995968732)\n",
      "     | > log_mle: -0.2336806058883667  (-0.2379410591992465)\n",
      "     | > loss_dur: 0.16013360023498535  (0.1758567596023733)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(14.5432, device='cuda:0')  (tensor(11.9389, device='cuda:0'))\n",
      "     | > current_lr: 9.75e-06 \n",
      "     | > step_time: 0.2769  (0.3687615828080611)\n",
      "     | > loader_time: 0.0037  (0.006036281585693359)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:27:03 -- STEP: 36/406 -- GLOBAL_STEP: 38600\u001b[0m\n",
      "     | > loss: -0.04136629402637482  (-0.05222691926691267)\n",
      "     | > log_mle: -0.23531794548034668  (-0.23765798740916783)\n",
      "     | > loss_dur: 0.19395165145397186  (0.18543106814225516)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(11.8833, device='cuda:0')  (tensor(16.5905, device='cuda:0'))\n",
      "     | > current_lr: 9.75e-06 \n",
      "     | > step_time: 0.5806  (0.48643958568573)\n",
      "     | > loader_time: 0.0039  (0.008861402670542402)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:27:18 -- STEP: 61/406 -- GLOBAL_STEP: 38625\u001b[0m\n",
      "     | > loss: -0.03320619463920593  (-0.0480927619777742)\n",
      "     | > log_mle: -0.24330735206604004  (-0.2388761688451298)\n",
      "     | > loss_dur: 0.2101011574268341  (0.1907834068673556)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(25.5068, device='cuda:0')  (tensor(17.3499, device='cuda:0'))\n",
      "     | > current_lr: 9.75e-06 \n",
      "     | > step_time: 0.6158  (0.5198063146872597)\n",
      "     | > loader_time: 0.0046  (0.008794518767810263)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:27:33 -- STEP: 86/406 -- GLOBAL_STEP: 38650\u001b[0m\n",
      "     | > loss: -0.026536524295806885  (-0.04635265157666317)\n",
      "     | > log_mle: -0.24146103858947754  (-0.24145636724871258)\n",
      "     | > loss_dur: 0.21492451429367065  (0.19510371567204945)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(8.2849, device='cuda:0')  (tensor(17.6256, device='cuda:0'))\n",
      "     | > current_lr: 9.75e-06 \n",
      "     | > step_time: 0.7364  (0.544789214466893)\n",
      "     | > loader_time: 0.0082  (0.009515285491943361)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:27:48 -- STEP: 111/406 -- GLOBAL_STEP: 38675\u001b[0m\n",
      "     | > loss: -0.055238932371139526  (-0.046173637246226404)\n",
      "     | > log_mle: -0.27362024784088135  (-0.2443278490960061)\n",
      "     | > loss_dur: 0.21838131546974182  (0.19815421184977972)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(24.2920, device='cuda:0')  (tensor(18.3827, device='cuda:0'))\n",
      "     | > current_lr: 9.75e-06 \n",
      "     | > step_time: 0.6047  (0.5557129297170551)\n",
      "     | > loader_time: 0.0309  (0.010000864664713541)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:28:04 -- STEP: 136/406 -- GLOBAL_STEP: 38700\u001b[0m\n",
      "     | > loss: -0.028865501284599304  (-0.04559631634722738)\n",
      "     | > log_mle: -0.26239752769470215  (-0.24650011518422296)\n",
      "     | > loss_dur: 0.23353202641010284  (0.2009037988369956)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(44.9966, device='cuda:0')  (tensor(20.0753, device='cuda:0'))\n",
      "     | > current_lr: 9.75e-06 \n",
      "     | > step_time: 0.9777  (0.567903325838201)\n",
      "     | > loader_time: 0.0049  (0.010265427477219525)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:28:21 -- STEP: 161/406 -- GLOBAL_STEP: 38725\u001b[0m\n",
      "     | > loss: -0.04094412922859192  (-0.04504406933458697)\n",
      "     | > log_mle: -0.25536930561065674  (-0.2480770778952178)\n",
      "     | > loss_dur: 0.21442517638206482  (0.20303300856063083)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(21.6850, device='cuda:0')  (tensor(19.9981, device='cuda:0'))\n",
      "     | > current_lr: 9.75e-06 \n",
      "     | > step_time: 0.8367  (0.5833777226276275)\n",
      "     | > loader_time: 0.0178  (0.010832665129477934)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:28:39 -- STEP: 186/406 -- GLOBAL_STEP: 38750\u001b[0m\n",
      "     | > loss: -0.053004488348960876  (-0.04500183118607409)\n",
      "     | > log_mle: -0.2641967535018921  (-0.24952500033122238)\n",
      "     | > loss_dur: 0.2111922651529312  (0.2045231691451483)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(44.6416, device='cuda:0')  (tensor(21.2028, device='cuda:0'))\n",
      "     | > current_lr: 9.75e-06 \n",
      "     | > step_time: 0.9355  (0.5958616643823599)\n",
      "     | > loader_time: 0.0243  (0.01120434397010393)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:28:57 -- STEP: 211/406 -- GLOBAL_STEP: 38775\u001b[0m\n",
      "     | > loss: -0.05400529503822327  (-0.04496540510541456)\n",
      "     | > log_mle: -0.26592540740966797  (-0.250765562622468)\n",
      "     | > loss_dur: 0.2119201123714447  (0.2058001575170535)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(20.6795, device='cuda:0')  (tensor(22.0743, device='cuda:0'))\n",
      "     | > current_lr: 9.75e-06 \n",
      "     | > step_time: 1.1521  (0.6106161042977281)\n",
      "     | > loader_time: 0.0052  (0.011153227910046328)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:29:15 -- STEP: 236/406 -- GLOBAL_STEP: 38800\u001b[0m\n",
      "     | > loss: -0.0407838374376297  (-0.04496719839714342)\n",
      "     | > log_mle: -0.25087785720825195  (-0.25212032259520856)\n",
      "     | > loss_dur: 0.21009401977062225  (0.20715312419806498)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(17.5908, device='cuda:0')  (tensor(22.0875, device='cuda:0'))\n",
      "     | > current_lr: 9.75e-06 \n",
      "     | > step_time: 0.571  (0.6183675103268379)\n",
      "     | > loader_time: 0.0233  (0.01170976889335503)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:29:33 -- STEP: 261/406 -- GLOBAL_STEP: 38825\u001b[0m\n",
      "     | > loss: -0.04683825373649597  (-0.045066715371563065)\n",
      "     | > log_mle: -0.26548516750335693  (-0.2534005582560983)\n",
      "     | > loss_dur: 0.21864691376686096  (0.20833384288453508)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(22.9944, device='cuda:0')  (tensor(22.2261, device='cuda:0'))\n",
      "     | > current_lr: 9.75e-06 \n",
      "     | > step_time: 0.4811  (0.6252584822789917)\n",
      "     | > loader_time: 0.0073  (0.011954930550293905)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:29:53 -- STEP: 286/406 -- GLOBAL_STEP: 38850\u001b[0m\n",
      "     | > loss: -0.046404942870140076  (-0.04543021910048866)\n",
      "     | > log_mle: -0.2630091905593872  (-0.254411928303592)\n",
      "     | > loss_dur: 0.21660424768924713  (0.20898170920310324)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(41.2809, device='cuda:0')  (tensor(22.3154, device='cuda:0'))\n",
      "     | > current_lr: 9.75e-06 \n",
      "     | > step_time: 0.6533  (0.6387913385471261)\n",
      "     | > loader_time: 0.044  (0.012348122530050212)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:30:12 -- STEP: 311/406 -- GLOBAL_STEP: 38875\u001b[0m\n",
      "     | > loss: -0.050085827708244324  (-0.045738868678881044)\n",
      "     | > log_mle: -0.2610914707183838  (-0.2552454490753616)\n",
      "     | > loss_dur: 0.21100564301013947  (0.20950658039648054)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(22.4318, device='cuda:0')  (tensor(22.4939, device='cuda:0'))\n",
      "     | > current_lr: 9.75e-06 \n",
      "     | > step_time: 0.7106  (0.6479343363709769)\n",
      "     | > loader_time: 0.0184  (0.012548280298901522)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:30:33 -- STEP: 336/406 -- GLOBAL_STEP: 38900\u001b[0m\n",
      "     | > loss: -0.057982638478279114  (-0.0455746360655342)\n",
      "     | > log_mle: -0.2679290771484375  (-0.2559115123890696)\n",
      "     | > loss_dur: 0.2099464386701584  (0.21033687632353537)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(19.6879, device='cuda:0')  (tensor(23.0892, device='cuda:0'))\n",
      "     | > current_lr: 9.75e-06 \n",
      "     | > step_time: 0.8974  (0.6596900749774203)\n",
      "     | > loader_time: 0.034  (0.012877120148567926)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:30:53 -- STEP: 361/406 -- GLOBAL_STEP: 38925\u001b[0m\n",
      "     | > loss: -0.034389182925224304  (-0.045521275942675646)\n",
      "     | > log_mle: -0.26431286334991455  (-0.2567027308604064)\n",
      "     | > loss_dur: 0.22992368042469025  (0.21118145491773074)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(23.9628, device='cuda:0')  (tensor(22.8580, device='cuda:0'))\n",
      "     | > current_lr: 9.75e-06 \n",
      "     | > step_time: 0.7259  (0.669925152760133)\n",
      "     | > loader_time: 0.0059  (0.01290296319449047)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:31:13 -- STEP: 386/406 -- GLOBAL_STEP: 38950\u001b[0m\n",
      "     | > loss: -0.036577075719833374  (-0.04569365717277628)\n",
      "     | > log_mle: -0.26775968074798584  (-0.2574634891717547)\n",
      "     | > loss_dur: 0.23118260502815247  (0.21176983199897828)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(30.4247, device='cuda:0')  (tensor(23.1749, device='cuda:0'))\n",
      "     | > current_lr: 9.75e-06 \n",
      "     | > step_time: 0.7006  (0.6773077187760503)\n",
      "     | > loader_time: 0.0072  (0.01302207195697053)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: -0.039288103580474854  (-0.039288103580474854)\n",
      "     | > log_mle: -0.24035179615020752  (-0.24035179615020752)\n",
      "     | > loss_dur: 0.20106369256973267  (0.20106369256973267)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: -0.11195963621139526  (-0.11195963621139526)\n",
      "     | > log_mle: -0.2779862880706787  (-0.2779862880706787)\n",
      "     | > loss_dur: 0.16602665185928345  (0.16602665185928345)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: -0.07861873507499695  (-0.0952891856431961)\n",
      "     | > log_mle: -0.23990559577941895  (-0.25894594192504883)\n",
      "     | > loss_dur: 0.161286860704422  (0.16365675628185272)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: -0.0673384815454483  (-0.08597228427728017)\n",
      "     | > log_mle: -0.2523120641708374  (-0.2567346493403117)\n",
      "     | > loss_dur: 0.1849735826253891  (0.17076236506303152)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: -0.08415485918521881  (-0.08551792800426483)\n",
      "     | > log_mle: -0.2777050733566284  (-0.26197725534439087)\n",
      "     | > loss_dur: 0.1935502141714096  (0.17645932734012604)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: -0.0829748809337616  (-0.08500931859016418)\n",
      "     | > log_mle: -0.275570273399353  (-0.2646958589553833)\n",
      "     | > loss_dur: 0.19259539246559143  (0.1796865403652191)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: -0.044537708163261414  (-0.07826405018568039)\n",
      "     | > log_mle: -0.28476381301879883  (-0.2680405179659526)\n",
      "     | > loss_dur: 0.24022610485553741  (0.18977646778027216)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: -0.07073727250099182  (-0.07718879623072487)\n",
      "     | > log_mle: -0.2507685422897339  (-0.2655730928693499)\n",
      "     | > loss_dur: 0.18003126978874207  (0.18838429663862502)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: -0.08845044672489166  (-0.07859650254249573)\n",
      "     | > log_mle: -0.26176726818084717  (-0.26509736478328705)\n",
      "     | > loss_dur: 0.1733168214559555  (0.18650086224079132)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: -0.05432255566120148  (-0.07589939733346303)\n",
      "     | > log_mle: -0.27288639545440674  (-0.2659628126356337)\n",
      "     | > loss_dur: 0.21856383979320526  (0.19006341530217064)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: -0.04321102797985077  (-0.07263056039810181)\n",
      "     | > log_mle: -0.26012277603149414  (-0.2653788089752197)\n",
      "     | > loss_dur: 0.21691174805164337  (0.19274824857711792)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: -0.07335513830184937  (-0.07269643111662431)\n",
      "     | > log_mle: -0.27573466300964355  (-0.2663202502510764)\n",
      "     | > loss_dur: 0.2023795247077942  (0.19362381913445212)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: -0.07664494216442108  (-0.0730254737039407)\n",
      "     | > log_mle: -0.26429247856140137  (-0.26615126927693683)\n",
      "     | > loss_dur: 0.18764753639698029  (0.19312579557299614)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: -0.09852470457553864  (-0.07498695300175594)\n",
      "     | > log_mle: -0.28306472301483154  (-0.26745230417985183)\n",
      "     | > loss_dur: 0.1845400184392929  (0.19246535117809588)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: -0.07160110771656036  (-0.07474510690995625)\n",
      "     | > log_mle: -0.27466869354248047  (-0.26796776056289673)\n",
      "     | > loss_dur: 0.2030675858259201  (0.19322265365294047)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: -0.06861943006515503  (-0.07433672845363617)\n",
      "     | > log_mle: -0.26872944831848145  (-0.2680185397466024)\n",
      "     | > loss_dur: 0.20011001825332642  (0.19368181129296622)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: -0.05608750879764557  (-0.07319615222513676)\n",
      "     | > log_mle: -0.2676464319229126  (-0.26799528300762177)\n",
      "     | > loss_dur: 0.21155892312526703  (0.194799130782485)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: audio amplitude out of range, auto clipped.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[91m 0.021439328789711 \u001b[0m(+0.01717473566532135)\n",
      "     | > avg_loss:\u001b[91m -0.07319615222513676 \u001b[0m(+2.9909424483803848e-05)\n",
      "     | > avg_log_mle:\u001b[91m -0.26799528300762177 \u001b[0m(+0.0007024183869361322)\n",
      "     | > avg_loss_dur:\u001b[92m 0.194799130782485 \u001b[0m(-0.0006725089624524117)\n",
      "\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 40/100\u001b[0m\n",
      " --> train/run-February-22-2025_10+59PM-fa84af3\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-23 02:31:41) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:31:45 -- STEP: 5/406 -- GLOBAL_STEP: 38975\u001b[0m\n",
      "     | > loss: -0.04679243266582489  (-0.05797266960144043)\n",
      "     | > log_mle: -0.2326500415802002  (-0.23963398933410646)\n",
      "     | > loss_dur: 0.1858576089143753  (0.18166131973266603)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(3.5140, device='cuda:0')  (tensor(12.5728, device='cuda:0'))\n",
      "     | > current_lr: 9.999999999999999e-06 \n",
      "     | > step_time: 0.311  (0.4201423168182373)\n",
      "     | > loader_time: 0.0043  (0.012240266799926758)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:31:57 -- STEP: 30/406 -- GLOBAL_STEP: 39000\u001b[0m\n",
      "     | > loss: -0.04198652505874634  (-0.055519433319568635)\n",
      "     | > log_mle: -0.23685109615325928  (-0.2397376577059428)\n",
      "     | > loss_dur: 0.19486457109451294  (0.18421822438637417)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(6.0218, device='cuda:0')  (tensor(15.9420, device='cuda:0'))\n",
      "     | > current_lr: 9.999999999999999e-06 \n",
      "     | > step_time: 0.6127  (0.46532825628916424)\n",
      "     | > loader_time: 0.0038  (0.006939323743184408)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:32:12 -- STEP: 55/406 -- GLOBAL_STEP: 39025\u001b[0m\n",
      "     | > loss: -0.05807328224182129  (-0.050085146047852254)\n",
      "     | > log_mle: -0.25463855266571045  (-0.2399440743706443)\n",
      "     | > loss_dur: 0.19656527042388916  (0.18985892832279205)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(18.9519, device='cuda:0')  (tensor(16.0378, device='cuda:0'))\n",
      "     | > current_lr: 9.999999999999999e-06 \n",
      "     | > step_time: 0.5375  (0.5192595091733067)\n",
      "     | > loader_time: 0.0044  (0.006724561344493519)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:32:28 -- STEP: 80/406 -- GLOBAL_STEP: 39050\u001b[0m\n",
      "     | > loss: -0.04798625409603119  (-0.04827455580234528)\n",
      "     | > log_mle: -0.24627959728240967  (-0.2421779677271843)\n",
      "     | > loss_dur: 0.19829334318637848  (0.193903411924839)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(10.7525, device='cuda:0')  (tensor(15.1461, device='cuda:0'))\n",
      "     | > current_lr: 9.999999999999999e-06 \n",
      "     | > step_time: 0.8321  (0.547176316380501)\n",
      "     | > loader_time: 0.0175  (0.007991537451744081)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:32:43 -- STEP: 105/406 -- GLOBAL_STEP: 39075\u001b[0m\n",
      "     | > loss: -0.06853309273719788  (-0.048836831819443476)\n",
      "     | > log_mle: -0.2523646354675293  (-0.24533523945581345)\n",
      "     | > loss_dur: 0.18383154273033142  (0.19649840763636997)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(12.4081, device='cuda:0')  (tensor(16.0639, device='cuda:0'))\n",
      "     | > current_lr: 9.999999999999999e-06 \n",
      "     | > step_time: 0.4722  (0.5580155463445754)\n",
      "     | > loader_time: 0.0042  (0.008867063976469492)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:33:00 -- STEP: 130/406 -- GLOBAL_STEP: 39100\u001b[0m\n",
      "     | > loss: -0.042332008481025696  (-0.04901580787622012)\n",
      "     | > log_mle: -0.2476102113723755  (-0.24784181851607104)\n",
      "     | > loss_dur: 0.2052782028913498  (0.19882601063985092)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(26.2716, device='cuda:0')  (tensor(19.6462, device='cuda:0'))\n",
      "     | > current_lr: 9.999999999999999e-06 \n",
      "     | > step_time: 0.5354  (0.5757701360262357)\n",
      "     | > loader_time: 0.0053  (0.009500100062443657)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:33:16 -- STEP: 155/406 -- GLOBAL_STEP: 39125\u001b[0m\n",
      "     | > loss: -0.04138819873332977  (-0.04846092558676195)\n",
      "     | > log_mle: -0.2565927505493164  (-0.2497449182694958)\n",
      "     | > loss_dur: 0.21520455181598663  (0.2012839926827338)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(11.8906, device='cuda:0')  (tensor(20.4911, device='cuda:0'))\n",
      "     | > current_lr: 9.999999999999999e-06 \n",
      "     | > step_time: 0.5243  (0.5894669948085663)\n",
      "     | > loader_time: 0.0055  (0.010183628143802765)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:33:34 -- STEP: 180/406 -- GLOBAL_STEP: 39150\u001b[0m\n",
      "     | > loss: -0.043052852153778076  (-0.04857831158571773)\n",
      "     | > log_mle: -0.26325666904449463  (-0.25138217276997027)\n",
      "     | > loss_dur: 0.22020381689071655  (0.20280386118425264)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(22.0358, device='cuda:0')  (tensor(20.6345, device='cuda:0'))\n",
      "     | > current_lr: 9.999999999999999e-06 \n",
      "     | > step_time: 0.6927  (0.6011497868431944)\n",
      "     | > loader_time: 0.007  (0.01063890854517619)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:33:51 -- STEP: 205/406 -- GLOBAL_STEP: 39175\u001b[0m\n",
      "     | > loss: -0.036086902022361755  (-0.048108215448333)\n",
      "     | > log_mle: -0.2678544521331787  (-0.25275993754224063)\n",
      "     | > loss_dur: 0.23176755011081696  (0.2046517220939078)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(31.5540, device='cuda:0')  (tensor(20.9225, device='cuda:0'))\n",
      "     | > current_lr: 9.999999999999999e-06 \n",
      "     | > step_time: 1.1742  (0.6099981866231783)\n",
      "     | > loader_time: 0.0062  (0.010920386198090343)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:34:09 -- STEP: 230/406 -- GLOBAL_STEP: 39200\u001b[0m\n",
      "     | > loss: -0.03889264166355133  (-0.04829553754433342)\n",
      "     | > log_mle: -0.2610902786254883  (-0.2540850281715391)\n",
      "     | > loss_dur: 0.22219763696193695  (0.2057894906272059)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(49.4604, device='cuda:0')  (tensor(21.5949, device='cuda:0'))\n",
      "     | > current_lr: 9.999999999999999e-06 \n",
      "     | > step_time: 0.5752  (0.6198234008706138)\n",
      "     | > loader_time: 0.0065  (0.01118333443351414)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:34:27 -- STEP: 255/406 -- GLOBAL_STEP: 39225\u001b[0m\n",
      "     | > loss: -0.05383719503879547  (-0.048508967313111995)\n",
      "     | > log_mle: -0.262160062789917  (-0.2553905225267596)\n",
      "     | > loss_dur: 0.20832286775112152  (0.20688155521364773)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(11.0996, device='cuda:0')  (tensor(22.5303, device='cuda:0'))\n",
      "     | > current_lr: 9.999999999999999e-06 \n",
      "     | > step_time: 0.8132  (0.628860649408079)\n",
      "     | > loader_time: 0.0087  (0.011123126160864737)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:34:45 -- STEP: 280/406 -- GLOBAL_STEP: 39250\u001b[0m\n",
      "     | > loss: -0.054586946964263916  (-0.04888005214078086)\n",
      "     | > log_mle: -0.275152325630188  (-0.2564831282411301)\n",
      "     | > loss_dur: 0.22056537866592407  (0.20760307610034942)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(33.4454, device='cuda:0')  (tensor(22.4737, device='cuda:0'))\n",
      "     | > current_lr: 9.999999999999999e-06 \n",
      "     | > step_time: 0.6845  (0.6357725756508964)\n",
      "     | > loader_time: 0.0063  (0.01152210491044181)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:35:05 -- STEP: 305/406 -- GLOBAL_STEP: 39275\u001b[0m\n",
      "     | > loss: -0.04829028248786926  (-0.04909306896514581)\n",
      "     | > log_mle: -0.26921355724334717  (-0.2574413448083595)\n",
      "     | > loss_dur: 0.2209232747554779  (0.20834827584321386)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(40.2337, device='cuda:0')  (tensor(22.9016, device='cuda:0'))\n",
      "     | > current_lr: 9.999999999999999e-06 \n",
      "     | > step_time: 0.5822  (0.6458177074057158)\n",
      "     | > loader_time: 0.0074  (0.01173456301454638)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:35:25 -- STEP: 330/406 -- GLOBAL_STEP: 39300\u001b[0m\n",
      "     | > loss: -0.028121113777160645  (-0.0491081690697959)\n",
      "     | > log_mle: -0.2733381986618042  (-0.25815749927000553)\n",
      "     | > loss_dur: 0.24521708488464355  (0.2090493302002098)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(23.8946, device='cuda:0')  (tensor(22.8480, device='cuda:0'))\n",
      "     | > current_lr: 9.999999999999999e-06 \n",
      "     | > step_time: 0.6672  (0.6560152761863938)\n",
      "     | > loader_time: 0.0178  (0.011825354171521734)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:35:46 -- STEP: 355/406 -- GLOBAL_STEP: 39325\u001b[0m\n",
      "     | > loss: -0.04945772886276245  (-0.04910904970807089)\n",
      "     | > log_mle: -0.27734458446502686  (-0.2589852618499541)\n",
      "     | > loss_dur: 0.2278868556022644  (0.20987621214188323)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(34.8046, device='cuda:0')  (tensor(23.0544, device='cuda:0'))\n",
      "     | > current_lr: 9.999999999999999e-06 \n",
      "     | > step_time: 1.616  (0.668466909166793)\n",
      "     | > loader_time: 0.0142  (0.012075913791925135)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:36:07 -- STEP: 380/406 -- GLOBAL_STEP: 39350\u001b[0m\n",
      "     | > loss: -0.04948921501636505  (-0.04931993606059175)\n",
      "     | > log_mle: -0.26991796493530273  (-0.2598290274017735)\n",
      "     | > loss_dur: 0.22042874991893768  (0.21050909134118184)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(15.7485, device='cuda:0')  (tensor(23.2545, device='cuda:0'))\n",
      "     | > current_lr: 9.999999999999999e-06 \n",
      "     | > step_time: 1.1143  (0.6784661907898756)\n",
      "     | > loader_time: 0.0261  (0.01234948572359587)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:36:26 -- STEP: 405/406 -- GLOBAL_STEP: 39375\u001b[0m\n",
      "     | > loss: -0.04399394989013672  (-0.049432556533519134)\n",
      "     | > log_mle: -0.2701537609100342  (-0.2606000920872628)\n",
      "     | > loss_dur: 0.22615981101989746  (0.21116753555374385)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(11.2633, device='cuda:0')  (tensor(23.5503, device='cuda:0'))\n",
      "     | > current_lr: 9.999999999999999e-06 \n",
      "     | > step_time: 0.4256  (0.6826805356108115)\n",
      "     | > loader_time: 0.0041  (0.0124333416974103)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: -0.043018996715545654  (-0.043018996715545654)\n",
      "     | > log_mle: -0.24354112148284912  (-0.24354112148284912)\n",
      "     | > loss_dur: 0.20052212476730347  (0.20052212476730347)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: -0.12009817361831665  (-0.12009817361831665)\n",
      "     | > log_mle: -0.28188467025756836  (-0.28188467025756836)\n",
      "     | > loss_dur: 0.1617864966392517  (0.1617864966392517)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: -0.08022843301296234  (-0.1001633033156395)\n",
      "     | > log_mle: -0.24231410026550293  (-0.26209938526153564)\n",
      "     | > loss_dur: 0.1620856672525406  (0.16193608194589615)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: -0.07486356794834137  (-0.09173005819320679)\n",
      "     | > log_mle: -0.2540600299835205  (-0.25941960016886395)\n",
      "     | > loss_dur: 0.17919646203517914  (0.16768954197565714)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: -0.08700273931026459  (-0.09054822847247124)\n",
      "     | > log_mle: -0.2812258005142212  (-0.26487115025520325)\n",
      "     | > loss_dur: 0.1942230612039566  (0.174322921782732)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: -0.08222055435180664  (-0.08888269364833831)\n",
      "     | > log_mle: -0.27330172061920166  (-0.2665572643280029)\n",
      "     | > loss_dur: 0.19108116626739502  (0.1776745706796646)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: -0.04929444193840027  (-0.08228465169668198)\n",
      "     | > log_mle: -0.28442180156707764  (-0.26953468720118207)\n",
      "     | > loss_dur: 0.23512735962867737  (0.18725003550450006)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: -0.06587892770767212  (-0.07994097684110914)\n",
      "     | > log_mle: -0.251700758934021  (-0.26698698316301617)\n",
      "     | > loss_dur: 0.18582183122634888  (0.18704600632190704)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: -0.09486441314220428  (-0.08180640637874603)\n",
      "     | > log_mle: -0.26514720916748047  (-0.2667570114135742)\n",
      "     | > loss_dur: 0.17028279602527618  (0.18495060503482819)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: -0.05781811475753784  (-0.07914104064305623)\n",
      "     | > log_mle: -0.27347350120544434  (-0.2675032880571153)\n",
      "     | > loss_dur: 0.2156553864479065  (0.1883622474140591)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: -0.044616907835006714  (-0.07568862736225128)\n",
      "     | > log_mle: -0.2624622583389282  (-0.26699918508529663)\n",
      "     | > loss_dur: 0.2178453505039215  (0.19131055772304534)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: -0.07298807799816132  (-0.07544312287460674)\n",
      "     | > log_mle: -0.2770012617111206  (-0.26790846477855335)\n",
      "     | > loss_dur: 0.2040131837129593  (0.19246534190394662)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: -0.0825081318616867  (-0.07603187362353007)\n",
      "     | > log_mle: -0.26623690128326416  (-0.2677691678206126)\n",
      "     | > loss_dur: 0.18372876942157745  (0.19173729419708252)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: -0.09644743800163269  (-0.07760230165261489)\n",
      "     | > log_mle: -0.280381441116333  (-0.26873934268951416)\n",
      "     | > loss_dur: 0.18393400311470032  (0.19113704103689927)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: -0.07098053395748138  (-0.07712931824581963)\n",
      "     | > log_mle: -0.27726829051971436  (-0.2693485532488142)\n",
      "     | > loss_dur: 0.20628775656223297  (0.19221923500299454)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: -0.06790229678153992  (-0.07651418348153433)\n",
      "     | > log_mle: -0.27051591873168945  (-0.2694263776143392)\n",
      "     | > loss_dur: 0.20261362195014954  (0.19291219413280486)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: -0.05813649296760559  (-0.07536557782441378)\n",
      "     | > log_mle: -0.26725029945373535  (-0.26929037272930145)\n",
      "     | > loss_dur: 0.20911380648612976  (0.19392479490488768)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: audio amplitude out of range, auto clipped.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.0045633018016815186 \u001b[0m(-0.01687602698802948)\n",
      "     | > avg_loss:\u001b[92m -0.07536557782441378 \u001b[0m(-0.0021694255992770195)\n",
      "     | > avg_log_mle:\u001b[92m -0.26929037272930145 \u001b[0m(-0.0012950897216796875)\n",
      "     | > avg_loss_dur:\u001b[92m 0.19392479490488768 \u001b[0m(-0.000874335877597332)\n",
      "\n",
      " > BEST MODEL : train/run-February-22-2025_10+59PM-fa84af3/best_model_39376.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 41/100\u001b[0m\n",
      " --> train/run-February-22-2025_10+59PM-fa84af3\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-23 02:36:42) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:36:55 -- STEP: 24/406 -- GLOBAL_STEP: 39400\u001b[0m\n",
      "     | > loss: -0.04767565429210663  (-0.06288984914620717)\n",
      "     | > log_mle: -0.24422705173492432  (-0.2423894206682841)\n",
      "     | > loss_dur: 0.1965513974428177  (0.17949957152207693)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(19.1749, device='cuda:0')  (tensor(14.6635, device='cuda:0'))\n",
      "     | > current_lr: 1.025e-05 \n",
      "     | > step_time: 0.3526  (0.44339380661646527)\n",
      "     | > loader_time: 0.0056  (0.007451117038726807)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:37:10 -- STEP: 49/406 -- GLOBAL_STEP: 39425\u001b[0m\n",
      "     | > loss: -0.06085655093193054  (-0.055530322449547906)\n",
      "     | > log_mle: -0.2426997423171997  (-0.24201675337188097)\n",
      "     | > loss_dur: 0.18184319138526917  (0.18648643092233308)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(18.0734, device='cuda:0')  (tensor(15.2548, device='cuda:0'))\n",
      "     | > current_lr: 1.025e-05 \n",
      "     | > step_time: 0.5196  (0.5130391266881204)\n",
      "     | > loader_time: 0.008  (0.010417393275669646)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:37:24 -- STEP: 74/406 -- GLOBAL_STEP: 39450\u001b[0m\n",
      "     | > loss: -0.05608396232128143  (-0.05393367864795633)\n",
      "     | > log_mle: -0.27345001697540283  (-0.24498582691759677)\n",
      "     | > loss_dur: 0.2173660546541214  (0.1910521482696404)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(27.5574, device='cuda:0')  (tensor(16.2938, device='cuda:0'))\n",
      "     | > current_lr: 1.025e-05 \n",
      "     | > step_time: 0.576  (0.5259015850118689)\n",
      "     | > loader_time: 0.0045  (0.009789859926378406)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:37:40 -- STEP: 99/406 -- GLOBAL_STEP: 39475\u001b[0m\n",
      "     | > loss: -0.046092256903648376  (-0.05287503037187788)\n",
      "     | > log_mle: -0.24934566020965576  (-0.24749026394853688)\n",
      "     | > loss_dur: 0.20325340330600739  (0.19461523357665894)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(26.7806, device='cuda:0')  (tensor(17.8596, device='cuda:0'))\n",
      "     | > current_lr: 1.025e-05 \n",
      "     | > step_time: 0.6122  (0.5484499594177861)\n",
      "     | > loader_time: 0.0042  (0.010146894840279015)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:37:56 -- STEP: 124/406 -- GLOBAL_STEP: 39500\u001b[0m\n",
      "     | > loss: -0.043454453349113464  (-0.052977328338930686)\n",
      "     | > log_mle: -0.2608295679092407  (-0.24989428443293418)\n",
      "     | > loss_dur: 0.21737511456012726  (0.19691695609400345)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(38.2343, device='cuda:0')  (tensor(18.6779, device='cuda:0'))\n",
      "     | > current_lr: 1.025e-05 \n",
      "     | > step_time: 0.829  (0.5639670856537359)\n",
      "     | > loader_time: 0.0144  (0.0102830010075723)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:38:12 -- STEP: 149/406 -- GLOBAL_STEP: 39525\u001b[0m\n",
      "     | > loss: -0.057740792632102966  (-0.05233564942875164)\n",
      "     | > log_mle: -0.2700086832046509  (-0.25186302357872065)\n",
      "     | > loss_dur: 0.2122678905725479  (0.1995273741499689)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(23.4159, device='cuda:0')  (tensor(19.4403, device='cuda:0'))\n",
      "     | > current_lr: 1.025e-05 \n",
      "     | > step_time: 0.5207  (0.5740359757570616)\n",
      "     | > loader_time: 0.0041  (0.010475419511731043)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:38:29 -- STEP: 174/406 -- GLOBAL_STEP: 39550\u001b[0m\n",
      "     | > loss: -0.06447474658489227  (-0.05210304148923391)\n",
      "     | > log_mle: -0.26120710372924805  (-0.2532977208323865)\n",
      "     | > loss_dur: 0.19673235714435577  (0.20119467934315233)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(7.5348, device='cuda:0')  (tensor(19.5362, device='cuda:0'))\n",
      "     | > current_lr: 1.025e-05 \n",
      "     | > step_time: 0.4248  (0.5849465666146118)\n",
      "     | > loader_time: 0.0067  (0.010914083184867068)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:38:46 -- STEP: 199/406 -- GLOBAL_STEP: 39575\u001b[0m\n",
      "     | > loss: -0.051051512360572815  (-0.05191401800318579)\n",
      "     | > log_mle: -0.26145267486572266  (-0.25462907522767064)\n",
      "     | > loss_dur: 0.21040116250514984  (0.20271505722448455)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(33.6940, device='cuda:0')  (tensor(21.5699, device='cuda:0'))\n",
      "     | > current_lr: 1.025e-05 \n",
      "     | > step_time: 0.6161  (0.5953993845225583)\n",
      "     | > loader_time: 0.0184  (0.011336980752609483)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:39:03 -- STEP: 224/406 -- GLOBAL_STEP: 39600\u001b[0m\n",
      "     | > loss: -0.05380818247795105  (-0.0520286127658827)\n",
      "     | > log_mle: -0.2605527639389038  (-0.25604984962514504)\n",
      "     | > loss_dur: 0.20674458146095276  (0.204021236859262)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(18.0330, device='cuda:0')  (tensor(21.4794, device='cuda:0'))\n",
      "     | > current_lr: 1.025e-05 \n",
      "     | > step_time: 0.8543  (0.6039488805191862)\n",
      "     | > loader_time: 0.0059  (0.01182486116886139)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:39:22 -- STEP: 249/406 -- GLOBAL_STEP: 39625\u001b[0m\n",
      "     | > loss: -0.04827338457107544  (-0.05212078001125749)\n",
      "     | > log_mle: -0.2610800266265869  (-0.25736728346491444)\n",
      "     | > loss_dur: 0.21280664205551147  (0.20524650345365686)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(31.9006, device='cuda:0')  (tensor(22.0125, device='cuda:0'))\n",
      "     | > current_lr: 1.025e-05 \n",
      "     | > step_time: 0.6011  (0.6167919310221235)\n",
      "     | > loader_time: 0.0162  (0.01201879930304715)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:39:42 -- STEP: 274/406 -- GLOBAL_STEP: 39650\u001b[0m\n",
      "     | > loss: -0.04964372515678406  (-0.05273641412058016)\n",
      "     | > log_mle: -0.27161431312561035  (-0.25860277449127544)\n",
      "     | > loss_dur: 0.2219705879688263  (0.20586636037069517)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(18.7971, device='cuda:0')  (tensor(22.1533, device='cuda:0'))\n",
      "     | > current_lr: 1.025e-05 \n",
      "     | > step_time: 0.8507  (0.631986042878924)\n",
      "     | > loader_time: 0.0065  (0.012204324241972316)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:40:01 -- STEP: 299/406 -- GLOBAL_STEP: 39675\u001b[0m\n",
      "     | > loss: -0.06585061550140381  (-0.05287159376319835)\n",
      "     | > log_mle: -0.29099392890930176  (-0.25951784869101546)\n",
      "     | > loss_dur: 0.22514331340789795  (0.206646254927817)\n",
      "     | > amp_scaler: 8192.0  (4315.183946488294)\n",
      "     | > grad_norm: tensor(33.4550, device='cuda:0')  (tensor(22.2890, device='cuda:0'))\n",
      "     | > current_lr: 1.025e-05 \n",
      "     | > step_time: 0.7496  (0.6416231102767997)\n",
      "     | > loader_time: 0.0261  (0.012316325037774432)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:40:21 -- STEP: 324/406 -- GLOBAL_STEP: 39700\u001b[0m\n",
      "     | > loss: -0.05886578559875488  (-0.05304904976560747)\n",
      "     | > log_mle: -0.27365314960479736  (-0.26034389086711557)\n",
      "     | > loss_dur: 0.21478736400604248  (0.2072948411015081)\n",
      "     | > amp_scaler: 8192.0  (4614.320987654323)\n",
      "     | > grad_norm: tensor(24.5903, device='cuda:0')  (tensor(22.6069, device='cuda:0'))\n",
      "     | > current_lr: 1.025e-05 \n",
      "     | > step_time: 0.8834  (0.6517475475499661)\n",
      "     | > loader_time: 0.0302  (0.01252631346384684)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:40:40 -- STEP: 349/406 -- GLOBAL_STEP: 39725\u001b[0m\n",
      "     | > loss: -0.03552575409412384  (-0.05285677130208659)\n",
      "     | > log_mle: -0.26423096656799316  (-0.26110700754859734)\n",
      "     | > loss_dur: 0.22870521247386932  (0.2082502362465107)\n",
      "     | > amp_scaler: 8192.0  (4870.601719197711)\n",
      "     | > grad_norm: tensor(21.3721, device='cuda:0')  (tensor(22.8836, device='cuda:0'))\n",
      "     | > current_lr: 1.025e-05 \n",
      "     | > step_time: 0.6118  (0.659065702924756)\n",
      "     | > loader_time: 0.0218  (0.012456224436063135)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:41:07 -- STEP: 374/406 -- GLOBAL_STEP: 39750\u001b[0m\n",
      "     | > loss: -0.05677446722984314  (-0.05304563535566637)\n",
      "     | > log_mle: -0.26932621002197266  (-0.2620045440719727)\n",
      "     | > loss_dur: 0.21255174279212952  (0.20895890871630632)\n",
      "     | > amp_scaler: 8192.0  (5092.620320855619)\n",
      "     | > grad_norm: tensor(19.2679, device='cuda:0')  (tensor(23.1487, device='cuda:0'))\n",
      "     | > current_lr: 1.025e-05 \n",
      "     | > step_time: 0.9748  (0.6848366980884167)\n",
      "     | > loader_time: 0.0102  (0.013010974236350644)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:41:26 -- STEP: 399/406 -- GLOBAL_STEP: 39775\u001b[0m\n",
      "     | > loss: -0.053427159786224365  (-0.05320052585954356)\n",
      "     | > log_mle: -0.27491867542266846  (-0.2627917997221602)\n",
      "     | > loss_dur: 0.2214915156364441  (0.20959127386261647)\n",
      "     | > amp_scaler: 8192.0  (5286.817042606516)\n",
      "     | > grad_norm: tensor(21.9750, device='cuda:0')  (tensor(23.2694, device='cuda:0'))\n",
      "     | > current_lr: 1.025e-05 \n",
      "     | > step_time: 0.5102  (0.6875704673298622)\n",
      "     | > loader_time: 0.0069  (0.01309549479855033)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: -0.03781597316265106  (-0.03781597316265106)\n",
      "     | > log_mle: -0.24556517601013184  (-0.24556517601013184)\n",
      "     | > loss_dur: 0.20774920284748077  (0.20774920284748077)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: -0.113229900598526  (-0.113229900598526)\n",
      "     | > log_mle: -0.284930944442749  (-0.284930944442749)\n",
      "     | > loss_dur: 0.17170104384422302  (0.17170104384422302)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: -0.08550360798835754  (-0.09936675429344177)\n",
      "     | > log_mle: -0.24583494663238525  (-0.26538294553756714)\n",
      "     | > loss_dur: 0.1603313386440277  (0.16601619124412537)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: -0.08006802201271057  (-0.09293384353319804)\n",
      "     | > log_mle: -0.25831854343414307  (-0.2630281448364258)\n",
      "     | > loss_dur: 0.1782505214214325  (0.17009430130322775)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: -0.0948532372713089  (-0.09341369196772575)\n",
      "     | > log_mle: -0.2849466800689697  (-0.26850777864456177)\n",
      "     | > loss_dur: 0.19009344279766083  (0.175094086676836)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: -0.09856852889060974  (-0.09444465935230255)\n",
      "     | > log_mle: -0.2828603982925415  (-0.27137830257415774)\n",
      "     | > loss_dur: 0.18429186940193176  (0.17693364322185517)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: -0.052635788917541504  (-0.08747651427984238)\n",
      "     | > log_mle: -0.291537880897522  (-0.27473823229471844)\n",
      "     | > loss_dur: 0.23890209197998047  (0.18726171801487604)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: -0.07522042095661163  (-0.08572564380509513)\n",
      "     | > log_mle: -0.2567892074584961  (-0.2721740858895438)\n",
      "     | > loss_dur: 0.18156878650188446  (0.1864484420844487)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: -0.10032860934734344  (-0.08755101449787617)\n",
      "     | > log_mle: -0.26833271980285645  (-0.2716939151287079)\n",
      "     | > loss_dur: 0.168004110455513  (0.18414290063083172)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: -0.06378577649593353  (-0.08491043249766032)\n",
      "     | > log_mle: -0.2793081998825073  (-0.27253994676801896)\n",
      "     | > loss_dur: 0.2155224233865738  (0.18762951427035862)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: -0.04847784340381622  (-0.08126717358827591)\n",
      "     | > log_mle: -0.26640450954437256  (-0.2719264030456543)\n",
      "     | > loss_dur: 0.21792666614055634  (0.1906592294573784)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: -0.0795724093914032  (-0.08111310411583293)\n",
      "     | > log_mle: -0.2821471691131592  (-0.27285556359724566)\n",
      "     | > loss_dur: 0.20257475972175598  (0.19174245948141272)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: -0.08572433888912201  (-0.0814973736802737)\n",
      "     | > log_mle: -0.2706674337387085  (-0.27267321944236755)\n",
      "     | > loss_dur: 0.1849430948495865  (0.19117584576209387)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: -0.10883191227912903  (-0.08360003049557026)\n",
      "     | > log_mle: -0.28962278366088867  (-0.2739770320745615)\n",
      "     | > loss_dur: 0.18079087138175964  (0.19037700157899123)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: -0.07685935497283936  (-0.08311855367251805)\n",
      "     | > log_mle: -0.2813594341278076  (-0.2745043465069362)\n",
      "     | > loss_dur: 0.20450007915496826  (0.19138579283441817)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: -0.07543538510799408  (-0.08260634243488311)\n",
      "     | > log_mle: -0.27498674392700195  (-0.2745365063349406)\n",
      "     | > loss_dur: 0.19955135881900787  (0.1919301639000575)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: -0.06606374680995941  (-0.08157243020832539)\n",
      "     | > log_mle: -0.2742685079574585  (-0.27451975643634796)\n",
      "     | > loss_dur: 0.20820476114749908  (0.19294732622802258)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: audio amplitude out of range, auto clipped.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[91m 0.005096882581710815 \u001b[0m(+0.0005335807800292969)\n",
      "     | > avg_loss:\u001b[92m -0.08157243020832539 \u001b[0m(-0.00620685238391161)\n",
      "     | > avg_log_mle:\u001b[92m -0.27451975643634796 \u001b[0m(-0.005229383707046509)\n",
      "     | > avg_loss_dur:\u001b[92m 0.19294732622802258 \u001b[0m(-0.0009774686768651009)\n",
      "\n",
      " > BEST MODEL : train/run-February-22-2025_10+59PM-fa84af3/best_model_39782.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 42/100\u001b[0m\n",
      " --> train/run-February-22-2025_10+59PM-fa84af3\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-23 02:41:46) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:41:58 -- STEP: 18/406 -- GLOBAL_STEP: 39800\u001b[0m\n",
      "     | > loss: -0.06852826476097107  (-0.0657131274541219)\n",
      "     | > log_mle: -0.2406095266342163  (-0.2470053964191013)\n",
      "     | > loss_dur: 0.17208126187324524  (0.18129226896497938)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(9.6793, device='cuda:0')  (tensor(14.3663, device='cuda:0'))\n",
      "     | > current_lr: 1.05e-05 \n",
      "     | > step_time: 0.4407  (0.5208752685123019)\n",
      "     | > loader_time: 0.0042  (0.005628996425204807)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:42:15 -- STEP: 43/406 -- GLOBAL_STEP: 39825\u001b[0m\n",
      "     | > loss: -0.06387852132320404  (-0.05946222120939298)\n",
      "     | > log_mle: -0.2339951992034912  (-0.24384979314582292)\n",
      "     | > loss_dur: 0.17011667788028717  (0.1843875719364299)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(9.6810, device='cuda:0')  (tensor(14.6119, device='cuda:0'))\n",
      "     | > current_lr: 1.05e-05 \n",
      "     | > step_time: 1.5676  (0.6044859997061796)\n",
      "     | > loader_time: 0.0065  (0.009117048840190089)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:42:36 -- STEP: 68/406 -- GLOBAL_STEP: 39850\u001b[0m\n",
      "     | > loss: -0.05003376305103302  (-0.056732785614097815)\n",
      "     | > log_mle: -0.2546294927597046  (-0.24626306400579565)\n",
      "     | > loss_dur: 0.20459572970867157  (0.18953027839169784)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(26.9827, device='cuda:0')  (tensor(15.6339, device='cuda:0'))\n",
      "     | > current_lr: 1.05e-05 \n",
      "     | > step_time: 0.5104  (0.6863167145672966)\n",
      "     | > loader_time: 0.038  (0.010847410734962015)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:42:52 -- STEP: 93/406 -- GLOBAL_STEP: 39875\u001b[0m\n",
      "     | > loss: -0.057269707322120667  (-0.056314610024934174)\n",
      "     | > log_mle: -0.2755270004272461  (-0.2494485096264911)\n",
      "     | > loss_dur: 0.21825729310512543  (0.19313389960155686)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(6.6353, device='cuda:0')  (tensor(16.8077, device='cuda:0'))\n",
      "     | > current_lr: 1.05e-05 \n",
      "     | > step_time: 0.679  (0.6706306190900905)\n",
      "     | > loader_time: 0.0078  (0.01029021765596123)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:43:08 -- STEP: 118/406 -- GLOBAL_STEP: 39900\u001b[0m\n",
      "     | > loss: -0.05664275586605072  (-0.05588674115932594)\n",
      "     | > log_mle: -0.26712512969970703  (-0.25169108378685134)\n",
      "     | > loss_dur: 0.2104823738336563  (0.19580434262752527)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(13.4396, device='cuda:0')  (tensor(17.2916, device='cuda:0'))\n",
      "     | > current_lr: 1.05e-05 \n",
      "     | > step_time: 0.4566  (0.6568258616883875)\n",
      "     | > loader_time: 0.0059  (0.010687868473893506)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:43:28 -- STEP: 143/406 -- GLOBAL_STEP: 39925\u001b[0m\n",
      "     | > loss: -0.05236673355102539  (-0.05496069632626913)\n",
      "     | > log_mle: -0.2670706510543823  (-0.2535666935927385)\n",
      "     | > loss_dur: 0.21470391750335693  (0.19860599726646924)\n",
      "     | > amp_scaler: 4096.0  (8077.426573426574)\n",
      "     | > grad_norm: tensor(32.7325, device='cuda:0')  (tensor(20.1344, device='cuda:0'))\n",
      "     | > current_lr: 1.05e-05 \n",
      "     | > step_time: 0.7586  (0.6789083830960148)\n",
      "     | > loader_time: 0.0103  (0.010890843984964009)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:43:45 -- STEP: 168/406 -- GLOBAL_STEP: 39950\u001b[0m\n",
      "     | > loss: -0.054347068071365356  (-0.05451558973817598)\n",
      "     | > log_mle: -0.2561541795730591  (-0.2548584718079795)\n",
      "     | > loss_dur: 0.20180711150169373  (0.20034288206980339)\n",
      "     | > amp_scaler: 4096.0  (7484.952380952381)\n",
      "     | > grad_norm: tensor(18.3244, device='cuda:0')  (tensor(20.4076, device='cuda:0'))\n",
      "     | > current_lr: 1.05e-05 \n",
      "     | > step_time: 0.4945  (0.6778330632618493)\n",
      "     | > loader_time: 0.0095  (0.011646604254132224)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:44:04 -- STEP: 193/406 -- GLOBAL_STEP: 39975\u001b[0m\n",
      "     | > loss: -0.04164823889732361  (-0.05471713323667259)\n",
      "     | > log_mle: -0.26682162284851074  (-0.2564349915697167)\n",
      "     | > loss_dur: 0.22517338395118713  (0.20171785833304406)\n",
      "     | > amp_scaler: 4096.0  (7045.968911917098)\n",
      "     | > grad_norm: tensor(37.9297, device='cuda:0')  (tensor(20.9443, device='cuda:0'))\n",
      "     | > current_lr: 1.05e-05 \n",
      "     | > step_time: 0.6362  (0.6835053757682366)\n",
      "     | > loader_time: 0.0051  (0.011664076790290794)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:44:22 -- STEP: 218/406 -- GLOBAL_STEP: 40000\u001b[0m\n",
      "     | > loss: -0.05820789933204651  (-0.05458292091658356)\n",
      "     | > log_mle: -0.2677145004272461  (-0.2576590535837575)\n",
      "     | > loss_dur: 0.20950660109519958  (0.203076132667174)\n",
      "     | > amp_scaler: 4096.0  (6707.6697247706425)\n",
      "     | > grad_norm: tensor(26.1677, device='cuda:0')  (tensor(21.2074, device='cuda:0'))\n",
      "     | > current_lr: 1.05e-05 \n",
      "     | > step_time: 0.6997  (0.6896407112069086)\n",
      "     | > loader_time: 0.0154  (0.01159775475843237)\n",
      "\n",
      "\n",
      " > CHECKPOINT : train/run-February-22-2025_10+59PM-fa84af3/checkpoint_40000.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: audio amplitude out of range, auto clipped.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:44:49 -- STEP: 243/406 -- GLOBAL_STEP: 40025\u001b[0m\n",
      "     | > loss: -0.05778372287750244  (-0.05470762049219736)\n",
      "     | > log_mle: -0.2859644889831543  (-0.25913612293117816)\n",
      "     | > loss_dur: 0.22818076610565186  (0.20442850243898084)\n",
      "     | > amp_scaler: 4096.0  (6438.979423868313)\n",
      "     | > grad_norm: tensor(37.4610, device='cuda:0')  (tensor(21.8348, device='cuda:0'))\n",
      "     | > current_lr: 1.05e-05 \n",
      "     | > step_time: 0.6415  (0.6905226746704353)\n",
      "     | > loader_time: 0.0123  (0.011484842732119463)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:45:08 -- STEP: 268/406 -- GLOBAL_STEP: 40050\u001b[0m\n",
      "     | > loss: -0.07414957880973816  (-0.055084471604717314)\n",
      "     | > log_mle: -0.2809332609176636  (-0.2601917733007402)\n",
      "     | > loss_dur: 0.20678368210792542  (0.20510730169602293)\n",
      "     | > amp_scaler: 4096.0  (6220.417910447762)\n",
      "     | > grad_norm: tensor(29.1408, device='cuda:0')  (tensor(22.4504, device='cuda:0'))\n",
      "     | > current_lr: 1.05e-05 \n",
      "     | > step_time: 0.5916  (0.6972888628048685)\n",
      "     | > loader_time: 0.0312  (0.011996298583585826)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:45:27 -- STEP: 293/406 -- GLOBAL_STEP: 40075\u001b[0m\n",
      "     | > loss: -0.0659615695476532  (-0.05542127442237867)\n",
      "     | > log_mle: -0.27512097358703613  (-0.2611661067187989)\n",
      "     | > loss_dur: 0.20915940403938293  (0.20574483229642024)\n",
      "     | > amp_scaler: 4096.0  (6039.153583617747)\n",
      "     | > grad_norm: tensor(38.8868, device='cuda:0')  (tensor(22.8484, device='cuda:0'))\n",
      "     | > current_lr: 1.05e-05 \n",
      "     | > step_time: 0.5476  (0.7003759044022283)\n",
      "     | > loader_time: 0.0209  (0.012479181582610355)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:45:46 -- STEP: 318/406 -- GLOBAL_STEP: 40100\u001b[0m\n",
      "     | > loss: -0.055551186203956604  (-0.0556995984424585)\n",
      "     | > log_mle: -0.26323413848876953  (-0.2620922364528824)\n",
      "     | > loss_dur: 0.20768295228481293  (0.20639263801042376)\n",
      "     | > amp_scaler: 4096.0  (5886.389937106916)\n",
      "     | > grad_norm: tensor(20.8582, device='cuda:0')  (tensor(23.0257, device='cuda:0'))\n",
      "     | > current_lr: 1.05e-05 \n",
      "     | > step_time: 0.4933  (0.7021708106094936)\n",
      "     | > loader_time: 0.0053  (0.012922080807715841)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:46:06 -- STEP: 343/406 -- GLOBAL_STEP: 40125\u001b[0m\n",
      "     | > loss: -0.05558045208454132  (-0.055646859348341605)\n",
      "     | > log_mle: -0.2843811511993408  (-0.26284533686957634)\n",
      "     | > loss_dur: 0.2288006991147995  (0.2071984775212345)\n",
      "     | > amp_scaler: 4096.0  (5755.895043731773)\n",
      "     | > grad_norm: tensor(12.9275, device='cuda:0')  (tensor(23.2298, device='cuda:0'))\n",
      "     | > current_lr: 1.05e-05 \n",
      "     | > step_time: 0.6183  (0.7088674393756748)\n",
      "     | > loader_time: 0.0079  (0.013467056063104301)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:46:26 -- STEP: 368/406 -- GLOBAL_STEP: 40150\u001b[0m\n",
      "     | > loss: -0.06284776329994202  (-0.05575186953596447)\n",
      "     | > log_mle: -0.27136099338531494  (-0.2636798244455587)\n",
      "     | > loss_dur: 0.20851323008537292  (0.20792795490959404)\n",
      "     | > amp_scaler: 4096.0  (5643.130434782601)\n",
      "     | > grad_norm: tensor(18.4098, device='cuda:0')  (tensor(23.3978, device='cuda:0'))\n",
      "     | > current_lr: 1.05e-05 \n",
      "     | > step_time: 0.7628  (0.7135748364355257)\n",
      "     | > loader_time: 0.031  (0.013805526754130487)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:46:47 -- STEP: 393/406 -- GLOBAL_STEP: 40175\u001b[0m\n",
      "     | > loss: -0.05477827787399292  (-0.05589498973833089)\n",
      "     | > log_mle: -0.2803831100463867  (-0.264457332268926)\n",
      "     | > loss_dur: 0.2256048321723938  (0.20856234253059502)\n",
      "     | > amp_scaler: 4096.0  (5544.712468193377)\n",
      "     | > grad_norm: tensor(27.3522, device='cuda:0')  (tensor(23.8177, device='cuda:0'))\n",
      "     | > current_lr: 1.05e-05 \n",
      "     | > step_time: 0.5925  (0.7186783852468013)\n",
      "     | > loader_time: 0.0151  (0.014167707384997652)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: -0.043422549962997437  (-0.043422549962997437)\n",
      "     | > log_mle: -0.24647128582000732  (-0.24647128582000732)\n",
      "     | > loss_dur: 0.2030487358570099  (0.2030487358570099)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: -0.1105952113866806  (-0.1105952113866806)\n",
      "     | > log_mle: -0.2835052013397217  (-0.2835052013397217)\n",
      "     | > loss_dur: 0.17290998995304108  (0.17290998995304108)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: -0.0827469527721405  (-0.09667108207941055)\n",
      "     | > log_mle: -0.2458200454711914  (-0.26466262340545654)\n",
      "     | > loss_dur: 0.1630730926990509  (0.167991541326046)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: -0.07337729632854462  (-0.0889064868291219)\n",
      "     | > log_mle: -0.25746119022369385  (-0.26226214567820233)\n",
      "     | > loss_dur: 0.18408389389514923  (0.1733556588490804)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: -0.08984680473804474  (-0.08914156630635262)\n",
      "     | > log_mle: -0.28229308128356934  (-0.26726987957954407)\n",
      "     | > loss_dur: 0.1924462765455246  (0.17812831327319145)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: -0.0907231867313385  (-0.0894578903913498)\n",
      "     | > log_mle: -0.2742140293121338  (-0.268658709526062)\n",
      "     | > loss_dur: 0.1834908425807953  (0.17920081913471222)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: -0.0419829785823822  (-0.0815454050898552)\n",
      "     | > log_mle: -0.2804335355758667  (-0.2706211805343628)\n",
      "     | > loss_dur: 0.2384505569934845  (0.1890757754445076)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: -0.07357284426689148  (-0.08040646782943181)\n",
      "     | > log_mle: -0.25302577018737793  (-0.2681075504847935)\n",
      "     | > loss_dur: 0.17945292592048645  (0.18770108265536173)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: -0.09578339755535126  (-0.08232858404517174)\n",
      "     | > log_mle: -0.2666374444961548  (-0.2679237872362137)\n",
      "     | > loss_dur: 0.17085404694080353  (0.18559520319104195)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: -0.05504409968852997  (-0.07929697467221154)\n",
      "     | > log_mle: -0.2736642360687256  (-0.26856161488427055)\n",
      "     | > loss_dur: 0.21862013638019562  (0.18926464021205902)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: -0.04551650583744049  (-0.07591892778873444)\n",
      "     | > log_mle: -0.2627377510070801  (-0.26797922849655154)\n",
      "     | > loss_dur: 0.2172212451696396  (0.19206030070781707)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: -0.07308293879032135  (-0.07566111060706052)\n",
      "     | > log_mle: -0.27867329120635986  (-0.268951416015625)\n",
      "     | > loss_dur: 0.2055903524160385  (0.19329030540856448)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: -0.08103708922863007  (-0.07610910882552464)\n",
      "     | > log_mle: -0.2684732675552368  (-0.26891157031059265)\n",
      "     | > loss_dur: 0.18743617832660675  (0.192802461485068)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: -0.0974687784910202  (-0.07775216033825508)\n",
      "     | > log_mle: -0.28269684314727783  (-0.2699719759134146)\n",
      "     | > loss_dur: 0.18522806465625763  (0.19221981557515952)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: -0.07178616523742676  (-0.07732601783105306)\n",
      "     | > log_mle: -0.27684473991394043  (-0.27046288762773785)\n",
      "     | > loss_dur: 0.20505857467651367  (0.19313686979668482)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: -0.07009980082511902  (-0.07684427003065745)\n",
      "     | > log_mle: -0.271059513092041  (-0.2705026626586914)\n",
      "     | > loss_dur: 0.200959712266922  (0.19365839262803394)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: -0.0624338835477829  (-0.07594362087547779)\n",
      "     | > log_mle: -0.26853954792022705  (-0.2703799679875374)\n",
      "     | > loss_dur: 0.20610566437244415  (0.1944363471120596)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: audio amplitude out of range, auto clipped.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.0033725351095199585 \u001b[0m(-0.001724347472190857)\n",
      "     | > avg_loss:\u001b[91m -0.07594362087547779 \u001b[0m(+0.005628809332847595)\n",
      "     | > avg_log_mle:\u001b[91m -0.2703799679875374 \u001b[0m(+0.004139788448810577)\n",
      "     | > avg_loss_dur:\u001b[91m 0.1944363471120596 \u001b[0m(+0.0014890208840370178)\n",
      "\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 43/100\u001b[0m\n",
      " --> train/run-February-22-2025_10+59PM-fa84af3\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-23 02:47:08) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:47:15 -- STEP: 12/406 -- GLOBAL_STEP: 40200\u001b[0m\n",
      "     | > loss: -0.0673997700214386  (-0.07333939149975777)\n",
      "     | > log_mle: -0.2575697898864746  (-0.2480644186337789)\n",
      "     | > loss_dur: 0.190170019865036  (0.17472502713402113)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(23.5822, device='cuda:0')  (tensor(14.0775, device='cuda:0'))\n",
      "     | > current_lr: 1.075e-05 \n",
      "     | > step_time: 0.295  (0.3607800006866455)\n",
      "     | > loader_time: 0.0047  (0.0068560441335042315)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:47:29 -- STEP: 37/406 -- GLOBAL_STEP: 40225\u001b[0m\n",
      "     | > loss: -0.05864311754703522  (-0.06388179394038948)\n",
      "     | > log_mle: -0.24217510223388672  (-0.24650387506227237)\n",
      "     | > loss_dur: 0.1835319846868515  (0.18262208112188288)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(14.0799, device='cuda:0')  (tensor(14.3015, device='cuda:0'))\n",
      "     | > current_lr: 1.075e-05 \n",
      "     | > step_time: 0.3774  (0.48032669118932775)\n",
      "     | > loader_time: 0.025  (0.008757275504034918)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:47:44 -- STEP: 62/406 -- GLOBAL_STEP: 40250\u001b[0m\n",
      "     | > loss: -0.06173337996006012  (-0.06027483747851464)\n",
      "     | > log_mle: -0.2458270788192749  (-0.24779248045336816)\n",
      "     | > loss_dur: 0.18409369885921478  (0.18751764297485352)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(5.2315, device='cuda:0')  (tensor(14.5054, device='cuda:0'))\n",
      "     | > current_lr: 1.075e-05 \n",
      "     | > step_time: 0.6557  (0.5180294398338564)\n",
      "     | > loader_time: 0.0114  (0.008659943457572691)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:47:59 -- STEP: 87/406 -- GLOBAL_STEP: 40275\u001b[0m\n",
      "     | > loss: -0.07121391594409943  (-0.05954765280087789)\n",
      "     | > log_mle: -0.2754255533218384  (-0.2504110788476878)\n",
      "     | > loss_dur: 0.20421163737773895  (0.19086342604680992)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(39.5883, device='cuda:0')  (tensor(17.0807, device='cuda:0'))\n",
      "     | > current_lr: 1.075e-05 \n",
      "     | > step_time: 0.339  (0.5460554703898812)\n",
      "     | > loader_time: 0.0198  (0.009652044581270771)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:48:15 -- STEP: 112/406 -- GLOBAL_STEP: 40300\u001b[0m\n",
      "     | > loss: -0.05867183208465576  (-0.058473650366067886)\n",
      "     | > log_mle: -0.2659742832183838  (-0.2528637679559844)\n",
      "     | > loss_dur: 0.20730245113372803  (0.1943901175899165)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(20.1378, device='cuda:0')  (tensor(19.3963, device='cuda:0'))\n",
      "     | > current_lr: 1.075e-05 \n",
      "     | > step_time: 0.7079  (0.5645626762083596)\n",
      "     | > loader_time: 0.0043  (0.009712381022317073)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:48:31 -- STEP: 137/406 -- GLOBAL_STEP: 40325\u001b[0m\n",
      "     | > loss: -0.05058121681213379  (-0.05816332898000731)\n",
      "     | > log_mle: -0.26504623889923096  (-0.254968281209904)\n",
      "     | > loss_dur: 0.21446502208709717  (0.1968049522298966)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(19.1716, device='cuda:0')  (tensor(19.5137, device='cuda:0'))\n",
      "     | > current_lr: 1.075e-05 \n",
      "     | > step_time: 0.7848  (0.5762490791125887)\n",
      "     | > loader_time: 0.005  (0.009582119266482168)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:48:47 -- STEP: 162/406 -- GLOBAL_STEP: 40350\u001b[0m\n",
      "     | > loss: -0.05256350338459015  (-0.057485610614588234)\n",
      "     | > log_mle: -0.26599979400634766  (-0.2564907412470124)\n",
      "     | > loss_dur: 0.2134362906217575  (0.19900513063242406)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(22.7455, device='cuda:0')  (tensor(20.6946, device='cuda:0'))\n",
      "     | > current_lr: 1.075e-05 \n",
      "     | > step_time: 0.4109  (0.583128527358726)\n",
      "     | > loader_time: 0.0061  (0.009741346041361492)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:49:04 -- STEP: 187/406 -- GLOBAL_STEP: 40375\u001b[0m\n",
      "     | > loss: -0.06268182396888733  (-0.05763178434282701)\n",
      "     | > log_mle: -0.2703357934951782  (-0.25806200058065015)\n",
      "     | > loss_dur: 0.2076539695262909  (0.20043021623782295)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(36.5140, device='cuda:0')  (tensor(21.5095, device='cuda:0'))\n",
      "     | > current_lr: 1.075e-05 \n",
      "     | > step_time: 0.4806  (0.5905108222349441)\n",
      "     | > loader_time: 0.0132  (0.010331491735529772)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:49:21 -- STEP: 212/406 -- GLOBAL_STEP: 40400\u001b[0m\n",
      "     | > loss: -0.055615589022636414  (-0.057712330851914746)\n",
      "     | > log_mle: -0.28110718727111816  (-0.2594135094363736)\n",
      "     | > loss_dur: 0.22549159824848175  (0.20170117858445868)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(22.5558, device='cuda:0')  (tensor(22.0476, device='cuda:0'))\n",
      "     | > current_lr: 1.075e-05 \n",
      "     | > step_time: 0.4081  (0.6002458738830851)\n",
      "     | > loader_time: 0.006  (0.010578612111649423)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:49:39 -- STEP: 237/406 -- GLOBAL_STEP: 40425\u001b[0m\n",
      "     | > loss: -0.0652627944946289  (-0.057786807543617764)\n",
      "     | > log_mle: -0.2852456569671631  (-0.26084239422520533)\n",
      "     | > loss_dur: 0.21998286247253418  (0.2030555866815873)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(24.5979, device='cuda:0')  (tensor(22.6453, device='cuda:0'))\n",
      "     | > current_lr: 1.075e-05 \n",
      "     | > step_time: 0.6207  (0.612770309931115)\n",
      "     | > loader_time: 0.0058  (0.010839310376452997)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:49:58 -- STEP: 262/406 -- GLOBAL_STEP: 40450\u001b[0m\n",
      "     | > loss: -0.05140407383441925  (-0.05804761573103548)\n",
      "     | > log_mle: -0.25349998474121094  (-0.2619410148103731)\n",
      "     | > loss_dur: 0.2020959109067917  (0.20389339907933737)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(20.6268, device='cuda:0')  (tensor(22.6490, device='cuda:0'))\n",
      "     | > current_lr: 1.075e-05 \n",
      "     | > step_time: 0.8763  (0.62403034890881)\n",
      "     | > loader_time: 0.0181  (0.011019860515157685)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:50:17 -- STEP: 287/406 -- GLOBAL_STEP: 40475\u001b[0m\n",
      "     | > loss: -0.05243600904941559  (-0.05845890622521111)\n",
      "     | > log_mle: -0.26997530460357666  (-0.26296119282885316)\n",
      "     | > loss_dur: 0.21753929555416107  (0.2045022866036418)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(6.4852, device='cuda:0')  (tensor(23.4810, device='cuda:0'))\n",
      "     | > current_lr: 1.075e-05 \n",
      "     | > step_time: 0.6432  (0.6343747340012925)\n",
      "     | > loader_time: 0.0065  (0.011365383759608253)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:50:37 -- STEP: 312/406 -- GLOBAL_STEP: 40500\u001b[0m\n",
      "     | > loss: -0.06573790311813354  (-0.0584330170486982)\n",
      "     | > log_mle: -0.2754398584365845  (-0.26365956625877285)\n",
      "     | > loss_dur: 0.20970195531845093  (0.20522654921007458)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(19.5906, device='cuda:0')  (tensor(24.0721, device='cuda:0'))\n",
      "     | > current_lr: 1.075e-05 \n",
      "     | > step_time: 0.6805  (0.6466380632840667)\n",
      "     | > loader_time: 0.0174  (0.011513496056581151)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:50:57 -- STEP: 337/406 -- GLOBAL_STEP: 40525\u001b[0m\n",
      "     | > loss: -0.05143114924430847  (-0.05832015791526534)\n",
      "     | > log_mle: -0.2700207233428955  (-0.26437567709461535)\n",
      "     | > loss_dur: 0.21858957409858704  (0.2060555191793498)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(22.2452, device='cuda:0')  (tensor(24.2887, device='cuda:0'))\n",
      "     | > current_lr: 1.075e-05 \n",
      "     | > step_time: 0.6054  (0.6558312867444767)\n",
      "     | > loader_time: 0.0069  (0.011628017227444516)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:51:17 -- STEP: 362/406 -- GLOBAL_STEP: 40550\u001b[0m\n",
      "     | > loss: -0.08079150319099426  (-0.05828628516164274)\n",
      "     | > log_mle: -0.285447359085083  (-0.2652517471524234)\n",
      "     | > loss_dur: 0.20465585589408875  (0.20696546199078056)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(21.7820, device='cuda:0')  (tensor(24.4358, device='cuda:0'))\n",
      "     | > current_lr: 1.075e-05 \n",
      "     | > step_time: 0.6569  (0.6633088476750069)\n",
      "     | > loader_time: 0.0103  (0.011935499491612551)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:51:37 -- STEP: 387/406 -- GLOBAL_STEP: 40575\u001b[0m\n",
      "     | > loss: -0.058757483959198  (-0.05834929236915992)\n",
      "     | > log_mle: -0.2786444425582886  (-0.26598655499845214)\n",
      "     | > loss_dur: 0.21988695859909058  (0.20763726262929208)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(36.8853, device='cuda:0')  (tensor(24.5590, device='cuda:0'))\n",
      "     | > current_lr: 1.075e-05 \n",
      "     | > step_time: 0.6733  (0.6716759981111036)\n",
      "     | > loader_time: 0.0057  (0.012275498042735014)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: -0.047814399003982544  (-0.047814399003982544)\n",
      "     | > log_mle: -0.2498340606689453  (-0.2498340606689453)\n",
      "     | > loss_dur: 0.20201966166496277  (0.20201966166496277)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: -0.12576238811016083  (-0.12576238811016083)\n",
      "     | > log_mle: -0.28885436058044434  (-0.28885436058044434)\n",
      "     | > loss_dur: 0.1630919724702835  (0.1630919724702835)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: -0.08871829509735107  (-0.10724034160375595)\n",
      "     | > log_mle: -0.2505631446838379  (-0.2697087526321411)\n",
      "     | > loss_dur: 0.16184484958648682  (0.16246841102838516)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: -0.08834208548069  (-0.1009409228960673)\n",
      "     | > log_mle: -0.2630600929260254  (-0.26749253273010254)\n",
      "     | > loss_dur: 0.1747180074453354  (0.16655160983403525)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: -0.09861680865287781  (-0.10035989433526993)\n",
      "     | > log_mle: -0.28908848762512207  (-0.2728915214538574)\n",
      "     | > loss_dur: 0.19047167897224426  (0.1725316271185875)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: -0.1084912121295929  (-0.10198615789413452)\n",
      "     | > log_mle: -0.2899510860443115  (-0.27630343437194826)\n",
      "     | > loss_dur: 0.18145987391471863  (0.17431727647781373)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: -0.06029367446899414  (-0.09503741065661113)\n",
      "     | > log_mle: -0.2988455295562744  (-0.2800604502360026)\n",
      "     | > loss_dur: 0.23855185508728027  (0.18502303957939148)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: -0.08360189199447632  (-0.09340376513344902)\n",
      "     | > log_mle: -0.2620581388473511  (-0.27748869146619526)\n",
      "     | > loss_dur: 0.17845624685287476  (0.18408492633274623)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: -0.10029707849025726  (-0.09426542930305004)\n",
      "     | > log_mle: -0.2725069522857666  (-0.27686597406864166)\n",
      "     | > loss_dur: 0.17220987379550934  (0.18260054476559162)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: -0.071309894323349  (-0.09171481430530548)\n",
      "     | > log_mle: -0.2851226329803467  (-0.2777833806143867)\n",
      "     | > loss_dur: 0.21381273865699768  (0.1860685663090812)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: -0.05855584144592285  (-0.08839891701936722)\n",
      "     | > log_mle: -0.2714047431945801  (-0.277145516872406)\n",
      "     | > loss_dur: 0.21284890174865723  (0.1887465998530388)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: -0.08724063634872437  (-0.0882936187765815)\n",
      "     | > log_mle: -0.28748881816864014  (-0.2780858169902455)\n",
      "     | > loss_dur: 0.20024818181991577  (0.18979219821366397)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: -0.0930337905883789  (-0.08868863309423129)\n",
      "     | > log_mle: -0.2752188444137573  (-0.27784690260887146)\n",
      "     | > loss_dur: 0.18218505382537842  (0.18915826951464018)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: -0.11675125360488892  (-0.09084729621043572)\n",
      "     | > log_mle: -0.29637610912323  (-0.27927222618689906)\n",
      "     | > loss_dur: 0.17962485551834106  (0.18842492997646332)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: -0.07766294479370117  (-0.0899055568235261)\n",
      "     | > log_mle: -0.2860943078994751  (-0.27975951773779734)\n",
      "     | > loss_dur: 0.20843136310577393  (0.18985396091427123)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: -0.08303548395633698  (-0.0894475519657135)\n",
      "     | > log_mle: -0.2796720266342163  (-0.2797536849975586)\n",
      "     | > loss_dur: 0.19663654267787933  (0.1903061330318451)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: -0.0755605399608612  (-0.08857961371541023)\n",
      "     | > log_mle: -0.2799718379974365  (-0.27976731956005096)\n",
      "     | > loss_dur: 0.20441129803657532  (0.19118770584464073)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: audio amplitude out of range, auto clipped.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.0028672069311141968 \u001b[0m(-0.0005053281784057617)\n",
      "     | > avg_loss:\u001b[92m -0.08857961371541023 \u001b[0m(-0.012635992839932442)\n",
      "     | > avg_log_mle:\u001b[92m -0.27976731956005096 \u001b[0m(-0.00938735157251358)\n",
      "     | > avg_loss_dur:\u001b[92m 0.19118770584464073 \u001b[0m(-0.0032486412674188614)\n",
      "\n",
      " > BEST MODEL : train/run-February-22-2025_10+59PM-fa84af3/best_model_40594.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 44/100\u001b[0m\n",
      " --> train/run-February-22-2025_10+59PM-fa84af3\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-23 02:52:04) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:52:08 -- STEP: 6/406 -- GLOBAL_STEP: 40600\u001b[0m\n",
      "     | > loss: -0.09811937808990479  (-0.07701095938682556)\n",
      "     | > log_mle: -0.25066614151000977  (-0.24955010414123535)\n",
      "     | > loss_dur: 0.15254676342010498  (0.1725391447544098)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(4.3670, device='cuda:0')  (tensor(15.4000, device='cuda:0'))\n",
      "     | > current_lr: 1.1e-05 \n",
      "     | > step_time: 0.2798  (0.4939001003901164)\n",
      "     | > loader_time: 0.0042  (0.005105813344319661)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:52:23 -- STEP: 31/406 -- GLOBAL_STEP: 40625\u001b[0m\n",
      "     | > loss: -0.0635267049074173  (-0.06975655546111446)\n",
      "     | > log_mle: -0.23993957042694092  (-0.24870973633181664)\n",
      "     | > loss_dur: 0.17641286551952362  (0.1789531808707022)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(22.0433, device='cuda:0')  (tensor(16.5813, device='cuda:0'))\n",
      "     | > current_lr: 1.1e-05 \n",
      "     | > step_time: 0.6754  (0.5477253390896705)\n",
      "     | > loader_time: 0.0041  (0.009026750441520445)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:52:41 -- STEP: 56/406 -- GLOBAL_STEP: 40650\u001b[0m\n",
      "     | > loss: -0.06661328673362732  (-0.06548916495272093)\n",
      "     | > log_mle: -0.25579798221588135  (-0.24955507900033677)\n",
      "     | > loss_dur: 0.18918469548225403  (0.18406591404761588)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(31.7880, device='cuda:0')  (tensor(16.5259, device='cuda:0'))\n",
      "     | > current_lr: 1.1e-05 \n",
      "     | > step_time: 0.9647  (0.6222379718508039)\n",
      "     | > loader_time: 0.0168  (0.009866982698440553)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:52:59 -- STEP: 81/406 -- GLOBAL_STEP: 40675\u001b[0m\n",
      "     | > loss: -0.08062100410461426  (-0.06353211384496574)\n",
      "     | > log_mle: -0.26432645320892334  (-0.2516879476146933)\n",
      "     | > loss_dur: 0.18370544910430908  (0.18815583376972767)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(14.8257, device='cuda:0')  (tensor(17.7434, device='cuda:0'))\n",
      "     | > current_lr: 1.1e-05 \n",
      "     | > step_time: 1.0294  (0.6491936636559758)\n",
      "     | > loader_time: 0.0111  (0.010361256422819914)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:53:18 -- STEP: 106/406 -- GLOBAL_STEP: 40700\u001b[0m\n",
      "     | > loss: -0.061215177178382874  (-0.06307832685843957)\n",
      "     | > log_mle: -0.2510840892791748  (-0.25452508229129717)\n",
      "     | > loss_dur: 0.18986891210079193  (0.19144675543285766)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(41.4211, device='cuda:0')  (tensor(19.4105, device='cuda:0'))\n",
      "     | > current_lr: 1.1e-05 \n",
      "     | > step_time: 0.6657  (0.6699394077624916)\n",
      "     | > loader_time: 0.0153  (0.011414284976023549)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:53:37 -- STEP: 131/406 -- GLOBAL_STEP: 40725\u001b[0m\n",
      "     | > loss: -0.08168366551399231  (-0.06308280352417754)\n",
      "     | > log_mle: -0.2662292718887329  (-0.2569376639737428)\n",
      "     | > loss_dur: 0.1845456063747406  (0.19385486044956526)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(19.8699, device='cuda:0')  (tensor(19.0335, device='cuda:0'))\n",
      "     | > current_lr: 1.1e-05 \n",
      "     | > step_time: 0.7414  (0.6789974147126876)\n",
      "     | > loader_time: 0.0052  (0.011460893936739623)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:53:56 -- STEP: 156/406 -- GLOBAL_STEP: 40750\u001b[0m\n",
      "     | > loss: -0.0493757426738739  (-0.061700891894407806)\n",
      "     | > log_mle: -0.2726172208786011  (-0.2585830122996599)\n",
      "     | > loss_dur: 0.22324147820472717  (0.19688212040525213)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(39.8205, device='cuda:0')  (tensor(19.2970, device='cuda:0'))\n",
      "     | > current_lr: 1.1e-05 \n",
      "     | > step_time: 0.5868  (0.69166082296616)\n",
      "     | > loader_time: 0.0124  (0.011679415519420918)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:54:14 -- STEP: 181/406 -- GLOBAL_STEP: 40775\u001b[0m\n",
      "     | > loss: -0.04047758877277374  (-0.061592951169988766)\n",
      "     | > log_mle: -0.26883983612060547  (-0.26008224092135773)\n",
      "     | > loss_dur: 0.22836224734783173  (0.19848928975136898)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(35.4399, device='cuda:0')  (tensor(20.4868, device='cuda:0'))\n",
      "     | > current_lr: 1.1e-05 \n",
      "     | > step_time: 0.8695  (0.6950241584145563)\n",
      "     | > loader_time: 0.0128  (0.012105976020433626)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:54:33 -- STEP: 206/406 -- GLOBAL_STEP: 40800\u001b[0m\n",
      "     | > loss: -0.05676142871379852  (-0.06145009579299727)\n",
      "     | > log_mle: -0.2683495283126831  (-0.26149770009864887)\n",
      "     | > loss_dur: 0.21158809959888458  (0.20004760430565158)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(21.2391, device='cuda:0')  (tensor(21.1325, device='cuda:0'))\n",
      "     | > current_lr: 1.1e-05 \n",
      "     | > step_time: 0.7277  (0.6987437380170359)\n",
      "     | > loader_time: 0.015  (0.012481621168192151)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:54:52 -- STEP: 231/406 -- GLOBAL_STEP: 40825\u001b[0m\n",
      "     | > loss: -0.05630888044834137  (-0.0617054780195286)\n",
      "     | > log_mle: -0.2841954231262207  (-0.26295792230796)\n",
      "     | > loss_dur: 0.22788654267787933  (0.2012524442884313)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(29.8608, device='cuda:0')  (tensor(21.9341, device='cuda:0'))\n",
      "     | > current_lr: 1.1e-05 \n",
      "     | > step_time: 0.5689  (0.7036082703313786)\n",
      "     | > loader_time: 0.0095  (0.012701379272328827)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:55:10 -- STEP: 256/406 -- GLOBAL_STEP: 40850\u001b[0m\n",
      "     | > loss: -0.06304112076759338  (-0.06190851278370249)\n",
      "     | > log_mle: -0.2768065929412842  (-0.2642334210686387)\n",
      "     | > loss_dur: 0.2137654721736908  (0.2023249082849361)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(35.6742, device='cuda:0')  (tensor(22.6806, device='cuda:0'))\n",
      "     | > current_lr: 1.1e-05 \n",
      "     | > step_time: 0.5591  (0.7021653428673744)\n",
      "     | > loader_time: 0.0399  (0.012676487676799297)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:55:29 -- STEP: 281/406 -- GLOBAL_STEP: 40875\u001b[0m\n",
      "     | > loss: -0.08320960402488708  (-0.06224838371166558)\n",
      "     | > log_mle: -0.28040337562561035  (-0.26528682657832364)\n",
      "     | > loss_dur: 0.19719377160072327  (0.20303844286665795)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(37.5467, device='cuda:0')  (tensor(23.1764, device='cuda:0'))\n",
      "     | > current_lr: 1.1e-05 \n",
      "     | > step_time: 0.7957  (0.7060168561562101)\n",
      "     | > loader_time: 0.0219  (0.012898283072637922)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:55:48 -- STEP: 306/406 -- GLOBAL_STEP: 40900\u001b[0m\n",
      "     | > loss: -0.044672220945358276  (-0.06232291348035042)\n",
      "     | > log_mle: -0.2690427303314209  (-0.2661802710271351)\n",
      "     | > loss_dur: 0.22437050938606262  (0.20385735754678444)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(8.0102, device='cuda:0')  (tensor(23.4043, device='cuda:0'))\n",
      "     | > current_lr: 1.1e-05 \n",
      "     | > step_time: 0.6435  (0.7087651662577211)\n",
      "     | > loader_time: 0.0277  (0.013168558575748624)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:56:07 -- STEP: 331/406 -- GLOBAL_STEP: 40925\u001b[0m\n",
      "     | > loss: -0.05462370812892914  (-0.06229711029104598)\n",
      "     | > log_mle: -0.2715038061141968  (-0.2668214539386715)\n",
      "     | > loss_dur: 0.21688009798526764  (0.20452434364762542)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(36.2686, device='cuda:0')  (tensor(23.7313, device='cuda:0'))\n",
      "     | > current_lr: 1.1e-05 \n",
      "     | > step_time: 0.5502  (0.7118729298928712)\n",
      "     | > loader_time: 0.0072  (0.013073678463247253)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:56:27 -- STEP: 356/406 -- GLOBAL_STEP: 40950\u001b[0m\n",
      "     | > loss: -0.05492164194583893  (-0.06209763315286531)\n",
      "     | > log_mle: -0.2857513427734375  (-0.2676553773076349)\n",
      "     | > loss_dur: 0.23082970082759857  (0.2055577441547693)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(20.4111, device='cuda:0')  (tensor(24.0332, device='cuda:0'))\n",
      "     | > current_lr: 1.1e-05 \n",
      "     | > step_time: 0.7119  (0.7169524203525498)\n",
      "     | > loader_time: 0.011  (0.013426880488234965)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:56:48 -- STEP: 381/406 -- GLOBAL_STEP: 40975\u001b[0m\n",
      "     | > loss: -0.048026397824287415  (-0.06234436914363873)\n",
      "     | > log_mle: -0.2672208547592163  (-0.2684732875798946)\n",
      "     | > loss_dur: 0.2191944569349289  (0.20612891843625558)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(11.9339, device='cuda:0')  (tensor(24.2645, device='cuda:0'))\n",
      "     | > current_lr: 1.1e-05 \n",
      "     | > step_time: 1.1055  (0.7233680577415804)\n",
      "     | > loader_time: 0.0289  (0.013505396880502781)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: -0.04694060981273651  (-0.04694060981273651)\n",
      "     | > log_mle: -0.25260305404663086  (-0.25260305404663086)\n",
      "     | > loss_dur: 0.20566244423389435  (0.20566244423389435)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: -0.13458392024040222  (-0.13458392024040222)\n",
      "     | > log_mle: -0.29213619232177734  (-0.29213619232177734)\n",
      "     | > loss_dur: 0.15755227208137512  (0.15755227208137512)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: -0.08721256256103516  (-0.11089824140071869)\n",
      "     | > log_mle: -0.2527773380279541  (-0.2724567651748657)\n",
      "     | > loss_dur: 0.16556477546691895  (0.16155852377414703)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: -0.08024293184280396  (-0.10067980488141377)\n",
      "     | > log_mle: -0.26605892181396484  (-0.2703241507212321)\n",
      "     | > loss_dur: 0.1858159899711609  (0.16964434583981833)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: -0.11057254672050476  (-0.10315299034118652)\n",
      "     | > log_mle: -0.2927039861679077  (-0.275919109582901)\n",
      "     | > loss_dur: 0.18213143944740295  (0.17276611924171448)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: -0.10815834999084473  (-0.10415406227111816)\n",
      "     | > log_mle: -0.2903635501861572  (-0.27880799770355225)\n",
      "     | > loss_dur: 0.1822052001953125  (0.17465393543243407)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: -0.07247710227966309  (-0.09887456893920898)\n",
      "     | > log_mle: -0.2997128963470459  (-0.28229214747746784)\n",
      "     | > loss_dur: 0.2272357940673828  (0.18341757853825888)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: -0.09059974551200867  (-0.09769245130675179)\n",
      "     | > log_mle: -0.26355791091918945  (-0.27961582796914236)\n",
      "     | > loss_dur: 0.1729581654071808  (0.18192337666239058)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: -0.10056906938552856  (-0.09805202856659889)\n",
      "     | > log_mle: -0.27588415145874023  (-0.2791493684053421)\n",
      "     | > loss_dur: 0.17531508207321167  (0.1810973398387432)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: -0.07750950753688812  (-0.09576952622996436)\n",
      "     | > log_mle: -0.2878382205963135  (-0.2801147964265611)\n",
      "     | > loss_dur: 0.21032871305942535  (0.18434527019659677)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: -0.0653826892375946  (-0.09273084253072739)\n",
      "     | > log_mle: -0.273262619972229  (-0.27942957878112795)\n",
      "     | > loss_dur: 0.2078799307346344  (0.18669873625040054)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: -0.08759325742721558  (-0.09226378933949904)\n",
      "     | > log_mle: -0.29036688804626465  (-0.2804238796234131)\n",
      "     | > loss_dur: 0.20277363061904907  (0.18816009028391403)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: -0.09942372143268585  (-0.0928604503472646)\n",
      "     | > log_mle: -0.27749407291412354  (-0.2801797290643056)\n",
      "     | > loss_dur: 0.17807035148143768  (0.18731927871704102)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: -0.11690549552440643  (-0.09471006920704475)\n",
      "     | > log_mle: -0.29630815982818604  (-0.28142037758460414)\n",
      "     | > loss_dur: 0.1794026643037796  (0.18671030837755936)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: -0.09045335650444031  (-0.09440601829971586)\n",
      "     | > log_mle: -0.28865325450897217  (-0.28193701165063045)\n",
      "     | > loss_dur: 0.19819989800453186  (0.18753099335091455)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: -0.0837637186050415  (-0.09369653165340423)\n",
      "     | > log_mle: -0.28199636936187744  (-0.28194096883138026)\n",
      "     | > loss_dur: 0.19823265075683594  (0.18824443717797598)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: -0.07818993926048279  (-0.09272736962884665)\n",
      "     | > log_mle: -0.28147685527801514  (-0.28191196173429495)\n",
      "     | > loss_dur: 0.20328691601753235  (0.18918459210544825)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: audio amplitude out of range, auto clipped.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[91m 0.0033174902200698853 \u001b[0m(+0.0004502832889556885)\n",
      "     | > avg_loss:\u001b[92m -0.09272736962884665 \u001b[0m(-0.004147755913436413)\n",
      "     | > avg_log_mle:\u001b[92m -0.28191196173429495 \u001b[0m(-0.0021446421742439825)\n",
      "     | > avg_loss_dur:\u001b[92m 0.18918459210544825 \u001b[0m(-0.002003113739192486)\n",
      "\n",
      " > BEST MODEL : train/run-February-22-2025_10+59PM-fa84af3/best_model_41000.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 45/100\u001b[0m\n",
      " --> train/run-February-22-2025_10+59PM-fa84af3\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-23 02:57:21) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:57:22 -- STEP: 0/406 -- GLOBAL_STEP: 41000\u001b[0m\n",
      "     | > loss: -0.08463898301124573  (-0.08463898301124573)\n",
      "     | > log_mle: -0.24691283702850342  (-0.24691283702850342)\n",
      "     | > loss_dur: 0.1622738540172577  (0.1622738540172577)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(5.3383, device='cuda:0')  (tensor(5.3383, device='cuda:0'))\n",
      "     | > current_lr: 1.125e-05 \n",
      "     | > step_time: 0.7957  (0.795668363571167)\n",
      "     | > loader_time: 0.9685  (0.9685251712799072)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:57:35 -- STEP: 25/406 -- GLOBAL_STEP: 41025\u001b[0m\n",
      "     | > loss: -0.06385849416255951  (-0.07387305200099946)\n",
      "     | > log_mle: -0.25505363941192627  (-0.2500363874435425)\n",
      "     | > loss_dur: 0.19119514524936676  (0.17616333544254303)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(21.9208, device='cuda:0')  (tensor(16.0735, device='cuda:0'))\n",
      "     | > current_lr: 1.125e-05 \n",
      "     | > step_time: 0.4287  (0.4921326732635498)\n",
      "     | > loader_time: 0.0042  (0.007978134155273438)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:57:50 -- STEP: 50/406 -- GLOBAL_STEP: 41050\u001b[0m\n",
      "     | > loss: -0.06833481788635254  (-0.06777703136205672)\n",
      "     | > log_mle: -0.27860379219055176  (-0.25007959842681887)\n",
      "     | > loss_dur: 0.21026897430419922  (0.1823025670647621)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(26.1656, device='cuda:0')  (tensor(19.4831, device='cuda:0'))\n",
      "     | > current_lr: 1.125e-05 \n",
      "     | > step_time: 0.7426  (0.5334421253204344)\n",
      "     | > loader_time: 0.004  (0.009045972824096679)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:58:05 -- STEP: 75/406 -- GLOBAL_STEP: 41075\u001b[0m\n",
      "     | > loss: -0.07035566866397858  (-0.06632921636104584)\n",
      "     | > log_mle: -0.2627248764038086  (-0.25279630819956467)\n",
      "     | > loss_dur: 0.19236920773983002  (0.18646709183851878)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(36.6323, device='cuda:0')  (tensor(20.0028, device='cuda:0'))\n",
      "     | > current_lr: 1.125e-05 \n",
      "     | > step_time: 0.4243  (0.5546930090586343)\n",
      "     | > loader_time: 0.0058  (0.009717419942220055)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:58:20 -- STEP: 100/406 -- GLOBAL_STEP: 41100\u001b[0m\n",
      "     | > loss: -0.05361810326576233  (-0.06459955677390102)\n",
      "     | > log_mle: -0.26730167865753174  (-0.2553120172023774)\n",
      "     | > loss_dur: 0.2136835753917694  (0.19071246042847634)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(20.6979, device='cuda:0')  (tensor(20.6545, device='cuda:0'))\n",
      "     | > current_lr: 1.125e-05 \n",
      "     | > step_time: 0.6941  (0.5651268601417541)\n",
      "     | > loader_time: 0.006  (0.01018211126327515)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:58:37 -- STEP: 125/406 -- GLOBAL_STEP: 41125\u001b[0m\n",
      "     | > loss: -0.0599450021982193  (-0.06500275695323944)\n",
      "     | > log_mle: -0.27534544467926025  (-0.25812769412994385)\n",
      "     | > loss_dur: 0.21540044248104095  (0.1931249371767044)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(32.9039, device='cuda:0')  (tensor(21.3531, device='cuda:0'))\n",
      "     | > current_lr: 1.125e-05 \n",
      "     | > step_time: 0.3827  (0.5791675815582276)\n",
      "     | > loader_time: 0.0048  (0.010133573532104496)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:58:53 -- STEP: 150/406 -- GLOBAL_STEP: 41150\u001b[0m\n",
      "     | > loss: -0.06898705661296844  (-0.06464613089958826)\n",
      "     | > log_mle: -0.2681417465209961  (-0.26020482301712033)\n",
      "     | > loss_dur: 0.19915468990802765  (0.1955586921175321)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(21.5788, device='cuda:0')  (tensor(21.7958, device='cuda:0'))\n",
      "     | > current_lr: 1.125e-05 \n",
      "     | > step_time: 0.7775  (0.5886999924977621)\n",
      "     | > loader_time: 0.005  (0.01076452414194743)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:59:09 -- STEP: 175/406 -- GLOBAL_STEP: 41175\u001b[0m\n",
      "     | > loss: -0.07849745452404022  (-0.06424326130322047)\n",
      "     | > log_mle: -0.27397942543029785  (-0.26161021845681315)\n",
      "     | > loss_dur: 0.19548197090625763  (0.1973669571535928)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(40.6810, device='cuda:0')  (tensor(21.7339, device='cuda:0'))\n",
      "     | > current_lr: 1.125e-05 \n",
      "     | > step_time: 0.657  (0.5955287061418806)\n",
      "     | > loader_time: 0.0046  (0.010877101080758235)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:59:27 -- STEP: 200/406 -- GLOBAL_STEP: 41200\u001b[0m\n",
      "     | > loss: -0.061048731207847595  (-0.06406229570508006)\n",
      "     | > log_mle: -0.27279889583587646  (-0.2630737406015395)\n",
      "     | > loss_dur: 0.21175016462802887  (0.19901144489645958)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(29.2952, device='cuda:0')  (tensor(22.0359, device='cuda:0'))\n",
      "     | > current_lr: 1.125e-05 \n",
      "     | > step_time: 0.543  (0.607257010936737)\n",
      "     | > loader_time: 0.0294  (0.011317534446716314)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 02:59:44 -- STEP: 225/406 -- GLOBAL_STEP: 41225\u001b[0m\n",
      "     | > loss: -0.06479781866073608  (-0.06427037868234849)\n",
      "     | > log_mle: -0.27563178539276123  (-0.26446111308203796)\n",
      "     | > loss_dur: 0.21083396673202515  (0.20019073439968957)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(39.4090, device='cuda:0')  (tensor(22.8790, device='cuda:0'))\n",
      "     | > current_lr: 1.125e-05 \n",
      "     | > step_time: 0.6724  (0.6133901341756185)\n",
      "     | > loader_time: 0.015  (0.011627207862006297)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:00:02 -- STEP: 250/406 -- GLOBAL_STEP: 41250\u001b[0m\n",
      "     | > loss: -0.08256113529205322  (-0.0643365925550461)\n",
      "     | > log_mle: -0.28812944889068604  (-0.2658091855049133)\n",
      "     | > loss_dur: 0.2055683135986328  (0.20147259294986725)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(35.6496, device='cuda:0')  (tensor(23.4739, device='cuda:0'))\n",
      "     | > current_lr: 1.125e-05 \n",
      "     | > step_time: 0.6794  (0.6205132026672363)\n",
      "     | > loader_time: 0.0057  (0.011736813545227055)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:00:20 -- STEP: 275/406 -- GLOBAL_STEP: 41275\u001b[0m\n",
      "     | > loss: -0.060659751296043396  (-0.06486216052012014)\n",
      "     | > log_mle: -0.27235639095306396  (-0.2669785915721546)\n",
      "     | > loss_dur: 0.21169663965702057  (0.20211643105203456)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(28.4795, device='cuda:0')  (tensor(24.0609, device='cuda:0'))\n",
      "     | > current_lr: 1.125e-05 \n",
      "     | > step_time: 0.8173  (0.6284586412256413)\n",
      "     | > loader_time: 0.0137  (0.012336211638017135)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:00:39 -- STEP: 300/406 -- GLOBAL_STEP: 41300\u001b[0m\n",
      "     | > loss: -0.05567392706871033  (-0.06490088855226843)\n",
      "     | > log_mle: -0.2632042169570923  (-0.2677890157699586)\n",
      "     | > loss_dur: 0.20753028988838196  (0.2028881272176902)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(25.6983, device='cuda:0')  (tensor(24.2754, device='cuda:0'))\n",
      "     | > current_lr: 1.125e-05 \n",
      "     | > step_time: 0.5143  (0.638615789413452)\n",
      "     | > loader_time: 0.0069  (0.01269835631052653)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:00:59 -- STEP: 325/406 -- GLOBAL_STEP: 41325\u001b[0m\n",
      "     | > loss: -0.06146113574504852  (-0.06498621330811435)\n",
      "     | > log_mle: -0.2667083740234375  (-0.2685864521906926)\n",
      "     | > loss_dur: 0.20524723827838898  (0.2036002388825784)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(44.5059, device='cuda:0')  (tensor(24.6476, device='cuda:0'))\n",
      "     | > current_lr: 1.125e-05 \n",
      "     | > step_time: 0.8399  (0.6477793260721059)\n",
      "     | > loader_time: 0.0059  (0.0127812070112962)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:01:18 -- STEP: 350/406 -- GLOBAL_STEP: 41350\u001b[0m\n",
      "     | > loss: -0.06668795645236969  (-0.06465010481221346)\n",
      "     | > log_mle: -0.28357887268066406  (-0.2691898604801723)\n",
      "     | > loss_dur: 0.21689091622829437  (0.20453975566795898)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(39.8684, device='cuda:0')  (tensor(24.6568, device='cuda:0'))\n",
      "     | > current_lr: 1.125e-05 \n",
      "     | > step_time: 0.5232  (0.6562938152040751)\n",
      "     | > loader_time: 0.0063  (0.01316483838217599)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:01:38 -- STEP: 375/406 -- GLOBAL_STEP: 41375\u001b[0m\n",
      "     | > loss: -0.08054277300834656  (-0.06484523860613514)\n",
      "     | > log_mle: -0.28936707973480225  (-0.2700768175125122)\n",
      "     | > loss_dur: 0.2088243067264557  (0.2052315789063772)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(25.3546, device='cuda:0')  (tensor(25.0791, device='cuda:0'))\n",
      "     | > current_lr: 1.125e-05 \n",
      "     | > step_time: 0.6598  (0.6649677270253497)\n",
      "     | > loader_time: 0.0067  (0.013285751342773438)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:01:58 -- STEP: 400/406 -- GLOBAL_STEP: 41400\u001b[0m\n",
      "     | > loss: -0.05384628474712372  (-0.06500406578183188)\n",
      "     | > log_mle: -0.28412961959838867  (-0.27086942136287695)\n",
      "     | > loss_dur: 0.23028333485126495  (0.20586535558104518)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(19.1982, device='cuda:0')  (tensor(25.2547, device='cuda:0'))\n",
      "     | > current_lr: 1.125e-05 \n",
      "     | > step_time: 0.6558  (0.6703208535909649)\n",
      "     | > loader_time: 0.0065  (0.01332690417766571)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: -0.046189382672309875  (-0.046189382672309875)\n",
      "     | > log_mle: -0.25090503692626953  (-0.25090503692626953)\n",
      "     | > loss_dur: 0.20471565425395966  (0.20471565425395966)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: -0.1247597187757492  (-0.1247597187757492)\n",
      "     | > log_mle: -0.2870725393295288  (-0.2870725393295288)\n",
      "     | > loss_dur: 0.1623128205537796  (0.1623128205537796)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: -0.08833238482475281  (-0.10654605180025101)\n",
      "     | > log_mle: -0.25124263763427734  (-0.2691575884819031)\n",
      "     | > loss_dur: 0.16291025280952454  (0.16261153668165207)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: -0.07775576412677765  (-0.09694928924242656)\n",
      "     | > log_mle: -0.26071465015411377  (-0.2663432757059733)\n",
      "     | > loss_dur: 0.18295888602733612  (0.16939398646354675)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: -0.08852750062942505  (-0.09484384208917618)\n",
      "     | > log_mle: -0.2847331762313843  (-0.27094075083732605)\n",
      "     | > loss_dur: 0.19620567560195923  (0.17609690874814987)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: -0.10249589383602142  (-0.09637425243854522)\n",
      "     | > log_mle: -0.2798473834991455  (-0.27272207736968995)\n",
      "     | > loss_dur: 0.17735148966312408  (0.1763478249311447)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: -0.04269032180309296  (-0.08742693066596985)\n",
      "     | > log_mle: -0.28731393814086914  (-0.2751540541648865)\n",
      "     | > loss_dur: 0.24462361633777618  (0.18772712349891663)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: -0.08757056295871735  (-0.08744744956493378)\n",
      "     | > log_mle: -0.2578643560409546  (-0.27268409729003906)\n",
      "     | > loss_dur: 0.17029379308223724  (0.18523664772510529)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: -0.09485547244548798  (-0.08837345242500305)\n",
      "     | > log_mle: -0.2694283723831177  (-0.2722771316766739)\n",
      "     | > loss_dur: 0.1745728999376297  (0.18390367925167084)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: -0.06733429431915283  (-0.0860357681910197)\n",
      "     | > log_mle: -0.27887630462646484  (-0.27301037311553955)\n",
      "     | > loss_dur: 0.211542010307312  (0.18697460492451987)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: -0.054819077253341675  (-0.08291409909725189)\n",
      "     | > log_mle: -0.26737964153289795  (-0.2724472999572754)\n",
      "     | > loss_dur: 0.21256056427955627  (0.1895332008600235)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: -0.07692991197109222  (-0.08237008208578284)\n",
      "     | > log_mle: -0.2825812101364136  (-0.2733685645190152)\n",
      "     | > loss_dur: 0.20565129816532135  (0.1909984824332324)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: -0.09066514670848846  (-0.0830613374710083)\n",
      "     | > log_mle: -0.2728595733642578  (-0.2733261485894521)\n",
      "     | > loss_dur: 0.18219442665576935  (0.19026481111844382)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: -0.11036588251590729  (-0.08516168708984669)\n",
      "     | > log_mle: -0.2889416217803955  (-0.2745273388349093)\n",
      "     | > loss_dur: 0.17857573926448822  (0.18936565174506262)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: -0.07306696474552155  (-0.08429777835096632)\n",
      "     | > log_mle: -0.28106093406677246  (-0.27499402420861385)\n",
      "     | > loss_dur: 0.20799396932125092  (0.1906962458576475)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: -0.08092133700847626  (-0.08407268226146698)\n",
      "     | > log_mle: -0.2755141258239746  (-0.27502869764963794)\n",
      "     | > loss_dur: 0.19459278881549835  (0.1909560153881709)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: -0.06957577168941498  (-0.08316662535071373)\n",
      "     | > log_mle: -0.27524685859680176  (-0.27504233270883566)\n",
      "     | > loss_dur: 0.20567108690738678  (0.19187570735812187)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: audio amplitude out of range, auto clipped.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.002970770001411438 \u001b[0m(-0.00034672021865844727)\n",
      "     | > avg_loss:\u001b[91m -0.08316662535071373 \u001b[0m(+0.009560744278132915)\n",
      "     | > avg_log_mle:\u001b[91m -0.27504233270883566 \u001b[0m(+0.0068696290254592896)\n",
      "     | > avg_loss_dur:\u001b[91m 0.19187570735812187 \u001b[0m(+0.002691115252673626)\n",
      "\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 46/100\u001b[0m\n",
      " --> train/run-February-22-2025_10+59PM-fa84af3\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-23 03:02:15) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:02:26 -- STEP: 19/406 -- GLOBAL_STEP: 41425\u001b[0m\n",
      "     | > loss: -0.0822472870349884  (-0.0805565008991643)\n",
      "     | > log_mle: -0.23939871788024902  (-0.2540744103883442)\n",
      "     | > loss_dur: 0.15715143084526062  (0.17351790948917992)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(11.7295, device='cuda:0')  (tensor(17.0156, device='cuda:0'))\n",
      "     | > current_lr: 1.15e-05 \n",
      "     | > step_time: 0.3691  (0.4618287964871055)\n",
      "     | > loader_time: 0.0047  (0.006894701405575401)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:02:41 -- STEP: 44/406 -- GLOBAL_STEP: 41450\u001b[0m\n",
      "     | > loss: -0.04565887153148651  (-0.07294912737878886)\n",
      "     | > log_mle: -0.2563910484313965  (-0.2522981573234904)\n",
      "     | > loss_dur: 0.21073217689990997  (0.17934902994470162)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(18.3134, device='cuda:0')  (tensor(16.4703, device='cuda:0'))\n",
      "     | > current_lr: 1.15e-05 \n",
      "     | > step_time: 0.4452  (0.5182692896236073)\n",
      "     | > loader_time: 0.0045  (0.009345694021745163)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:02:56 -- STEP: 69/406 -- GLOBAL_STEP: 41475\u001b[0m\n",
      "     | > loss: -0.055584266781806946  (-0.06954277425572494)\n",
      "     | > log_mle: -0.2654848098754883  (-0.25489714871282143)\n",
      "     | > loss_dur: 0.20990054309368134  (0.1853543744570967)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(22.7231, device='cuda:0')  (tensor(17.8580, device='cuda:0'))\n",
      "     | > current_lr: 1.15e-05 \n",
      "     | > step_time: 0.7333  (0.5529203553130662)\n",
      "     | > loader_time: 0.0191  (0.009590114372363989)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:03:12 -- STEP: 94/406 -- GLOBAL_STEP: 41500\u001b[0m\n",
      "     | > loss: -0.06880758702754974  (-0.06889361380896675)\n",
      "     | > log_mle: -0.26748740673065186  (-0.2581297691832196)\n",
      "     | > loss_dur: 0.1986798197031021  (0.18923615537425312)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(24.7436, device='cuda:0')  (tensor(19.0282, device='cuda:0'))\n",
      "     | > current_lr: 1.15e-05 \n",
      "     | > step_time: 0.689  (0.5655863868429306)\n",
      "     | > loader_time: 0.005  (0.009663513366212234)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:03:28 -- STEP: 119/406 -- GLOBAL_STEP: 41525\u001b[0m\n",
      "     | > loss: -0.07865491509437561  (-0.06859439461171132)\n",
      "     | > log_mle: -0.28010499477386475  (-0.26055975421136157)\n",
      "     | > loss_dur: 0.20145007967948914  (0.19196535959965047)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(20.3629, device='cuda:0')  (tensor(19.6224, device='cuda:0'))\n",
      "     | > current_lr: 1.15e-05 \n",
      "     | > step_time: 0.5994  (0.5780136184532101)\n",
      "     | > loader_time: 0.0211  (0.010032024704107717)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:03:44 -- STEP: 144/406 -- GLOBAL_STEP: 41550\u001b[0m\n",
      "     | > loss: -0.0692492127418518  (-0.06832607442306153)\n",
      "     | > log_mle: -0.2712513208389282  (-0.2626794096496369)\n",
      "     | > loss_dur: 0.20200210809707642  (0.19435333522657558)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(21.4528, device='cuda:0')  (tensor(19.9160, device='cuda:0'))\n",
      "     | > current_lr: 1.15e-05 \n",
      "     | > step_time: 0.7472  (0.587078501780828)\n",
      "     | > loader_time: 0.0125  (0.010409497552447848)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:04:00 -- STEP: 169/406 -- GLOBAL_STEP: 41575\u001b[0m\n",
      "     | > loss: -0.06804271042346954  (-0.06752776535305051)\n",
      "     | > log_mle: -0.27563023567199707  (-0.26402787555604296)\n",
      "     | > loss_dur: 0.20758752524852753  (0.19650011020299246)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(32.7242, device='cuda:0')  (tensor(21.1820, device='cuda:0'))\n",
      "     | > current_lr: 1.15e-05 \n",
      "     | > step_time: 0.649  (0.5943865451587025)\n",
      "     | > loader_time: 0.0057  (0.010451721721852316)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:04:17 -- STEP: 194/406 -- GLOBAL_STEP: 41600\u001b[0m\n",
      "     | > loss: -0.05904604494571686  (-0.06772136987791849)\n",
      "     | > log_mle: -0.275349497795105  (-0.26554850757736526)\n",
      "     | > loss_dur: 0.21630345284938812  (0.19782713769944674)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(19.8939, device='cuda:0')  (tensor(21.8472, device='cuda:0'))\n",
      "     | > current_lr: 1.15e-05 \n",
      "     | > step_time: 0.419  (0.5999836823374955)\n",
      "     | > loader_time: 0.0047  (0.01099453021570579)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:04:34 -- STEP: 219/406 -- GLOBAL_STEP: 41625\u001b[0m\n",
      "     | > loss: -0.08116042613983154  (-0.06780526960549292)\n",
      "     | > log_mle: -0.2751353979110718  (-0.26668032554730975)\n",
      "     | > loss_dur: 0.19397497177124023  (0.19887505594181687)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(19.2977, device='cuda:0')  (tensor(22.5948, device='cuda:0'))\n",
      "     | > current_lr: 1.15e-05 \n",
      "     | > step_time: 0.6985  (0.6087046126796775)\n",
      "     | > loader_time: 0.0079  (0.0111349848307431)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:04:52 -- STEP: 244/406 -- GLOBAL_STEP: 41650\u001b[0m\n",
      "     | > loss: -0.07336175441741943  (-0.06748823229162422)\n",
      "     | > log_mle: -0.2784101963043213  (-0.2679337009054716)\n",
      "     | > loss_dur: 0.20504844188690186  (0.20044546861384735)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(29.9805, device='cuda:0')  (tensor(22.5996, device='cuda:0'))\n",
      "     | > current_lr: 1.15e-05 \n",
      "     | > step_time: 0.5033  (0.6159337133657737)\n",
      "     | > loader_time: 0.0112  (0.011276450313505578)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:05:10 -- STEP: 269/406 -- GLOBAL_STEP: 41675\u001b[0m\n",
      "     | > loss: -0.07260145246982574  (-0.06769830005098013)\n",
      "     | > log_mle: -0.27701783180236816  (-0.2687830490693727)\n",
      "     | > loss_dur: 0.20441637933254242  (0.20108474901839263)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(56.9924, device='cuda:0')  (tensor(23.8563, device='cuda:0'))\n",
      "     | > current_lr: 1.15e-05 \n",
      "     | > step_time: 0.9179  (0.6268648879678719)\n",
      "     | > loader_time: 0.0234  (0.011593376393654974)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:05:30 -- STEP: 294/406 -- GLOBAL_STEP: 41700\u001b[0m\n",
      "     | > loss: -0.06829459965229034  (-0.06784903445616874)\n",
      "     | > log_mle: -0.2846485376358032  (-0.2696405511324099)\n",
      "     | > loss_dur: 0.21635393798351288  (0.20179151667624107)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(28.2692, device='cuda:0')  (tensor(24.1794, device='cuda:0'))\n",
      "     | > current_lr: 1.15e-05 \n",
      "     | > step_time: 0.7968  (0.6381211515997542)\n",
      "     | > loader_time: 0.0055  (0.012026695167126305)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:05:48 -- STEP: 319/406 -- GLOBAL_STEP: 41725\u001b[0m\n",
      "     | > loss: -0.06469851732254028  (-0.06785148461597469)\n",
      "     | > log_mle: -0.2790154218673706  (-0.27044065058418226)\n",
      "     | > loss_dur: 0.21431690454483032  (0.20258916596820736)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(35.6067, device='cuda:0')  (tensor(24.3410, device='cuda:0'))\n",
      "     | > current_lr: 1.15e-05 \n",
      "     | > step_time: 0.5694  (0.6439040910487636)\n",
      "     | > loader_time: 0.01  (0.012132352422397344)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:06:08 -- STEP: 344/406 -- GLOBAL_STEP: 41750\u001b[0m\n",
      "     | > loss: -0.06332039833068848  (-0.06774992643054145)\n",
      "     | > log_mle: -0.27176809310913086  (-0.2711218876201056)\n",
      "     | > loss_dur: 0.20844769477844238  (0.20337196118956388)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(25.8998, device='cuda:0')  (tensor(24.6842, device='cuda:0'))\n",
      "     | > current_lr: 1.15e-05 \n",
      "     | > step_time: 0.6566  (0.6532895017501914)\n",
      "     | > loader_time: 0.0066  (0.01251098097756852)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:06:29 -- STEP: 369/406 -- GLOBAL_STEP: 41775\u001b[0m\n",
      "     | > loss: -0.06996458768844604  (-0.06786026763237588)\n",
      "     | > log_mle: -0.2798032760620117  (-0.2719941051994886)\n",
      "     | > loss_dur: 0.20983868837356567  (0.20413383756711231)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(31.6294, device='cuda:0')  (tensor(24.9093, device='cuda:0'))\n",
      "     | > current_lr: 1.15e-05 \n",
      "     | > step_time: 0.7963  (0.6633791936445359)\n",
      "     | > loader_time: 0.0196  (0.012693964691989149)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:06:49 -- STEP: 394/406 -- GLOBAL_STEP: 41800\u001b[0m\n",
      "     | > loss: -0.0715644359588623  (-0.06802458418202277)\n",
      "     | > log_mle: -0.2850000858306885  (-0.27277143473552595)\n",
      "     | > loss_dur: 0.21343564987182617  (0.2047468505535029)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(24.6266, device='cuda:0')  (tensor(25.0606, device='cuda:0'))\n",
      "     | > current_lr: 1.15e-05 \n",
      "     | > step_time: 0.5298  (0.6720622572196916)\n",
      "     | > loader_time: 0.0059  (0.012788495436537694)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: -0.049823760986328125  (-0.049823760986328125)\n",
      "     | > log_mle: -0.25629281997680664  (-0.25629281997680664)\n",
      "     | > loss_dur: 0.20646905899047852  (0.20646905899047852)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: -0.1325438916683197  (-0.1325438916683197)\n",
      "     | > log_mle: -0.2957296371459961  (-0.2957296371459961)\n",
      "     | > loss_dur: 0.1631857454776764  (0.1631857454776764)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: -0.09539242088794708  (-0.11396815627813339)\n",
      "     | > log_mle: -0.2571765184402466  (-0.27645307779312134)\n",
      "     | > loss_dur: 0.1617840975522995  (0.16248492151498795)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: -0.08644112944602966  (-0.10479248066743214)\n",
      "     | > log_mle: -0.26944684982299805  (-0.2741176684697469)\n",
      "     | > loss_dur: 0.18300572037696838  (0.16932518780231476)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: -0.11722688376903534  (-0.10790108144283295)\n",
      "     | > log_mle: -0.29638969898223877  (-0.2796856760978699)\n",
      "     | > loss_dur: 0.17916281521320343  (0.17178459465503693)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: -0.12427133321762085  (-0.11117513179779052)\n",
      "     | > log_mle: -0.2966729402542114  (-0.2830831289291382)\n",
      "     | > loss_dur: 0.17240160703659058  (0.17190799713134766)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: -0.07211153209209442  (-0.10466453184684117)\n",
      "     | > log_mle: -0.3062089681625366  (-0.2869374354680379)\n",
      "     | > loss_dur: 0.2340974360704422  (0.18227290362119675)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: -0.09763450920581818  (-0.1036602428981236)\n",
      "     | > log_mle: -0.26836228370666504  (-0.28428384235927034)\n",
      "     | > loss_dur: 0.17072777450084686  (0.18062359946114676)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: -0.10780039429664612  (-0.10417776182293892)\n",
      "     | > log_mle: -0.28010642528533936  (-0.283761665225029)\n",
      "     | > loss_dur: 0.17230603098869324  (0.17958390340209007)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: -0.0864650160074234  (-0.1022096789545483)\n",
      "     | > log_mle: -0.29368138313293457  (-0.28486385610368514)\n",
      "     | > loss_dur: 0.20721636712551117  (0.18265417714913687)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: -0.07038836181163788  (-0.09902754724025727)\n",
      "     | > log_mle: -0.27821457386016846  (-0.2841989278793335)\n",
      "     | > loss_dur: 0.20782621204853058  (0.18517138063907623)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: -0.09419398009777069  (-0.09858813204548576)\n",
      "     | > log_mle: -0.2953857183456421  (-0.2852159088308161)\n",
      "     | > loss_dur: 0.2011917382478714  (0.18662777678533035)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: -0.10242433845996857  (-0.09890781591335933)\n",
      "     | > log_mle: -0.2814279794692993  (-0.2849002480506897)\n",
      "     | > loss_dur: 0.17900364100933075  (0.18599243213733038)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: -0.12408466637134552  (-0.1008444967178198)\n",
      "     | > log_mle: -0.3030592203140259  (-0.28629709207094634)\n",
      "     | > loss_dur: 0.17897455394268036  (0.18545259535312653)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: -0.09275785088539124  (-0.10026687915836062)\n",
      "     | > log_mle: -0.2935326099395752  (-0.2868139147758484)\n",
      "     | > loss_dur: 0.20077475905418396  (0.18654703561748778)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: -0.09493279457092285  (-0.0999112735191981)\n",
      "     | > log_mle: -0.2869377136230469  (-0.2868221680323283)\n",
      "     | > loss_dur: 0.19200491905212402  (0.1869108945131302)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: -0.0811944305896759  (-0.09874147083610296)\n",
      "     | > log_mle: -0.2870875597000122  (-0.28683875501155853)\n",
      "     | > loss_dur: 0.2058931291103363  (0.18809728417545557)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: audio amplitude out of range, auto clipped.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[91m 0.004098325967788696 \u001b[0m(+0.0011275559663772583)\n",
      "     | > avg_loss:\u001b[92m -0.09874147083610296 \u001b[0m(-0.015574845485389233)\n",
      "     | > avg_log_mle:\u001b[92m -0.28683875501155853 \u001b[0m(-0.011796422302722875)\n",
      "     | > avg_loss_dur:\u001b[92m 0.18809728417545557 \u001b[0m(-0.0037784231826663017)\n",
      "\n",
      " > BEST MODEL : train/run-February-22-2025_10+59PM-fa84af3/best_model_41812.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 47/100\u001b[0m\n",
      " --> train/run-February-22-2025_10+59PM-fa84af3\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-23 03:07:11) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:07:19 -- STEP: 13/406 -- GLOBAL_STEP: 41825\u001b[0m\n",
      "     | > loss: -0.08664408326148987  (-0.09024222424397102)\n",
      "     | > log_mle: -0.2589918375015259  (-0.25707873931297887)\n",
      "     | > loss_dur: 0.172347754240036  (0.16683651506900787)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(10.5832, device='cuda:0')  (tensor(19.5916, device='cuda:0'))\n",
      "     | > current_lr: 1.1750000000000001e-05 \n",
      "     | > step_time: 0.6195  (0.4109492118542011)\n",
      "     | > loader_time: 0.0027  (0.005890314395611103)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:07:33 -- STEP: 38/406 -- GLOBAL_STEP: 41850\u001b[0m\n",
      "     | > loss: -0.06594030559062958  (-0.07700361781998684)\n",
      "     | > log_mle: -0.2622426748275757  (-0.25473450986962565)\n",
      "     | > loss_dur: 0.1963023692369461  (0.17773089204963888)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(8.5203, device='cuda:0')  (tensor(15.9932, device='cuda:0'))\n",
      "     | > current_lr: 1.1750000000000001e-05 \n",
      "     | > step_time: 0.5448  (0.5073492150557669)\n",
      "     | > loader_time: 0.0042  (0.008044242858886717)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:07:48 -- STEP: 63/406 -- GLOBAL_STEP: 41875\u001b[0m\n",
      "     | > loss: -0.05559350550174713  (-0.0725158282688686)\n",
      "     | > log_mle: -0.25686120986938477  (-0.25552313479166183)\n",
      "     | > loss_dur: 0.20126770436763763  (0.18300730652279323)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(14.6290, device='cuda:0')  (tensor(14.5263, device='cuda:0'))\n",
      "     | > current_lr: 1.1750000000000001e-05 \n",
      "     | > step_time: 0.7381  (0.5348158109755747)\n",
      "     | > loader_time: 0.0133  (0.010570995391361295)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:08:02 -- STEP: 88/406 -- GLOBAL_STEP: 41900\u001b[0m\n",
      "     | > loss: -0.07038353383541107  (-0.07145357165824283)\n",
      "     | > log_mle: -0.2522118091583252  (-0.2581020959398963)\n",
      "     | > loss_dur: 0.18182827532291412  (0.18664852428165346)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(11.3477, device='cuda:0')  (tensor(16.5721, device='cuda:0'))\n",
      "     | > current_lr: 1.1750000000000001e-05 \n",
      "     | > step_time: 0.6153  (0.5411288900808858)\n",
      "     | > loader_time: 0.0098  (0.0105729346925562)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:08:18 -- STEP: 113/406 -- GLOBAL_STEP: 41925\u001b[0m\n",
      "     | > loss: -0.07474289834499359  (-0.07133895712616169)\n",
      "     | > log_mle: -0.2674144506454468  (-0.2610932092751022)\n",
      "     | > loss_dur: 0.19267155230045319  (0.18975425214894046)\n",
      "     | > amp_scaler: 8192.0  (4240.991150442477)\n",
      "     | > grad_norm: tensor(24.2997, device='cuda:0')  (tensor(18.2951, device='cuda:0'))\n",
      "     | > current_lr: 1.1750000000000001e-05 \n",
      "     | > step_time: 0.6786  (0.5568097123002586)\n",
      "     | > loader_time: 0.0234  (0.010634057289731182)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:08:33 -- STEP: 138/406 -- GLOBAL_STEP: 41950\u001b[0m\n",
      "     | > loss: -0.040566131472587585  (-0.0708692646112995)\n",
      "     | > log_mle: -0.27612948417663574  (-0.2634361576342929)\n",
      "     | > loss_dur: 0.23556335270404816  (0.19256689302299332)\n",
      "     | > amp_scaler: 8192.0  (4956.753623188406)\n",
      "     | > grad_norm: tensor(20.4490, device='cuda:0')  (tensor(19.5270, device='cuda:0'))\n",
      "     | > current_lr: 1.1750000000000001e-05 \n",
      "     | > step_time: 0.7199  (0.5649576238963917)\n",
      "     | > loader_time: 0.0238  (0.010477834853573119)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:08:50 -- STEP: 163/406 -- GLOBAL_STEP: 41975\u001b[0m\n",
      "     | > loss: -0.06290028989315033  (-0.07026007698357468)\n",
      "     | > log_mle: -0.28583621978759766  (-0.26506166589772034)\n",
      "     | > loss_dur: 0.22293592989444733  (0.1948015889141457)\n",
      "     | > amp_scaler: 8192.0  (5452.957055214723)\n",
      "     | > grad_norm: tensor(33.7793, device='cuda:0')  (tensor(20.5691, device='cuda:0'))\n",
      "     | > current_lr: 1.1750000000000001e-05 \n",
      "     | > step_time: 0.683  (0.5798623547232228)\n",
      "     | > loader_time: 0.0061  (0.010731596156863341)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:09:07 -- STEP: 188/406 -- GLOBAL_STEP: 42000\u001b[0m\n",
      "     | > loss: -0.06603386998176575  (-0.07034711848865162)\n",
      "     | > log_mle: -0.28459465503692627  (-0.26658288912570216)\n",
      "     | > loss_dur: 0.21856078505516052  (0.19623577063705056)\n",
      "     | > amp_scaler: 4096.0  (5773.617021276596)\n",
      "     | > grad_norm: tensor(58.2200, device='cuda:0')  (tensor(21.8015, device='cuda:0'))\n",
      "     | > current_lr: 1.1750000000000001e-05 \n",
      "     | > step_time: 0.5042  (0.5900090552390899)\n",
      "     | > loader_time: 0.0051  (0.010716598084632382)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:09:25 -- STEP: 213/406 -- GLOBAL_STEP: 42025\u001b[0m\n",
      "     | > loss: -0.08066420257091522  (-0.07020292021858857)\n",
      "     | > log_mle: -0.2840275764465332  (-0.2677386747279636)\n",
      "     | > loss_dur: 0.20336337387561798  (0.1975357545093751)\n",
      "     | > amp_scaler: 4096.0  (5576.713615023475)\n",
      "     | > grad_norm: tensor(12.9175, device='cuda:0')  (tensor(22.1831, device='cuda:0'))\n",
      "     | > current_lr: 1.1750000000000001e-05 \n",
      "     | > step_time: 0.8771  (0.602324367129188)\n",
      "     | > loader_time: 0.0063  (0.010708948815932292)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:09:42 -- STEP: 238/406 -- GLOBAL_STEP: 42050\u001b[0m\n",
      "     | > loss: -0.06954945623874664  (-0.07020132080847472)\n",
      "     | > log_mle: -0.29072272777557373  (-0.26914037926858203)\n",
      "     | > loss_dur: 0.2211732715368271  (0.19893905846010734)\n",
      "     | > amp_scaler: 4096.0  (5421.176470588235)\n",
      "     | > grad_norm: tensor(24.0053, device='cuda:0')  (tensor(22.7192, device='cuda:0'))\n",
      "     | > current_lr: 1.1750000000000001e-05 \n",
      "     | > step_time: 0.4774  (0.6100683392596854)\n",
      "     | > loader_time: 0.0057  (0.010972958652913065)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:10:00 -- STEP: 263/406 -- GLOBAL_STEP: 42075\u001b[0m\n",
      "     | > loss: -0.08948056399822235  (-0.07052181899094305)\n",
      "     | > log_mle: -0.29053568840026855  (-0.2703529836560382)\n",
      "     | > loss_dur: 0.2010551244020462  (0.19983116466509523)\n",
      "     | > amp_scaler: 4096.0  (5295.209125475285)\n",
      "     | > grad_norm: tensor(36.4012, device='cuda:0')  (tensor(23.2800, device='cuda:0'))\n",
      "     | > current_lr: 1.1750000000000001e-05 \n",
      "     | > step_time: 1.2027  (0.6187553940617094)\n",
      "     | > loader_time: 0.0134  (0.011173452261282914)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:10:19 -- STEP: 288/406 -- GLOBAL_STEP: 42100\u001b[0m\n",
      "     | > loss: -0.0872340202331543  (-0.0709118285319871)\n",
      "     | > log_mle: -0.277148962020874  (-0.27138678439789343)\n",
      "     | > loss_dur: 0.18991494178771973  (0.2004749558659063)\n",
      "     | > amp_scaler: 4096.0  (5191.111111111112)\n",
      "     | > grad_norm: tensor(16.7626, device='cuda:0')  (tensor(23.3686, device='cuda:0'))\n",
      "     | > current_lr: 1.1750000000000001e-05 \n",
      "     | > step_time: 0.5332  (0.6284237669573898)\n",
      "     | > loader_time: 0.0082  (0.011630853017171218)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:10:39 -- STEP: 313/406 -- GLOBAL_STEP: 42125\u001b[0m\n",
      "     | > loss: -0.06658615171909332  (-0.07098901424164204)\n",
      "     | > log_mle: -0.27525222301483154  (-0.2722747261150956)\n",
      "     | > loss_dur: 0.20866607129573822  (0.20128571187345362)\n",
      "     | > amp_scaler: 4096.0  (5103.642172523963)\n",
      "     | > grad_norm: tensor(48.7755, device='cuda:0')  (tensor(23.3847, device='cuda:0'))\n",
      "     | > current_lr: 1.1750000000000001e-05 \n",
      "     | > step_time: 0.9408  (0.6389086353131384)\n",
      "     | > loader_time: 0.0084  (0.011851438699058062)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:10:58 -- STEP: 338/406 -- GLOBAL_STEP: 42150\u001b[0m\n",
      "     | > loss: -0.068889319896698  (-0.07095740810477516)\n",
      "     | > log_mle: -0.2854907512664795  (-0.27297042989166526)\n",
      "     | > loss_dur: 0.2166014313697815  (0.2020130217868901)\n",
      "     | > amp_scaler: 4096.0  (5029.112426035505)\n",
      "     | > grad_norm: tensor(32.7100, device='cuda:0')  (tensor(23.7407, device='cuda:0'))\n",
      "     | > current_lr: 1.1750000000000001e-05 \n",
      "     | > step_time: 0.8732  (0.6466522068666996)\n",
      "     | > loader_time: 0.039  (0.012194676512091818)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:11:17 -- STEP: 363/406 -- GLOBAL_STEP: 42175\u001b[0m\n",
      "     | > loss: -0.07618813216686249  (-0.0709835508063476)\n",
      "     | > log_mle: -0.2888009548187256  (-0.2738325109823347)\n",
      "     | > loss_dur: 0.2126128226518631  (0.2028489601759871)\n",
      "     | > amp_scaler: 4096.0  (4964.848484848487)\n",
      "     | > grad_norm: tensor(27.3332, device='cuda:0')  (tensor(24.2357, device='cuda:0'))\n",
      "     | > current_lr: 1.1750000000000001e-05 \n",
      "     | > step_time: 0.872  (0.6547016453808668)\n",
      "     | > loader_time: 0.0365  (0.012454382972612192)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:11:38 -- STEP: 388/406 -- GLOBAL_STEP: 42200\u001b[0m\n",
      "     | > loss: -0.06621478497982025  (-0.07105978639777165)\n",
      "     | > log_mle: -0.28898346424102783  (-0.2745489216956895)\n",
      "     | > loss_dur: 0.22276867926120758  (0.20348913529791782)\n",
      "     | > amp_scaler: 4096.0  (4908.865979381445)\n",
      "     | > grad_norm: tensor(24.5313, device='cuda:0')  (tensor(24.4838, device='cuda:0'))\n",
      "     | > current_lr: 1.1750000000000001e-05 \n",
      "     | > step_time: 1.2699  (0.6640576118046482)\n",
      "     | > loader_time: 0.0066  (0.012919194305065976)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: -0.05592790246009827  (-0.05592790246009827)\n",
      "     | > log_mle: -0.25774455070495605  (-0.25774455070495605)\n",
      "     | > loss_dur: 0.2018166482448578  (0.2018166482448578)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: -0.13404516875743866  (-0.13404516875743866)\n",
      "     | > log_mle: -0.2955434322357178  (-0.2955434322357178)\n",
      "     | > loss_dur: 0.1614982634782791  (0.1614982634782791)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: -0.09652368724346161  (-0.11528442800045013)\n",
      "     | > log_mle: -0.25817692279815674  (-0.27686017751693726)\n",
      "     | > loss_dur: 0.16165323555469513  (0.16157574951648712)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: -0.08988091349601746  (-0.10681658983230591)\n",
      "     | > log_mle: -0.2699390649795532  (-0.2745531400044759)\n",
      "     | > loss_dur: 0.18005815148353577  (0.16773655017217)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: -0.1047300398349762  (-0.10629495233297348)\n",
      "     | > log_mle: -0.29582762718200684  (-0.27987176179885864)\n",
      "     | > loss_dur: 0.19109758734703064  (0.17357680946588516)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: -0.11893823742866516  (-0.10882360935211181)\n",
      "     | > log_mle: -0.29216456413269043  (-0.282330322265625)\n",
      "     | > loss_dur: 0.17322632670402527  (0.1735067129135132)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: -0.058676764369010925  (-0.10046580185492833)\n",
      "     | > log_mle: -0.30075061321258545  (-0.2854003707567851)\n",
      "     | > loss_dur: 0.24207384884357452  (0.18493456890185675)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: -0.08880643546581268  (-0.09880017808505467)\n",
      "     | > log_mle: -0.26741743087768555  (-0.28283137934548513)\n",
      "     | > loss_dur: 0.17861099541187286  (0.18403120126043046)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: -0.10834157466888428  (-0.09999285265803337)\n",
      "     | > log_mle: -0.27958500385284424  (-0.28242558240890503)\n",
      "     | > loss_dur: 0.17124342918395996  (0.18243272975087166)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: -0.08010977506637573  (-0.09778362181451586)\n",
      "     | > log_mle: -0.29106390476226807  (-0.28338539600372314)\n",
      "     | > loss_dur: 0.21095412969589233  (0.18560177418920729)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: -0.06536324322223663  (-0.09454158395528793)\n",
      "     | > log_mle: -0.27697622776031494  (-0.28274447917938234)\n",
      "     | > loss_dur: 0.2116129845380783  (0.1882028952240944)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: -0.09500862658023834  (-0.09458404237573798)\n",
      "     | > log_mle: -0.2940179109573364  (-0.28376933661374176)\n",
      "     | > loss_dur: 0.19900928437709808  (0.18918529423800381)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: -0.10153651237487793  (-0.0951634148756663)\n",
      "     | > log_mle: -0.2811267375946045  (-0.28354912002881366)\n",
      "     | > loss_dur: 0.17959022521972656  (0.18838570515314737)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: -0.11685800552368164  (-0.09683222954089825)\n",
      "     | > log_mle: -0.30007123947143555  (-0.2848200522936307)\n",
      "     | > loss_dur: 0.1832132339477539  (0.1879878227527325)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: -0.09225527942180634  (-0.09650530453239169)\n",
      "     | > log_mle: -0.29172027111053467  (-0.2853129250662667)\n",
      "     | > loss_dur: 0.19946499168872833  (0.18880762053387506)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: -0.0963524878025055  (-0.09649511675039928)\n",
      "     | > log_mle: -0.28562450408935547  (-0.2853336970011393)\n",
      "     | > loss_dur: 0.18927201628684998  (0.18883858025074005)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: -0.08178107440471649  (-0.0955754891037941)\n",
      "     | > log_mle: -0.28564155101776123  (-0.2853529378771782)\n",
      "     | > loss_dur: 0.20386047661304474  (0.1897774487733841)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: audio amplitude out of range, auto clipped.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.003452807664871216 \u001b[0m(-0.0006455183029174805)\n",
      "     | > avg_loss:\u001b[91m -0.0955754891037941 \u001b[0m(+0.0031659817323088646)\n",
      "     | > avg_log_mle:\u001b[91m -0.2853529378771782 \u001b[0m(+0.0014858171343803406)\n",
      "     | > avg_loss_dur:\u001b[91m 0.1897774487733841 \u001b[0m(+0.001680164597928524)\n",
      "\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 48/100\u001b[0m\n",
      " --> train/run-February-22-2025_10+59PM-fa84af3\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-23 03:12:03) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:12:08 -- STEP: 7/406 -- GLOBAL_STEP: 42225\u001b[0m\n",
      "     | > loss: -0.0899558961391449  (-0.08967736576284681)\n",
      "     | > log_mle: -0.2526731491088867  (-0.2571960176740374)\n",
      "     | > loss_dur: 0.16271725296974182  (0.16751865191119059)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(20.7638, device='cuda:0')  (tensor(16.6780, device='cuda:0'))\n",
      "     | > current_lr: 1.2e-05 \n",
      "     | > step_time: 0.2588  (0.37272279603140696)\n",
      "     | > loader_time: 0.0041  (0.006477015359061105)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:12:21 -- STEP: 32/406 -- GLOBAL_STEP: 42250\u001b[0m\n",
      "     | > loss: -0.07184106111526489  (-0.0825400254689157)\n",
      "     | > log_mle: -0.25980985164642334  (-0.2581293918192387)\n",
      "     | > loss_dur: 0.18796879053115845  (0.17558936635032296)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(28.3255, device='cuda:0')  (tensor(19.7676, device='cuda:0'))\n",
      "     | > current_lr: 1.2e-05 \n",
      "     | > step_time: 0.6024  (0.48025983572006226)\n",
      "     | > loader_time: 0.0118  (0.006895385682582855)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:12:35 -- STEP: 57/406 -- GLOBAL_STEP: 42275\u001b[0m\n",
      "     | > loss: -0.07184179127216339  (-0.07741495862341764)\n",
      "     | > log_mle: -0.25517022609710693  (-0.2584609964437654)\n",
      "     | > loss_dur: 0.18332843482494354  (0.18104603782034756)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(22.3527, device='cuda:0')  (tensor(20.1700, device='cuda:0'))\n",
      "     | > current_lr: 1.2e-05 \n",
      "     | > step_time: 0.4225  (0.5191949417716577)\n",
      "     | > loader_time: 0.0043  (0.009395829418249298)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:12:51 -- STEP: 82/406 -- GLOBAL_STEP: 42300\u001b[0m\n",
      "     | > loss: -0.07573722302913666  (-0.07594147124668449)\n",
      "     | > log_mle: -0.26812469959259033  (-0.2604068037940237)\n",
      "     | > loss_dur: 0.19238747656345367  (0.184465332547339)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(25.0192, device='cuda:0')  (tensor(21.5114, device='cuda:0'))\n",
      "     | > current_lr: 1.2e-05 \n",
      "     | > step_time: 0.3394  (0.5498862499144019)\n",
      "     | > loader_time: 0.0097  (0.008752628070552179)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:13:07 -- STEP: 107/406 -- GLOBAL_STEP: 42325\u001b[0m\n",
      "     | > loss: -0.07917314767837524  (-0.07512986492887837)\n",
      "     | > log_mle: -0.2768818140029907  (-0.2629371758933382)\n",
      "     | > loss_dur: 0.19770866632461548  (0.18780731096445957)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(38.2717, device='cuda:0')  (tensor(22.5399, device='cuda:0'))\n",
      "     | > current_lr: 1.2e-05 \n",
      "     | > step_time: 0.4759  (0.5641253863539654)\n",
      "     | > loader_time: 0.0052  (0.009801387786865238)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:13:23 -- STEP: 132/406 -- GLOBAL_STEP: 42350\u001b[0m\n",
      "     | > loss: -0.09024268388748169  (-0.07462363091833665)\n",
      "     | > log_mle: -0.28910553455352783  (-0.2651787580865804)\n",
      "     | > loss_dur: 0.19886285066604614  (0.19055512716824358)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(47.0741, device='cuda:0')  (tensor(24.3995, device='cuda:0'))\n",
      "     | > current_lr: 1.2e-05 \n",
      "     | > step_time: 0.424  (0.5754594423554162)\n",
      "     | > loader_time: 0.0261  (0.010437302517168453)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:13:40 -- STEP: 157/406 -- GLOBAL_STEP: 42375\u001b[0m\n",
      "     | > loss: -0.07226063311100006  (-0.07324344707522425)\n",
      "     | > log_mle: -0.2656770944595337  (-0.26649410709454013)\n",
      "     | > loss_dur: 0.19341646134853363  (0.19325066001931576)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(16.2569, device='cuda:0')  (tensor(24.1249, device='cuda:0'))\n",
      "     | > current_lr: 1.2e-05 \n",
      "     | > step_time: 0.7692  (0.5901093391855813)\n",
      "     | > loader_time: 0.0076  (0.010609033001456296)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:13:57 -- STEP: 182/406 -- GLOBAL_STEP: 42400\u001b[0m\n",
      "     | > loss: -0.07564763724803925  (-0.07302284658282669)\n",
      "     | > log_mle: -0.27721524238586426  (-0.26787739009647604)\n",
      "     | > loss_dur: 0.201567605137825  (0.19485454351364914)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(15.5698, device='cuda:0')  (tensor(24.3226, device='cuda:0'))\n",
      "     | > current_lr: 1.2e-05 \n",
      "     | > step_time: 0.4983  (0.5979125106727685)\n",
      "     | > loader_time: 0.0197  (0.010977277388939492)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:14:14 -- STEP: 207/406 -- GLOBAL_STEP: 42425\u001b[0m\n",
      "     | > loss: -0.062098726630210876  (-0.07280530582591531)\n",
      "     | > log_mle: -0.2728201150894165  (-0.26924542240474547)\n",
      "     | > loss_dur: 0.21072138845920563  (0.19644011657883007)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(62.0333, device='cuda:0')  (tensor(24.2733, device='cuda:0'))\n",
      "     | > current_lr: 1.2e-05 \n",
      "     | > step_time: 0.4734  (0.6082097470472403)\n",
      "     | > loader_time: 0.0058  (0.011027948867871566)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:14:31 -- STEP: 232/406 -- GLOBAL_STEP: 42450\u001b[0m\n",
      "     | > loss: -0.07249748706817627  (-0.07312177436362051)\n",
      "     | > log_mle: -0.2817281484603882  (-0.2707641253183629)\n",
      "     | > loss_dur: 0.20923066139221191  (0.1976423509547423)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(59.0720, device='cuda:0')  (tensor(24.6866, device='cuda:0'))\n",
      "     | > current_lr: 1.2e-05 \n",
      "     | > step_time: 0.744  (0.6157551705837251)\n",
      "     | > loader_time: 0.0057  (0.011162172103750295)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:14:49 -- STEP: 257/406 -- GLOBAL_STEP: 42475\u001b[0m\n",
      "     | > loss: -0.08101879060268402  (-0.0733239101064808)\n",
      "     | > log_mle: -0.2869558334350586  (-0.27207728536212505)\n",
      "     | > loss_dur: 0.20593704283237457  (0.19875337525564413)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(29.5311, device='cuda:0')  (tensor(25.1578, device='cuda:0'))\n",
      "     | > current_lr: 1.2e-05 \n",
      "     | > step_time: 0.659  (0.6240805011778955)\n",
      "     | > loader_time: 0.056  (0.011431061340213286)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:15:08 -- STEP: 282/406 -- GLOBAL_STEP: 42500\u001b[0m\n",
      "     | > loss: -0.09572647511959076  (-0.0736977566324227)\n",
      "     | > log_mle: -0.29985690116882324  (-0.2732392236696069)\n",
      "     | > loss_dur: 0.20413042604923248  (0.199541467037184)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(25.1614, device='cuda:0')  (tensor(25.4615, device='cuda:0'))\n",
      "     | > current_lr: 1.2e-05 \n",
      "     | > step_time: 0.4801  (0.6323315471622115)\n",
      "     | > loader_time: 0.0053  (0.011652744408194901)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:15:27 -- STEP: 307/406 -- GLOBAL_STEP: 42525\u001b[0m\n",
      "     | > loss: -0.0767119824886322  (-0.073827227037582)\n",
      "     | > log_mle: -0.28085243701934814  (-0.27416980344231834)\n",
      "     | > loss_dur: 0.20414045453071594  (0.2003425764047362)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(35.8857, device='cuda:0')  (tensor(25.6646, device='cuda:0'))\n",
      "     | > current_lr: 1.2e-05 \n",
      "     | > step_time: 0.6484  (0.642685800887863)\n",
      "     | > loader_time: 0.0074  (0.011815408930328071)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:15:47 -- STEP: 332/406 -- GLOBAL_STEP: 42550\u001b[0m\n",
      "     | > loss: -0.07348136603832245  (-0.07392617386866761)\n",
      "     | > log_mle: -0.274822473526001  (-0.2748719601027939)\n",
      "     | > loss_dur: 0.20134110748767853  (0.20094578623412604)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(25.6598, device='cuda:0')  (tensor(25.7681, device='cuda:0'))\n",
      "     | > current_lr: 1.2e-05 \n",
      "     | > step_time: 1.0285  (0.653606176376343)\n",
      "     | > loader_time: 0.0068  (0.011924156223435001)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:16:08 -- STEP: 357/406 -- GLOBAL_STEP: 42575\u001b[0m\n",
      "     | > loss: -0.06441250443458557  (-0.07381364540392606)\n",
      "     | > log_mle: -0.27875471115112305  (-0.27569941546068827)\n",
      "     | > loss_dur: 0.21434220671653748  (0.20188577005676195)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(48.2948, device='cuda:0')  (tensor(25.6725, device='cuda:0'))\n",
      "     | > current_lr: 1.2e-05 \n",
      "     | > step_time: 0.8757  (0.6629059568506663)\n",
      "     | > loader_time: 0.0149  (0.01206172147050959)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:16:28 -- STEP: 382/406 -- GLOBAL_STEP: 42600\u001b[0m\n",
      "     | > loss: -0.06382982432842255  (-0.07397140901906323)\n",
      "     | > log_mle: -0.2877761125564575  (-0.27643968796854895)\n",
      "     | > loss_dur: 0.22394628822803497  (0.2024682789494854)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(29.0702, device='cuda:0')  (tensor(25.9028, device='cuda:0'))\n",
      "     | > current_lr: 1.2e-05 \n",
      "     | > step_time: 0.997  (0.6728162646917771)\n",
      "     | > loader_time: 0.0225  (0.012400492947763173)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: -0.060544490814208984  (-0.060544490814208984)\n",
      "     | > log_mle: -0.2605702877044678  (-0.2605702877044678)\n",
      "     | > loss_dur: 0.2000257968902588  (0.2000257968902588)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: -0.12964361906051636  (-0.12964361906051636)\n",
      "     | > log_mle: -0.29952752590179443  (-0.29952752590179443)\n",
      "     | > loss_dur: 0.16988390684127808  (0.16988390684127808)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: -0.10272930562496185  (-0.1161864623427391)\n",
      "     | > log_mle: -0.2614389657974243  (-0.2804832458496094)\n",
      "     | > loss_dur: 0.15870966017246246  (0.16429678350687027)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: -0.09952038526535034  (-0.11063110331694286)\n",
      "     | > log_mle: -0.2729642391204834  (-0.27797691027323407)\n",
      "     | > loss_dur: 0.17344385385513306  (0.1673458069562912)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: -0.1133735179901123  (-0.11131670698523521)\n",
      "     | > log_mle: -0.29961490631103516  (-0.2833864092826843)\n",
      "     | > loss_dur: 0.18624138832092285  (0.1720697022974491)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: -0.12533800303936005  (-0.11412096619606019)\n",
      "     | > log_mle: -0.2975238561630249  (-0.28621389865875246)\n",
      "     | > loss_dur: 0.17218585312366486  (0.17209293246269225)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: -0.0696888267993927  (-0.10671560962994893)\n",
      "     | > log_mle: -0.3059192895889282  (-0.2894981304804484)\n",
      "     | > loss_dur: 0.23623046278953552  (0.18278252085049948)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: -0.08883656561374664  (-0.10416146048477717)\n",
      "     | > log_mle: -0.271098256111145  (-0.28686957699911936)\n",
      "     | > loss_dur: 0.18226169049739838  (0.18270811651434218)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: -0.11686033010482788  (-0.10574881918728352)\n",
      "     | > log_mle: -0.28365659713745117  (-0.2864679545164108)\n",
      "     | > loss_dur: 0.1667962670326233  (0.1807191353291273)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: -0.08418990671634674  (-0.10335338446829054)\n",
      "     | > log_mle: -0.294988751411438  (-0.2874147097269694)\n",
      "     | > loss_dur: 0.21079884469509125  (0.18406132525867885)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: -0.06862151622772217  (-0.0998801976442337)\n",
      "     | > log_mle: -0.2810554504394531  (-0.28677878379821775)\n",
      "     | > loss_dur: 0.21243393421173096  (0.18689858615398408)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: -0.09608966112136841  (-0.09953560341488231)\n",
      "     | > log_mle: -0.29794108867645264  (-0.2877935387871482)\n",
      "     | > loss_dur: 0.20185142755508423  (0.1882579353722659)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: -0.10066597163677216  (-0.09962980076670647)\n",
      "     | > log_mle: -0.284517765045166  (-0.28752055764198303)\n",
      "     | > loss_dur: 0.18385179340839386  (0.18789075687527657)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: -0.11923204362392426  (-0.10113766560187706)\n",
      "     | > log_mle: -0.3047083616256714  (-0.2888426964099591)\n",
      "     | > loss_dur: 0.18547631800174713  (0.18770503080808199)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: -0.09277082979679108  (-0.10054003447294235)\n",
      "     | > log_mle: -0.2956143617630005  (-0.28932638679231915)\n",
      "     | > loss_dur: 0.2028435319662094  (0.18878635231937682)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: -0.0989670604467392  (-0.10043516953786215)\n",
      "     | > log_mle: -0.28949403762817383  (-0.28933756351470946)\n",
      "     | > loss_dur: 0.19052697718143463  (0.18890239397684733)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: -0.08137078583240509  (-0.09924364555627108)\n",
      "     | > log_mle: -0.28888189792633057  (-0.2893090844154358)\n",
      "     | > loss_dur: 0.20751111209392548  (0.19006543885916471)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: audio amplitude out of range, auto clipped.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[91m 0.005610853433609009 \u001b[0m(+0.002158045768737793)\n",
      "     | > avg_loss:\u001b[92m -0.09924364555627108 \u001b[0m(-0.0036681564524769783)\n",
      "     | > avg_log_mle:\u001b[92m -0.2893090844154358 \u001b[0m(-0.003956146538257599)\n",
      "     | > avg_loss_dur:\u001b[91m 0.19006543885916471 \u001b[0m(+0.0002879900857806206)\n",
      "\n",
      " > BEST MODEL : train/run-February-22-2025_10+59PM-fa84af3/best_model_42624.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 49/100\u001b[0m\n",
      " --> train/run-February-22-2025_10+59PM-fa84af3\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-23 03:16:59) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:17:02 -- STEP: 1/406 -- GLOBAL_STEP: 42625\u001b[0m\n",
      "     | > loss: -0.1002843827009201  (-0.1002843827009201)\n",
      "     | > log_mle: -0.2576467990875244  (-0.2576467990875244)\n",
      "     | > loss_dur: 0.1573624163866043  (0.1573624163866043)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(23.3471, device='cuda:0')  (tensor(23.3471, device='cuda:0'))\n",
      "     | > current_lr: 1.225e-05 \n",
      "     | > step_time: 0.9626  (0.9626455307006836)\n",
      "     | > loader_time: 0.0037  (0.0037403106689453125)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:17:14 -- STEP: 26/406 -- GLOBAL_STEP: 42650\u001b[0m\n",
      "     | > loss: -0.08022385835647583  (-0.08534189027089341)\n",
      "     | > log_mle: -0.2606997489929199  (-0.2587451705565819)\n",
      "     | > loss_dur: 0.1804758906364441  (0.17340328028568855)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(10.2641, device='cuda:0')  (tensor(17.4339, device='cuda:0'))\n",
      "     | > current_lr: 1.225e-05 \n",
      "     | > step_time: 0.4335  (0.4752582036531888)\n",
      "     | > loader_time: 0.0172  (0.009715859706585226)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:17:28 -- STEP: 51/406 -- GLOBAL_STEP: 42675\u001b[0m\n",
      "     | > loss: -0.06989413499832153  (-0.07784088160477433)\n",
      "     | > log_mle: -0.2728114128112793  (-0.2585932039747051)\n",
      "     | > loss_dur: 0.20291727781295776  (0.1807523223699308)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(26.1694, device='cuda:0')  (tensor(19.2424, device='cuda:0'))\n",
      "     | > current_lr: 1.225e-05 \n",
      "     | > step_time: 0.3093  (0.5115611225950951)\n",
      "     | > loader_time: 0.0041  (0.009004807939716414)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:17:43 -- STEP: 76/406 -- GLOBAL_STEP: 42700\u001b[0m\n",
      "     | > loss: -0.07670949399471283  (-0.07603383142697184)\n",
      "     | > log_mle: -0.2617849111557007  (-0.26043599687124563)\n",
      "     | > loss_dur: 0.18507541716098785  (0.18440216544427368)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(23.4334, device='cuda:0')  (tensor(19.2718, device='cuda:0'))\n",
      "     | > current_lr: 1.225e-05 \n",
      "     | > step_time: 0.4826  (0.5383041155965703)\n",
      "     | > loader_time: 0.0052  (0.009049161484366968)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:17:58 -- STEP: 101/406 -- GLOBAL_STEP: 42725\u001b[0m\n",
      "     | > loss: -0.057339414954185486  (-0.0750561955541667)\n",
      "     | > log_mle: -0.2675135135650635  (-0.26296889899980896)\n",
      "     | > loss_dur: 0.210174098610878  (0.18791270344564232)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(14.9572, device='cuda:0')  (tensor(18.6036, device='cuda:0'))\n",
      "     | > current_lr: 1.225e-05 \n",
      "     | > step_time: 0.5228  (0.5475640344147633)\n",
      "     | > loader_time: 0.005  (0.009617161042619463)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:18:14 -- STEP: 126/406 -- GLOBAL_STEP: 42750\u001b[0m\n",
      "     | > loss: -0.0744953602552414  (-0.07506625271505776)\n",
      "     | > log_mle: -0.27262771129608154  (-0.2654772372472853)\n",
      "     | > loss_dur: 0.19813235104084015  (0.1904109845322276)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(45.4449, device='cuda:0')  (tensor(22.2201, device='cuda:0'))\n",
      "     | > current_lr: 1.225e-05 \n",
      "     | > step_time: 0.7814  (0.5617891114855569)\n",
      "     | > loader_time: 0.0163  (0.009666170392717636)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:18:31 -- STEP: 151/406 -- GLOBAL_STEP: 42775\u001b[0m\n",
      "     | > loss: -0.05095072090625763  (-0.07482529189807689)\n",
      "     | > log_mle: -0.269811749458313  (-0.26755708732352346)\n",
      "     | > loss_dur: 0.21886102855205536  (0.1927317954254466)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(33.5478, device='cuda:0')  (tensor(22.5788, device='cuda:0'))\n",
      "     | > current_lr: 1.225e-05 \n",
      "     | > step_time: 0.3763  (0.5782880167297971)\n",
      "     | > loader_time: 0.006  (0.010548784243349997)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:18:47 -- STEP: 176/406 -- GLOBAL_STEP: 42800\u001b[0m\n",
      "     | > loss: -0.06880736351013184  (-0.07495186816562309)\n",
      "     | > log_mle: -0.2741246223449707  (-0.2690959186716512)\n",
      "     | > loss_dur: 0.20531725883483887  (0.19414405050602823)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(14.1680, device='cuda:0')  (tensor(23.3473, device='cuda:0'))\n",
      "     | > current_lr: 1.225e-05 \n",
      "     | > step_time: 0.8419  (0.5865049186077986)\n",
      "     | > loader_time: 0.0211  (0.010938166217370465)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:19:04 -- STEP: 201/406 -- GLOBAL_STEP: 42825\u001b[0m\n",
      "     | > loss: -0.08169625699520111  (-0.07521796359944699)\n",
      "     | > log_mle: -0.27201902866363525  (-0.2706827832691706)\n",
      "     | > loss_dur: 0.19032277166843414  (0.19546481966972348)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(24.7089, device='cuda:0')  (tensor(23.8073, device='cuda:0'))\n",
      "     | > current_lr: 1.225e-05 \n",
      "     | > step_time: 0.4761  (0.5970388431454177)\n",
      "     | > loader_time: 0.0057  (0.010664458298564546)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:19:21 -- STEP: 226/406 -- GLOBAL_STEP: 42850\u001b[0m\n",
      "     | > loss: -0.08645474910736084  (-0.07544505906052294)\n",
      "     | > log_mle: -0.29002881050109863  (-0.272269291160381)\n",
      "     | > loss_dur: 0.2035740613937378  (0.19682423209985797)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(18.6824, device='cuda:0')  (tensor(24.2604, device='cuda:0'))\n",
      "     | > current_lr: 1.225e-05 \n",
      "     | > step_time: 0.4307  (0.6029482489138576)\n",
      "     | > loader_time: 0.0061  (0.010983843719009801)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:19:39 -- STEP: 251/406 -- GLOBAL_STEP: 42875\u001b[0m\n",
      "     | > loss: -0.07280981540679932  (-0.07532132888932627)\n",
      "     | > log_mle: -0.2828937768936157  (-0.27343294962468856)\n",
      "     | > loss_dur: 0.2100839614868164  (0.1981116207353622)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(43.0524, device='cuda:0')  (tensor(25.2032, device='cuda:0'))\n",
      "     | > current_lr: 1.225e-05 \n",
      "     | > step_time: 0.7605  (0.6118493574074063)\n",
      "     | > loader_time: 0.0053  (0.011092101435262364)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:19:58 -- STEP: 276/406 -- GLOBAL_STEP: 42900\u001b[0m\n",
      "     | > loss: -0.0625436007976532  (-0.07571388808065566)\n",
      "     | > log_mle: -0.2848389148712158  (-0.27458071060802625)\n",
      "     | > loss_dur: 0.22229531407356262  (0.19886682252737056)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(7.9446, device='cuda:0')  (tensor(24.9338, device='cuda:0'))\n",
      "     | > current_lr: 1.225e-05 \n",
      "     | > step_time: 0.7244  (0.6233575292255565)\n",
      "     | > loader_time: 0.0065  (0.011256546214006947)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:20:17 -- STEP: 301/406 -- GLOBAL_STEP: 42925\u001b[0m\n",
      "     | > loss: -0.08194538950920105  (-0.07579994261066778)\n",
      "     | > log_mle: -0.30112767219543457  (-0.2754313165563284)\n",
      "     | > loss_dur: 0.21918228268623352  (0.19963137394566077)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(69.7556, device='cuda:0')  (tensor(24.7605, device='cuda:0'))\n",
      "     | > current_lr: 1.225e-05 \n",
      "     | > step_time: 0.9804  (0.6335910824050139)\n",
      "     | > loader_time: 0.0317  (0.011490969166803198)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:20:35 -- STEP: 326/406 -- GLOBAL_STEP: 42950\u001b[0m\n",
      "     | > loss: -0.07994696497917175  (-0.07589356898347291)\n",
      "     | > log_mle: -0.2771782875061035  (-0.2761336839272199)\n",
      "     | > loss_dur: 0.19723132252693176  (0.20024011494374713)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(19.5393, device='cuda:0')  (tensor(25.5963, device='cuda:0'))\n",
      "     | > current_lr: 1.225e-05 \n",
      "     | > step_time: 0.6415  (0.6407768294855128)\n",
      "     | > loader_time: 0.0064  (0.011906430033818347)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:20:56 -- STEP: 351/406 -- GLOBAL_STEP: 42975\u001b[0m\n",
      "     | > loss: -0.05796222388744354  (-0.07581737552612935)\n",
      "     | > log_mle: -0.2790793180465698  (-0.27688457245840287)\n",
      "     | > loss_dur: 0.22111709415912628  (0.2010671969322737)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(39.7850, device='cuda:0')  (tensor(26.5179, device='cuda:0'))\n",
      "     | > current_lr: 1.225e-05 \n",
      "     | > step_time: 0.6456  (0.6516740532682154)\n",
      "     | > loader_time: 0.0198  (0.012160368454761997)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:21:16 -- STEP: 376/406 -- GLOBAL_STEP: 43000\u001b[0m\n",
      "     | > loss: -0.07423979043960571  (-0.07612871243915662)\n",
      "     | > log_mle: -0.29177355766296387  (-0.27782084238021915)\n",
      "     | > loss_dur: 0.21753376722335815  (0.20169212994106273)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(25.3182, device='cuda:0')  (tensor(26.5161, device='cuda:0'))\n",
      "     | > current_lr: 1.225e-05 \n",
      "     | > step_time: 0.8032  (0.6606130580952825)\n",
      "     | > loader_time: 0.0193  (0.012507741121535607)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:21:34 -- STEP: 401/406 -- GLOBAL_STEP: 43025\u001b[0m\n",
      "     | > loss: -0.090791717171669  (-0.07628293632717802)\n",
      "     | > log_mle: -0.2932734489440918  (-0.2786362703304334)\n",
      "     | > loss_dur: 0.2024817317724228  (0.20235333400325584)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(21.0970, device='cuda:0')  (tensor(26.8907, device='cuda:0'))\n",
      "     | > current_lr: 1.225e-05 \n",
      "     | > step_time: 0.5287  (0.6641539635503676)\n",
      "     | > loader_time: 0.0062  (0.01255095272587422)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: -0.062484800815582275  (-0.062484800815582275)\n",
      "     | > log_mle: -0.2635030746459961  (-0.2635030746459961)\n",
      "     | > loss_dur: 0.20101827383041382  (0.20101827383041382)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: -0.14259782433509827  (-0.14259782433509827)\n",
      "     | > log_mle: -0.30430901050567627  (-0.30430901050567627)\n",
      "     | > loss_dur: 0.161711186170578  (0.161711186170578)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: -0.10635615885257721  (-0.12447699159383774)\n",
      "     | > log_mle: -0.26544272899627686  (-0.28487586975097656)\n",
      "     | > loss_dur: 0.15908657014369965  (0.16039887815713882)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: -0.1034262627363205  (-0.11746008197466533)\n",
      "     | > log_mle: -0.2783010005950928  (-0.2826842466990153)\n",
      "     | > loss_dur: 0.17487473785877228  (0.16522416472434998)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: -0.11998966336250305  (-0.11809247732162476)\n",
      "     | > log_mle: -0.3054664134979248  (-0.2883797883987427)\n",
      "     | > loss_dur: 0.18547675013542175  (0.17028731107711792)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: -0.13400942087173462  (-0.12127586603164672)\n",
      "     | > log_mle: -0.3094698190689087  (-0.2925977945327759)\n",
      "     | > loss_dur: 0.17546039819717407  (0.17132192850112915)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: -0.07910589873790741  (-0.11424753814935684)\n",
      "     | > log_mle: -0.3190181255340576  (-0.2970011830329895)\n",
      "     | > loss_dur: 0.2399122267961502  (0.18275364488363266)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: -0.10561993718147278  (-0.1130150237253734)\n",
      "     | > log_mle: -0.2778879404067993  (-0.2942707198006766)\n",
      "     | > loss_dur: 0.17226800322532654  (0.1812556960753032)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: -0.11959448456764221  (-0.113837456330657)\n",
      "     | > log_mle: -0.2891685962677002  (-0.29363295435905457)\n",
      "     | > loss_dur: 0.16957411170005798  (0.17979549802839756)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: -0.09345556795597076  (-0.11157280206680298)\n",
      "     | > log_mle: -0.30383193492889404  (-0.2947661744223701)\n",
      "     | > loss_dur: 0.21037636697292328  (0.1831933723555671)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: -0.07711881399154663  (-0.10812740325927735)\n",
      "     | > log_mle: -0.2875782251358032  (-0.2940473794937134)\n",
      "     | > loss_dur: 0.2104594111442566  (0.18591997623443604)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: -0.11339028179645538  (-0.10860584676265717)\n",
      "     | > log_mle: -0.30487990379333496  (-0.2950321544300426)\n",
      "     | > loss_dur: 0.19148962199687958  (0.18642630766738544)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: -0.10977619886398315  (-0.10870337610443433)\n",
      "     | > log_mle: -0.29029953479766846  (-0.2946377694606781)\n",
      "     | > loss_dur: 0.1805233359336853  (0.18593439335624376)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: -0.13082599639892578  (-0.11040511612708752)\n",
      "     | > log_mle: -0.3145047426223755  (-0.29616599816542405)\n",
      "     | > loss_dur: 0.1836787462234497  (0.18576088203833654)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: -0.10220983624458313  (-0.10981973899262291)\n",
      "     | > log_mle: -0.3030954599380493  (-0.2966609597206116)\n",
      "     | > loss_dur: 0.2008856236934662  (0.18684122072798864)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: -0.10937492549419403  (-0.10979008475939432)\n",
      "     | > log_mle: -0.2962573766708374  (-0.29663405418395994)\n",
      "     | > loss_dur: 0.18688245117664337  (0.18684396942456563)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: -0.094143807888031  (-0.10881219245493412)\n",
      "     | > log_mle: -0.2977640628814697  (-0.2967046797275543)\n",
      "     | > loss_dur: 0.20362025499343872  (0.1878924872726202)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: audio amplitude out of range, auto clipped.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.00340406596660614 \u001b[0m(-0.0022067874670028687)\n",
      "     | > avg_loss:\u001b[92m -0.10881219245493412 \u001b[0m(-0.009568546898663044)\n",
      "     | > avg_log_mle:\u001b[92m -0.2967046797275543 \u001b[0m(-0.00739559531211853)\n",
      "     | > avg_loss_dur:\u001b[92m 0.1878924872726202 \u001b[0m(-0.0021729515865445137)\n",
      "\n",
      " > BEST MODEL : train/run-February-22-2025_10+59PM-fa84af3/best_model_43030.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 50/100\u001b[0m\n",
      " --> train/run-February-22-2025_10+59PM-fa84af3\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-23 03:21:53) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:22:04 -- STEP: 20/406 -- GLOBAL_STEP: 43050\u001b[0m\n",
      "     | > loss: -0.08778505027294159  (-0.09222386851906776)\n",
      "     | > log_mle: -0.24424207210540771  (-0.26204934120178225)\n",
      "     | > loss_dur: 0.15645702183246613  (0.16982547268271447)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(4.6692, device='cuda:0')  (tensor(17.9533, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-05 \n",
      "     | > step_time: 0.9264  (0.4433570623397827)\n",
      "     | > loader_time: 0.018  (0.00740044116973877)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:22:18 -- STEP: 45/406 -- GLOBAL_STEP: 43075\u001b[0m\n",
      "     | > loss: -0.09008866548538208  (-0.08383385770850711)\n",
      "     | > log_mle: -0.2602372169494629  (-0.260387306743198)\n",
      "     | > loss_dur: 0.1701485514640808  (0.1765534490346909)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(16.5726, device='cuda:0')  (tensor(17.9409, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-05 \n",
      "     | > step_time: 0.5347  (0.5016167057885064)\n",
      "     | > loader_time: 0.0041  (0.008375295003255208)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:22:33 -- STEP: 70/406 -- GLOBAL_STEP: 43100\u001b[0m\n",
      "     | > loss: -0.10419425368309021  (-0.08078834478344236)\n",
      "     | > log_mle: -0.271531343460083  (-0.2624367339270455)\n",
      "     | > loss_dur: 0.1673370897769928  (0.1816483891436032)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(14.6371, device='cuda:0')  (tensor(20.7274, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-05 \n",
      "     | > step_time: 0.3276  (0.5262614727020262)\n",
      "     | > loader_time: 0.0064  (0.008977219036647251)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:22:49 -- STEP: 95/406 -- GLOBAL_STEP: 43125\u001b[0m\n",
      "     | > loss: -0.06924952566623688  (-0.08034108061539502)\n",
      "     | > log_mle: -0.2723797559738159  (-0.26547388528522686)\n",
      "     | > loss_dur: 0.20313023030757904  (0.18513280466983192)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(22.3687, device='cuda:0')  (tensor(21.1283, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-05 \n",
      "     | > step_time: 0.958  (0.5546111960160103)\n",
      "     | > loader_time: 0.0396  (0.00974388373525519)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:23:05 -- STEP: 120/406 -- GLOBAL_STEP: 43150\u001b[0m\n",
      "     | > loss: -0.07405194640159607  (-0.08002464920282366)\n",
      "     | > log_mle: -0.2755880355834961  (-0.26797805229822785)\n",
      "     | > loss_dur: 0.20153608918190002  (0.18795340309540431)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(21.8660, device='cuda:0')  (tensor(22.1168, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-05 \n",
      "     | > step_time: 0.47  (0.5656100412209827)\n",
      "     | > loader_time: 0.0181  (0.010305396715799968)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:23:21 -- STEP: 145/406 -- GLOBAL_STEP: 43175\u001b[0m\n",
      "     | > loss: -0.06843100488185883  (-0.07963238214624342)\n",
      "     | > log_mle: -0.2608509063720703  (-0.2698075146510682)\n",
      "     | > loss_dur: 0.1924199014902115  (0.19017513250482493)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(16.5133, device='cuda:0')  (tensor(22.5343, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-05 \n",
      "     | > step_time: 0.6919  (0.5760457729471139)\n",
      "     | > loader_time: 0.0267  (0.01114109466815817)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:23:38 -- STEP: 170/406 -- GLOBAL_STEP: 43200\u001b[0m\n",
      "     | > loss: -0.08313485980033875  (-0.07883181528133504)\n",
      "     | > log_mle: -0.27505600452423096  (-0.27111618238336893)\n",
      "     | > loss_dur: 0.1919211447238922  (0.19228436710203395)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(28.2565, device='cuda:0')  (tensor(23.1468, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-05 \n",
      "     | > step_time: 0.645  (0.5885703086853027)\n",
      "     | > loader_time: 0.0124  (0.011300276307498707)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:23:55 -- STEP: 195/406 -- GLOBAL_STEP: 43225\u001b[0m\n",
      "     | > loss: -0.07216411828994751  (-0.07889169286458919)\n",
      "     | > log_mle: -0.27341699600219727  (-0.2726524426386906)\n",
      "     | > loss_dur: 0.20125287771224976  (0.19376074977410146)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(25.5929, device='cuda:0')  (tensor(23.6923, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-05 \n",
      "     | > step_time: 0.4964  (0.5991577551915094)\n",
      "     | > loader_time: 0.0209  (0.011762522428463667)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:24:12 -- STEP: 220/406 -- GLOBAL_STEP: 43250\u001b[0m\n",
      "     | > loss: -0.09165738523006439  (-0.07904443679885431)\n",
      "     | > log_mle: -0.30567121505737305  (-0.27414119677110155)\n",
      "     | > loss_dur: 0.21401382982730865  (0.1950967599722472)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(31.5947, device='cuda:0')  (tensor(24.4759, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-05 \n",
      "     | > step_time: 0.4755  (0.6076379006559198)\n",
      "     | > loader_time: 0.005  (0.01168317361311479)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:24:31 -- STEP: 245/406 -- GLOBAL_STEP: 43275\u001b[0m\n",
      "     | > loss: -0.07460059225559235  (-0.07896669811132002)\n",
      "     | > log_mle: -0.2839324474334717  (-0.2755076442446029)\n",
      "     | > loss_dur: 0.20933185517787933  (0.1965409461332827)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(24.5329, device='cuda:0')  (tensor(24.7098, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-05 \n",
      "     | > step_time: 1.0999  (0.6207349096025739)\n",
      "     | > loader_time: 0.0193  (0.012027263641357422)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:24:49 -- STEP: 270/406 -- GLOBAL_STEP: 43300\u001b[0m\n",
      "     | > loss: -0.09009909629821777  (-0.07926205805054418)\n",
      "     | > log_mle: -0.29281342029571533  (-0.2765274665973806)\n",
      "     | > loss_dur: 0.20271432399749756  (0.1972654085468363)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(37.5284, device='cuda:0')  (tensor(24.9232, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-05 \n",
      "     | > step_time: 0.7029  (0.6282631194150007)\n",
      "     | > loader_time: 0.0127  (0.01252267978809498)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:25:08 -- STEP: 295/406 -- GLOBAL_STEP: 43325\u001b[0m\n",
      "     | > loss: -0.08198285102844238  (-0.07929537634728319)\n",
      "     | > log_mle: -0.2854900360107422  (-0.2773437993001131)\n",
      "     | > loss_dur: 0.2035071849822998  (0.19804842295282982)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(35.0794, device='cuda:0')  (tensor(25.4480, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-05 \n",
      "     | > step_time: 0.7673  (0.6375516139854818)\n",
      "     | > loader_time: 0.0058  (0.012805291353645974)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:25:25 -- STEP: 320/406 -- GLOBAL_STEP: 43350\u001b[0m\n",
      "     | > loss: -0.07219098508358002  (-0.07929313024505974)\n",
      "     | > log_mle: -0.2797800302505493  (-0.2781617339700463)\n",
      "     | > loss_dur: 0.2075890451669693  (0.1988686037249863)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(20.5028, device='cuda:0')  (tensor(25.6431, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-05 \n",
      "     | > step_time: 0.8574  (0.6395899854600429)\n",
      "     | > loader_time: 0.0069  (0.012788287550210956)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:25:45 -- STEP: 345/406 -- GLOBAL_STEP: 43375\u001b[0m\n",
      "     | > loss: -0.07967981696128845  (-0.0792527403520501)\n",
      "     | > log_mle: -0.2913578748703003  (-0.2789399876110799)\n",
      "     | > loss_dur: 0.21167805790901184  (0.19968724725902945)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(14.3804, device='cuda:0')  (tensor(25.4868, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-05 \n",
      "     | > step_time: 1.0564  (0.649169795409493)\n",
      "     | > loader_time: 0.0131  (0.012886357652968257)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:26:06 -- STEP: 370/406 -- GLOBAL_STEP: 43400\u001b[0m\n",
      "     | > loss: -0.08570900559425354  (-0.07935900148507712)\n",
      "     | > log_mle: -0.31113767623901367  (-0.279808578297899)\n",
      "     | > loss_dur: 0.22542867064476013  (0.20044957681282147)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(41.0927, device='cuda:0')  (tensor(26.1769, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-05 \n",
      "     | > step_time: 0.7943  (0.6602461344486961)\n",
      "     | > loader_time: 0.0209  (0.013269055211866226)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:26:27 -- STEP: 395/406 -- GLOBAL_STEP: 43425\u001b[0m\n",
      "     | > loss: -0.09444662928581238  (-0.07950191063971462)\n",
      "     | > log_mle: -0.2995051145553589  (-0.2805681319176401)\n",
      "     | > loss_dur: 0.2050584852695465  (0.20106622127792503)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(24.4546, device='cuda:0')  (tensor(26.5144, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-05 \n",
      "     | > step_time: 0.5457  (0.6691989989220345)\n",
      "     | > loader_time: 0.0069  (0.01350714164444163)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: -0.06424742937088013  (-0.06424742937088013)\n",
      "     | > log_mle: -0.2652651071548462  (-0.2652651071548462)\n",
      "     | > loss_dur: 0.20101767778396606  (0.20101767778396606)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: -0.1402425765991211  (-0.1402425765991211)\n",
      "     | > log_mle: -0.30599963665008545  (-0.30599963665008545)\n",
      "     | > loss_dur: 0.16575706005096436  (0.16575706005096436)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: -0.10976402461528778  (-0.12500330060720444)\n",
      "     | > log_mle: -0.26739633083343506  (-0.28669798374176025)\n",
      "     | > loss_dur: 0.15763230621814728  (0.16169468313455582)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: -0.10978084802627563  (-0.11992914974689484)\n",
      "     | > log_mle: -0.2796899080276489  (-0.28436195850372314)\n",
      "     | > loss_dur: 0.1699090600013733  (0.1644328087568283)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: -0.13381057977676392  (-0.1233995072543621)\n",
      "     | > log_mle: -0.3064345121383667  (-0.28988009691238403)\n",
      "     | > loss_dur: 0.17262393236160278  (0.16648058965802193)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: -0.12673348188400269  (-0.12406630218029022)\n",
      "     | > log_mle: -0.30797457695007324  (-0.2934989929199219)\n",
      "     | > loss_dur: 0.18124109506607056  (0.16943269073963166)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: -0.08198802173137665  (-0.11705325543880463)\n",
      "     | > log_mle: -0.31640851497650146  (-0.2973172465960185)\n",
      "     | > loss_dur: 0.23442049324512482  (0.18026399115721384)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: -0.09618926048278809  (-0.11407268473080226)\n",
      "     | > log_mle: -0.2781202793121338  (-0.29457482269832064)\n",
      "     | > loss_dur: 0.1819310188293457  (0.1805021379675184)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: -0.12407277524471283  (-0.11532269604504108)\n",
      "     | > log_mle: -0.29012250900268555  (-0.29401828348636627)\n",
      "     | > loss_dur: 0.16604973375797272  (0.1786955874413252)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: -0.09374755620956421  (-0.11292545828554365)\n",
      "     | > log_mle: -0.30274200439453125  (-0.2949875858094957)\n",
      "     | > loss_dur: 0.20899444818496704  (0.18206212752395207)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: -0.07734566926956177  (-0.10936747938394546)\n",
      "     | > log_mle: -0.287997841835022  (-0.2942886114120483)\n",
      "     | > loss_dur: 0.2106521725654602  (0.18492113202810287)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: -0.10944575071334839  (-0.10937459495934573)\n",
      "     | > log_mle: -0.3052232265472412  (-0.2952826673334295)\n",
      "     | > loss_dur: 0.19577747583389282  (0.18590807237408377)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: -0.1128121167421341  (-0.10966105510791142)\n",
      "     | > log_mle: -0.2910473346710205  (-0.29492972294489544)\n",
      "     | > loss_dur: 0.1782352179288864  (0.185268667836984)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: -0.13190481066703796  (-0.11137211322784424)\n",
      "     | > log_mle: -0.31399333477020264  (-0.29639615462376523)\n",
      "     | > loss_dur: 0.18208852410316467  (0.18502404139592096)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: -0.10045257210731506  (-0.1105921460049493)\n",
      "     | > log_mle: -0.3031914234161377  (-0.29688153096607756)\n",
      "     | > loss_dur: 0.20273885130882263  (0.18628938496112823)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: -0.10643956065177917  (-0.11031530698140463)\n",
      "     | > log_mle: -0.29676318168640137  (-0.29687364101409913)\n",
      "     | > loss_dur: 0.1903236210346222  (0.1865583340326945)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: -0.09534923732280731  (-0.10937992762774229)\n",
      "     | > log_mle: -0.2977278232574463  (-0.2969270274043083)\n",
      "     | > loss_dur: 0.20237858593463898  (0.18754709977656603)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: audio amplitude out of range, auto clipped.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[91m 0.003821849822998047 \u001b[0m(+0.00041778385639190674)\n",
      "     | > avg_loss:\u001b[92m -0.10937992762774229 \u001b[0m(-0.0005677351728081703)\n",
      "     | > avg_log_mle:\u001b[92m -0.2969270274043083 \u001b[0m(-0.0002223476767539978)\n",
      "     | > avg_loss_dur:\u001b[92m 0.18754709977656603 \u001b[0m(-0.0003453874960541725)\n",
      "\n",
      " > BEST MODEL : train/run-February-22-2025_10+59PM-fa84af3/best_model_43436.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 51/100\u001b[0m\n",
      " --> train/run-February-22-2025_10+59PM-fa84af3\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-23 03:26:48) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:26:55 -- STEP: 14/406 -- GLOBAL_STEP: 43450\u001b[0m\n",
      "     | > loss: -0.07358141243457794  (-0.09779856247561318)\n",
      "     | > log_mle: -0.27536606788635254  (-0.2659557972635542)\n",
      "     | > loss_dur: 0.2017846554517746  (0.16815723478794098)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(24.4697, device='cuda:0')  (tensor(17.0584, device='cuda:0'))\n",
      "     | > current_lr: 1.275e-05 \n",
      "     | > step_time: 0.5378  (0.38201466628483366)\n",
      "     | > loader_time: 0.0027  (0.004605122974940708)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:27:10 -- STEP: 39/406 -- GLOBAL_STEP: 43475\u001b[0m\n",
      "     | > loss: -0.06794005632400513  (-0.08563327674682324)\n",
      "     | > log_mle: -0.2557026147842407  (-0.2620303294597528)\n",
      "     | > loss_dur: 0.1877625584602356  (0.17639705271292955)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(21.5378, device='cuda:0')  (tensor(18.4973, device='cuda:0'))\n",
      "     | > current_lr: 1.275e-05 \n",
      "     | > step_time: 0.3077  (0.4976687798133263)\n",
      "     | > loader_time: 0.0045  (0.008239850019797301)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:27:25 -- STEP: 64/406 -- GLOBAL_STEP: 43500\u001b[0m\n",
      "     | > loss: -0.08896768093109131  (-0.08298285584896803)\n",
      "     | > log_mle: -0.2759823799133301  (-0.2634748611599207)\n",
      "     | > loss_dur: 0.18701469898223877  (0.18049200531095266)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(11.7552, device='cuda:0')  (tensor(18.5939, device='cuda:0'))\n",
      "     | > current_lr: 1.275e-05 \n",
      "     | > step_time: 0.5737  (0.5264327526092528)\n",
      "     | > loader_time: 0.0105  (0.008853696286678316)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:27:40 -- STEP: 89/406 -- GLOBAL_STEP: 43525\u001b[0m\n",
      "     | > loss: -0.07333190739154816  (-0.08234995084532193)\n",
      "     | > log_mle: -0.2696264982223511  (-0.2663575009013831)\n",
      "     | > loss_dur: 0.19629459083080292  (0.18400755005606098)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(21.5375, device='cuda:0')  (tensor(19.9925, device='cuda:0'))\n",
      "     | > current_lr: 1.275e-05 \n",
      "     | > step_time: 0.4705  (0.5448082404190235)\n",
      "     | > loader_time: 0.0042  (0.008995482091153603)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:27:56 -- STEP: 114/406 -- GLOBAL_STEP: 43550\u001b[0m\n",
      "     | > loss: -0.11008420586585999  (-0.08262994885444643)\n",
      "     | > log_mle: -0.3066462278366089  (-0.2695791637688352)\n",
      "     | > loss_dur: 0.1965620219707489  (0.18694921491438876)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(36.2579, device='cuda:0')  (tensor(20.8699, device='cuda:0'))\n",
      "     | > current_lr: 1.275e-05 \n",
      "     | > step_time: 0.8398  (0.5640461653993841)\n",
      "     | > loader_time: 0.0203  (0.009521327520671644)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:28:12 -- STEP: 139/406 -- GLOBAL_STEP: 43575\u001b[0m\n",
      "     | > loss: -0.07534188032150269  (-0.08181489811097976)\n",
      "     | > log_mle: -0.2780437469482422  (-0.2715634493519076)\n",
      "     | > loss_dur: 0.2027018666267395  (0.1897485512409278)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(18.8680, device='cuda:0')  (tensor(21.4451, device='cuda:0'))\n",
      "     | > current_lr: 1.275e-05 \n",
      "     | > step_time: 0.8903  (0.5745901615499592)\n",
      "     | > loader_time: 0.0507  (0.009419844304914955)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:28:29 -- STEP: 164/406 -- GLOBAL_STEP: 43600\u001b[0m\n",
      "     | > loss: -0.07320070266723633  (-0.08145796362219786)\n",
      "     | > log_mle: -0.2699981927871704  (-0.2730919464332301)\n",
      "     | > loss_dur: 0.19679749011993408  (0.1916339828110322)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(20.2265, device='cuda:0')  (tensor(22.0432, device='cuda:0'))\n",
      "     | > current_lr: 1.275e-05 \n",
      "     | > step_time: 0.9977  (0.5919706080018019)\n",
      "     | > loader_time: 0.0211  (0.009937210780818283)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:28:47 -- STEP: 189/406 -- GLOBAL_STEP: 43625\u001b[0m\n",
      "     | > loss: -0.08551636338233948  (-0.08180966847157349)\n",
      "     | > log_mle: -0.2872202396392822  (-0.27477978209339105)\n",
      "     | > loss_dur: 0.20170387625694275  (0.19297011362181762)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(26.6911, device='cuda:0')  (tensor(22.5712, device='cuda:0'))\n",
      "     | > current_lr: 1.275e-05 \n",
      "     | > step_time: 0.7238  (0.602912032414996)\n",
      "     | > loader_time: 0.0449  (0.010676140507693005)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:29:05 -- STEP: 214/406 -- GLOBAL_STEP: 43650\u001b[0m\n",
      "     | > loss: -0.09364214539527893  (-0.08205073953510443)\n",
      "     | > log_mle: -0.29326772689819336  (-0.27613590253847764)\n",
      "     | > loss_dur: 0.19962558150291443  (0.1940851630033733)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(28.2421, device='cuda:0')  (tensor(23.4587, device='cuda:0'))\n",
      "     | > current_lr: 1.275e-05 \n",
      "     | > step_time: 0.8071  (0.6138906088944902)\n",
      "     | > loader_time: 0.0273  (0.011189468553133092)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:29:23 -- STEP: 239/406 -- GLOBAL_STEP: 43675\u001b[0m\n",
      "     | > loss: -0.07234324514865875  (-0.08212980852466246)\n",
      "     | > log_mle: -0.2837498188018799  (-0.2775998838775824)\n",
      "     | > loss_dur: 0.21140657365322113  (0.1954700753529201)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(13.6445, device='cuda:0')  (tensor(24.2964, device='cuda:0'))\n",
      "     | > current_lr: 1.275e-05 \n",
      "     | > step_time: 0.4645  (0.6245036115207427)\n",
      "     | > loader_time: 0.0053  (0.011415726968932843)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:29:42 -- STEP: 264/406 -- GLOBAL_STEP: 43700\u001b[0m\n",
      "     | > loss: -0.08244533836841583  (-0.0825489323699113)\n",
      "     | > log_mle: -0.28282344341278076  (-0.27874552210171993)\n",
      "     | > loss_dur: 0.20037810504436493  (0.1961965897318088)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(19.3761, device='cuda:0')  (tensor(24.0305, device='cuda:0'))\n",
      "     | > current_lr: 1.275e-05 \n",
      "     | > step_time: 0.8621  (0.6341574661659468)\n",
      "     | > loader_time: 0.037  (0.01175298383741667)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:30:01 -- STEP: 289/406 -- GLOBAL_STEP: 43725\u001b[0m\n",
      "     | > loss: -0.07886368036270142  (-0.08274006833254675)\n",
      "     | > log_mle: -0.2770693302154541  (-0.27968701771798826)\n",
      "     | > loss_dur: 0.19820564985275269  (0.1969469493854417)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(29.1875, device='cuda:0')  (tensor(24.6495, device='cuda:0'))\n",
      "     | > current_lr: 1.275e-05 \n",
      "     | > step_time: 0.9839  (0.6448191400217759)\n",
      "     | > loader_time: 0.0235  (0.012213891765238086)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:30:21 -- STEP: 314/406 -- GLOBAL_STEP: 43750\u001b[0m\n",
      "     | > loss: -0.09996017813682556  (-0.08300678270637613)\n",
      "     | > log_mle: -0.2988210916519165  (-0.2806650388772319)\n",
      "     | > loss_dur: 0.19886091351509094  (0.19765825617085594)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(17.5896, device='cuda:0')  (tensor(25.1818, device='cuda:0'))\n",
      "     | > current_lr: 1.275e-05 \n",
      "     | > step_time: 0.7626  (0.6544128010986713)\n",
      "     | > loader_time: 0.0173  (0.012361023076780277)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:30:41 -- STEP: 339/406 -- GLOBAL_STEP: 43775\u001b[0m\n",
      "     | > loss: -0.08247220516204834  (-0.08299258953526313)\n",
      "     | > log_mle: -0.29511749744415283  (-0.281403179365625)\n",
      "     | > loss_dur: 0.2126452922821045  (0.198410589830362)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(27.1428, device='cuda:0')  (tensor(25.4969, device='cuda:0'))\n",
      "     | > current_lr: 1.275e-05 \n",
      "     | > step_time: 0.6945  (0.6636846339808099)\n",
      "     | > loader_time: 0.0213  (0.012577010466989152)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:31:01 -- STEP: 364/406 -- GLOBAL_STEP: 43800\u001b[0m\n",
      "     | > loss: -0.08226169645786285  (-0.08297771330063161)\n",
      "     | > log_mle: -0.2885599136352539  (-0.282258845947601)\n",
      "     | > loss_dur: 0.20629821717739105  (0.1992811326469694)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(23.8225, device='cuda:0')  (tensor(25.6795, device='cuda:0'))\n",
      "     | > current_lr: 1.275e-05 \n",
      "     | > step_time: 0.6982  (0.6727570622831911)\n",
      "     | > loader_time: 0.0071  (0.012646010288825392)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:31:22 -- STEP: 389/406 -- GLOBAL_STEP: 43825\u001b[0m\n",
      "     | > loss: -0.08582907915115356  (-0.08304985507288447)\n",
      "     | > log_mle: -0.2890346050262451  (-0.2829388818275038)\n",
      "     | > loss_dur: 0.20320552587509155  (0.19988902675461953)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(34.5407, device='cuda:0')  (tensor(26.0893, device='cuda:0'))\n",
      "     | > current_lr: 1.275e-05 \n",
      "     | > step_time: 0.842  (0.6828833202469932)\n",
      "     | > loader_time: 0.0466  (0.012754257663050154)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: -0.069959357380867  (-0.069959357380867)\n",
      "     | > log_mle: -0.2673604488372803  (-0.2673604488372803)\n",
      "     | > loss_dur: 0.19740109145641327  (0.19740109145641327)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: -0.14319364726543427  (-0.14319364726543427)\n",
      "     | > log_mle: -0.30759644508361816  (-0.30759644508361816)\n",
      "     | > loss_dur: 0.1644027978181839  (0.1644027978181839)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: -0.11042991280555725  (-0.12681178003549576)\n",
      "     | > log_mle: -0.2691171169281006  (-0.2883567810058594)\n",
      "     | > loss_dur: 0.15868720412254333  (0.16154500097036362)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: -0.10509215295314789  (-0.1195719043413798)\n",
      "     | > log_mle: -0.2816500663757324  (-0.2861212094624837)\n",
      "     | > loss_dur: 0.17655791342258453  (0.1665493051211039)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: -0.134336918592453  (-0.1232631579041481)\n",
      "     | > log_mle: -0.3083442449569702  (-0.29167696833610535)\n",
      "     | > loss_dur: 0.1740073263645172  (0.16841381043195724)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: -0.13218048214912415  (-0.12504662275314332)\n",
      "     | > log_mle: -0.30778610706329346  (-0.29489879608154296)\n",
      "     | > loss_dur: 0.1756056249141693  (0.16985217332839966)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: -0.07971003651618958  (-0.11749052504698436)\n",
      "     | > log_mle: -0.31642186641693115  (-0.29848597447077435)\n",
      "     | > loss_dur: 0.23671182990074158  (0.18099544942378998)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: -0.09816215932369232  (-0.11472932994365692)\n",
      "     | > log_mle: -0.2789195775985718  (-0.29569077491760254)\n",
      "     | > loss_dur: 0.18075741827487946  (0.18096144497394562)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: -0.1255771815776825  (-0.11608531139791012)\n",
      "     | > log_mle: -0.29194164276123047  (-0.29522213339805603)\n",
      "     | > loss_dur: 0.16636446118354797  (0.1791368220001459)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: -0.09565931558609009  (-0.11381575630770789)\n",
      "     | > log_mle: -0.3041231632232666  (-0.2962111367119683)\n",
      "     | > loss_dur: 0.2084638476371765  (0.18239538040426043)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: -0.08387482166290283  (-0.11082166284322739)\n",
      "     | > log_mle: -0.28930795192718506  (-0.29552081823348997)\n",
      "     | > loss_dur: 0.20543313026428223  (0.1846991553902626)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: -0.10814020037651062  (-0.11057789352807132)\n",
      "     | > log_mle: -0.3067575693130493  (-0.2965423410589045)\n",
      "     | > loss_dur: 0.1986173689365387  (0.18596444753083316)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: -0.11452946066856384  (-0.11090719078977902)\n",
      "     | > log_mle: -0.29297423362731934  (-0.296244998772939)\n",
      "     | > loss_dur: 0.1784447729587555  (0.18533780798316002)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: -0.13723967969417572  (-0.112932766859348)\n",
      "     | > log_mle: -0.31366539001464844  (-0.29758502886845517)\n",
      "     | > loss_dur: 0.17642571032047272  (0.18465226200910714)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: -0.10778249800205231  (-0.1125648905123983)\n",
      "     | > log_mle: -0.304050087928772  (-0.29804681880133493)\n",
      "     | > loss_dur: 0.19626758992671967  (0.18548192828893661)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: -0.11014203727245331  (-0.11240336696306864)\n",
      "     | > log_mle: -0.29775357246398926  (-0.29802726904551186)\n",
      "     | > loss_dur: 0.18761153519153595  (0.18562390208244323)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: -0.10127127170562744  (-0.11170761100947857)\n",
      "     | > log_mle: -0.2988402843475342  (-0.2980780825018883)\n",
      "     | > loss_dur: 0.19756901264190674  (0.1863704714924097)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: audio amplitude out of range, auto clipped.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.0033137500286102295 \u001b[0m(-0.0005080997943878174)\n",
      "     | > avg_loss:\u001b[92m -0.11170761100947857 \u001b[0m(-0.0023276833817362785)\n",
      "     | > avg_log_mle:\u001b[92m -0.2980780825018883 \u001b[0m(-0.001151055097579956)\n",
      "     | > avg_loss_dur:\u001b[92m 0.1863704714924097 \u001b[0m(-0.0011766282841563225)\n",
      "\n",
      " > BEST MODEL : train/run-February-22-2025_10+59PM-fa84af3/best_model_43842.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 52/100\u001b[0m\n",
      " --> train/run-February-22-2025_10+59PM-fa84af3\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-23 03:31:47) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:31:52 -- STEP: 8/406 -- GLOBAL_STEP: 43850\u001b[0m\n",
      "     | > loss: -0.12580673396587372  (-0.1020219624042511)\n",
      "     | > log_mle: -0.27539122104644775  (-0.2662690132856369)\n",
      "     | > loss_dur: 0.14958448708057404  (0.1642470508813858)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(26.9448, device='cuda:0')  (tensor(23.9821, device='cuda:0'))\n",
      "     | > current_lr: 1.3e-05 \n",
      "     | > step_time: 0.4828  (0.38972875475883484)\n",
      "     | > loader_time: 0.0056  (0.0050743818283081055)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:32:06 -- STEP: 33/406 -- GLOBAL_STEP: 43875\u001b[0m\n",
      "     | > loss: -0.06669867038726807  (-0.09158995657256155)\n",
      "     | > log_mle: -0.2554985284805298  (-0.2660547350392197)\n",
      "     | > loss_dur: 0.18879985809326172  (0.17446477846665817)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(14.0284, device='cuda:0')  (tensor(19.0359, device='cuda:0'))\n",
      "     | > current_lr: 1.3e-05 \n",
      "     | > step_time: 0.345  (0.48861553452231665)\n",
      "     | > loader_time: 0.0046  (0.006721048644094756)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:32:20 -- STEP: 58/406 -- GLOBAL_STEP: 43900\u001b[0m\n",
      "     | > loss: -0.08522124588489532  (-0.08708324026444861)\n",
      "     | > log_mle: -0.271586537361145  (-0.2663233382948513)\n",
      "     | > loss_dur: 0.1863652914762497  (0.17924009803040275)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(17.2879, device='cuda:0')  (tensor(19.3788, device='cuda:0'))\n",
      "     | > current_lr: 1.3e-05 \n",
      "     | > step_time: 0.8612  (0.524622469112791)\n",
      "     | > loader_time: 0.0192  (0.007379005695211476)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:32:35 -- STEP: 83/406 -- GLOBAL_STEP: 43925\u001b[0m\n",
      "     | > loss: -0.09144259989261627  (-0.08566263515547097)\n",
      "     | > log_mle: -0.28091907501220703  (-0.26840750998761276)\n",
      "     | > loss_dur: 0.18947647511959076  (0.18274487483214183)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(34.3941, device='cuda:0')  (tensor(20.4336, device='cuda:0'))\n",
      "     | > current_lr: 1.3e-05 \n",
      "     | > step_time: 0.5314  (0.5334913328469522)\n",
      "     | > loader_time: 0.0121  (0.009001717509993588)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:32:50 -- STEP: 108/406 -- GLOBAL_STEP: 43950\u001b[0m\n",
      "     | > loss: -0.09141342341899872  (-0.08512668049445858)\n",
      "     | > log_mle: -0.27446210384368896  (-0.2709848626896187)\n",
      "     | > loss_dur: 0.18304868042469025  (0.18585818219516012)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(27.2682, device='cuda:0')  (tensor(22.3777, device='cuda:0'))\n",
      "     | > current_lr: 1.3e-05 \n",
      "     | > step_time: 0.3186  (0.54685906789921)\n",
      "     | > loader_time: 0.0059  (0.009522204045896177)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:33:06 -- STEP: 133/406 -- GLOBAL_STEP: 43975\u001b[0m\n",
      "     | > loss: -0.08627130091190338  (-0.08555639484771212)\n",
      "     | > log_mle: -0.28905248641967773  (-0.2736882060990298)\n",
      "     | > loss_dur: 0.20278118550777435  (0.18813181125131764)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(15.5401, device='cuda:0')  (tensor(23.2147, device='cuda:0'))\n",
      "     | > current_lr: 1.3e-05 \n",
      "     | > step_time: 0.748  (0.5594267665891723)\n",
      "     | > loader_time: 0.0431  (0.010209915333224419)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:33:22 -- STEP: 158/406 -- GLOBAL_STEP: 44000\u001b[0m\n",
      "     | > loss: -0.07538124918937683  (-0.08462991376843632)\n",
      "     | > log_mle: -0.28888821601867676  (-0.27504175297821615)\n",
      "     | > loss_dur: 0.21350696682929993  (0.19041183920977983)\n",
      "     | > amp_scaler: 8192.0  (4147.848101265823)\n",
      "     | > grad_norm: tensor(28.0495, device='cuda:0')  (tensor(23.4935, device='cuda:0'))\n",
      "     | > current_lr: 1.3e-05 \n",
      "     | > step_time: 0.5823  (0.5697482220734228)\n",
      "     | > loader_time: 0.0069  (0.010873610460305516)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:33:39 -- STEP: 183/406 -- GLOBAL_STEP: 44025\u001b[0m\n",
      "     | > loss: -0.08781270682811737  (-0.08438462768096089)\n",
      "     | > log_mle: -0.2873278856277466  (-0.27635201925788405)\n",
      "     | > loss_dur: 0.1995151787996292  (0.19196739157692327)\n",
      "     | > amp_scaler: 8192.0  (4700.327868852456)\n",
      "     | > grad_norm: tensor(69.5284, device='cuda:0')  (tensor(24.3090, device='cuda:0'))\n",
      "     | > current_lr: 1.3e-05 \n",
      "     | > step_time: 0.6148  (0.5839998200942916)\n",
      "     | > loader_time: 0.0087  (0.01123739461429783)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:33:57 -- STEP: 208/406 -- GLOBAL_STEP: 44050\u001b[0m\n",
      "     | > loss: -0.09935024380683899  (-0.08395866763133265)\n",
      "     | > log_mle: -0.29416120052337646  (-0.2774390188547281)\n",
      "     | > loss_dur: 0.19481095671653748  (0.19348035122339538)\n",
      "     | > amp_scaler: 4096.0  (4627.692307692307)\n",
      "     | > grad_norm: tensor(34.3336, device='cuda:0')  (tensor(25.0408, device='cuda:0'))\n",
      "     | > current_lr: 1.3e-05 \n",
      "     | > step_time: 0.5732  (0.5978441479114391)\n",
      "     | > loader_time: 0.0213  (0.011925415350840638)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:34:15 -- STEP: 233/406 -- GLOBAL_STEP: 44075\u001b[0m\n",
      "     | > loss: -0.08327880501747131  (-0.08417851301989328)\n",
      "     | > log_mle: -0.2962017059326172  (-0.2789597506175226)\n",
      "     | > loss_dur: 0.21292290091514587  (0.1947812375976292)\n",
      "     | > amp_scaler: 4096.0  (4570.643776824036)\n",
      "     | > grad_norm: tensor(29.4906, device='cuda:0')  (tensor(25.7647, device='cuda:0'))\n",
      "     | > current_lr: 1.3e-05 \n",
      "     | > step_time: 0.579  (0.6069444678883701)\n",
      "     | > loader_time: 0.0175  (0.01196964718241548)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:34:34 -- STEP: 258/406 -- GLOBAL_STEP: 44100\u001b[0m\n",
      "     | > loss: -0.08155587315559387  (-0.08450849464004351)\n",
      "     | > log_mle: -0.2772759199142456  (-0.28021940242412485)\n",
      "     | > loss_dur: 0.19572004675865173  (0.1957109077840812)\n",
      "     | > amp_scaler: 4096.0  (4524.651162790698)\n",
      "     | > grad_norm: tensor(16.4773, device='cuda:0')  (tensor(26.0920, device='cuda:0'))\n",
      "     | > current_lr: 1.3e-05 \n",
      "     | > step_time: 0.7435  (0.6211121997167902)\n",
      "     | > loader_time: 0.0076  (0.012471993764241534)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:34:52 -- STEP: 283/406 -- GLOBAL_STEP: 44125\u001b[0m\n",
      "     | > loss: -0.0808040052652359  (-0.0848837030965953)\n",
      "     | > log_mle: -0.2918514013290405  (-0.2813088978137228)\n",
      "     | > loss_dur: 0.21104739606380463  (0.19642519471712744)\n",
      "     | > amp_scaler: 4096.0  (4486.784452296822)\n",
      "     | > grad_norm: tensor(21.1831, device='cuda:0')  (tensor(26.7162, device='cuda:0'))\n",
      "     | > current_lr: 1.3e-05 \n",
      "     | > step_time: 0.7929  (0.6291255883530261)\n",
      "     | > loader_time: 0.0185  (0.012352368856908573)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:35:10 -- STEP: 308/406 -- GLOBAL_STEP: 44150\u001b[0m\n",
      "     | > loss: -0.07974523305892944  (-0.08479042273837246)\n",
      "     | > log_mle: -0.2929195165634155  (-0.2820544943406983)\n",
      "     | > loss_dur: 0.21317428350448608  (0.19726407160232579)\n",
      "     | > amp_scaler: 4096.0  (4455.0649350649355)\n",
      "     | > grad_norm: tensor(25.6133, device='cuda:0')  (tensor(27.3157, device='cuda:0'))\n",
      "     | > current_lr: 1.3e-05 \n",
      "     | > step_time: 0.769  (0.6358390295660346)\n",
      "     | > loader_time: 0.0274  (0.012610881359546211)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:35:30 -- STEP: 333/406 -- GLOBAL_STEP: 44175\u001b[0m\n",
      "     | > loss: -0.09010963141918182  (-0.08471149546248055)\n",
      "     | > log_mle: -0.2982363700866699  (-0.2826492206470384)\n",
      "     | > loss_dur: 0.2081267386674881  (0.1979377251845579)\n",
      "     | > amp_scaler: 4096.0  (4428.108108108109)\n",
      "     | > grad_norm: tensor(71.6434, device='cuda:0')  (tensor(27.8818, device='cuda:0'))\n",
      "     | > current_lr: 1.3e-05 \n",
      "     | > step_time: 0.8279  (0.644663411217767)\n",
      "     | > loader_time: 0.0397  (0.013050023499909816)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:35:50 -- STEP: 358/406 -- GLOBAL_STEP: 44200\u001b[0m\n",
      "     | > loss: -0.09958431124687195  (-0.08423562947265262)\n",
      "     | > log_mle: -0.30488264560699463  (-0.2831953311099685)\n",
      "     | > loss_dur: 0.20529833436012268  (0.1989597016373159)\n",
      "     | > amp_scaler: 4096.0  (4404.916201117319)\n",
      "     | > grad_norm: tensor(25.7496, device='cuda:0')  (tensor(28.5697, device='cuda:0'))\n",
      "     | > current_lr: 1.3e-05 \n",
      "     | > step_time: 0.8496  (0.6538489584150262)\n",
      "     | > loader_time: 0.0286  (0.013106326151160549)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:36:11 -- STEP: 383/406 -- GLOBAL_STEP: 44225\u001b[0m\n",
      "     | > loss: -0.07595644891262054  (-0.08409881144372973)\n",
      "     | > log_mle: -0.28376471996307373  (-0.2836734246336137)\n",
      "     | > loss_dur: 0.20780827105045319  (0.1995746131898839)\n",
      "     | > amp_scaler: 4096.0  (4384.751958224544)\n",
      "     | > grad_norm: tensor(20.4052, device='cuda:0')  (tensor(28.8167, device='cuda:0'))\n",
      "     | > current_lr: 1.3e-05 \n",
      "     | > step_time: 0.8255  (0.664296066792142)\n",
      "     | > loader_time: 0.0072  (0.013177115363178298)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: -0.06974847614765167  (-0.06974847614765167)\n",
      "     | > log_mle: -0.2679227590560913  (-0.2679227590560913)\n",
      "     | > loss_dur: 0.19817428290843964  (0.19817428290843964)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: -0.13882696628570557  (-0.13882696628570557)\n",
      "     | > log_mle: -0.3081510066986084  (-0.3081510066986084)\n",
      "     | > loss_dur: 0.16932404041290283  (0.16932404041290283)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: -0.11450117826461792  (-0.12666407227516174)\n",
      "     | > log_mle: -0.27055132389068604  (-0.2893511652946472)\n",
      "     | > loss_dur: 0.15605014562606812  (0.16268709301948547)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: -0.11660286784172058  (-0.1233103374640147)\n",
      "     | > log_mle: -0.28167200088500977  (-0.28679144382476807)\n",
      "     | > loss_dur: 0.16506913304328918  (0.1634811063607534)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: -0.1362520456314087  (-0.1265457645058632)\n",
      "     | > log_mle: -0.3081521987915039  (-0.292131632566452)\n",
      "     | > loss_dur: 0.17190015316009521  (0.16558586806058884)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: -0.13023492693901062  (-0.12728359699249267)\n",
      "     | > log_mle: -0.3087249994277954  (-0.2954503059387207)\n",
      "     | > loss_dur: 0.1784900724887848  (0.16816670894622804)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: -0.08036620914936066  (-0.11946403235197067)\n",
      "     | > log_mle: -0.3161255121231079  (-0.2988961736361186)\n",
      "     | > loss_dur: 0.23575930297374725  (0.1794321412841479)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: -0.10224597156047821  (-0.11700430938175746)\n",
      "     | > log_mle: -0.2792975902557373  (-0.2960963760103498)\n",
      "     | > loss_dur: 0.1770516186952591  (0.17909206662859237)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: -0.13091415166854858  (-0.11874303966760635)\n",
      "     | > log_mle: -0.2921311855316162  (-0.2956007272005081)\n",
      "     | > loss_dur: 0.16121703386306763  (0.17685768753290176)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: -0.09162576496601105  (-0.11573000914520687)\n",
      "     | > log_mle: -0.3036116361618042  (-0.2964908281962077)\n",
      "     | > loss_dur: 0.21198587119579315  (0.1807608190510008)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: -0.08264060318470001  (-0.11242106854915619)\n",
      "     | > log_mle: -0.2901918888092041  (-0.2958609342575073)\n",
      "     | > loss_dur: 0.2075512856245041  (0.18343986570835114)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: -0.10803166031837463  (-0.11202203143726695)\n",
      "     | > log_mle: -0.30651772022247314  (-0.29682973298159515)\n",
      "     | > loss_dur: 0.1984860599040985  (0.18480770154432816)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: -0.12193149328231812  (-0.11284781992435455)\n",
      "     | > log_mle: -0.29286444187164307  (-0.2964992920557658)\n",
      "     | > loss_dur: 0.17093294858932495  (0.18365147213141123)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: -0.1371842324733734  (-0.11471985165889446)\n",
      "     | > log_mle: -0.31505024433135986  (-0.2979262883846576)\n",
      "     | > loss_dur: 0.17786601185798645  (0.18320643672576317)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: -0.10403113067150116  (-0.11395637158836637)\n",
      "     | > log_mle: -0.30445778369903564  (-0.2983928237642561)\n",
      "     | > loss_dur: 0.20042665302753448  (0.1844364521758897)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: -0.11483742296695709  (-0.11401510834693909)\n",
      "     | > log_mle: -0.2983008623123169  (-0.29838669300079346)\n",
      "     | > loss_dur: 0.1834634393453598  (0.18437158465385436)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: -0.09636799991130829  (-0.11291216406971216)\n",
      "     | > log_mle: -0.29879510402679443  (-0.2984122186899185)\n",
      "     | > loss_dur: 0.20242710411548615  (0.18550005462020636)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: audio amplitude out of range, auto clipped.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[91m 0.003899648785591127 \u001b[0m(+0.0005858987569808973)\n",
      "     | > avg_loss:\u001b[92m -0.11291216406971216 \u001b[0m(-0.001204553060233593)\n",
      "     | > avg_log_mle:\u001b[92m -0.2984122186899185 \u001b[0m(-0.0003341361880302429)\n",
      "     | > avg_loss_dur:\u001b[92m 0.18550005462020636 \u001b[0m(-0.0008704168722033501)\n",
      "\n",
      " > BEST MODEL : train/run-February-22-2025_10+59PM-fa84af3/best_model_44248.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 53/100\u001b[0m\n",
      " --> train/run-February-22-2025_10+59PM-fa84af3\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-23 03:36:42) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:36:45 -- STEP: 2/406 -- GLOBAL_STEP: 44250\u001b[0m\n",
      "     | > loss: -0.12613557279109955  (-0.12309597432613373)\n",
      "     | > log_mle: -0.2809901237487793  (-0.2736174464225769)\n",
      "     | > loss_dur: 0.15485455095767975  (0.15052147209644318)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(25.4321, device='cuda:0')  (tensor(21.1775, device='cuda:0'))\n",
      "     | > current_lr: 1.325e-05 \n",
      "     | > step_time: 0.3691  (0.5109878778457642)\n",
      "     | > loader_time: 0.0027  (0.008030295372009277)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:36:57 -- STEP: 27/406 -- GLOBAL_STEP: 44275\u001b[0m\n",
      "     | > loss: -0.09822958707809448  (-0.09678571146947366)\n",
      "     | > log_mle: -0.2634161710739136  (-0.2668171458774143)\n",
      "     | > loss_dur: 0.1651865839958191  (0.1700314344079406)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(13.3857, device='cuda:0')  (tensor(24.3977, device='cuda:0'))\n",
      "     | > current_lr: 1.325e-05 \n",
      "     | > step_time: 0.5217  (0.4615717375719989)\n",
      "     | > loader_time: 0.004  (0.008666700787014432)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:37:12 -- STEP: 52/406 -- GLOBAL_STEP: 44300\u001b[0m\n",
      "     | > loss: -0.0425051748752594  (-0.0881338082253933)\n",
      "     | > log_mle: -0.26289403438568115  (-0.2656019811446849)\n",
      "     | > loss_dur: 0.22038885951042175  (0.17746817291929168)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(12.9294, device='cuda:0')  (tensor(22.7647, device='cuda:0'))\n",
      "     | > current_lr: 1.325e-05 \n",
      "     | > step_time: 0.4248  (0.5192269224386948)\n",
      "     | > loader_time: 0.0236  (0.011028927106123704)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:37:27 -- STEP: 77/406 -- GLOBAL_STEP: 44325\u001b[0m\n",
      "     | > loss: -0.06092333793640137  (-0.08705373921177605)\n",
      "     | > log_mle: -0.2616574764251709  (-0.2677108297100314)\n",
      "     | > loss_dur: 0.20073413848876953  (0.18065709049825546)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(21.9728, device='cuda:0')  (tensor(22.0342, device='cuda:0'))\n",
      "     | > current_lr: 1.325e-05 \n",
      "     | > step_time: 0.2833  (0.5440556136044589)\n",
      "     | > loader_time: 0.0051  (0.012461361946997705)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:37:42 -- STEP: 102/406 -- GLOBAL_STEP: 44350\u001b[0m\n",
      "     | > loss: -0.10686297714710236  (-0.08626515783515631)\n",
      "     | > log_mle: -0.2902618646621704  (-0.2705715520709169)\n",
      "     | > loss_dur: 0.18339888751506805  (0.18430639423576056)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(15.6552, device='cuda:0')  (tensor(20.2932, device='cuda:0'))\n",
      "     | > current_lr: 1.325e-05 \n",
      "     | > step_time: 0.7271  (0.5536235290415147)\n",
      "     | > loader_time: 0.0044  (0.011809227513331993)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:37:57 -- STEP: 127/406 -- GLOBAL_STEP: 44375\u001b[0m\n",
      "     | > loss: -0.0817066878080368  (-0.08668375848315832)\n",
      "     | > log_mle: -0.2863830327987671  (-0.2732928859905935)\n",
      "     | > loss_dur: 0.20467634499073029  (0.18660912750743505)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(31.8463, device='cuda:0')  (tensor(21.6561, device='cuda:0'))\n",
      "     | > current_lr: 1.325e-05 \n",
      "     | > step_time: 0.328  (0.5619654373859797)\n",
      "     | > loader_time: 0.0056  (0.011438118191215936)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:38:13 -- STEP: 152/406 -- GLOBAL_STEP: 44400\u001b[0m\n",
      "     | > loss: -0.07485447824001312  (-0.08674426484656962)\n",
      "     | > log_mle: -0.28188860416412354  (-0.2754994646499032)\n",
      "     | > loss_dur: 0.2070341259241104  (0.18875519980333352)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(25.5504, device='cuda:0')  (tensor(22.8448, device='cuda:0'))\n",
      "     | > current_lr: 1.325e-05 \n",
      "     | > step_time: 0.5992  (0.5724740185235677)\n",
      "     | > loader_time: 0.0056  (0.0110056902232923)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:38:30 -- STEP: 177/406 -- GLOBAL_STEP: 44425\u001b[0m\n",
      "     | > loss: -0.08537976443767548  (-0.08688850372524581)\n",
      "     | > log_mle: -0.2889634370803833  (-0.27712887087784255)\n",
      "     | > loss_dur: 0.20358367264270782  (0.1902403671525966)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(29.5796, device='cuda:0')  (tensor(23.3793, device='cuda:0'))\n",
      "     | > current_lr: 1.325e-05 \n",
      "     | > step_time: 0.4  (0.5843032026021497)\n",
      "     | > loader_time: 0.0184  (0.011878831238396424)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:38:48 -- STEP: 202/406 -- GLOBAL_STEP: 44450\u001b[0m\n",
      "     | > loss: -0.062764972448349  (-0.08686766072665111)\n",
      "     | > log_mle: -0.27619051933288574  (-0.2785792669447344)\n",
      "     | > loss_dur: 0.21342554688453674  (0.19171160621808306)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(17.2994, device='cuda:0')  (tensor(23.5809, device='cuda:0'))\n",
      "     | > current_lr: 1.325e-05 \n",
      "     | > step_time: 0.5856  (0.5956743955612185)\n",
      "     | > loader_time: 0.0068  (0.012207124492909649)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:39:04 -- STEP: 227/406 -- GLOBAL_STEP: 44475\u001b[0m\n",
      "     | > loss: -0.07675634324550629  (-0.08692545755581708)\n",
      "     | > log_mle: -0.28529465198516846  (-0.27995868138804875)\n",
      "     | > loss_dur: 0.20853830873966217  (0.19303322383223126)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(31.3724, device='cuda:0')  (tensor(24.7130, device='cuda:0'))\n",
      "     | > current_lr: 1.325e-05 \n",
      "     | > step_time: 0.7064  (0.6002760637174097)\n",
      "     | > loader_time: 0.0056  (0.012124367222386835)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:39:23 -- STEP: 252/406 -- GLOBAL_STEP: 44500\u001b[0m\n",
      "     | > loss: -0.0814775675535202  (-0.08702033728597657)\n",
      "     | > log_mle: -0.2865731716156006  (-0.2812227554737579)\n",
      "     | > loss_dur: 0.20509560406208038  (0.19420241818778097)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(23.7775, device='cuda:0')  (tensor(24.5570, device='cuda:0'))\n",
      "     | > current_lr: 1.325e-05 \n",
      "     | > step_time: 0.473  (0.6123201998453295)\n",
      "     | > loader_time: 0.0056  (0.012656550558786544)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:39:41 -- STEP: 277/406 -- GLOBAL_STEP: 44525\u001b[0m\n",
      "     | > loss: -0.09490029513835907  (-0.08740432388300501)\n",
      "     | > log_mle: -0.2904454469680786  (-0.28232244162783326)\n",
      "     | > loss_dur: 0.19554515182971954  (0.19491811774482795)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(21.6924, device='cuda:0')  (tensor(25.2980, device='cuda:0'))\n",
      "     | > current_lr: 1.325e-05 \n",
      "     | > step_time: 0.6485  (0.6199736095938014)\n",
      "     | > loader_time: 0.0054  (0.012819470911680144)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:40:00 -- STEP: 302/406 -- GLOBAL_STEP: 44550\u001b[0m\n",
      "     | > loss: -0.08454611897468567  (-0.08759344689893409)\n",
      "     | > log_mle: -0.29905784130096436  (-0.2833405721266542)\n",
      "     | > loss_dur: 0.2145117223262787  (0.19574712522771975)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(18.9516, device='cuda:0')  (tensor(25.6930, device='cuda:0'))\n",
      "     | > current_lr: 1.325e-05 \n",
      "     | > step_time: 0.8676  (0.6306117244114153)\n",
      "     | > loader_time: 0.006  (0.013017793364872205)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:40:19 -- STEP: 327/406 -- GLOBAL_STEP: 44575\u001b[0m\n",
      "     | > loss: -0.08414654433727264  (-0.08773713196636342)\n",
      "     | > log_mle: -0.2885777950286865  (-0.28403321172848417)\n",
      "     | > loss_dur: 0.20443125069141388  (0.19629607976212046)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(18.1985, device='cuda:0')  (tensor(25.8348, device='cuda:0'))\n",
      "     | > current_lr: 1.325e-05 \n",
      "     | > step_time: 0.4535  (0.6389985777187059)\n",
      "     | > loader_time: 0.0077  (0.01293936417372584)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:40:39 -- STEP: 352/406 -- GLOBAL_STEP: 44600\u001b[0m\n",
      "     | > loss: -0.08590944111347198  (-0.08748922814530409)\n",
      "     | > log_mle: -0.2896972894668579  (-0.28476054052060334)\n",
      "     | > loss_dur: 0.20378784835338593  (0.1972713123752989)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(45.1115, device='cuda:0')  (tensor(26.2359, device='cuda:0'))\n",
      "     | > current_lr: 1.325e-05 \n",
      "     | > step_time: 0.9433  (0.6491958092559473)\n",
      "     | > loader_time: 0.0332  (0.013032166117971594)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:40:59 -- STEP: 377/406 -- GLOBAL_STEP: 44625\u001b[0m\n",
      "     | > loss: -0.08021330833435059  (-0.08775428534344591)\n",
      "     | > log_mle: -0.29335176944732666  (-0.2856997447557729)\n",
      "     | > loss_dur: 0.21313846111297607  (0.19794545941232683)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(27.3808, device='cuda:0')  (tensor(26.5400, device='cuda:0'))\n",
      "     | > current_lr: 1.325e-05 \n",
      "     | > step_time: 1.0879  (0.6589221328259783)\n",
      "     | > loader_time: 0.0116  (0.013072863181642892)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:41:17 -- STEP: 402/406 -- GLOBAL_STEP: 44650\u001b[0m\n",
      "     | > loss: -0.09668809175491333  (-0.08781473090251289)\n",
      "     | > log_mle: -0.3047299385070801  (-0.2863967113233918)\n",
      "     | > loss_dur: 0.20804184675216675  (0.19858198042087882)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(41.0858, device='cuda:0')  (tensor(27.0144, device='cuda:0'))\n",
      "     | > current_lr: 1.325e-05 \n",
      "     | > step_time: 0.6008  (0.6604405724587135)\n",
      "     | > loader_time: 0.0071  (0.01302035175152679)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: -0.07306994497776031  (-0.07306994497776031)\n",
      "     | > log_mle: -0.27009117603302  (-0.27009117603302)\n",
      "     | > loss_dur: 0.1970212310552597  (0.1970212310552597)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: -0.14637304842472076  (-0.14637304842472076)\n",
      "     | > log_mle: -0.3093935251235962  (-0.3093935251235962)\n",
      "     | > loss_dur: 0.16302047669887543  (0.16302047669887543)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: -0.11509039998054504  (-0.1307317242026329)\n",
      "     | > log_mle: -0.27195489406585693  (-0.29067420959472656)\n",
      "     | > loss_dur: 0.1568644940853119  (0.15994248539209366)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: -0.11924026906490326  (-0.12690123915672302)\n",
      "     | > log_mle: -0.283491849899292  (-0.28828008969624835)\n",
      "     | > loss_dur: 0.16425158083438873  (0.16137885053952536)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: -0.13859319686889648  (-0.1298242285847664)\n",
      "     | > log_mle: -0.3095446825027466  (-0.2935962378978729)\n",
      "     | > loss_dur: 0.1709514856338501  (0.16377200931310654)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: -0.13329719007015228  (-0.13051882088184358)\n",
      "     | > log_mle: -0.30718207359313965  (-0.29631340503692627)\n",
      "     | > loss_dur: 0.17388488352298737  (0.1657945841550827)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: -0.07762892544269562  (-0.12170383830865224)\n",
      "     | > log_mle: -0.31494081020355225  (-0.29941797256469727)\n",
      "     | > loss_dur: 0.23731188476085663  (0.17771413425604501)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: -0.1000312864780426  (-0.11860775947570801)\n",
      "     | > log_mle: -0.28038716316223145  (-0.29669928550720215)\n",
      "     | > loss_dur: 0.18035587668418884  (0.17809152603149414)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: -0.13357733190059662  (-0.12047895602881908)\n",
      "     | > log_mle: -0.2934541702270508  (-0.2962936460971832)\n",
      "     | > loss_dur: 0.15987683832645416  (0.17581469006836414)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: -0.09769454598426819  (-0.11794735491275787)\n",
      "     | > log_mle: -0.3042203187942505  (-0.2971743875079685)\n",
      "     | > loss_dur: 0.2065257728099823  (0.1792270325952106)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: -0.08786463737487793  (-0.11493908315896988)\n",
      "     | > log_mle: -0.290960431098938  (-0.2965529918670654)\n",
      "     | > loss_dur: 0.20309579372406006  (0.18161390870809554)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: -0.11409157514572144  (-0.1148620369759473)\n",
      "     | > log_mle: -0.30760514736175537  (-0.2975577332756736)\n",
      "     | > loss_dur: 0.19351357221603394  (0.18269569629972632)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: -0.12277448177337646  (-0.11552140737573306)\n",
      "     | > log_mle: -0.2946118116378784  (-0.29731223980585736)\n",
      "     | > loss_dur: 0.17183732986450195  (0.18179083243012428)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: -0.13219790160655975  (-0.11680421462425819)\n",
      "     | > log_mle: -0.3143106698989868  (-0.2986198113514827)\n",
      "     | > loss_dur: 0.18211276829242706  (0.1818155967272245)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: -0.10536594688892365  (-0.11598719550030571)\n",
      "     | > log_mle: -0.3052314519882202  (-0.2990920713969639)\n",
      "     | > loss_dur: 0.19986550509929657  (0.18310487589665822)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: -0.11220245063304901  (-0.11573487917582194)\n",
      "     | > log_mle: -0.2986302375793457  (-0.2990612824757894)\n",
      "     | > loss_dur: 0.1864277869462967  (0.18332640329996744)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: -0.10575510561466217  (-0.11511114332824945)\n",
      "     | > log_mle: -0.2996445894241333  (-0.2990977391600609)\n",
      "     | > loss_dur: 0.19388948380947113  (0.18398659583181143)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: audio amplitude out of range, auto clipped.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.003232300281524658 \u001b[0m(-0.0006673485040664686)\n",
      "     | > avg_loss:\u001b[92m -0.11511114332824945 \u001b[0m(-0.0021989792585372925)\n",
      "     | > avg_log_mle:\u001b[92m -0.2990977391600609 \u001b[0m(-0.0006855204701423645)\n",
      "     | > avg_loss_dur:\u001b[92m 0.18398659583181143 \u001b[0m(-0.001513458788394928)\n",
      "\n",
      " > BEST MODEL : train/run-February-22-2025_10+59PM-fa84af3/best_model_44654.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 54/100\u001b[0m\n",
      " --> train/run-February-22-2025_10+59PM-fa84af3\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-23 03:41:34) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:41:47 -- STEP: 21/406 -- GLOBAL_STEP: 44675\u001b[0m\n",
      "     | > loss: -0.09430044889450073  (-0.10144783556461334)\n",
      "     | > log_mle: -0.27129650115966797  (-0.268403104373387)\n",
      "     | > loss_dur: 0.17699605226516724  (0.1669552688087736)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(16.6156, device='cuda:0')  (tensor(22.1678, device='cuda:0'))\n",
      "     | > current_lr: 1.35e-05 \n",
      "     | > step_time: 0.5364  (0.44823661304655527)\n",
      "     | > loader_time: 0.004  (0.005162988390241351)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:42:02 -- STEP: 46/406 -- GLOBAL_STEP: 44700\u001b[0m\n",
      "     | > loss: -0.07821094989776611  (-0.09228002992661102)\n",
      "     | > log_mle: -0.2616924047470093  (-0.26640835793122003)\n",
      "     | > loss_dur: 0.18348145484924316  (0.17412832800460898)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(26.5796, device='cuda:0')  (tensor(20.1580, device='cuda:0'))\n",
      "     | > current_lr: 1.35e-05 \n",
      "     | > step_time: 0.4378  (0.5191075387208357)\n",
      "     | > loader_time: 0.0046  (0.007199328878651496)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:42:17 -- STEP: 71/406 -- GLOBAL_STEP: 44725\u001b[0m\n",
      "     | > loss: -0.08768574893474579  (-0.09082391312424566)\n",
      "     | > log_mle: -0.2861553430557251  (-0.26989084062441965)\n",
      "     | > loss_dur: 0.1984695941209793  (0.17906692750017408)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(16.3706, device='cuda:0')  (tensor(21.2226, device='cuda:0'))\n",
      "     | > current_lr: 1.35e-05 \n",
      "     | > step_time: 0.754  (0.5448423976629553)\n",
      "     | > loader_time: 0.0182  (0.008510183280622455)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:42:32 -- STEP: 96/406 -- GLOBAL_STEP: 44750\u001b[0m\n",
      "     | > loss: -0.07658244669437408  (-0.09097139785687129)\n",
      "     | > log_mle: -0.2845808267593384  (-0.27334593981504446)\n",
      "     | > loss_dur: 0.2079983800649643  (0.18237454195817313)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(29.1095, device='cuda:0')  (tensor(22.5744, device='cuda:0'))\n",
      "     | > current_lr: 1.35e-05 \n",
      "     | > step_time: 0.4218  (0.5556564480066298)\n",
      "     | > loader_time: 0.0045  (0.009702545901139574)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:42:48 -- STEP: 121/406 -- GLOBAL_STEP: 44775\u001b[0m\n",
      "     | > loss: -0.09131665527820587  (-0.0913797784442744)\n",
      "     | > log_mle: -0.28323793411254883  (-0.2760564157785464)\n",
      "     | > loss_dur: 0.19192127883434296  (0.1846766373342719)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(26.1760, device='cuda:0')  (tensor(22.6430, device='cuda:0'))\n",
      "     | > current_lr: 1.35e-05 \n",
      "     | > step_time: 0.8037  (0.5656139594464262)\n",
      "     | > loader_time: 0.0056  (0.010222529576829642)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:43:04 -- STEP: 146/406 -- GLOBAL_STEP: 44800\u001b[0m\n",
      "     | > loss: -0.08892391622066498  (-0.09112582120993366)\n",
      "     | > log_mle: -0.281835675239563  (-0.2780172261473251)\n",
      "     | > loss_dur: 0.192911759018898  (0.18689140493739145)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(29.3508, device='cuda:0')  (tensor(22.6116, device='cuda:0'))\n",
      "     | > current_lr: 1.35e-05 \n",
      "     | > step_time: 0.739  (0.577429715901205)\n",
      "     | > loader_time: 0.0098  (0.010277405177077202)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:43:20 -- STEP: 171/406 -- GLOBAL_STEP: 44825\u001b[0m\n",
      "     | > loss: -0.10169734060764313  (-0.09076557338934894)\n",
      "     | > log_mle: -0.29631781578063965  (-0.279527569374843)\n",
      "     | > loss_dur: 0.19462047517299652  (0.18876199598549412)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(23.4829, device='cuda:0')  (tensor(23.5517, device='cuda:0'))\n",
      "     | > current_lr: 1.35e-05 \n",
      "     | > step_time: 0.6365  (0.5864709831817807)\n",
      "     | > loader_time: 0.0068  (0.010872202309948663)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:43:37 -- STEP: 196/406 -- GLOBAL_STEP: 44850\u001b[0m\n",
      "     | > loss: -0.09080849587917328  (-0.09077889289782975)\n",
      "     | > log_mle: -0.2902320623397827  (-0.28104207710343976)\n",
      "     | > loss_dur: 0.19942356646060944  (0.19026318420561)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(21.9983, device='cuda:0')  (tensor(23.9386, device='cuda:0'))\n",
      "     | > current_lr: 1.35e-05 \n",
      "     | > step_time: 0.6436  (0.5964695774779025)\n",
      "     | > loader_time: 0.0108  (0.011325543024102038)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:43:55 -- STEP: 221/406 -- GLOBAL_STEP: 44875\u001b[0m\n",
      "     | > loss: -0.06682774424552917  (-0.09050545757172877)\n",
      "     | > log_mle: -0.2914525270462036  (-0.2823052805473362)\n",
      "     | > loss_dur: 0.22462478280067444  (0.19179982297560755)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(25.8877, device='cuda:0')  (tensor(25.1539, device='cuda:0'))\n",
      "     | > current_lr: 1.35e-05 \n",
      "     | > step_time: 1.0314  (0.6068225521847128)\n",
      "     | > loader_time: 0.0267  (0.0118558741263135)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:44:13 -- STEP: 246/406 -- GLOBAL_STEP: 44900\u001b[0m\n",
      "     | > loss: -0.09251159429550171  (-0.09056751133222893)\n",
      "     | > log_mle: -0.2896907329559326  (-0.2836013693150465)\n",
      "     | > loss_dur: 0.1971791386604309  (0.19303385798281777)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(16.1139, device='cuda:0')  (tensor(25.1522, device='cuda:0'))\n",
      "     | > current_lr: 1.35e-05 \n",
      "     | > step_time: 0.5505  (0.6153928341904302)\n",
      "     | > loader_time: 0.0163  (0.012216179351496504)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:44:31 -- STEP: 271/406 -- GLOBAL_STEP: 44925\u001b[0m\n",
      "     | > loss: -0.11031119525432587  (-0.09087905287742618)\n",
      "     | > log_mle: -0.3011218309402466  (-0.28456778851822284)\n",
      "     | > loss_dur: 0.19081063568592072  (0.19368873564079686)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(81.2383, device='cuda:0')  (tensor(25.8747, device='cuda:0'))\n",
      "     | > current_lr: 1.35e-05 \n",
      "     | > step_time: 0.7236  (0.6243959229810647)\n",
      "     | > loader_time: 0.0188  (0.012447125797342112)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:44:50 -- STEP: 296/406 -- GLOBAL_STEP: 44950\u001b[0m\n",
      "     | > loss: -0.0859222561120987  (-0.09058507833931902)\n",
      "     | > log_mle: -0.2993443012237549  (-0.2851892754032805)\n",
      "     | > loss_dur: 0.2134220451116562  (0.19460419706396162)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(31.3758, device='cuda:0')  (tensor(26.6150, device='cuda:0'))\n",
      "     | > current_lr: 1.35e-05 \n",
      "     | > step_time: 0.8331  (0.6331571823841815)\n",
      "     | > loader_time: 0.0066  (0.012915184368958348)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:45:11 -- STEP: 321/406 -- GLOBAL_STEP: 44975\u001b[0m\n",
      "     | > loss: -0.08297376334667206  (-0.09059965870462111)\n",
      "     | > log_mle: -0.2900794744491577  (-0.2860195428782905)\n",
      "     | > loss_dur: 0.20710571110248566  (0.1954198841736696)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(27.6481, device='cuda:0')  (tensor(26.9272, device='cuda:0'))\n",
      "     | > current_lr: 1.35e-05 \n",
      "     | > step_time: 0.9924  (0.6479951562911177)\n",
      "     | > loader_time: 0.0066  (0.013136481941674731)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:45:35 -- STEP: 346/406 -- GLOBAL_STEP: 45000\u001b[0m\n",
      "     | > loss: -0.10529360175132751  (-0.09062385976831358)\n",
      "     | > log_mle: -0.3042548894882202  (-0.28686256835915436)\n",
      "     | > loss_dur: 0.1989612877368927  (0.19623870859084105)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(28.0169, device='cuda:0')  (tensor(27.1865, device='cuda:0'))\n",
      "     | > current_lr: 1.35e-05 \n",
      "     | > step_time: 0.9886  (0.6683075317757665)\n",
      "     | > loader_time: 0.0612  (0.013803905834352353)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:45:57 -- STEP: 371/406 -- GLOBAL_STEP: 45025\u001b[0m\n",
      "     | > loss: -0.0936393141746521  (-0.09082684957113557)\n",
      "     | > log_mle: -0.29923343658447266  (-0.287802251522753)\n",
      "     | > loss_dur: 0.20559412240982056  (0.19697540195161767)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(24.8434, device='cuda:0')  (tensor(27.3595, device='cuda:0'))\n",
      "     | > current_lr: 1.35e-05 \n",
      "     | > step_time: 0.715  (0.679669774767523)\n",
      "     | > loader_time: 0.0076  (0.014138172257621335)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:46:16 -- STEP: 396/406 -- GLOBAL_STEP: 45050\u001b[0m\n",
      "     | > loss: -0.10029904544353485  (-0.09106291552083667)\n",
      "     | > log_mle: -0.304874062538147  (-0.28858121296372063)\n",
      "     | > loss_dur: 0.20457501709461212  (0.19751829744288418)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(43.0081, device='cuda:0')  (tensor(27.5771, device='cuda:0'))\n",
      "     | > current_lr: 1.35e-05 \n",
      "     | > step_time: 0.6012  (0.6853827286248251)\n",
      "     | > loader_time: 0.0063  (0.014339538535686456)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: -0.07323341071605682  (-0.07323341071605682)\n",
      "     | > log_mle: -0.27208495140075684  (-0.27208495140075684)\n",
      "     | > loss_dur: 0.1988515406847  (0.1988515406847)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: -0.15000486373901367  (-0.15000486373901367)\n",
      "     | > log_mle: -0.3108936548233032  (-0.3108936548233032)\n",
      "     | > loss_dur: 0.16088879108428955  (0.16088879108428955)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: -0.11442959308624268  (-0.13221722841262817)\n",
      "     | > log_mle: -0.27422237396240234  (-0.2925580143928528)\n",
      "     | > loss_dur: 0.15979278087615967  (0.1603407859802246)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: -0.11913134157657623  (-0.12785526613394418)\n",
      "     | > log_mle: -0.28490936756134033  (-0.2900084654490153)\n",
      "     | > loss_dur: 0.1657780259847641  (0.1621531993150711)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: -0.1373833864927292  (-0.13023729622364044)\n",
      "     | > log_mle: -0.31126344203948975  (-0.2953222095966339)\n",
      "     | > loss_dur: 0.17388005554676056  (0.16508491337299347)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: -0.1386132389307022  (-0.1319124847650528)\n",
      "     | > log_mle: -0.31049227714538574  (-0.29835622310638427)\n",
      "     | > loss_dur: 0.17187903821468353  (0.16644373834133147)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: -0.08190274238586426  (-0.1235775277018547)\n",
      "     | > log_mle: -0.31807565689086914  (-0.3016427954037984)\n",
      "     | > loss_dur: 0.23617291450500488  (0.17806526770194372)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: -0.10288417339324951  (-0.12062133422919682)\n",
      "     | > log_mle: -0.2827274799346924  (-0.2989406074796404)\n",
      "     | > loss_dur: 0.17984330654144287  (0.17831927325044358)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: -0.12986138463020325  (-0.12177634052932262)\n",
      "     | > log_mle: -0.2953530550003052  (-0.2984921634197235)\n",
      "     | > loss_dur: 0.16549167037010193  (0.1767158228904009)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: -0.10883209109306335  (-0.12033809059196049)\n",
      "     | > log_mle: -0.3071221113204956  (-0.2994510465198093)\n",
      "     | > loss_dur: 0.19829002022743225  (0.17911295592784882)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: -0.08875897526741028  (-0.11718017905950547)\n",
      "     | > log_mle: -0.2929922342300415  (-0.2988051652908325)\n",
      "     | > loss_dur: 0.20423325896263123  (0.18162498623132706)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: -0.10819472372531891  (-0.11636331948367032)\n",
      "     | > log_mle: -0.3099651336669922  (-0.2998197078704834)\n",
      "     | > loss_dur: 0.20177040994167328  (0.18345638838681308)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: -0.12092925608158112  (-0.11674381420016289)\n",
      "     | > log_mle: -0.2959557771682739  (-0.29949771364529926)\n",
      "     | > loss_dur: 0.1750265210866928  (0.1827538994451364)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: -0.13938646018505096  (-0.11848555619900043)\n",
      "     | > log_mle: -0.3175506591796875  (-0.30088640176332915)\n",
      "     | > loss_dur: 0.17816419899463654  (0.1824008455643287)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: -0.11235646903514862  (-0.1180477642587253)\n",
      "     | > log_mle: -0.3077486753463745  (-0.3013765641621181)\n",
      "     | > loss_dur: 0.1953922063112259  (0.1833287999033928)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: -0.11572699248790741  (-0.11789304614067078)\n",
      "     | > log_mle: -0.3010718822479248  (-0.3013562520345052)\n",
      "     | > loss_dur: 0.1853448897600174  (0.18346320589383444)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: -0.10269860923290253  (-0.11694339383393526)\n",
      "     | > log_mle: -0.30202996730804443  (-0.3013983592391014)\n",
      "     | > loss_dur: 0.1993313580751419  (0.18445496540516615)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: audio amplitude out of range, auto clipped.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[91m 0.003908157348632813 \u001b[0m(+0.0006758570671081552)\n",
      "     | > avg_loss:\u001b[92m -0.11694339383393526 \u001b[0m(-0.0018322505056858063)\n",
      "     | > avg_log_mle:\u001b[92m -0.3013983592391014 \u001b[0m(-0.0023006200790405273)\n",
      "     | > avg_loss_dur:\u001b[91m 0.18445496540516615 \u001b[0m(+0.00046836957335472107)\n",
      "\n",
      " > BEST MODEL : train/run-February-22-2025_10+59PM-fa84af3/best_model_45060.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 55/100\u001b[0m\n",
      " --> train/run-February-22-2025_10+59PM-fa84af3\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-23 03:46:38) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:46:45 -- STEP: 15/406 -- GLOBAL_STEP: 45075\u001b[0m\n",
      "     | > loss: -0.09101343154907227  (-0.10585810343424479)\n",
      "     | > log_mle: -0.2725414037704468  (-0.27295780976613365)\n",
      "     | > loss_dur: 0.1815279722213745  (0.16709970633188884)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(31.1442, device='cuda:0')  (tensor(26.0253, device='cuda:0'))\n",
      "     | > current_lr: 1.375e-05 \n",
      "     | > step_time: 0.519  (0.3675781408945719)\n",
      "     | > loader_time: 0.0039  (0.006803210576375326)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:46:59 -- STEP: 40/406 -- GLOBAL_STEP: 45100\u001b[0m\n",
      "     | > loss: -0.0847189873456955  (-0.0972248412668705)\n",
      "     | > log_mle: -0.25190722942352295  (-0.2701177954673767)\n",
      "     | > loss_dur: 0.16718824207782745  (0.17289295420050618)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(8.0592, device='cuda:0')  (tensor(19.9771, device='cuda:0'))\n",
      "     | > current_lr: 1.375e-05 \n",
      "     | > step_time: 0.62  (0.47212369441986085)\n",
      "     | > loader_time: 0.0087  (0.008565866947174072)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:47:13 -- STEP: 65/406 -- GLOBAL_STEP: 45125\u001b[0m\n",
      "     | > loss: -0.09217473864555359  (-0.09372203304217412)\n",
      "     | > log_mle: -0.2679649591445923  (-0.2713074757502629)\n",
      "     | > loss_dur: 0.1757902204990387  (0.1775854427080888)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(15.6215, device='cuda:0')  (tensor(20.9570, device='cuda:0'))\n",
      "     | > current_lr: 1.375e-05 \n",
      "     | > step_time: 0.9275  (0.505828175177941)\n",
      "     | > loader_time: 0.0072  (0.008528907482440654)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:47:28 -- STEP: 90/406 -- GLOBAL_STEP: 45150\u001b[0m\n",
      "     | > loss: -0.11311414837837219  (-0.093467325799995)\n",
      "     | > log_mle: -0.2895694971084595  (-0.2737972749604119)\n",
      "     | > loss_dur: 0.17645534873008728  (0.18032994916041692)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(28.7093, device='cuda:0')  (tensor(20.2311, device='cuda:0'))\n",
      "     | > current_lr: 1.375e-05 \n",
      "     | > step_time: 0.3144  (0.5206088834338717)\n",
      "     | > loader_time: 0.0047  (0.008624964290195042)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:47:44 -- STEP: 115/406 -- GLOBAL_STEP: 45175\u001b[0m\n",
      "     | > loss: -0.07263047993183136  (-0.0931920667057452)\n",
      "     | > log_mle: -0.2709813117980957  (-0.27680923627770465)\n",
      "     | > loss_dur: 0.19835083186626434  (0.18361716957195945)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(9.8415, device='cuda:0')  (tensor(20.5060, device='cuda:0'))\n",
      "     | > current_lr: 1.375e-05 \n",
      "     | > step_time: 0.647  (0.5444492277891737)\n",
      "     | > loader_time: 0.0046  (0.009074816496475888)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:48:01 -- STEP: 140/406 -- GLOBAL_STEP: 45200\u001b[0m\n",
      "     | > loss: -0.09403809905052185  (-0.09244235828518868)\n",
      "     | > log_mle: -0.29558229446411133  (-0.27875803709030156)\n",
      "     | > loss_dur: 0.20154419541358948  (0.18631567880511288)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(39.1155, device='cuda:0')  (tensor(23.1082, device='cuda:0'))\n",
      "     | > current_lr: 1.375e-05 \n",
      "     | > step_time: 0.7298  (0.5632865139416284)\n",
      "     | > loader_time: 0.0196  (0.009402409621647428)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:48:17 -- STEP: 165/406 -- GLOBAL_STEP: 45225\u001b[0m\n",
      "     | > loss: -0.11404930055141449  (-0.09207261024099408)\n",
      "     | > log_mle: -0.31189703941345215  (-0.28048337806354867)\n",
      "     | > loss_dur: 0.19784773886203766  (0.18841076782255467)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(38.3149, device='cuda:0')  (tensor(24.2745, device='cuda:0'))\n",
      "     | > current_lr: 1.375e-05 \n",
      "     | > step_time: 0.3451  (0.5727691679289844)\n",
      "     | > loader_time: 0.0052  (0.009807654583092894)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:48:34 -- STEP: 190/406 -- GLOBAL_STEP: 45250\u001b[0m\n",
      "     | > loss: -0.10027509927749634  (-0.09240940424956773)\n",
      "     | > log_mle: -0.3032342195510864  (-0.2821822053507755)\n",
      "     | > loss_dur: 0.2029591202735901  (0.18977280110120773)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(26.7318, device='cuda:0')  (tensor(25.0231, device='cuda:0'))\n",
      "     | > current_lr: 1.375e-05 \n",
      "     | > step_time: 0.5324  (0.5871042515102183)\n",
      "     | > loader_time: 0.0068  (0.010051023332696215)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:48:51 -- STEP: 215/406 -- GLOBAL_STEP: 45275\u001b[0m\n",
      "     | > loss: -0.09118439257144928  (-0.09260817447374034)\n",
      "     | > log_mle: -0.2884432077407837  (-0.2834890875705454)\n",
      "     | > loss_dur: 0.1972588151693344  (0.19088091309680494)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(34.0020, device='cuda:0')  (tensor(25.4846, device='cuda:0'))\n",
      "     | > current_lr: 1.375e-05 \n",
      "     | > step_time: 0.5947  (0.5955562646998914)\n",
      "     | > loader_time: 0.0059  (0.01012425422668457)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:49:08 -- STEP: 240/406 -- GLOBAL_STEP: 45300\u001b[0m\n",
      "     | > loss: -0.11203740537166595  (-0.09249508908639352)\n",
      "     | > log_mle: -0.3026881217956543  (-0.28477195700009666)\n",
      "     | > loss_dur: 0.19065071642398834  (0.19227686791370313)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(20.6174, device='cuda:0')  (tensor(26.2867, device='cuda:0'))\n",
      "     | > current_lr: 1.375e-05 \n",
      "     | > step_time: 0.6298  (0.6038981417814889)\n",
      "     | > loader_time: 0.0051  (0.010239792863527934)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:49:26 -- STEP: 265/406 -- GLOBAL_STEP: 45325\u001b[0m\n",
      "     | > loss: -0.09417140483856201  (-0.09259413385166312)\n",
      "     | > log_mle: -0.29754018783569336  (-0.2857068642130438)\n",
      "     | > loss_dur: 0.20336878299713135  (0.19311273036138066)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(40.0603, device='cuda:0')  (tensor(26.6156, device='cuda:0'))\n",
      "     | > current_lr: 1.375e-05 \n",
      "     | > step_time: 0.9017  (0.6117591471042272)\n",
      "     | > loader_time: 0.0363  (0.010763872794385227)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:49:44 -- STEP: 290/406 -- GLOBAL_STEP: 45350\u001b[0m\n",
      "     | > loss: -0.10763317346572876  (-0.09285384843061711)\n",
      "     | > log_mle: -0.3062906265258789  (-0.28664608947161974)\n",
      "     | > loss_dur: 0.19865745306015015  (0.19379224104100257)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(60.8316, device='cuda:0')  (tensor(26.8152, device='cuda:0'))\n",
      "     | > current_lr: 1.375e-05 \n",
      "     | > step_time: 0.6343  (0.6207812876536929)\n",
      "     | > loader_time: 0.019  (0.011162137163096457)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:50:03 -- STEP: 315/406 -- GLOBAL_STEP: 45375\u001b[0m\n",
      "     | > loss: -0.09209370613098145  (-0.09299905986066849)\n",
      "     | > log_mle: -0.2958561182022095  (-0.2874807236686585)\n",
      "     | > loss_dur: 0.20376241207122803  (0.19448166380799)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(34.6689, device='cuda:0')  (tensor(27.2918, device='cuda:0'))\n",
      "     | > current_lr: 1.375e-05 \n",
      "     | > step_time: 0.6812  (0.6307728002941803)\n",
      "     | > loader_time: 0.0573  (0.011560651991102426)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:50:22 -- STEP: 340/406 -- GLOBAL_STEP: 45400\u001b[0m\n",
      "     | > loss: -0.08638070523738861  (-0.09294772174428494)\n",
      "     | > log_mle: -0.2889246940612793  (-0.2882017489741828)\n",
      "     | > loss_dur: 0.20254398882389069  (0.195254027229898)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(37.5180, device='cuda:0')  (tensor(27.8189, device='cuda:0'))\n",
      "     | > current_lr: 1.375e-05 \n",
      "     | > step_time: 0.9688  (0.6374759463702936)\n",
      "     | > loader_time: 0.0341  (0.012181767996619724)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:50:43 -- STEP: 365/406 -- GLOBAL_STEP: 45425\u001b[0m\n",
      "     | > loss: -0.10323479771614075  (-0.09308111508415172)\n",
      "     | > log_mle: -0.3057354688644409  (-0.28914753443574254)\n",
      "     | > loss_dur: 0.20250067114830017  (0.1960664193515907)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(20.7904, device='cuda:0')  (tensor(28.1413, device='cuda:0'))\n",
      "     | > current_lr: 1.375e-05 \n",
      "     | > step_time: 0.5162  (0.6493916354767272)\n",
      "     | > loader_time: 0.02  (0.012510856210368949)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:51:04 -- STEP: 390/406 -- GLOBAL_STEP: 45450\u001b[0m\n",
      "     | > loss: -0.11242790520191193  (-0.09323750165028452)\n",
      "     | > log_mle: -0.3136560916900635  (-0.28990590419524753)\n",
      "     | > loss_dur: 0.20122818648815155  (0.19666840254496296)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(28.3079, device='cuda:0')  (tensor(28.4710, device='cuda:0'))\n",
      "     | > current_lr: 1.375e-05 \n",
      "     | > step_time: 0.8631  (0.6605501278852813)\n",
      "     | > loader_time: 0.0223  (0.012642183059301128)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: -0.0747852623462677  (-0.0747852623462677)\n",
      "     | > log_mle: -0.27338123321533203  (-0.27338123321533203)\n",
      "     | > loss_dur: 0.19859597086906433  (0.19859597086906433)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: -0.15135197341442108  (-0.15135197341442108)\n",
      "     | > log_mle: -0.31365907192230225  (-0.31365907192230225)\n",
      "     | > loss_dur: 0.16230709850788116  (0.16230709850788116)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: -0.12129387259483337  (-0.13632292300462723)\n",
      "     | > log_mle: -0.27683377265930176  (-0.295246422290802)\n",
      "     | > loss_dur: 0.15553990006446838  (0.15892349928617477)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: -0.11920128762722015  (-0.1306157112121582)\n",
      "     | > log_mle: -0.2875927686691284  (-0.2926952044169108)\n",
      "     | > loss_dur: 0.16839148104190826  (0.1620794932047526)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: -0.13290786743164062  (-0.1311887502670288)\n",
      "     | > log_mle: -0.31384599208831787  (-0.2979829013347626)\n",
      "     | > loss_dur: 0.18093812465667725  (0.16679415106773376)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: -0.14599670469760895  (-0.13415034115314484)\n",
      "     | > log_mle: -0.31603753566741943  (-0.30159382820129393)\n",
      "     | > loss_dur: 0.17004083096981049  (0.1674434870481491)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: -0.08080434799194336  (-0.12525934229294458)\n",
      "     | > log_mle: -0.32543063163757324  (-0.30556662877400714)\n",
      "     | > loss_dur: 0.24462628364562988  (0.18030728648106256)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: -0.11274021863937378  (-0.1234708960567202)\n",
      "     | > log_mle: -0.2864978313446045  (-0.30284251485552105)\n",
      "     | > loss_dur: 0.1737576127052307  (0.17937161879880087)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: -0.13981184363365173  (-0.12551351450383663)\n",
      "     | > log_mle: -0.2979588508605957  (-0.3022320568561554)\n",
      "     | > loss_dur: 0.15814700722694397  (0.17671854235231876)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: -0.10972024500370026  (-0.12375870678159925)\n",
      "     | > log_mle: -0.31111371517181396  (-0.30321890778011745)\n",
      "     | > loss_dur: 0.2013934701681137  (0.1794602009985182)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: -0.09193204343318939  (-0.12057604044675826)\n",
      "     | > log_mle: -0.29671430587768555  (-0.3025684475898743)\n",
      "     | > loss_dur: 0.20478226244449615  (0.181992407143116)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: -0.11150309443473816  (-0.11975122717293826)\n",
      "     | > log_mle: -0.3131633996963501  (-0.30353162505409936)\n",
      "     | > loss_dur: 0.20166030526161194  (0.18378039788116107)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: -0.12917760014533997  (-0.12053675825397174)\n",
      "     | > log_mle: -0.2991830110549927  (-0.30316924055417377)\n",
      "     | > loss_dur: 0.1700054109096527  (0.18263248230020204)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: -0.13633131980895996  (-0.12175172452743237)\n",
      "     | > log_mle: -0.32258176803588867  (-0.3046625118989211)\n",
      "     | > loss_dur: 0.1862504482269287  (0.18291078737148872)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: -0.1159677803516388  (-0.12133858565773283)\n",
      "     | > log_mle: -0.31145405769348145  (-0.3051476223128183)\n",
      "     | > loss_dur: 0.19548627734184265  (0.18380903665508544)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: -0.11305250227451324  (-0.12078618009885152)\n",
      "     | > log_mle: -0.30433499813079834  (-0.3050934473673503)\n",
      "     | > loss_dur: 0.1912824958562851  (0.18430726726849875)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: -0.10446687042713165  (-0.11976622324436903)\n",
      "     | > log_mle: -0.3066678047180176  (-0.30519184470176697)\n",
      "     | > loss_dur: 0.20220093429088593  (0.18542562145739794)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: audio amplitude out of range, auto clipped.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.003559216856956482 \u001b[0m(-0.00034894049167633143)\n",
      "     | > avg_loss:\u001b[92m -0.11976622324436903 \u001b[0m(-0.0028228294104337692)\n",
      "     | > avg_log_mle:\u001b[92m -0.30519184470176697 \u001b[0m(-0.003793485462665558)\n",
      "     | > avg_loss_dur:\u001b[91m 0.18542562145739794 \u001b[0m(+0.0009706560522317886)\n",
      "\n",
      " > BEST MODEL : train/run-February-22-2025_10+59PM-fa84af3/best_model_45466.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 56/100\u001b[0m\n",
      " --> train/run-February-22-2025_10+59PM-fa84af3\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-23 03:51:29) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:51:34 -- STEP: 9/406 -- GLOBAL_STEP: 45475\u001b[0m\n",
      "     | > loss: -0.0907905101776123  (-0.11149569849173228)\n",
      "     | > log_mle: -0.2765108346939087  (-0.27383266554938424)\n",
      "     | > loss_dur: 0.1857203245162964  (0.16233696705765194)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(25.7537, device='cuda:0')  (tensor(21.1825, device='cuda:0'))\n",
      "     | > current_lr: 1.4e-05 \n",
      "     | > step_time: 0.2744  (0.3499859703911675)\n",
      "     | > loader_time: 0.0042  (0.004388782713148329)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:51:47 -- STEP: 34/406 -- GLOBAL_STEP: 45500\u001b[0m\n",
      "     | > loss: -0.08403421938419342  (-0.10360762389267192)\n",
      "     | > log_mle: -0.26785361766815186  (-0.2732930919703315)\n",
      "     | > loss_dur: 0.18381939828395844  (0.1696854680776596)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(13.7100, device='cuda:0')  (tensor(20.7189, device='cuda:0'))\n",
      "     | > current_lr: 1.4e-05 \n",
      "     | > step_time: 0.3603  (0.470781031776877)\n",
      "     | > loader_time: 0.0077  (0.00751036054947797)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:52:02 -- STEP: 59/406 -- GLOBAL_STEP: 45525\u001b[0m\n",
      "     | > loss: -0.09314270317554474  (-0.09864604700419863)\n",
      "     | > log_mle: -0.2761772871017456  (-0.27407946829068447)\n",
      "     | > loss_dur: 0.18303458392620087  (0.17543342128648595)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(24.9341, device='cuda:0')  (tensor(20.7390, device='cuda:0'))\n",
      "     | > current_lr: 1.4e-05 \n",
      "     | > step_time: 0.9311  (0.5117781970460537)\n",
      "     | > loader_time: 0.0141  (0.008003687454482258)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:52:17 -- STEP: 84/406 -- GLOBAL_STEP: 45550\u001b[0m\n",
      "     | > loss: -0.10223670303821564  (-0.09805707722192719)\n",
      "     | > log_mle: -0.2876933813095093  (-0.2763927380243936)\n",
      "     | > loss_dur: 0.18545667827129364  (0.17833566080246654)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(38.5693, device='cuda:0')  (tensor(21.9568, device='cuda:0'))\n",
      "     | > current_lr: 1.4e-05 \n",
      "     | > step_time: 0.5367  (0.5324884454409285)\n",
      "     | > loader_time: 0.0076  (0.008851204599652973)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:52:33 -- STEP: 109/406 -- GLOBAL_STEP: 45575\u001b[0m\n",
      "     | > loss: -0.10500398278236389  (-0.0973683967502839)\n",
      "     | > log_mle: -0.2980860471725464  (-0.27890379494483314)\n",
      "     | > loss_dur: 0.1930820643901825  (0.1815353981945493)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(35.9064, device='cuda:0')  (tensor(23.1099, device='cuda:0'))\n",
      "     | > current_lr: 1.4e-05 \n",
      "     | > step_time: 0.5499  (0.5530892840219206)\n",
      "     | > loader_time: 0.0062  (0.011011079910698288)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:52:48 -- STEP: 134/406 -- GLOBAL_STEP: 45600\u001b[0m\n",
      "     | > loss: -0.07230037450790405  (-0.09702032570963476)\n",
      "     | > log_mle: -0.2797722816467285  (-0.2811437097947989)\n",
      "     | > loss_dur: 0.20747190713882446  (0.18412338408516415)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(34.9156, device='cuda:0')  (tensor(24.2654, device='cuda:0'))\n",
      "     | > current_lr: 1.4e-05 \n",
      "     | > step_time: 0.5609  (0.5605945658327932)\n",
      "     | > loader_time: 0.0128  (0.01132303209447149)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:53:04 -- STEP: 159/406 -- GLOBAL_STEP: 45625\u001b[0m\n",
      "     | > loss: -0.09703902900218964  (-0.09577134326568938)\n",
      "     | > log_mle: -0.2923179864883423  (-0.2824881001838348)\n",
      "     | > loss_dur: 0.19527895748615265  (0.18671675691814546)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(15.6593, device='cuda:0')  (tensor(25.0046, device='cuda:0'))\n",
      "     | > current_lr: 1.4e-05 \n",
      "     | > step_time: 0.7376  (0.5736338507454354)\n",
      "     | > loader_time: 0.0058  (0.011261397187814775)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:53:21 -- STEP: 184/406 -- GLOBAL_STEP: 45650\u001b[0m\n",
      "     | > loss: -0.08525167405605316  (-0.09567441119124061)\n",
      "     | > log_mle: -0.3000532388687134  (-0.28386476830295904)\n",
      "     | > loss_dur: 0.21480156481266022  (0.18819035711171841)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(13.3297, device='cuda:0')  (tensor(25.4968, device='cuda:0'))\n",
      "     | > current_lr: 1.4e-05 \n",
      "     | > step_time: 0.7283  (0.5853558649187507)\n",
      "     | > loader_time: 0.0205  (0.011530592389728714)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:53:38 -- STEP: 209/406 -- GLOBAL_STEP: 45675\u001b[0m\n",
      "     | > loss: -0.10559600591659546  (-0.09559995114232935)\n",
      "     | > log_mle: -0.2994239330291748  (-0.285199497305035)\n",
      "     | > loss_dur: 0.19382792711257935  (0.18959954616270575)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(39.8040, device='cuda:0')  (tensor(26.7198, device='cuda:0'))\n",
      "     | > current_lr: 1.4e-05 \n",
      "     | > step_time: 0.6943  (0.5924088578475154)\n",
      "     | > loader_time: 0.0058  (0.011431179548564712)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:53:55 -- STEP: 234/406 -- GLOBAL_STEP: 45700\u001b[0m\n",
      "     | > loss: -0.0916496068239212  (-0.09587804412739909)\n",
      "     | > log_mle: -0.30677151679992676  (-0.2868401280835145)\n",
      "     | > loss_dur: 0.21512190997600555  (0.19096208395611533)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(29.6915, device='cuda:0')  (tensor(27.4204, device='cuda:0'))\n",
      "     | > current_lr: 1.4e-05 \n",
      "     | > step_time: 0.8498  (0.5993225136373802)\n",
      "     | > loader_time: 0.0054  (0.011365007131527634)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:54:12 -- STEP: 259/406 -- GLOBAL_STEP: 45725\u001b[0m\n",
      "     | > loss: -0.10007582604885101  (-0.0961967926458042)\n",
      "     | > log_mle: -0.31475090980529785  (-0.28812799260423)\n",
      "     | > loss_dur: 0.21467508375644684  (0.19193119995842575)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(34.7984, device='cuda:0')  (tensor(27.9208, device='cuda:0'))\n",
      "     | > current_lr: 1.4e-05 \n",
      "     | > step_time: 0.6547  (0.6081074710978509)\n",
      "     | > loader_time: 0.0057  (0.011382932368392652)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:54:31 -- STEP: 284/406 -- GLOBAL_STEP: 45750\u001b[0m\n",
      "     | > loss: -0.09170247614383698  (-0.09632230303447009)\n",
      "     | > log_mle: -0.304728627204895  (-0.2889955077372807)\n",
      "     | > loss_dur: 0.21302615106105804  (0.1926732047028105)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(25.1737, device='cuda:0')  (tensor(28.2934, device='cuda:0'))\n",
      "     | > current_lr: 1.4e-05 \n",
      "     | > step_time: 0.9455  (0.6172942955728992)\n",
      "     | > loader_time: 0.0159  (0.011920043280426885)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:54:50 -- STEP: 309/406 -- GLOBAL_STEP: 45775\u001b[0m\n",
      "     | > loss: -0.11462186276912689  (-0.09630848877252492)\n",
      "     | > log_mle: -0.2999533414840698  (-0.28971273382118995)\n",
      "     | > loss_dur: 0.18533147871494293  (0.1934042450486649)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(23.4654, device='cuda:0')  (tensor(28.2615, device='cuda:0'))\n",
      "     | > current_lr: 1.4e-05 \n",
      "     | > step_time: 0.7005  (0.627792905449482)\n",
      "     | > loader_time: 0.0062  (0.012595429003817363)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:55:10 -- STEP: 334/406 -- GLOBAL_STEP: 45800\u001b[0m\n",
      "     | > loss: -0.09648340940475464  (-0.09635963670150959)\n",
      "     | > log_mle: -0.30924975872039795  (-0.2903989560589819)\n",
      "     | > loss_dur: 0.2127663493156433  (0.19403931935747223)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(14.4680, device='cuda:0')  (tensor(28.5226, device='cuda:0'))\n",
      "     | > current_lr: 1.4e-05 \n",
      "     | > step_time: 0.6759  (0.6383711135316043)\n",
      "     | > loader_time: 0.0196  (0.012822533795933521)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:55:30 -- STEP: 359/406 -- GLOBAL_STEP: 45825\u001b[0m\n",
      "     | > loss: -0.09106381237506866  (-0.0963292603373195)\n",
      "     | > log_mle: -0.2927807569503784  (-0.2912383192428973)\n",
      "     | > loss_dur: 0.20171694457530975  (0.19490905890557755)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(26.2452, device='cuda:0')  (tensor(28.3561, device='cuda:0'))\n",
      "     | > current_lr: 1.4e-05 \n",
      "     | > step_time: 0.8093  (0.6484212862083845)\n",
      "     | > loader_time: 0.006  (0.013051867817105687)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:55:51 -- STEP: 384/406 -- GLOBAL_STEP: 45850\u001b[0m\n",
      "     | > loss: -0.09420925378799438  (-0.09655301990763591)\n",
      "     | > log_mle: -0.3058326244354248  (-0.29199913361420243)\n",
      "     | > loss_dur: 0.21162337064743042  (0.19544611370656637)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(27.2500, device='cuda:0')  (tensor(29.1859, device='cuda:0'))\n",
      "     | > current_lr: 1.4e-05 \n",
      "     | > step_time: 0.6495  (0.659295245384177)\n",
      "     | > loader_time: 0.0061  (0.013012437149882315)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: -0.08122758567333221  (-0.08122758567333221)\n",
      "     | > log_mle: -0.27711641788482666  (-0.27711641788482666)\n",
      "     | > loss_dur: 0.19588883221149445  (0.19588883221149445)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: -0.1500633955001831  (-0.1500633955001831)\n",
      "     | > log_mle: -0.3181777000427246  (-0.3181777000427246)\n",
      "     | > loss_dur: 0.1681143045425415  (0.1681143045425415)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: -0.12516605854034424  (-0.13761472702026367)\n",
      "     | > log_mle: -0.28030669689178467  (-0.29924219846725464)\n",
      "     | > loss_dur: 0.15514063835144043  (0.16162747144699097)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: -0.12693816423416138  (-0.13405587275822958)\n",
      "     | > log_mle: -0.2918567657470703  (-0.29678038756052655)\n",
      "     | > loss_dur: 0.16491860151290894  (0.16272451480229697)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: -0.15309756994247437  (-0.13881629705429077)\n",
      "     | > log_mle: -0.3184446096420288  (-0.3021964430809021)\n",
      "     | > loss_dur: 0.16534703969955444  (0.16338014602661133)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: -0.14180240035057068  (-0.13941351771354676)\n",
      "     | > log_mle: -0.31915533542633057  (-0.30558822154998777)\n",
      "     | > loss_dur: 0.1773529350757599  (0.16617470383644103)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: -0.0938827246427536  (-0.1318250522017479)\n",
      "     | > log_mle: -0.3271063566207886  (-0.3091745773951213)\n",
      "     | > loss_dur: 0.23322363197803497  (0.17734952519337335)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: -0.11251065135002136  (-0.12906585208007268)\n",
      "     | > log_mle: -0.28960955142974854  (-0.3063795736857823)\n",
      "     | > loss_dur: 0.17709890007972717  (0.17731372160570963)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: -0.13904210925102234  (-0.13031288422644138)\n",
      "     | > log_mle: -0.30266761779785156  (-0.30591557919979095)\n",
      "     | > loss_dur: 0.16362550854682922  (0.17560269497334957)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: -0.1050986498594284  (-0.1275113026301066)\n",
      "     | > log_mle: -0.31433022022247314  (-0.3068505393134223)\n",
      "     | > loss_dur: 0.20923157036304474  (0.1793392366833157)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: -0.09911316633224487  (-0.12467148900032043)\n",
      "     | > log_mle: -0.2996368408203125  (-0.30612916946411134)\n",
      "     | > loss_dur: 0.20052367448806763  (0.1814576804637909)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: -0.1283656805753708  (-0.12500732459805228)\n",
      "     | > log_mle: -0.31721532344818115  (-0.3071370016444813)\n",
      "     | > loss_dur: 0.18884964287281036  (0.18212967704642902)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: -0.12911133468151093  (-0.12534932543834051)\n",
      "     | > log_mle: -0.3030984401702881  (-0.3068004548549652)\n",
      "     | > loss_dur: 0.17398710548877716  (0.1814511294166247)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: -0.15056359767913818  (-0.1272888848414788)\n",
      "     | > log_mle: -0.3250962495803833  (-0.3082078236799974)\n",
      "     | > loss_dur: 0.17453265190124512  (0.1809189388385186)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: -0.12150007486343384  (-0.12687539841447557)\n",
      "     | > log_mle: -0.3148297071456909  (-0.30868081535611835)\n",
      "     | > loss_dur: 0.19332963228225708  (0.18180541694164276)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: -0.12296195328235626  (-0.12661450207233427)\n",
      "     | > log_mle: -0.3080681562423706  (-0.30863997141520183)\n",
      "     | > loss_dur: 0.18510620296001434  (0.18202546934286754)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: -0.11374296247959137  (-0.12581003084778783)\n",
      "     | > log_mle: -0.30940914154052734  (-0.30868804454803467)\n",
      "     | > loss_dur: 0.19566617906093597  (0.1828780137002468)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: audio amplitude out of range, auto clipped.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[91m 0.003877848386764526 \u001b[0m(+0.000318631529808044)\n",
      "     | > avg_loss:\u001b[92m -0.12581003084778783 \u001b[0m(-0.006043807603418799)\n",
      "     | > avg_log_mle:\u001b[92m -0.30868804454803467 \u001b[0m(-0.0034961998462677)\n",
      "     | > avg_loss_dur:\u001b[92m 0.1828780137002468 \u001b[0m(-0.002547607757151127)\n",
      "\n",
      " > BEST MODEL : train/run-February-22-2025_10+59PM-fa84af3/best_model_45872.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 57/100\u001b[0m\n",
      " --> train/run-February-22-2025_10+59PM-fa84af3\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-23 03:56:21) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:56:25 -- STEP: 3/406 -- GLOBAL_STEP: 45875\u001b[0m\n",
      "     | > loss: -0.10669612884521484  (-0.11986365914344788)\n",
      "     | > log_mle: -0.2815312147140503  (-0.28273101647694904)\n",
      "     | > loss_dur: 0.17483508586883545  (0.1628673573335012)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(34.8021, device='cuda:0')  (tensor(30.6327, device='cuda:0'))\n",
      "     | > current_lr: 1.425e-05 \n",
      "     | > step_time: 0.2917  (0.4219669500986735)\n",
      "     | > loader_time: 0.0052  (0.011151949564615885)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:56:37 -- STEP: 28/406 -- GLOBAL_STEP: 45900\u001b[0m\n",
      "     | > loss: -0.08803078532218933  (-0.11009456270507403)\n",
      "     | > log_mle: -0.2761145830154419  (-0.2761214588369641)\n",
      "     | > loss_dur: 0.18808379769325256  (0.16602689613189017)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(17.5872, device='cuda:0')  (tensor(23.6759, device='cuda:0'))\n",
      "     | > current_lr: 1.425e-05 \n",
      "     | > step_time: 0.5921  (0.46469816991261076)\n",
      "     | > loader_time: 0.0052  (0.008122512272426061)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:56:52 -- STEP: 53/406 -- GLOBAL_STEP: 45925\u001b[0m\n",
      "     | > loss: -0.09958671033382416  (-0.10311484083814441)\n",
      "     | > log_mle: -0.2731804847717285  (-0.2760779902620136)\n",
      "     | > loss_dur: 0.17359377443790436  (0.1729631494238691)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(6.4808, device='cuda:0')  (tensor(21.4653, device='cuda:0'))\n",
      "     | > current_lr: 1.425e-05 \n",
      "     | > step_time: 0.3529  (0.5279989242553711)\n",
      "     | > loader_time: 0.018  (0.009027764482318231)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:57:07 -- STEP: 78/406 -- GLOBAL_STEP: 45950\u001b[0m\n",
      "     | > loss: -0.10241721570491791  (-0.1005936765517944)\n",
      "     | > log_mle: -0.28062963485717773  (-0.2779218416947584)\n",
      "     | > loss_dur: 0.17821241915225983  (0.17732816514296404)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(32.1687, device='cuda:0')  (tensor(21.0449, device='cuda:0'))\n",
      "     | > current_lr: 1.425e-05 \n",
      "     | > step_time: 0.7987  (0.5430083641639123)\n",
      "     | > loader_time: 0.0045  (0.009211295690291967)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:57:22 -- STEP: 103/406 -- GLOBAL_STEP: 45975\u001b[0m\n",
      "     | > loss: -0.10064762830734253  (-0.10004236252562514)\n",
      "     | > log_mle: -0.29370105266571045  (-0.28063932090129684)\n",
      "     | > loss_dur: 0.19305342435836792  (0.18059695837567147)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(26.6858, device='cuda:0')  (tensor(22.1932, device='cuda:0'))\n",
      "     | > current_lr: 1.425e-05 \n",
      "     | > step_time: 0.6359  (0.5560402245197481)\n",
      "     | > loader_time: 0.0163  (0.010183345924303363)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:57:39 -- STEP: 128/406 -- GLOBAL_STEP: 46000\u001b[0m\n",
      "     | > loss: -0.10908909142017365  (-0.09946294676046818)\n",
      "     | > log_mle: -0.29025721549987793  (-0.2825499530881644)\n",
      "     | > loss_dur: 0.18116812407970428  (0.1830870063276961)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(39.7289, device='cuda:0')  (tensor(24.1823, device='cuda:0'))\n",
      "     | > current_lr: 1.425e-05 \n",
      "     | > step_time: 0.8893  (0.5758165363222358)\n",
      "     | > loader_time: 0.0098  (0.010911641642451281)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:57:55 -- STEP: 153/406 -- GLOBAL_STEP: 46025\u001b[0m\n",
      "     | > loss: -0.09539420902729034  (-0.09887283796968024)\n",
      "     | > log_mle: -0.296512246131897  (-0.28427547878689224)\n",
      "     | > loss_dur: 0.20111803710460663  (0.18540264081721208)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(28.0820, device='cuda:0')  (tensor(25.1359, device='cuda:0'))\n",
      "     | > current_lr: 1.425e-05 \n",
      "     | > step_time: 0.4374  (0.5811521648581509)\n",
      "     | > loader_time: 0.0057  (0.010666699191324073)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:58:11 -- STEP: 178/406 -- GLOBAL_STEP: 46050\u001b[0m\n",
      "     | > loss: -0.08846242725849152  (-0.0985348577914613)\n",
      "     | > log_mle: -0.28109264373779297  (-0.28534174970026754)\n",
      "     | > loss_dur: 0.19263021647930145  (0.1868068919088063)\n",
      "     | > amp_scaler: 8192.0  (4671.280898876404)\n",
      "     | > grad_norm: tensor(13.1222, device='cuda:0')  (tensor(25.7257, device='cuda:0'))\n",
      "     | > current_lr: 1.425e-05 \n",
      "     | > step_time: 0.4856  (0.5890661223550855)\n",
      "     | > loader_time: 0.012  (0.010724970463956344)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:58:27 -- STEP: 203/406 -- GLOBAL_STEP: 46075\u001b[0m\n",
      "     | > loss: -0.09088607132434845  (-0.09825316056829368)\n",
      "     | > log_mle: -0.2927584648132324  (-0.2867405408708919)\n",
      "     | > loss_dur: 0.20187239348888397  (0.1884873803025983)\n",
      "     | > amp_scaler: 4096.0  (4600.433497536947)\n",
      "     | > grad_norm: tensor(20.0317, device='cuda:0')  (tensor(26.7519, device='cuda:0'))\n",
      "     | > current_lr: 1.425e-05 \n",
      "     | > step_time: 0.794  (0.5937607323594865)\n",
      "     | > loader_time: 0.0089  (0.010476411857041236)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:58:46 -- STEP: 228/406 -- GLOBAL_STEP: 46100\u001b[0m\n",
      "     | > loss: -0.10819528996944427  (-0.09846440964100654)\n",
      "     | > log_mle: -0.29914164543151855  (-0.28820502862595665)\n",
      "     | > loss_dur: 0.19094635546207428  (0.18974061898495018)\n",
      "     | > amp_scaler: 4096.0  (4545.122807017544)\n",
      "     | > grad_norm: tensor(25.6806, device='cuda:0')  (tensor(28.1048, device='cuda:0'))\n",
      "     | > current_lr: 1.425e-05 \n",
      "     | > step_time: 0.9529  (0.6083196955814691)\n",
      "     | > loader_time: 0.0163  (0.010792929875223263)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:59:04 -- STEP: 253/406 -- GLOBAL_STEP: 46125\u001b[0m\n",
      "     | > loss: -0.117216557264328  (-0.09868523348932681)\n",
      "     | > log_mle: -0.3146466016769409  (-0.289558576500934)\n",
      "     | > loss_dur: 0.19743004441261292  (0.19087334301160727)\n",
      "     | > amp_scaler: 4096.0  (4500.743083003952)\n",
      "     | > grad_norm: tensor(26.6006, device='cuda:0')  (tensor(28.1778, device='cuda:0'))\n",
      "     | > current_lr: 1.425e-05 \n",
      "     | > step_time: 0.7725  (0.6173544731064743)\n",
      "     | > loader_time: 0.0118  (0.011424966480420988)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:59:22 -- STEP: 278/406 -- GLOBAL_STEP: 46150\u001b[0m\n",
      "     | > loss: -0.10054036974906921  (-0.0990764317002228)\n",
      "     | > log_mle: -0.2919262647628784  (-0.2905894676558405)\n",
      "     | > loss_dur: 0.1913858950138092  (0.1915130359556177)\n",
      "     | > amp_scaler: 4096.0  (4464.345323741008)\n",
      "     | > grad_norm: tensor(29.0241, device='cuda:0')  (tensor(28.9856, device='cuda:0'))\n",
      "     | > current_lr: 1.425e-05 \n",
      "     | > step_time: 0.9846  (0.6255990206766469)\n",
      "     | > loader_time: 0.0269  (0.011879589917848439)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 03:59:40 -- STEP: 303/406 -- GLOBAL_STEP: 46175\u001b[0m\n",
      "     | > loss: -0.08574210107326508  (-0.0992000909528323)\n",
      "     | > log_mle: -0.30340051651000977  (-0.29158879782107006)\n",
      "     | > loss_dur: 0.2176584154367447  (0.19238870686823775)\n",
      "     | > amp_scaler: 4096.0  (4433.953795379538)\n",
      "     | > grad_norm: tensor(24.2928, device='cuda:0')  (tensor(29.2180, device='cuda:0'))\n",
      "     | > current_lr: 1.425e-05 \n",
      "     | > step_time: 0.5306  (0.6314397086404727)\n",
      "     | > loader_time: 0.0079  (0.011914212318143439)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:00:00 -- STEP: 328/406 -- GLOBAL_STEP: 46200\u001b[0m\n",
      "     | > loss: -0.08574019372463226  (-0.09929415624497871)\n",
      "     | > log_mle: -0.3108464479446411  (-0.2922797043149064)\n",
      "     | > loss_dur: 0.22510625422000885  (0.19298554806992768)\n",
      "     | > amp_scaler: 4096.0  (4408.1951219512175)\n",
      "     | > grad_norm: tensor(37.2548, device='cuda:0')  (tensor(29.0803, device='cuda:0'))\n",
      "     | > current_lr: 1.425e-05 \n",
      "     | > step_time: 0.695  (0.642600068231908)\n",
      "     | > loader_time: 0.0344  (0.012204729202317034)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:00:19 -- STEP: 353/406 -- GLOBAL_STEP: 46225\u001b[0m\n",
      "     | > loss: -0.1004287600517273  (-0.09914379839181228)\n",
      "     | > log_mle: -0.31694507598876953  (-0.29305263990721014)\n",
      "     | > loss_dur: 0.21651631593704224  (0.1939088415153978)\n",
      "     | > amp_scaler: 4096.0  (4386.084985835692)\n",
      "     | > grad_norm: tensor(39.8709, device='cuda:0')  (tensor(29.5278, device='cuda:0'))\n",
      "     | > current_lr: 1.425e-05 \n",
      "     | > step_time: 0.8894  (0.649783686267755)\n",
      "     | > loader_time: 0.0168  (0.012191452993549644)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:00:38 -- STEP: 378/406 -- GLOBAL_STEP: 46250\u001b[0m\n",
      "     | > loss: -0.09792560338973999  (-0.09951406110216074)\n",
      "     | > log_mle: -0.30310237407684326  (-0.2939672722387564)\n",
      "     | > loss_dur: 0.20517677068710327  (0.19445321113659583)\n",
      "     | > amp_scaler: 4096.0  (4366.899470899469)\n",
      "     | > grad_norm: tensor(33.4249, device='cuda:0')  (tensor(29.8606, device='cuda:0'))\n",
      "     | > current_lr: 1.425e-05 \n",
      "     | > step_time: 0.8556  (0.6574294762636612)\n",
      "     | > loader_time: 0.0145  (0.012260505762049765)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:00:56 -- STEP: 403/406 -- GLOBAL_STEP: 46275\u001b[0m\n",
      "     | > loss: -0.1167788952589035  (-0.09967321996801252)\n",
      "     | > log_mle: -0.2983126640319824  (-0.2947102977383517)\n",
      "     | > loss_dur: 0.18153376877307892  (0.19503707777033957)\n",
      "     | > amp_scaler: 4096.0  (4350.094292803969)\n",
      "     | > grad_norm: tensor(28.8279, device='cuda:0')  (tensor(29.8337, device='cuda:0'))\n",
      "     | > current_lr: 1.425e-05 \n",
      "     | > step_time: 0.5282  (0.6593306443235709)\n",
      "     | > loader_time: 0.0073  (0.01228120486730382)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: -0.0888112336397171  (-0.0888112336397171)\n",
      "     | > log_mle: -0.27827906608581543  (-0.27827906608581543)\n",
      "     | > loss_dur: 0.18946783244609833  (0.18946783244609833)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: -0.16146518290042877  (-0.16146518290042877)\n",
      "     | > log_mle: -0.3194986581802368  (-0.3194986581802368)\n",
      "     | > loss_dur: 0.15803347527980804  (0.15803347527980804)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: -0.1275760382413864  (-0.1445206105709076)\n",
      "     | > log_mle: -0.28158438205718994  (-0.3005415201187134)\n",
      "     | > loss_dur: 0.15400834381580353  (0.1560209095478058)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: -0.1320313811302185  (-0.1403575340906779)\n",
      "     | > log_mle: -0.29243600368499756  (-0.2978396813074748)\n",
      "     | > loss_dur: 0.16040462255477905  (0.15748214721679688)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: -0.15289901196956635  (-0.1434929035604)\n",
      "     | > log_mle: -0.31983673572540283  (-0.3033389449119568)\n",
      "     | > loss_dur: 0.1669377237558365  (0.15984604135155678)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: -0.14850738644599915  (-0.14449580013751984)\n",
      "     | > log_mle: -0.32072603702545166  (-0.3068163633346558)\n",
      "     | > loss_dur: 0.17221865057945251  (0.16232056319713592)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: -0.10420958697795868  (-0.137781431277593)\n",
      "     | > log_mle: -0.3298962116241455  (-0.31066300471623737)\n",
      "     | > loss_dur: 0.22568662464618683  (0.1728815734386444)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: -0.11916060745716095  (-0.13512131358895982)\n",
      "     | > log_mle: -0.2914663553237915  (-0.30792062623160227)\n",
      "     | > loss_dur: 0.17230574786663055  (0.17279931264264242)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: -0.14337611198425293  (-0.13615316338837147)\n",
      "     | > log_mle: -0.30332911014556885  (-0.3073466867208481)\n",
      "     | > loss_dur: 0.15995299816131592  (0.17119352333247662)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: -0.11691229045391083  (-0.13401528861787584)\n",
      "     | > log_mle: -0.3169138431549072  (-0.3084097041024102)\n",
      "     | > loss_dur: 0.2000015527009964  (0.17439441548453438)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: -0.10199685394763947  (-0.1308134451508522)\n",
      "     | > log_mle: -0.301517128944397  (-0.3077204465866089)\n",
      "     | > loss_dur: 0.1995202749967575  (0.1769070014357567)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: -0.12597568333148956  (-0.13037364862181924)\n",
      "     | > log_mle: -0.31864047050476074  (-0.3087131760337136)\n",
      "     | > loss_dur: 0.19266478717327118  (0.17833952741189438)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: -0.13953955471515656  (-0.13113747412959734)\n",
      "     | > log_mle: -0.30408942699432373  (-0.30832786361376446)\n",
      "     | > loss_dur: 0.16454987227916718  (0.1771903894841671)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: -0.15367642045021057  (-0.132871239231183)\n",
      "     | > log_mle: -0.32698512077331543  (-0.30976303724142223)\n",
      "     | > loss_dur: 0.17330870032310486  (0.17689179801023924)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: -0.12613274157047272  (-0.1323899179697037)\n",
      "     | > log_mle: -0.31667065620422363  (-0.310256438595908)\n",
      "     | > loss_dur: 0.19053791463375092  (0.17786652062620437)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: -0.1223488450050354  (-0.13172051310539248)\n",
      "     | > log_mle: -0.30970561504364014  (-0.31021971702575685)\n",
      "     | > loss_dur: 0.18735677003860474  (0.1784992039203644)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: -0.11605240404605865  (-0.13074125628918412)\n",
      "     | > log_mle: -0.31157875061035156  (-0.310304656624794)\n",
      "     | > loss_dur: 0.1955263465642929  (0.1795634003356099)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: audio amplitude out of range, auto clipped.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.0034363120794296265 \u001b[0m(-0.00044153630733489947)\n",
      "     | > avg_loss:\u001b[92m -0.13074125628918412 \u001b[0m(-0.004931225441396292)\n",
      "     | > avg_log_mle:\u001b[92m -0.310304656624794 \u001b[0m(-0.0016166120767593384)\n",
      "     | > avg_loss_dur:\u001b[92m 0.1795634003356099 \u001b[0m(-0.003314613364636898)\n",
      "\n",
      " > BEST MODEL : train/run-February-22-2025_10+59PM-fa84af3/best_model_46278.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 58/100\u001b[0m\n",
      " --> train/run-February-22-2025_10+59PM-fa84af3\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-23 04:01:13) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:01:25 -- STEP: 22/406 -- GLOBAL_STEP: 46300\u001b[0m\n",
      "     | > loss: -0.08626747131347656  (-0.11233527687462894)\n",
      "     | > log_mle: -0.26568603515625  (-0.2761745344508778)\n",
      "     | > loss_dur: 0.17941856384277344  (0.16383925757624887)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(12.4685, device='cuda:0')  (tensor(21.8591, device='cuda:0'))\n",
      "     | > current_lr: 1.45e-05 \n",
      "     | > step_time: 0.4004  (0.44260867075486615)\n",
      "     | > loader_time: 0.0089  (0.007888804782520641)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:01:39 -- STEP: 47/406 -- GLOBAL_STEP: 46325\u001b[0m\n",
      "     | > loss: -0.10579106211662292  (-0.10544310224817154)\n",
      "     | > log_mle: -0.2992727756500244  (-0.275859292517317)\n",
      "     | > loss_dur: 0.1934817135334015  (0.17041619026914556)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(32.9448, device='cuda:0')  (tensor(22.1259, device='cuda:0'))\n",
      "     | > current_lr: 1.45e-05 \n",
      "     | > step_time: 0.5539  (0.49220665972283545)\n",
      "     | > loader_time: 0.006  (0.009869991464817778)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:01:54 -- STEP: 72/406 -- GLOBAL_STEP: 46350\u001b[0m\n",
      "     | > loss: -0.10342948138713837  (-0.10384180852108532)\n",
      "     | > log_mle: -0.27171599864959717  (-0.27849207487371225)\n",
      "     | > loss_dur: 0.1682865172624588  (0.174650266352627)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(17.0424, device='cuda:0')  (tensor(22.6227, device='cuda:0'))\n",
      "     | > current_lr: 1.45e-05 \n",
      "     | > step_time: 0.6193  (0.5256387922498917)\n",
      "     | > loader_time: 0.0211  (0.00970889131228129)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:02:09 -- STEP: 97/406 -- GLOBAL_STEP: 46375\u001b[0m\n",
      "     | > loss: -0.09178318083286285  (-0.10302336114583556)\n",
      "     | > log_mle: -0.2868081331253052  (-0.2816944146893688)\n",
      "     | > loss_dur: 0.19502495229244232  (0.17867105354353327)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(22.8260, device='cuda:0')  (tensor(22.7004, device='cuda:0'))\n",
      "     | > current_lr: 1.45e-05 \n",
      "     | > step_time: 0.5576  (0.5344074190277417)\n",
      "     | > loader_time: 0.0058  (0.010326107752691842)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:02:25 -- STEP: 122/406 -- GLOBAL_STEP: 46400\u001b[0m\n",
      "     | > loss: -0.10577446222305298  (-0.1027485689178842)\n",
      "     | > log_mle: -0.2808380126953125  (-0.28397115820744)\n",
      "     | > loss_dur: 0.17506355047225952  (0.1812225892895558)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(20.7444, device='cuda:0')  (tensor(23.7474, device='cuda:0'))\n",
      "     | > current_lr: 1.45e-05 \n",
      "     | > step_time: 0.5599  (0.553207884069349)\n",
      "     | > loader_time: 0.0272  (0.011083935127883663)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:02:41 -- STEP: 147/406 -- GLOBAL_STEP: 46425\u001b[0m\n",
      "     | > loss: -0.0934048593044281  (-0.10207139168466842)\n",
      "     | > log_mle: -0.29250621795654297  (-0.2859860350485562)\n",
      "     | > loss_dur: 0.19910135865211487  (0.1839146433638878)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(16.8948, device='cuda:0')  (tensor(25.0624, device='cuda:0'))\n",
      "     | > current_lr: 1.45e-05 \n",
      "     | > step_time: 1.0206  (0.5656671167230929)\n",
      "     | > loader_time: 0.0276  (0.01100816856436178)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:02:57 -- STEP: 172/406 -- GLOBAL_STEP: 46450\u001b[0m\n",
      "     | > loss: -0.09881383180618286  (-0.10156461414556173)\n",
      "     | > log_mle: -0.2930614948272705  (-0.28730909006540184)\n",
      "     | > loss_dur: 0.19424766302108765  (0.18574447591984)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(29.2297, device='cuda:0')  (tensor(25.7127, device='cuda:0'))\n",
      "     | > current_lr: 1.45e-05 \n",
      "     | > step_time: 0.5441  (0.5764651977738665)\n",
      "     | > loader_time: 0.0057  (0.011054145735363625)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:03:15 -- STEP: 197/406 -- GLOBAL_STEP: 46475\u001b[0m\n",
      "     | > loss: -0.1204034686088562  (-0.10147273767418065)\n",
      "     | > log_mle: -0.29755067825317383  (-0.28866735932790694)\n",
      "     | > loss_dur: 0.17714720964431763  (0.18719462165372633)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(50.9767, device='cuda:0')  (tensor(26.4877, device='cuda:0'))\n",
      "     | > current_lr: 1.45e-05 \n",
      "     | > step_time: 0.6214  (0.5880382883972319)\n",
      "     | > loader_time: 0.0282  (0.011522158753448327)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:03:32 -- STEP: 222/406 -- GLOBAL_STEP: 46500\u001b[0m\n",
      "     | > loss: -0.10992655158042908  (-0.10158751475381424)\n",
      "     | > log_mle: -0.30045783519744873  (-0.2901272134737926)\n",
      "     | > loss_dur: 0.19053128361701965  (0.1885396987199784)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(30.0038, device='cuda:0')  (tensor(27.0381, device='cuda:0'))\n",
      "     | > current_lr: 1.45e-05 \n",
      "     | > step_time: 0.9663  (0.599224772539224)\n",
      "     | > loader_time: 0.0349  (0.011908878077257858)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:03:51 -- STEP: 247/406 -- GLOBAL_STEP: 46525\u001b[0m\n",
      "     | > loss: -0.09872086346149445  (-0.10165314008349834)\n",
      "     | > log_mle: -0.29098737239837646  (-0.29140028586754435)\n",
      "     | > loss_dur: 0.19226650893688202  (0.18974714578404606)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(26.4459, device='cuda:0')  (tensor(27.2925, device='cuda:0'))\n",
      "     | > current_lr: 1.45e-05 \n",
      "     | > step_time: 0.569  (0.6108429267821519)\n",
      "     | > loader_time: 0.0063  (0.012109136774472376)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:04:10 -- STEP: 272/406 -- GLOBAL_STEP: 46550\u001b[0m\n",
      "     | > loss: -0.1100517064332962  (-0.10219060870654444)\n",
      "     | > log_mle: -0.312886118888855  (-0.29256870685254827)\n",
      "     | > loss_dur: 0.20283441245555878  (0.1903780981460039)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(46.0205, device='cuda:0')  (tensor(27.6410, device='cuda:0'))\n",
      "     | > current_lr: 1.45e-05 \n",
      "     | > step_time: 0.8495  (0.622455890564357)\n",
      "     | > loader_time: 0.0085  (0.012258904821732461)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:04:28 -- STEP: 297/406 -- GLOBAL_STEP: 46575\u001b[0m\n",
      "     | > loss: -0.09979508817195892  (-0.10209349409899725)\n",
      "     | > log_mle: -0.3016613721847534  (-0.29341601041029614)\n",
      "     | > loss_dur: 0.2018662840127945  (0.1913225163112987)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(96.5425, device='cuda:0')  (tensor(27.6884, device='cuda:0'))\n",
      "     | > current_lr: 1.45e-05 \n",
      "     | > step_time: 0.6498  (0.6311313383507)\n",
      "     | > loader_time: 0.0069  (0.01235067322599366)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:04:47 -- STEP: 322/406 -- GLOBAL_STEP: 46600\u001b[0m\n",
      "     | > loss: -0.11979493498802185  (-0.10199316692833572)\n",
      "     | > log_mle: -0.3063274621963501  (-0.29411817300393733)\n",
      "     | > loss_dur: 0.18653252720832825  (0.1921250060756015)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(30.4446, device='cuda:0')  (tensor(27.9740, device='cuda:0'))\n",
      "     | > current_lr: 1.45e-05 \n",
      "     | > step_time: 0.6613  (0.6389112502151391)\n",
      "     | > loader_time: 0.0067  (0.01270387409636693)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:05:07 -- STEP: 347/406 -- GLOBAL_STEP: 46625\u001b[0m\n",
      "     | > loss: -0.11325863003730774  (-0.10191134971053867)\n",
      "     | > log_mle: -0.303241491317749  (-0.2948239485193743)\n",
      "     | > loss_dur: 0.18998286128044128  (0.19291259880883566)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(32.8427, device='cuda:0')  (tensor(29.0075, device='cuda:0'))\n",
      "     | > current_lr: 1.45e-05 \n",
      "     | > step_time: 0.661  (0.6483976483688568)\n",
      "     | > loader_time: 0.0069  (0.013044669236504722)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:05:27 -- STEP: 372/406 -- GLOBAL_STEP: 46650\u001b[0m\n",
      "     | > loss: -0.0909176915884018  (-0.10205070914760711)\n",
      "     | > log_mle: -0.29739856719970703  (-0.2957142517771773)\n",
      "     | > loss_dur: 0.20648087561130524  (0.19366354262957025)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(40.3933, device='cuda:0')  (tensor(29.6065, device='cuda:0'))\n",
      "     | > current_lr: 1.45e-05 \n",
      "     | > step_time: 0.6697  (0.6571647826061447)\n",
      "     | > loader_time: 0.0434  (0.01327759091572095)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:05:46 -- STEP: 397/406 -- GLOBAL_STEP: 46675\u001b[0m\n",
      "     | > loss: -0.11266325414180756  (-0.10206487193065565)\n",
      "     | > log_mle: -0.31378841400146484  (-0.296280845286564)\n",
      "     | > loss_dur: 0.2011251598596573  (0.19421597335590837)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(33.8297, device='cuda:0')  (tensor(30.5756, device='cuda:0'))\n",
      "     | > current_lr: 1.45e-05 \n",
      "     | > step_time: 0.5132  (0.6634644459116663)\n",
      "     | > loader_time: 0.0062  (0.0133685597244378)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: -0.09463372826576233  (-0.09463372826576233)\n",
      "     | > log_mle: -0.2800072431564331  (-0.2800072431564331)\n",
      "     | > loss_dur: 0.18537351489067078  (0.18537351489067078)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: -0.16158203780651093  (-0.16158203780651093)\n",
      "     | > log_mle: -0.321377158164978  (-0.321377158164978)\n",
      "     | > loss_dur: 0.1597951203584671  (0.1597951203584671)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: -0.13133499026298523  (-0.14645851403474808)\n",
      "     | > log_mle: -0.2836500406265259  (-0.30251359939575195)\n",
      "     | > loss_dur: 0.15231505036354065  (0.15605508536100388)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: -0.14057959616184235  (-0.1444988747437795)\n",
      "     | > log_mle: -0.29475247859954834  (-0.29992655913035077)\n",
      "     | > loss_dur: 0.154172882437706  (0.15542768438657126)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: -0.15660537779331207  (-0.14752550050616264)\n",
      "     | > log_mle: -0.3218710422515869  (-0.3054126799106598)\n",
      "     | > loss_dur: 0.16526566445827484  (0.15788717940449715)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: -0.1519034504890442  (-0.14840109050273895)\n",
      "     | > log_mle: -0.32365262508392334  (-0.3090606689453125)\n",
      "     | > loss_dur: 0.17174917459487915  (0.16065957844257356)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: -0.10198859870433807  (-0.14066567520300546)\n",
      "     | > log_mle: -0.33319973945617676  (-0.31308384736378986)\n",
      "     | > loss_dur: 0.23121114075183868  (0.1724181721607844)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: -0.11573615670204163  (-0.13710431541715348)\n",
      "     | > log_mle: -0.293148398399353  (-0.31023592608315603)\n",
      "     | > loss_dur: 0.1774122416973114  (0.17313161066600255)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: -0.14659179747104645  (-0.1382902506738901)\n",
      "     | > log_mle: -0.30580949783325195  (-0.30968262255191803)\n",
      "     | > loss_dur: 0.1592177003622055  (0.17139237187802792)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: -0.12334078550338745  (-0.13662919898827872)\n",
      "     | > log_mle: -0.3194758892059326  (-0.31077076329125297)\n",
      "     | > loss_dur: 0.19613510370254517  (0.17414156430297428)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: -0.10684885084629059  (-0.1336511641740799)\n",
      "     | > log_mle: -0.3041955232620239  (-0.31011323928833007)\n",
      "     | > loss_dur: 0.19734667241573334  (0.1764620751142502)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: -0.1262533962726593  (-0.1329786398194053)\n",
      "     | > log_mle: -0.3211243152618408  (-0.3111142461950129)\n",
      "     | > loss_dur: 0.19487091898918152  (0.17813560637560757)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: -0.14081327617168427  (-0.1336315261820952)\n",
      "     | > log_mle: -0.3062320947647095  (-0.3107074002424876)\n",
      "     | > loss_dur: 0.1654188185930252  (0.17707587406039238)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: -0.1643839329481125  (-0.13599709593332732)\n",
      "     | > log_mle: -0.32950520515441895  (-0.31215338523571307)\n",
      "     | > loss_dur: 0.16512127220630646  (0.17615628930238578)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: -0.12694649398326874  (-0.135350624365466)\n",
      "     | > log_mle: -0.3187345266342163  (-0.31262346676417757)\n",
      "     | > loss_dur: 0.19178803265094757  (0.1772728423987116)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: -0.12510421872138977  (-0.1346675306558609)\n",
      "     | > log_mle: -0.3117917776107788  (-0.3125680208206177)\n",
      "     | > loss_dur: 0.18668755888938904  (0.17790049016475679)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: -0.11204953491687775  (-0.13325390592217445)\n",
      "     | > log_mle: -0.31388700008392334  (-0.3126504570245743)\n",
      "     | > loss_dur: 0.2018374651670456  (0.17939655110239983)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: audio amplitude out of range, auto clipped.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[91m 0.004582032561302185 \u001b[0m(+0.0011457204818725586)\n",
      "     | > avg_loss:\u001b[92m -0.13325390592217445 \u001b[0m(-0.0025126496329903325)\n",
      "     | > avg_log_mle:\u001b[92m -0.3126504570245743 \u001b[0m(-0.0023458003997802734)\n",
      "     | > avg_loss_dur:\u001b[92m 0.17939655110239983 \u001b[0m(-0.00016684923321008682)\n",
      "\n",
      " > BEST MODEL : train/run-February-22-2025_10+59PM-fa84af3/best_model_46684.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 59/100\u001b[0m\n",
      " --> train/run-February-22-2025_10+59PM-fa84af3\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-23 04:06:07) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:06:15 -- STEP: 16/406 -- GLOBAL_STEP: 46700\u001b[0m\n",
      "     | > loss: -0.11629067361354828  (-0.12176601402461529)\n",
      "     | > log_mle: -0.2811928987503052  (-0.28138429671525955)\n",
      "     | > loss_dur: 0.1649022251367569  (0.15961828269064426)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(20.6439, device='cuda:0')  (tensor(23.2995, device='cuda:0'))\n",
      "     | > current_lr: 1.475e-05 \n",
      "     | > step_time: 0.4529  (0.3829340934753418)\n",
      "     | > loader_time: 0.0038  (0.006347954273223877)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:06:29 -- STEP: 41/406 -- GLOBAL_STEP: 46725\u001b[0m\n",
      "     | > loss: -0.10785427689552307  (-0.11039028807384212)\n",
      "     | > log_mle: -0.27550816535949707  (-0.2774628866009596)\n",
      "     | > loss_dur: 0.167653888463974  (0.16707259852711745)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(9.8102, device='cuda:0')  (tensor(23.3043, device='cuda:0'))\n",
      "     | > current_lr: 1.475e-05 \n",
      "     | > step_time: 0.7362  (0.4824294171682218)\n",
      "     | > loader_time: 0.0042  (0.008173035412299924)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:06:44 -- STEP: 66/406 -- GLOBAL_STEP: 46750\u001b[0m\n",
      "     | > loss: -0.08621153235435486  (-0.1055904638135072)\n",
      "     | > log_mle: -0.2825216054916382  (-0.2787214011857003)\n",
      "     | > loss_dur: 0.19631007313728333  (0.1731309373721932)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(14.6402, device='cuda:0')  (tensor(25.1142, device='cuda:0'))\n",
      "     | > current_lr: 1.475e-05 \n",
      "     | > step_time: 0.3383  (0.5197868383291998)\n",
      "     | > loader_time: 0.0191  (0.009983799674294209)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:06:59 -- STEP: 91/406 -- GLOBAL_STEP: 46775\u001b[0m\n",
      "     | > loss: -0.1144368052482605  (-0.10507168514387948)\n",
      "     | > log_mle: -0.29795002937316895  (-0.281561677272503)\n",
      "     | > loss_dur: 0.18351322412490845  (0.1764899921286237)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(37.3921, device='cuda:0')  (tensor(24.5253, device='cuda:0'))\n",
      "     | > current_lr: 1.475e-05 \n",
      "     | > step_time: 0.7804  (0.5376457617833064)\n",
      "     | > loader_time: 0.0065  (0.010256686053433257)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:07:15 -- STEP: 116/406 -- GLOBAL_STEP: 46800\u001b[0m\n",
      "     | > loss: -0.08881448209285736  (-0.10464697241269309)\n",
      "     | > log_mle: -0.28246915340423584  (-0.2842231300370446)\n",
      "     | > loss_dur: 0.19365467131137848  (0.17957615762435156)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(18.3530, device='cuda:0')  (tensor(26.3118, device='cuda:0'))\n",
      "     | > current_lr: 1.475e-05 \n",
      "     | > step_time: 0.8845  (0.5547884312169308)\n",
      "     | > loader_time: 0.0053  (0.010170439193988665)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:07:30 -- STEP: 141/406 -- GLOBAL_STEP: 46825\u001b[0m\n",
      "     | > loss: -0.1037214994430542  (-0.10396747978021068)\n",
      "     | > log_mle: -0.302390456199646  (-0.2864682598316923)\n",
      "     | > loss_dur: 0.1986689567565918  (0.18250078005148165)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(29.4512, device='cuda:0')  (tensor(26.2948, device='cuda:0'))\n",
      "     | > current_lr: 1.475e-05 \n",
      "     | > step_time: 0.746  (0.5604285771119681)\n",
      "     | > loader_time: 0.0303  (0.010529519818353312)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:07:45 -- STEP: 166/406 -- GLOBAL_STEP: 46850\u001b[0m\n",
      "     | > loss: -0.11532805860042572  (-0.10351988466748271)\n",
      "     | > log_mle: -0.3046640157699585  (-0.288069185722305)\n",
      "     | > loss_dur: 0.18933595716953278  (0.1845493010548224)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(36.5310, device='cuda:0')  (tensor(26.7217, device='cuda:0'))\n",
      "     | > current_lr: 1.475e-05 \n",
      "     | > step_time: 0.5962  (0.5657879817916688)\n",
      "     | > loader_time: 0.0224  (0.011130202247435786)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:08:03 -- STEP: 191/406 -- GLOBAL_STEP: 46875\u001b[0m\n",
      "     | > loss: -0.10941560566425323  (-0.1036573060207966)\n",
      "     | > log_mle: -0.29388511180877686  (-0.28957864189647264)\n",
      "     | > loss_dur: 0.18446950614452362  (0.18592133587567597)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(19.1191, device='cuda:0')  (tensor(26.4769, device='cuda:0'))\n",
      "     | > current_lr: 1.475e-05 \n",
      "     | > step_time: 0.5459  (0.5820524692535402)\n",
      "     | > loader_time: 0.0311  (0.011207109970572102)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:08:20 -- STEP: 216/406 -- GLOBAL_STEP: 46900\u001b[0m\n",
      "     | > loss: -0.10649733245372772  (-0.10388039307737792)\n",
      "     | > log_mle: -0.31215739250183105  (-0.2909125768476064)\n",
      "     | > loss_dur: 0.20566006004810333  (0.18703218377022834)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(28.3342, device='cuda:0')  (tensor(27.2633, device='cuda:0'))\n",
      "     | > current_lr: 1.475e-05 \n",
      "     | > step_time: 0.6129  (0.593027299201047)\n",
      "     | > loader_time: 0.0063  (0.011528744741722385)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:08:40 -- STEP: 241/406 -- GLOBAL_STEP: 46925\u001b[0m\n",
      "     | > loss: -0.09628637135028839  (-0.10400331743772594)\n",
      "     | > log_mle: -0.29868805408477783  (-0.2923175368566237)\n",
      "     | > loss_dur: 0.20240168273448944  (0.1883142194188977)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(30.0547, device='cuda:0')  (tensor(28.1028, device='cuda:0'))\n",
      "     | > current_lr: 1.475e-05 \n",
      "     | > step_time: 0.7012  (0.6111337347149355)\n",
      "     | > loader_time: 0.0109  (0.011795811633351428)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:08:57 -- STEP: 266/406 -- GLOBAL_STEP: 46950\u001b[0m\n",
      "     | > loss: -0.1089877039194107  (-0.10409267610849295)\n",
      "     | > log_mle: -0.304288387298584  (-0.2932778767177038)\n",
      "     | > loss_dur: 0.19530068337917328  (0.18918520060921076)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(40.7524, device='cuda:0')  (tensor(29.1087, device='cuda:0'))\n",
      "     | > current_lr: 1.475e-05 \n",
      "     | > step_time: 0.9958  (0.61820788222148)\n",
      "     | > loader_time: 0.0094  (0.011908011328905146)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:09:16 -- STEP: 291/406 -- GLOBAL_STEP: 46975\u001b[0m\n",
      "     | > loss: -0.09775763750076294  (-0.10423133381453582)\n",
      "     | > log_mle: -0.2996056079864502  (-0.29421429412881117)\n",
      "     | > loss_dur: 0.20184797048568726  (0.18998296031427547)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(18.5723, device='cuda:0')  (tensor(28.9599, device='cuda:0'))\n",
      "     | > current_lr: 1.475e-05 \n",
      "     | > step_time: 0.676  (0.6278462754082434)\n",
      "     | > loader_time: 0.0185  (0.012321967849207085)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:09:36 -- STEP: 316/406 -- GLOBAL_STEP: 47000\u001b[0m\n",
      "     | > loss: -0.11541013419628143  (-0.10447718226645573)\n",
      "     | > log_mle: -0.313443660736084  (-0.2951424502873721)\n",
      "     | > loss_dur: 0.19803352653980255  (0.19066526802091657)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(19.8119, device='cuda:0')  (tensor(29.6166, device='cuda:0'))\n",
      "     | > current_lr: 1.475e-05 \n",
      "     | > step_time: 0.8211  (0.6392597752281386)\n",
      "     | > loader_time: 0.0069  (0.01240618696695641)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:09:55 -- STEP: 341/406 -- GLOBAL_STEP: 47025\u001b[0m\n",
      "     | > loss: -0.1079803854227066  (-0.10415429777064288)\n",
      "     | > log_mle: -0.306209921836853  (-0.2957076428572801)\n",
      "     | > loss_dur: 0.19822953641414642  (0.1915533450866375)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(22.7644, device='cuda:0')  (tensor(29.2720, device='cuda:0'))\n",
      "     | > current_lr: 1.475e-05 \n",
      "     | > step_time: 0.7868  (0.6470484223184004)\n",
      "     | > loader_time: 0.0085  (0.01249671052278311)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:10:15 -- STEP: 366/406 -- GLOBAL_STEP: 47050\u001b[0m\n",
      "     | > loss: -0.11353735625743866  (-0.10408558859362634)\n",
      "     | > log_mle: -0.3102741241455078  (-0.29648457329129896)\n",
      "     | > loss_dur: 0.19673676788806915  (0.19239898469767283)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(31.9748, device='cuda:0')  (tensor(30.0604, device='cuda:0'))\n",
      "     | > current_lr: 1.475e-05 \n",
      "     | > step_time: 0.6175  (0.655831711539806)\n",
      "     | > loader_time: 0.0073  (0.012738743114992563)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:10:36 -- STEP: 391/406 -- GLOBAL_STEP: 47075\u001b[0m\n",
      "     | > loss: -0.11066719889640808  (-0.10408591789662691)\n",
      "     | > log_mle: -0.31296050548553467  (-0.2971509798713351)\n",
      "     | > loss_dur: 0.2022933065891266  (0.19306506197470838)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(64.2339, device='cuda:0')  (tensor(30.5950, device='cuda:0'))\n",
      "     | > current_lr: 1.475e-05 \n",
      "     | > step_time: 0.9632  (0.666878474033093)\n",
      "     | > loader_time: 0.0178  (0.01303299247761211)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: -0.0972515344619751  (-0.0972515344619751)\n",
      "     | > log_mle: -0.2801518440246582  (-0.2801518440246582)\n",
      "     | > loss_dur: 0.1829003095626831  (0.1829003095626831)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: -0.15973344445228577  (-0.15973344445228577)\n",
      "     | > log_mle: -0.31918442249298096  (-0.31918442249298096)\n",
      "     | > loss_dur: 0.1594509780406952  (0.1594509780406952)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: -0.13002076745033264  (-0.1448771059513092)\n",
      "     | > log_mle: -0.28358352184295654  (-0.30138397216796875)\n",
      "     | > loss_dur: 0.1535627543926239  (0.15650686621665955)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: -0.13034605979919434  (-0.14003342390060425)\n",
      "     | > log_mle: -0.2930166721343994  (-0.298594872156779)\n",
      "     | > loss_dur: 0.16267061233520508  (0.15856144825617471)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: -0.15250664949417114  (-0.14315173029899597)\n",
      "     | > log_mle: -0.3187556266784668  (-0.3036350607872009)\n",
      "     | > loss_dur: 0.16624897718429565  (0.16048333048820496)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: -0.14690986275672913  (-0.1439033567905426)\n",
      "     | > log_mle: -0.3182269334793091  (-0.30655343532562257)\n",
      "     | > loss_dur: 0.17131707072257996  (0.16265007853507996)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: -0.09453463554382324  (-0.13567523658275604)\n",
      "     | > log_mle: -0.32538485527038574  (-0.30969200531641644)\n",
      "     | > loss_dur: 0.2308502197265625  (0.17401676873366037)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: -0.10808339715003967  (-0.13173354523522512)\n",
      "     | > log_mle: -0.2906930446624756  (-0.30697786808013916)\n",
      "     | > loss_dur: 0.1826096475124359  (0.17524432284491404)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: -0.138419046998024  (-0.132569232955575)\n",
      "     | > log_mle: -0.30306220054626465  (-0.30648840963840485)\n",
      "     | > loss_dur: 0.16464315354824066  (0.17391917668282986)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: -0.11186504364013672  (-0.13026876747608185)\n",
      "     | > log_mle: -0.3141803741455078  (-0.3073430723614163)\n",
      "     | > loss_dur: 0.2023153305053711  (0.17707430488533443)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: -0.1047104001045227  (-0.12771293073892592)\n",
      "     | > log_mle: -0.3009239435195923  (-0.30670115947723386)\n",
      "     | > loss_dur: 0.19621354341506958  (0.17898822873830794)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: -0.11933448910713196  (-0.12695125422694467)\n",
      "     | > log_mle: -0.31708967685699463  (-0.3076455701481212)\n",
      "     | > loss_dur: 0.19775518774986267  (0.18069431592117657)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: -0.13119879364967346  (-0.1273052158455054)\n",
      "     | > log_mle: -0.3042205572128296  (-0.3073601524035136)\n",
      "     | > loss_dur: 0.17302176356315613  (0.1800549365580082)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: -0.15700919926166534  (-0.12959013764674848)\n",
      "     | > log_mle: -0.32637202739715576  (-0.3088226043261014)\n",
      "     | > loss_dur: 0.16936282813549042  (0.17923246667935297)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: -0.11823485791683197  (-0.12877904623746875)\n",
      "     | > log_mle: -0.3150531053543091  (-0.30926764011383057)\n",
      "     | > loss_dur: 0.1968182474374771  (0.18048859387636185)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: -0.12411175668239594  (-0.1284678936004639)\n",
      "     | > log_mle: -0.30855703353881836  (-0.3092202663421631)\n",
      "     | > loss_dur: 0.18444527685642242  (0.18075237274169922)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: -0.11623746156692505  (-0.12770349159836772)\n",
      "     | > log_mle: -0.3104318380355835  (-0.30929598957300186)\n",
      "     | > loss_dur: 0.19419437646865845  (0.18159249797463417)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: audio amplitude out of range, auto clipped.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.0034376829862594604 \u001b[0m(-0.0011443495750427246)\n",
      "     | > avg_loss:\u001b[91m -0.12770349159836772 \u001b[0m(+0.005550414323806735)\n",
      "     | > avg_log_mle:\u001b[91m -0.30929598957300186 \u001b[0m(+0.003354467451572418)\n",
      "     | > avg_loss_dur:\u001b[91m 0.18159249797463417 \u001b[0m(+0.0021959468722343445)\n",
      "\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 60/100\u001b[0m\n",
      " --> train/run-February-22-2025_10+59PM-fa84af3\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-23 04:10:58) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:11:04 -- STEP: 10/406 -- GLOBAL_STEP: 47100\u001b[0m\n",
      "     | > loss: -0.14001287519931793  (-0.12425225377082824)\n",
      "     | > log_mle: -0.2858097553253174  (-0.28134191036224365)\n",
      "     | > loss_dur: 0.14579688012599945  (0.1570896565914154)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(17.9096, device='cuda:0')  (tensor(21.8384, device='cuda:0'))\n",
      "     | > current_lr: 1.4999999999999999e-05 \n",
      "     | > step_time: 0.3459  (0.41073424816131593)\n",
      "     | > loader_time: 0.0028  (0.007928180694580077)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:11:17 -- STEP: 35/406 -- GLOBAL_STEP: 47125\u001b[0m\n",
      "     | > loss: -0.12100258469581604  (-0.1129607502903257)\n",
      "     | > log_mle: -0.2894822359085083  (-0.2794672455106463)\n",
      "     | > loss_dur: 0.16847965121269226  (0.16650649522032057)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(9.4165, device='cuda:0')  (tensor(21.8191, device='cuda:0'))\n",
      "     | > current_lr: 1.4999999999999999e-05 \n",
      "     | > step_time: 0.7997  (0.4820686340332031)\n",
      "     | > loader_time: 0.0083  (0.008100734438214983)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:11:31 -- STEP: 60/406 -- GLOBAL_STEP: 47150\u001b[0m\n",
      "     | > loss: -0.10159577429294586  (-0.108131492882967)\n",
      "     | > log_mle: -0.2814081907272339  (-0.28033310373624165)\n",
      "     | > loss_dur: 0.17981241643428802  (0.17220161085327462)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(46.7330, device='cuda:0')  (tensor(21.6246, device='cuda:0'))\n",
      "     | > current_lr: 1.4999999999999999e-05 \n",
      "     | > step_time: 0.3207  (0.5042153080304463)\n",
      "     | > loader_time: 0.0045  (0.009140205383300782)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:11:46 -- STEP: 85/406 -- GLOBAL_STEP: 47175\u001b[0m\n",
      "     | > loss: -0.12699194252490997  (-0.10749866717001971)\n",
      "     | > log_mle: -0.30285072326660156  (-0.2828719559837789)\n",
      "     | > loss_dur: 0.1758587807416916  (0.17537328881375924)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(30.4801, device='cuda:0')  (tensor(24.5434, device='cuda:0'))\n",
      "     | > current_lr: 1.4999999999999999e-05 \n",
      "     | > step_time: 0.6731  (0.5298167986028334)\n",
      "     | > loader_time: 0.0536  (0.010526934792013729)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:12:00 -- STEP: 110/406 -- GLOBAL_STEP: 47200\u001b[0m\n",
      "     | > loss: -0.09505169093608856  (-0.10644966540011493)\n",
      "     | > log_mle: -0.3094877004623413  (-0.28554199392145324)\n",
      "     | > loss_dur: 0.21443600952625275  (0.1790923285213383)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(24.9273, device='cuda:0')  (tensor(25.2918, device='cuda:0'))\n",
      "     | > current_lr: 1.4999999999999999e-05 \n",
      "     | > step_time: 0.3487  (0.5358586007898504)\n",
      "     | > loader_time: 0.0046  (0.010345994342457162)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:12:16 -- STEP: 135/406 -- GLOBAL_STEP: 47225\u001b[0m\n",
      "     | > loss: -0.09864364564418793  (-0.10621853316271747)\n",
      "     | > log_mle: -0.3039517402648926  (-0.28778771471094194)\n",
      "     | > loss_dur: 0.20530809462070465  (0.1815691815482245)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(16.7604, device='cuda:0')  (tensor(26.3728, device='cuda:0'))\n",
      "     | > current_lr: 1.4999999999999999e-05 \n",
      "     | > step_time: 0.6262  (0.5472328556908499)\n",
      "     | > loader_time: 0.0053  (0.010635686803747104)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:12:33 -- STEP: 160/406 -- GLOBAL_STEP: 47250\u001b[0m\n",
      "     | > loss: -0.09763754904270172  (-0.10558342169970276)\n",
      "     | > log_mle: -0.30139636993408203  (-0.2893843092024325)\n",
      "     | > loss_dur: 0.2037588208913803  (0.18380088750272983)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(42.0970, device='cuda:0')  (tensor(26.9757, device='cuda:0'))\n",
      "     | > current_lr: 1.4999999999999999e-05 \n",
      "     | > step_time: 0.563  (0.5666663900017734)\n",
      "     | > loader_time: 0.0063  (0.010874736309051511)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:12:51 -- STEP: 185/406 -- GLOBAL_STEP: 47275\u001b[0m\n",
      "     | > loss: -0.11108416318893433  (-0.10558709872735515)\n",
      "     | > log_mle: -0.30827200412750244  (-0.2907936057528933)\n",
      "     | > loss_dur: 0.19718784093856812  (0.18520650702553826)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(16.2141, device='cuda:0')  (tensor(27.2668, device='cuda:0'))\n",
      "     | > current_lr: 1.4999999999999999e-05 \n",
      "     | > step_time: 0.7844  (0.5852000983985692)\n",
      "     | > loader_time: 0.0051  (0.011099459673907306)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:13:08 -- STEP: 210/406 -- GLOBAL_STEP: 47300\u001b[0m\n",
      "     | > loss: -0.10932140052318573  (-0.10551833765847345)\n",
      "     | > log_mle: -0.2992227077484131  (-0.2919434905052183)\n",
      "     | > loss_dur: 0.18990130722522736  (0.18642515284674507)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(63.5813, device='cuda:0')  (tensor(28.2136, device='cuda:0'))\n",
      "     | > current_lr: 1.4999999999999999e-05 \n",
      "     | > step_time: 1.0514  (0.5967688969203403)\n",
      "     | > loader_time: 0.0101  (0.011469172296069917)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:13:26 -- STEP: 235/406 -- GLOBAL_STEP: 47325\u001b[0m\n",
      "     | > loss: -0.10709585249423981  (-0.10547265752832942)\n",
      "     | > log_mle: -0.3011455535888672  (-0.2933456319443721)\n",
      "     | > loss_dur: 0.19404970109462738  (0.1878729744160429)\n",
      "     | > amp_scaler: 2048.0  (3895.5574468085106)\n",
      "     | > grad_norm: tensor(29.6880, device='cuda:0')  (tensor(30.2281, device='cuda:0'))\n",
      "     | > current_lr: 1.4999999999999999e-05 \n",
      "     | > step_time: 0.4991  (0.6070139245784028)\n",
      "     | > loader_time: 0.0066  (0.011886228399073825)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:13:45 -- STEP: 260/406 -- GLOBAL_STEP: 47350\u001b[0m\n",
      "     | > loss: -0.11977170407772064  (-0.10591447399212765)\n",
      "     | > log_mle: -0.3148510456085205  (-0.294685289951471)\n",
      "     | > loss_dur: 0.19507934153079987  (0.18877081595934353)\n",
      "     | > amp_scaler: 2048.0  (3717.9076923076923)\n",
      "     | > grad_norm: tensor(24.0651, device='cuda:0')  (tensor(29.9074, device='cuda:0'))\n",
      "     | > current_lr: 1.4999999999999999e-05 \n",
      "     | > step_time: 0.7558  (0.6172568330397972)\n",
      "     | > loader_time: 0.031  (0.012254155599153958)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:14:03 -- STEP: 285/406 -- GLOBAL_STEP: 47375\u001b[0m\n",
      "     | > loss: -0.09835155308246613  (-0.10622430569247197)\n",
      "     | > log_mle: -0.29754066467285156  (-0.29568683180892663)\n",
      "     | > loss_dur: 0.19918911159038544  (0.1894625261164548)\n",
      "     | > amp_scaler: 2048.0  (3571.4245614035085)\n",
      "     | > grad_norm: tensor(25.6833, device='cuda:0')  (tensor(30.7966, device='cuda:0'))\n",
      "     | > current_lr: 1.4999999999999999e-05 \n",
      "     | > step_time: 0.7319  (0.6249249960246837)\n",
      "     | > loader_time: 0.0222  (0.012550131479899087)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:14:22 -- STEP: 310/406 -- GLOBAL_STEP: 47400\u001b[0m\n",
      "     | > loss: -0.10831020772457123  (-0.10640239994372092)\n",
      "     | > log_mle: -0.30949676036834717  (-0.29656533925764006)\n",
      "     | > loss_dur: 0.20118655264377594  (0.19016293931391928)\n",
      "     | > amp_scaler: 2048.0  (3448.567741935483)\n",
      "     | > grad_norm: tensor(23.9545, device='cuda:0')  (tensor(30.4423, device='cuda:0'))\n",
      "     | > current_lr: 1.4999999999999999e-05 \n",
      "     | > step_time: 0.7476  (0.6339735315692039)\n",
      "     | > loader_time: 0.0196  (0.0129432785895563)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:14:42 -- STEP: 335/406 -- GLOBAL_STEP: 47425\u001b[0m\n",
      "     | > loss: -0.0806388258934021  (-0.10627743975440068)\n",
      "     | > log_mle: -0.30413222312927246  (-0.29722170723018343)\n",
      "     | > loss_dur: 0.22349339723587036  (0.19094426747578286)\n",
      "     | > amp_scaler: 2048.0  (3344.047761194029)\n",
      "     | > grad_norm: tensor(30.4927, device='cuda:0')  (tensor(30.2145, device='cuda:0'))\n",
      "     | > current_lr: 1.4999999999999999e-05 \n",
      "     | > step_time: 0.7252  (0.6443480982709288)\n",
      "     | > loader_time: 0.0085  (0.013103934188387293)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:15:02 -- STEP: 360/406 -- GLOBAL_STEP: 47450\u001b[0m\n",
      "     | > loss: -0.12117230892181396  (-0.10618619260688623)\n",
      "     | > log_mle: -0.3096778392791748  (-0.2979134682152006)\n",
      "     | > loss_dur: 0.18850553035736084  (0.19172727560831432)\n",
      "     | > amp_scaler: 2048.0  (3254.044444444444)\n",
      "     | > grad_norm: tensor(11.8471, device='cuda:0')  (tensor(30.3582, device='cuda:0'))\n",
      "     | > current_lr: 1.4999999999999999e-05 \n",
      "     | > step_time: 0.6001  (0.6534863081243305)\n",
      "     | > loader_time: 0.0133  (0.013405425018734407)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:15:22 -- STEP: 385/406 -- GLOBAL_STEP: 47475\u001b[0m\n",
      "     | > loss: -0.10186071693897247  (-0.10629185202059807)\n",
      "     | > log_mle: -0.3033188581466675  (-0.29864227121526543)\n",
      "     | > loss_dur: 0.201458141207695  (0.1923504191946673)\n",
      "     | > amp_scaler: 2048.0  (3175.7298701298696)\n",
      "     | > grad_norm: tensor(20.2738, device='cuda:0')  (tensor(30.9184, device='cuda:0'))\n",
      "     | > current_lr: 1.4999999999999999e-05 \n",
      "     | > step_time: 0.7045  (0.6632738330147487)\n",
      "     | > loader_time: 0.0088  (0.01361607204784047)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: -0.09540623426437378  (-0.09540623426437378)\n",
      "     | > log_mle: -0.2833186388015747  (-0.2833186388015747)\n",
      "     | > loss_dur: 0.18791240453720093  (0.18791240453720093)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: -0.15451893210411072  (-0.15451893210411072)\n",
      "     | > log_mle: -0.3231238126754761  (-0.3231238126754761)\n",
      "     | > loss_dur: 0.16860488057136536  (0.16860488057136536)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: -0.12943938374519348  (-0.1419791579246521)\n",
      "     | > log_mle: -0.2864797115325928  (-0.3048017621040344)\n",
      "     | > loss_dur: 0.1570403277873993  (0.16282260417938232)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: -0.13925129175186157  (-0.14106986920038858)\n",
      "     | > log_mle: -0.2965056896209717  (-0.3020364046096802)\n",
      "     | > loss_dur: 0.1572543978691101  (0.1609665354092916)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: -0.15760670602321625  (-0.1452040784060955)\n",
      "     | > log_mle: -0.3231329917907715  (-0.307310551404953)\n",
      "     | > loss_dur: 0.16552628576755524  (0.1621064729988575)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: -0.15138842165470123  (-0.14644094705581664)\n",
      "     | > log_mle: -0.3224186897277832  (-0.31033217906951904)\n",
      "     | > loss_dur: 0.17103026807308197  (0.1638912320137024)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: -0.09661850333213806  (-0.13813720643520355)\n",
      "     | > log_mle: -0.33053135871887207  (-0.3136987090110779)\n",
      "     | > loss_dur: 0.233912855386734  (0.17556150257587433)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: -0.11270678043365479  (-0.1345042884349823)\n",
      "     | > log_mle: -0.2944357395172119  (-0.3109468562262399)\n",
      "     | > loss_dur: 0.18172895908355713  (0.17644256779125758)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: -0.1487387865781784  (-0.1362836007028818)\n",
      "     | > log_mle: -0.30677926540374756  (-0.31042590737342834)\n",
      "     | > loss_dur: 0.15804047882556915  (0.17414230667054653)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: -0.11784897744655609  (-0.13423530922995675)\n",
      "     | > log_mle: -0.3192802667617798  (-0.31140972508324516)\n",
      "     | > loss_dur: 0.2014312893152237  (0.17717441585328844)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: -0.11065663397312164  (-0.13187744170427323)\n",
      "     | > log_mle: -0.30522990226745605  (-0.31079174280166627)\n",
      "     | > loss_dur: 0.1945732682943344  (0.17891430109739304)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: -0.1253129243850708  (-0.13128066740252756)\n",
      "     | > log_mle: -0.32163405418395996  (-0.3117774074727839)\n",
      "     | > loss_dur: 0.19632112979888916  (0.18049674007025632)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: -0.1382991075515747  (-0.13186553741494814)\n",
      "     | > log_mle: -0.3077263832092285  (-0.3114398221174876)\n",
      "     | > loss_dur: 0.1694272756576538  (0.17957428470253944)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: -0.15855006873607635  (-0.13391819367041954)\n",
      "     | > log_mle: -0.3295431137084961  (-0.31283238300910365)\n",
      "     | > loss_dur: 0.17099304497241974  (0.17891418933868408)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: -0.11721515655517578  (-0.13272511959075928)\n",
      "     | > log_mle: -0.3192923069000244  (-0.3132938061441694)\n",
      "     | > loss_dur: 0.20207715034484863  (0.18056868655341013)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: -0.12726958096027374  (-0.13236141701539358)\n",
      "     | > log_mle: -0.31279051303863525  (-0.31326025327046714)\n",
      "     | > loss_dur: 0.1855209320783615  (0.18089883625507355)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: -0.11661191284656525  (-0.1313770730048418)\n",
      "     | > log_mle: -0.3146728277206421  (-0.31334853917360306)\n",
      "     | > loss_dur: 0.19806091487407684  (0.18197146616876125)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: audio amplitude out of range, auto clipped.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[91m 0.0035121142864227295 \u001b[0m(+7.443130016326904e-05)\n",
      "     | > avg_loss:\u001b[92m -0.1313770730048418 \u001b[0m(-0.0036735814064740857)\n",
      "     | > avg_log_mle:\u001b[92m -0.31334853917360306 \u001b[0m(-0.004052549600601196)\n",
      "     | > avg_loss_dur:\u001b[91m 0.18197146616876125 \u001b[0m(+0.0003789681941270828)\n",
      "\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 61/100\u001b[0m\n",
      " --> train/run-February-22-2025_10+59PM-fa84af3\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-23 04:15:50) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:15:54 -- STEP: 4/406 -- GLOBAL_STEP: 47500\u001b[0m\n",
      "     | > loss: -0.10970067977905273  (-0.1257842518389225)\n",
      "     | > log_mle: -0.2678046226501465  (-0.2840851843357086)\n",
      "     | > loss_dur: 0.15810394287109375  (0.15830093249678612)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(18.2369, device='cuda:0')  (tensor(32.6531, device='cuda:0'))\n",
      "     | > current_lr: 1.525e-05 \n",
      "     | > step_time: 0.2985  (0.46642202138900757)\n",
      "     | > loader_time: 0.0038  (0.00969153642654419)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:16:06 -- STEP: 29/406 -- GLOBAL_STEP: 47525\u001b[0m\n",
      "     | > loss: -0.11356194317340851  (-0.11924023001358428)\n",
      "     | > log_mle: -0.2923562526702881  (-0.28411720538961477)\n",
      "     | > loss_dur: 0.17879430949687958  (0.16487697537603047)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(16.8794, device='cuda:0')  (tensor(24.2320, device='cuda:0'))\n",
      "     | > current_lr: 1.525e-05 \n",
      "     | > step_time: 0.7634  (0.46914998416242926)\n",
      "     | > loader_time: 0.0056  (0.007368400179106613)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:16:21 -- STEP: 54/406 -- GLOBAL_STEP: 47550\u001b[0m\n",
      "     | > loss: -0.11248546838760376  (-0.11207822903438851)\n",
      "     | > log_mle: -0.2850022315979004  (-0.2825942635536194)\n",
      "     | > loss_dur: 0.17251676321029663  (0.1705160345192309)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(27.8589, device='cuda:0')  (tensor(24.5616, device='cuda:0'))\n",
      "     | > current_lr: 1.525e-05 \n",
      "     | > step_time: 0.8447  (0.5151855371616505)\n",
      "     | > loader_time: 0.0045  (0.008307496706644693)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:16:35 -- STEP: 79/406 -- GLOBAL_STEP: 47575\u001b[0m\n",
      "     | > loss: -0.09826460480690002  (-0.11012182224400435)\n",
      "     | > log_mle: -0.29084181785583496  (-0.28452707544157774)\n",
      "     | > loss_dur: 0.19257721304893494  (0.17440525319757344)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(22.1536, device='cuda:0')  (tensor(24.1837, device='cuda:0'))\n",
      "     | > current_lr: 1.525e-05 \n",
      "     | > step_time: 0.4819  (0.5316030858438223)\n",
      "     | > loader_time: 0.0098  (0.008902643300309968)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:16:50 -- STEP: 104/406 -- GLOBAL_STEP: 47600\u001b[0m\n",
      "     | > loss: -0.11010174453258514  (-0.10951527938819848)\n",
      "     | > log_mle: -0.2905116081237793  (-0.28739803112470186)\n",
      "     | > loss_dur: 0.18040986359119415  (0.17788275173650342)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(31.5086, device='cuda:0')  (tensor(24.0801, device='cuda:0'))\n",
      "     | > current_lr: 1.525e-05 \n",
      "     | > step_time: 0.7223  (0.5439100448901829)\n",
      "     | > loader_time: 0.0143  (0.009383671558820287)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:17:06 -- STEP: 129/406 -- GLOBAL_STEP: 47625\u001b[0m\n",
      "     | > loss: -0.11569444835186005  (-0.10973177272682041)\n",
      "     | > log_mle: -0.30633294582366943  (-0.28985910729844433)\n",
      "     | > loss_dur: 0.1906384974718094  (0.18012733457162403)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(53.2297, device='cuda:0')  (tensor(25.6891, device='cuda:0'))\n",
      "     | > current_lr: 1.525e-05 \n",
      "     | > step_time: 0.7954  (0.5561709866043203)\n",
      "     | > loader_time: 0.0054  (0.009673327438591062)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:17:22 -- STEP: 154/406 -- GLOBAL_STEP: 47650\u001b[0m\n",
      "     | > loss: -0.08800385892391205  (-0.10923988168889825)\n",
      "     | > log_mle: -0.2808115482330322  (-0.2916017329538023)\n",
      "     | > loss_dur: 0.19280768930912018  (0.18236185126490403)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(17.7075, device='cuda:0')  (tensor(26.0769, device='cuda:0'))\n",
      "     | > current_lr: 1.525e-05 \n",
      "     | > step_time: 0.7298  (0.5685249567031853)\n",
      "     | > loader_time: 0.0062  (0.010079826627458847)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:17:39 -- STEP: 179/406 -- GLOBAL_STEP: 47675\u001b[0m\n",
      "     | > loss: -0.13022850453853607  (-0.10940701518644834)\n",
      "     | > log_mle: -0.3161052465438843  (-0.29309419480116006)\n",
      "     | > loss_dur: 0.1858767420053482  (0.18368717961471173)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(10.4218, device='cuda:0')  (tensor(25.6765, device='cuda:0'))\n",
      "     | > current_lr: 1.525e-05 \n",
      "     | > step_time: 0.5515  (0.579335978577256)\n",
      "     | > loader_time: 0.0142  (0.010021850383481504)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:17:56 -- STEP: 204/406 -- GLOBAL_STEP: 47700\u001b[0m\n",
      "     | > loss: -0.1115998774766922  (-0.10894663690351973)\n",
      "     | > log_mle: -0.3054792881011963  (-0.294364822845833)\n",
      "     | > loss_dur: 0.1938794106245041  (0.18541818594231324)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(34.5924, device='cuda:0')  (tensor(27.1685, device='cuda:0'))\n",
      "     | > current_lr: 1.525e-05 \n",
      "     | > step_time: 0.8251  (0.5912611718271286)\n",
      "     | > loader_time: 0.0052  (0.010094301373350854)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:18:14 -- STEP: 229/406 -- GLOBAL_STEP: 47725\u001b[0m\n",
      "     | > loss: -0.10666227340698242  (-0.1093790193442174)\n",
      "     | > log_mle: -0.3045084476470947  (-0.29590543544969183)\n",
      "     | > loss_dur: 0.1978461742401123  (0.18652641610547444)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(33.6320, device='cuda:0')  (tensor(28.2482, device='cuda:0'))\n",
      "     | > current_lr: 1.525e-05 \n",
      "     | > step_time: 0.5674  (0.6019926924892901)\n",
      "     | > loader_time: 0.0182  (0.010361722463083058)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:18:32 -- STEP: 254/406 -- GLOBAL_STEP: 47750\u001b[0m\n",
      "     | > loss: -0.11356726288795471  (-0.10981547386627498)\n",
      "     | > log_mle: -0.30120527744293213  (-0.2973393154895212)\n",
      "     | > loss_dur: 0.18763801455497742  (0.1875238416232462)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(37.3158, device='cuda:0')  (tensor(28.9137, device='cuda:0'))\n",
      "     | > current_lr: 1.525e-05 \n",
      "     | > step_time: 0.7053  (0.6139316136442764)\n",
      "     | > loader_time: 0.0134  (0.010650778379965954)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:18:51 -- STEP: 279/406 -- GLOBAL_STEP: 47775\u001b[0m\n",
      "     | > loss: -0.08062310516834259  (-0.1101292015510648)\n",
      "     | > log_mle: -0.2935866117477417  (-0.2984297335361494)\n",
      "     | > loss_dur: 0.2129635065793991  (0.18830053198508462)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(32.1104, device='cuda:0')  (tensor(29.0879, device='cuda:0'))\n",
      "     | > current_lr: 1.525e-05 \n",
      "     | > step_time: 0.7588  (0.6233509142339011)\n",
      "     | > loader_time: 0.0186  (0.010927001207960122)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:19:09 -- STEP: 304/406 -- GLOBAL_STEP: 47800\u001b[0m\n",
      "     | > loss: -0.12090034782886505  (-0.11034127873809714)\n",
      "     | > log_mle: -0.3107779026031494  (-0.29943798443204467)\n",
      "     | > loss_dur: 0.18987755477428436  (0.1890967056939476)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(19.0034, device='cuda:0')  (tensor(29.0836, device='cuda:0'))\n",
      "     | > current_lr: 1.525e-05 \n",
      "     | > step_time: 0.52  (0.6309402937951835)\n",
      "     | > loader_time: 0.0194  (0.011201716567340652)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:19:29 -- STEP: 329/406 -- GLOBAL_STEP: 47825\u001b[0m\n",
      "     | > loss: -0.11301678419113159  (-0.11029188846744666)\n",
      "     | > log_mle: -0.29786765575408936  (-0.3000506539475228)\n",
      "     | > loss_dur: 0.18485087156295776  (0.18975876548007628)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(25.2113, device='cuda:0')  (tensor(29.4284, device='cuda:0'))\n",
      "     | > current_lr: 1.525e-05 \n",
      "     | > step_time: 0.9338  (0.641991727620272)\n",
      "     | > loader_time: 0.0234  (0.011618825077648224)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:19:48 -- STEP: 354/406 -- GLOBAL_STEP: 47850\u001b[0m\n",
      "     | > loss: -0.1088942438364029  (-0.10996886001805127)\n",
      "     | > log_mle: -0.309442400932312  (-0.3007377510690417)\n",
      "     | > loss_dur: 0.20054815709590912  (0.19076889105099068)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(38.5568, device='cuda:0')  (tensor(29.6674, device='cuda:0'))\n",
      "     | > current_lr: 1.525e-05 \n",
      "     | > step_time: 0.4997  (0.6494139776391489)\n",
      "     | > loader_time: 0.0089  (0.012004302719892081)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:20:09 -- STEP: 379/406 -- GLOBAL_STEP: 47875\u001b[0m\n",
      "     | > loss: -0.1188761293888092  (-0.11009781632700193)\n",
      "     | > log_mle: -0.3103734254837036  (-0.30145986382124584)\n",
      "     | > loss_dur: 0.1914972960948944  (0.19136204749424413)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(28.7964, device='cuda:0')  (tensor(29.8654, device='cuda:0'))\n",
      "     | > current_lr: 1.525e-05 \n",
      "     | > step_time: 0.6633  (0.6588183952824728)\n",
      "     | > loader_time: 0.0317  (0.012487673822367725)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:20:26 -- STEP: 404/406 -- GLOBAL_STEP: 47900\u001b[0m\n",
      "     | > loss: -0.1269213855266571  (-0.11026226924640117)\n",
      "     | > log_mle: -0.31122076511383057  (-0.30216629965470554)\n",
      "     | > loss_dur: 0.18429937958717346  (0.1919040304083045)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(33.3106, device='cuda:0')  (tensor(30.0591, device='cuda:0'))\n",
      "     | > current_lr: 1.525e-05 \n",
      "     | > step_time: 0.5246  (0.6601018197465642)\n",
      "     | > loader_time: 0.0071  (0.012535163671663492)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: -0.09577089548110962  (-0.09577089548110962)\n",
      "     | > log_mle: -0.2841756343841553  (-0.2841756343841553)\n",
      "     | > loss_dur: 0.18840473890304565  (0.18840473890304565)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: -0.15632255375385284  (-0.15632255375385284)\n",
      "     | > log_mle: -0.324196457862854  (-0.324196457862854)\n",
      "     | > loss_dur: 0.16787390410900116  (0.16787390410900116)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: -0.1334228515625  (-0.14487270265817642)\n",
      "     | > log_mle: -0.2879934310913086  (-0.3060949444770813)\n",
      "     | > loss_dur: 0.1545705795288086  (0.16122224181890488)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: -0.1426880955696106  (-0.14414450029532114)\n",
      "     | > log_mle: -0.2953263521194458  (-0.3025054136912028)\n",
      "     | > loss_dur: 0.1526382565498352  (0.15836091339588165)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: -0.1602204442024231  (-0.14816348627209663)\n",
      "     | > log_mle: -0.32234764099121094  (-0.30746597051620483)\n",
      "     | > loss_dur: 0.16212719678878784  (0.1593024842441082)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: -0.1487225443124771  (-0.14827529788017274)\n",
      "     | > log_mle: -0.3236030340194702  (-0.3106933832168579)\n",
      "     | > loss_dur: 0.1748804897069931  (0.16241808533668517)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: -0.1045597493648529  (-0.14098937312761942)\n",
      "     | > log_mle: -0.3314049243927002  (-0.314145306746165)\n",
      "     | > loss_dur: 0.2268451750278473  (0.17315593361854553)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: -0.12291136384010315  (-0.13840680037225997)\n",
      "     | > log_mle: -0.294877290725708  (-0.3113927330289568)\n",
      "     | > loss_dur: 0.17196592688560486  (0.17298593265669687)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: -0.14944373071193695  (-0.13978641666471958)\n",
      "     | > log_mle: -0.3070265054702759  (-0.3108469545841217)\n",
      "     | > loss_dur: 0.15758277475833893  (0.17106053791940212)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: -0.12492172420024872  (-0.13813478416866726)\n",
      "     | > log_mle: -0.319263219833374  (-0.311782095167372)\n",
      "     | > loss_dur: 0.1943414956331253  (0.1736473109987047)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: -0.11725319921970367  (-0.1360466256737709)\n",
      "     | > log_mle: -0.30539608001708984  (-0.31114349365234373)\n",
      "     | > loss_dur: 0.18814288079738617  (0.17509686797857285)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: -0.13797923922538757  (-0.13622231781482697)\n",
      "     | > log_mle: -0.3215761184692383  (-0.3120919140902432)\n",
      "     | > loss_dur: 0.1835968792438507  (0.1758695962754163)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: -0.13896994292736053  (-0.13645128657420477)\n",
      "     | > log_mle: -0.307598352432251  (-0.31171745061874384)\n",
      "     | > loss_dur: 0.16862840950489044  (0.17526616404453912)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: -0.15870094299316406  (-0.1381627986064324)\n",
      "     | > log_mle: -0.33015453815460205  (-0.31313568812150216)\n",
      "     | > loss_dur: 0.171453595161438  (0.1749728895150698)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: -0.1291578710079193  (-0.1375195894922529)\n",
      "     | > log_mle: -0.31977880001068115  (-0.31361019611358637)\n",
      "     | > loss_dur: 0.19062092900276184  (0.17609060662133352)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: -0.1327955573797226  (-0.1372046540180842)\n",
      "     | > log_mle: -0.31371963024139404  (-0.3136174917221069)\n",
      "     | > loss_dur: 0.18092407286167145  (0.17641283770402272)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: -0.12742815911769867  (-0.1365936230868101)\n",
      "     | > log_mle: -0.31538188457489014  (-0.31372776627540583)\n",
      "     | > loss_dur: 0.18795372545719147  (0.17713414318859577)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: audio amplitude out of range, auto clipped.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[91m 0.003980562090873718 \u001b[0m(+0.00046844780445098877)\n",
      "     | > avg_loss:\u001b[92m -0.1365936230868101 \u001b[0m(-0.0052165500819683075)\n",
      "     | > avg_log_mle:\u001b[92m -0.31372776627540583 \u001b[0m(-0.0003792271018027704)\n",
      "     | > avg_loss_dur:\u001b[92m 0.17713414318859577 \u001b[0m(-0.004837322980165482)\n",
      "\n",
      " > BEST MODEL : train/run-February-22-2025_10+59PM-fa84af3/best_model_47902.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 62/100\u001b[0m\n",
      " --> train/run-February-22-2025_10+59PM-fa84af3\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-23 04:20:43) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:20:56 -- STEP: 23/406 -- GLOBAL_STEP: 47925\u001b[0m\n",
      "     | > loss: -0.1062772274017334  (-0.12289174484170004)\n",
      "     | > log_mle: -0.28684568405151367  (-0.28463765849237854)\n",
      "     | > loss_dur: 0.18056845664978027  (0.16174591365067856)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(29.7224, device='cuda:0')  (tensor(33.2346, device='cuda:0'))\n",
      "     | > current_lr: 1.55e-05 \n",
      "     | > step_time: 0.4596  (0.4542986517367156)\n",
      "     | > loader_time: 0.012  (0.008765085883762524)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:21:10 -- STEP: 48/406 -- GLOBAL_STEP: 47950\u001b[0m\n",
      "     | > loss: -0.08196647465229034  (-0.11712968877206247)\n",
      "     | > log_mle: -0.2740478515625  (-0.2843066304922104)\n",
      "     | > loss_dur: 0.19208137691020966  (0.16717694172014794)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(14.6415, device='cuda:0')  (tensor(27.9196, device='cuda:0'))\n",
      "     | > current_lr: 1.55e-05 \n",
      "     | > step_time: 0.5317  (0.5037997215986252)\n",
      "     | > loader_time: 0.0141  (0.010595987240473429)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:21:24 -- STEP: 73/406 -- GLOBAL_STEP: 47975\u001b[0m\n",
      "     | > loss: -0.1089402288198471  (-0.11476869493314665)\n",
      "     | > log_mle: -0.2972651720046997  (-0.28633345316534164)\n",
      "     | > loss_dur: 0.1883249431848526  (0.17156475823219508)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(30.8256, device='cuda:0')  (tensor(26.7228, device='cuda:0'))\n",
      "     | > current_lr: 1.55e-05 \n",
      "     | > step_time: 0.3915  (0.5246584872676902)\n",
      "     | > loader_time: 0.0051  (0.010365606987313047)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:21:39 -- STEP: 98/406 -- GLOBAL_STEP: 48000\u001b[0m\n",
      "     | > loss: -0.08690525591373444  (-0.11247869079210321)\n",
      "     | > log_mle: -0.28095221519470215  (-0.28857111930847174)\n",
      "     | > loss_dur: 0.1940469592809677  (0.17609242851636847)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(15.4657, device='cuda:0')  (tensor(27.1922, device='cuda:0'))\n",
      "     | > current_lr: 1.55e-05 \n",
      "     | > step_time: 0.7213  (0.5417573646623264)\n",
      "     | > loader_time: 0.005  (0.010534308394607228)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:21:55 -- STEP: 123/406 -- GLOBAL_STEP: 48025\u001b[0m\n",
      "     | > loss: -0.10664403438568115  (-0.11220144874196712)\n",
      "     | > log_mle: -0.3065856695175171  (-0.29077000637364586)\n",
      "     | > loss_dur: 0.19994163513183594  (0.1785685576316787)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(37.7029, device='cuda:0')  (tensor(26.9082, device='cuda:0'))\n",
      "     | > current_lr: 1.55e-05 \n",
      "     | > step_time: 0.3414  (0.5520602241764224)\n",
      "     | > loader_time: 0.0167  (0.011255167364104974)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:22:10 -- STEP: 148/406 -- GLOBAL_STEP: 48050\u001b[0m\n",
      "     | > loss: -0.10424411296844482  (-0.11175492345481305)\n",
      "     | > log_mle: -0.30868422985076904  (-0.29264771857777166)\n",
      "     | > loss_dur: 0.20444011688232422  (0.18089279512295853)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(37.0502, device='cuda:0')  (tensor(28.0738, device='cuda:0'))\n",
      "     | > current_lr: 1.55e-05 \n",
      "     | > step_time: 0.8424  (0.5601702348606007)\n",
      "     | > loader_time: 0.0059  (0.011386249516461342)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:22:27 -- STEP: 173/406 -- GLOBAL_STEP: 48075\u001b[0m\n",
      "     | > loss: -0.11214543879032135  (-0.11103426066437208)\n",
      "     | > log_mle: -0.2993282079696655  (-0.29380386275363124)\n",
      "     | > loss_dur: 0.18718276917934418  (0.18276960208925902)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(21.4576, device='cuda:0')  (tensor(27.7404, device='cuda:0'))\n",
      "     | > current_lr: 1.55e-05 \n",
      "     | > step_time: 0.722  (0.5718587864341077)\n",
      "     | > loader_time: 0.006  (0.011624960541036086)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:22:44 -- STEP: 198/406 -- GLOBAL_STEP: 48100\u001b[0m\n",
      "     | > loss: -0.11086183786392212  (-0.11116312971018781)\n",
      "     | > log_mle: -0.3081895112991333  (-0.2953064724652455)\n",
      "     | > loss_dur: 0.19732767343521118  (0.18414334275505767)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(33.4181, device='cuda:0')  (tensor(27.8889, device='cuda:0'))\n",
      "     | > current_lr: 1.55e-05 \n",
      "     | > step_time: 0.8599  (0.585304020631193)\n",
      "     | > loader_time: 0.0069  (0.011818635343301173)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:23:00 -- STEP: 223/406 -- GLOBAL_STEP: 48125\u001b[0m\n",
      "     | > loss: -0.12194621562957764  (-0.11142651636504272)\n",
      "     | > log_mle: -0.3076024055480957  (-0.2966704010428869)\n",
      "     | > loss_dur: 0.18565618991851807  (0.18524388467784425)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(22.8195, device='cuda:0')  (tensor(29.0616, device='cuda:0'))\n",
      "     | > current_lr: 1.55e-05 \n",
      "     | > step_time: 0.6354  (0.5919392290671314)\n",
      "     | > loader_time: 0.0242  (0.01191275643660883)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:23:19 -- STEP: 248/406 -- GLOBAL_STEP: 48150\u001b[0m\n",
      "     | > loss: -0.12212604284286499  (-0.11146391056958706)\n",
      "     | > log_mle: -0.30844640731811523  (-0.2979495775315069)\n",
      "     | > loss_dur: 0.18632036447525024  (0.18648566696191993)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(41.3992, device='cuda:0')  (tensor(29.3855, device='cuda:0'))\n",
      "     | > current_lr: 1.55e-05 \n",
      "     | > step_time: 0.6123  (0.6046164756821051)\n",
      "     | > loader_time: 0.0064  (0.01225648772331976)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:23:38 -- STEP: 273/406 -- GLOBAL_STEP: 48175\u001b[0m\n",
      "     | > loss: -0.11832897365093231  (-0.11180353541295607)\n",
      "     | > log_mle: -0.3110494613647461  (-0.2990629917536026)\n",
      "     | > loss_dur: 0.19272048771381378  (0.18725945634064667)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(26.1589, device='cuda:0')  (tensor(29.4357, device='cuda:0'))\n",
      "     | > current_lr: 1.55e-05 \n",
      "     | > step_time: 0.9191  (0.616479487646194)\n",
      "     | > loader_time: 0.0123  (0.012452979664226151)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:23:56 -- STEP: 298/406 -- GLOBAL_STEP: 48200\u001b[0m\n",
      "     | > loss: -0.10815276205539703  (-0.11176745723557953)\n",
      "     | > log_mle: -0.3006458282470703  (-0.29986089668017907)\n",
      "     | > loss_dur: 0.19249306619167328  (0.18809343944459955)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(23.5747, device='cuda:0')  (tensor(29.6783, device='cuda:0'))\n",
      "     | > current_lr: 1.55e-05 \n",
      "     | > step_time: 0.7606  (0.6237028853205226)\n",
      "     | > loader_time: 0.0189  (0.012585327129235999)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:24:16 -- STEP: 323/406 -- GLOBAL_STEP: 48225\u001b[0m\n",
      "     | > loss: -0.11277395486831665  (-0.1116390674844984)\n",
      "     | > log_mle: -0.3144948482513428  (-0.30055693391675936)\n",
      "     | > loss_dur: 0.20172089338302612  (0.1889178664322608)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(21.3960, device='cuda:0')  (tensor(30.6028, device='cuda:0'))\n",
      "     | > current_lr: 1.55e-05 \n",
      "     | > step_time: 1.0166  (0.6351423640000192)\n",
      "     | > loader_time: 0.006  (0.012877984681734728)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:24:35 -- STEP: 348/406 -- GLOBAL_STEP: 48250\u001b[0m\n",
      "     | > loss: -0.11149251461029053  (-0.11135207347828767)\n",
      "     | > log_mle: -0.3151404857635498  (-0.30120907158687216)\n",
      "     | > loss_dur: 0.20364797115325928  (0.18985699810858434)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(19.0488, device='cuda:0')  (tensor(30.7437, device='cuda:0'))\n",
      "     | > current_lr: 1.55e-05 \n",
      "     | > step_time: 1.0046  (0.6433929759880593)\n",
      "     | > loader_time: 0.0125  (0.012950936268115866)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:24:55 -- STEP: 373/406 -- GLOBAL_STEP: 48275\u001b[0m\n",
      "     | > loss: -0.12927697598934174  (-0.11142052558248229)\n",
      "     | > log_mle: -0.31794798374176025  (-0.3020279260487085)\n",
      "     | > loss_dur: 0.18867100775241852  (0.1906074004662261)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(34.9366, device='cuda:0')  (tensor(31.3138, device='cuda:0'))\n",
      "     | > current_lr: 1.55e-05 \n",
      "     | > step_time: 0.7079  (0.6519135367774452)\n",
      "     | > loader_time: 0.0203  (0.013058074997193692)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:25:13 -- STEP: 398/406 -- GLOBAL_STEP: 48300\u001b[0m\n",
      "     | > loss: -0.1134127527475357  (-0.11152703610796426)\n",
      "     | > log_mle: -0.3099212646484375  (-0.30268403423491447)\n",
      "     | > loss_dur: 0.1965085119009018  (0.19115699812695014)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(33.1956, device='cuda:0')  (tensor(31.6144, device='cuda:0'))\n",
      "     | > current_lr: 1.55e-05 \n",
      "     | > step_time: 0.5487  (0.6563904764664233)\n",
      "     | > loader_time: 0.007  (0.013117540421797403)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: -0.09810999035835266  (-0.09810999035835266)\n",
      "     | > log_mle: -0.28630030155181885  (-0.28630030155181885)\n",
      "     | > loss_dur: 0.1881903111934662  (0.1881903111934662)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: -0.1625017523765564  (-0.1625017523765564)\n",
      "     | > log_mle: -0.3268088102340698  (-0.3268088102340698)\n",
      "     | > loss_dur: 0.16430705785751343  (0.16430705785751343)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: -0.142182394862175  (-0.1523420736193657)\n",
      "     | > log_mle: -0.2901841402053833  (-0.30849647521972656)\n",
      "     | > loss_dur: 0.1480017453432083  (0.15615440160036087)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: -0.1462685614824295  (-0.1503175695737203)\n",
      "     | > log_mle: -0.29793334007263184  (-0.304975430170695)\n",
      "     | > loss_dur: 0.15166477859020233  (0.1546578605969747)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: -0.15567384660243988  (-0.1516566388309002)\n",
      "     | > log_mle: -0.3251194953918457  (-0.31001144647598267)\n",
      "     | > loss_dur: 0.16944564878940582  (0.15835480764508247)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: -0.15091253817081451  (-0.15150781869888305)\n",
      "     | > log_mle: -0.3230060338973999  (-0.3126103639602661)\n",
      "     | > loss_dur: 0.1720934957265854  (0.16110254526138307)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: -0.10762140154838562  (-0.14419341584046683)\n",
      "     | > log_mle: -0.33310675621032715  (-0.3160264293352763)\n",
      "     | > loss_dur: 0.22548535466194153  (0.17183301349480948)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: -0.12732040882110596  (-0.14178298626627242)\n",
      "     | > log_mle: -0.2968193292617798  (-0.31328255789620535)\n",
      "     | > loss_dur: 0.16949892044067383  (0.17149957162993296)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: -0.15258696675300598  (-0.1431334838271141)\n",
      "     | > log_mle: -0.31025636196136475  (-0.3129042834043503)\n",
      "     | > loss_dur: 0.15766939520835876  (0.16977079957723618)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: -0.13577955961227417  (-0.14231638113657633)\n",
      "     | > log_mle: -0.32140374183654785  (-0.31384866767459446)\n",
      "     | > loss_dur: 0.18562418222427368  (0.1715322865380181)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: -0.11707739531993866  (-0.13979248255491256)\n",
      "     | > log_mle: -0.3084651231765747  (-0.31331031322479247)\n",
      "     | > loss_dur: 0.19138772785663605  (0.1735178306698799)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: -0.13181419670581818  (-0.13906718384135852)\n",
      "     | > log_mle: -0.3241623640060425  (-0.3142968632958152)\n",
      "     | > loss_dur: 0.1923481673002243  (0.17522967945445667)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: -0.1468823403120041  (-0.139718446880579)\n",
      "     | > log_mle: -0.31069159507751465  (-0.3139964242776235)\n",
      "     | > loss_dur: 0.16380925476551056  (0.1742779773970445)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: -0.16863073408603668  (-0.1419424689733065)\n",
      "     | > log_mle: -0.33137989044189453  (-0.31533361398256743)\n",
      "     | > loss_dur: 0.16274915635585785  (0.17339114500926092)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: -0.13398264348506927  (-0.141373910009861)\n",
      "     | > log_mle: -0.32178306579589844  (-0.31579428911209106)\n",
      "     | > loss_dur: 0.18780042231082916  (0.17442037910223007)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: -0.12948833405971527  (-0.1405815382798513)\n",
      "     | > log_mle: -0.3155968189239502  (-0.3157811244328817)\n",
      "     | > loss_dur: 0.18610848486423492  (0.17519958615303038)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: -0.12706197798252106  (-0.13973656576126814)\n",
      "     | > log_mle: -0.31683647632598877  (-0.31584708392620087)\n",
      "     | > loss_dur: 0.1897744983434677  (0.17611051816493273)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: audio amplitude out of range, auto clipped.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.00367186963558197 \u001b[0m(-0.00030869245529174805)\n",
      "     | > avg_loss:\u001b[92m -0.13973656576126814 \u001b[0m(-0.003142942674458027)\n",
      "     | > avg_log_mle:\u001b[92m -0.31584708392620087 \u001b[0m(-0.0021193176507950384)\n",
      "     | > avg_loss_dur:\u001b[92m 0.17611051816493273 \u001b[0m(-0.001023625023663044)\n",
      "\n",
      " > BEST MODEL : train/run-February-22-2025_10+59PM-fa84af3/best_model_48308.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 63/100\u001b[0m\n",
      " --> train/run-February-22-2025_10+59PM-fa84af3\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-23 04:25:33) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:25:42 -- STEP: 17/406 -- GLOBAL_STEP: 48325\u001b[0m\n",
      "     | > loss: -0.12055826187133789  (-0.1276967762147679)\n",
      "     | > log_mle: -0.2866630554199219  (-0.28648902388180003)\n",
      "     | > loss_dur: 0.16610479354858398  (0.15879224766703212)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(10.8390, device='cuda:0')  (tensor(33.4214, device='cuda:0'))\n",
      "     | > current_lr: 1.575e-05 \n",
      "     | > step_time: 0.5938  (0.40905460189370546)\n",
      "     | > loader_time: 0.011  (0.0052982498617733225)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:25:56 -- STEP: 42/406 -- GLOBAL_STEP: 48350\u001b[0m\n",
      "     | > loss: -0.12246657907962799  (-0.12013227031344459)\n",
      "     | > log_mle: -0.2904798984527588  (-0.2844057253428868)\n",
      "     | > loss_dur: 0.1680133193731308  (0.16427345502944218)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(39.4063, device='cuda:0')  (tensor(25.2757, device='cuda:0'))\n",
      "     | > current_lr: 1.575e-05 \n",
      "     | > step_time: 0.9485  (0.5013296660922822)\n",
      "     | > loader_time: 0.0224  (0.00760801633199056)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:26:11 -- STEP: 67/406 -- GLOBAL_STEP: 48375\u001b[0m\n",
      "     | > loss: -0.10997171700000763  (-0.11655895256284457)\n",
      "     | > log_mle: -0.30055975914001465  (-0.2865075388951088)\n",
      "     | > loss_dur: 0.19058804214000702  (0.16994858633226423)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(28.3510, device='cuda:0')  (tensor(25.0544, device='cuda:0'))\n",
      "     | > current_lr: 1.575e-05 \n",
      "     | > step_time: 0.3784  (0.528302733577899)\n",
      "     | > loader_time: 0.0063  (0.009223831233693594)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:26:26 -- STEP: 92/406 -- GLOBAL_STEP: 48400\u001b[0m\n",
      "     | > loss: -0.11675529181957245  (-0.11588597411046857)\n",
      "     | > log_mle: -0.314439058303833  (-0.28968406371448335)\n",
      "     | > loss_dur: 0.19768376648426056  (0.1737980896040149)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(20.1128, device='cuda:0')  (tensor(26.3488, device='cuda:0'))\n",
      "     | > current_lr: 1.575e-05 \n",
      "     | > step_time: 0.4426  (0.5465668984081434)\n",
      "     | > loader_time: 0.0155  (0.009863078594207764)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:26:42 -- STEP: 117/406 -- GLOBAL_STEP: 48425\u001b[0m\n",
      "     | > loss: -0.11865867674350739  (-0.11522240440050761)\n",
      "     | > log_mle: -0.30006277561187744  (-0.2921210405154106)\n",
      "     | > loss_dur: 0.18140409886837006  (0.17689863611490297)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(16.6583, device='cuda:0')  (tensor(27.2055, device='cuda:0'))\n",
      "     | > current_lr: 1.575e-05 \n",
      "     | > step_time: 0.9037  (0.5589018560882307)\n",
      "     | > loader_time: 0.0062  (0.01004279780591655)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:26:58 -- STEP: 142/406 -- GLOBAL_STEP: 48450\u001b[0m\n",
      "     | > loss: -0.1214764267206192  (-0.11450368333870256)\n",
      "     | > log_mle: -0.31251704692840576  (-0.2941999292709458)\n",
      "     | > loss_dur: 0.19104062020778656  (0.17969624593224323)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(34.4744, device='cuda:0')  (tensor(30.7490, device='cuda:0'))\n",
      "     | > current_lr: 1.575e-05 \n",
      "     | > step_time: 0.5234  (0.5686754777397908)\n",
      "     | > loader_time: 0.0068  (0.010810922568952535)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:27:13 -- STEP: 167/406 -- GLOBAL_STEP: 48475\u001b[0m\n",
      "     | > loss: -0.11790089309215546  (-0.11412904817544058)\n",
      "     | > log_mle: -0.3008488416671753  (-0.2957788213284431)\n",
      "     | > loss_dur: 0.18294794857501984  (0.1816497731530024)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(18.5325, device='cuda:0')  (tensor(30.3576, device='cuda:0'))\n",
      "     | > current_lr: 1.575e-05 \n",
      "     | > step_time: 0.4997  (0.5726203133246139)\n",
      "     | > loader_time: 0.0072  (0.011073376604182991)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:27:31 -- STEP: 192/406 -- GLOBAL_STEP: 48500\u001b[0m\n",
      "     | > loss: -0.12229907512664795  (-0.11430980226335426)\n",
      "     | > log_mle: -0.31108272075653076  (-0.2972417635222277)\n",
      "     | > loss_dur: 0.1887836456298828  (0.18293196125887334)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(16.2277, device='cuda:0')  (tensor(29.9872, device='cuda:0'))\n",
      "     | > current_lr: 1.575e-05 \n",
      "     | > step_time: 0.8196  (0.5889138964315251)\n",
      "     | > loader_time: 0.021  (0.011336834480365118)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:27:49 -- STEP: 217/406 -- GLOBAL_STEP: 48525\u001b[0m\n",
      "     | > loss: -0.10564033687114716  (-0.11405935835453772)\n",
      "     | > log_mle: -0.3147372007369995  (-0.29846164707763934)\n",
      "     | > loss_dur: 0.20909686386585236  (0.18440228872310183)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(51.4387, device='cuda:0')  (tensor(30.3360, device='cuda:0'))\n",
      "     | > current_lr: 1.575e-05 \n",
      "     | > step_time: 0.5734  (0.601898415297407)\n",
      "     | > loader_time: 0.0063  (0.01158566408992363)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:28:07 -- STEP: 242/406 -- GLOBAL_STEP: 48550\u001b[0m\n",
      "     | > loss: -0.11957967281341553  (-0.1143350899219513)\n",
      "     | > log_mle: -0.3190101385116577  (-0.29993808269500716)\n",
      "     | > loss_dur: 0.1994304656982422  (0.18560299277305603)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(26.7519, device='cuda:0')  (tensor(30.6342, device='cuda:0'))\n",
      "     | > current_lr: 1.575e-05 \n",
      "     | > step_time: 0.8878  (0.612247002026266)\n",
      "     | > loader_time: 0.0162  (0.01190905236015635)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:28:24 -- STEP: 267/406 -- GLOBAL_STEP: 48575\u001b[0m\n",
      "     | > loss: -0.12108232080936432  (-0.1145244666587994)\n",
      "     | > log_mle: -0.3032567501068115  (-0.30085361182466414)\n",
      "     | > loss_dur: 0.1821744292974472  (0.1863291451658649)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(26.6166, device='cuda:0')  (tensor(31.4773, device='cuda:0'))\n",
      "     | > current_lr: 1.575e-05 \n",
      "     | > step_time: 0.908  (0.6192622122246673)\n",
      "     | > loader_time: 0.0066  (0.012003560191236632)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:28:44 -- STEP: 292/406 -- GLOBAL_STEP: 48600\u001b[0m\n",
      "     | > loss: -0.10869990289211273  (-0.11480077014189877)\n",
      "     | > log_mle: -0.30715858936309814  (-0.30180286177217136)\n",
      "     | > loss_dur: 0.1984586864709854  (0.18700209163027262)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(16.4835, device='cuda:0')  (tensor(31.6204, device='cuda:0'))\n",
      "     | > current_lr: 1.575e-05 \n",
      "     | > step_time: 0.9336  (0.6315470958409243)\n",
      "     | > loader_time: 0.0193  (0.012157178904912245)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:29:03 -- STEP: 317/406 -- GLOBAL_STEP: 48625\u001b[0m\n",
      "     | > loss: -0.11388610303401947  (-0.11494339071801785)\n",
      "     | > log_mle: -0.3153015375137329  (-0.30280573699000485)\n",
      "     | > loss_dur: 0.20141543447971344  (0.18786234627198709)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(28.7256, device='cuda:0')  (tensor(31.5089, device='cuda:0'))\n",
      "     | > current_lr: 1.575e-05 \n",
      "     | > step_time: 0.6672  (0.6395389612540838)\n",
      "     | > loader_time: 0.0072  (0.012353044955136273)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:29:23 -- STEP: 342/406 -- GLOBAL_STEP: 48650\u001b[0m\n",
      "     | > loss: -0.11893525719642639  (-0.11476202317845752)\n",
      "     | > log_mle: -0.32332301139831543  (-0.30337609394251924)\n",
      "     | > loss_dur: 0.20438775420188904  (0.18861407076406195)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(61.6849, device='cuda:0')  (tensor(31.5643, device='cuda:0'))\n",
      "     | > current_lr: 1.575e-05 \n",
      "     | > step_time: 0.8521  (0.6494006852657475)\n",
      "     | > loader_time: 0.0068  (0.012385373227080406)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:29:43 -- STEP: 367/406 -- GLOBAL_STEP: 48675\u001b[0m\n",
      "     | > loss: -0.12438836693763733  (-0.11475433973590425)\n",
      "     | > log_mle: -0.3184795379638672  (-0.30416222261797793)\n",
      "     | > loss_dur: 0.19409117102622986  (0.18940788288207402)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(23.6649, device='cuda:0')  (tensor(31.2805, device='cuda:0'))\n",
      "     | > current_lr: 1.575e-05 \n",
      "     | > step_time: 0.8677  (0.6597019164373827)\n",
      "     | > loader_time: 0.0071  (0.01277053193760178)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:30:04 -- STEP: 392/406 -- GLOBAL_STEP: 48700\u001b[0m\n",
      "     | > loss: -0.1181081086397171  (-0.11482628195413522)\n",
      "     | > log_mle: -0.31082165241241455  (-0.3048758327352755)\n",
      "     | > loss_dur: 0.19271354377269745  (0.1900495507811405)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(46.1518, device='cuda:0')  (tensor(31.4751, device='cuda:0'))\n",
      "     | > current_lr: 1.575e-05 \n",
      "     | > step_time: 0.6485  (0.6684664049927069)\n",
      "     | > loader_time: 0.023  (0.013118026816115087)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: -0.10707511007785797  (-0.10707511007785797)\n",
      "     | > log_mle: -0.288952112197876  (-0.288952112197876)\n",
      "     | > loss_dur: 0.181877002120018  (0.181877002120018)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: -0.16319435834884644  (-0.16319435834884644)\n",
      "     | > log_mle: -0.3297741413116455  (-0.3297741413116455)\n",
      "     | > loss_dur: 0.16657978296279907  (0.16657978296279907)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: -0.1535578817129135  (-0.15837612003087997)\n",
      "     | > log_mle: -0.29382336139678955  (-0.31179875135421753)\n",
      "     | > loss_dur: 0.14026547968387604  (0.15342263132333755)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: -0.15427042543888092  (-0.15700755516688028)\n",
      "     | > log_mle: -0.3033020496368408  (-0.3089665174484253)\n",
      "     | > loss_dur: 0.1490316241979599  (0.151958962281545)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: -0.16238553822040558  (-0.1583520509302616)\n",
      "     | > log_mle: -0.32952880859375  (-0.31410709023475647)\n",
      "     | > loss_dur: 0.16714327037334442  (0.15575503930449486)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: -0.1667748987674713  (-0.16003662049770356)\n",
      "     | > log_mle: -0.3303232192993164  (-0.31735031604766845)\n",
      "     | > loss_dur: 0.1635483205318451  (0.1573136955499649)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: -0.10292172431945801  (-0.15051747113466263)\n",
      "     | > log_mle: -0.33690786361694336  (-0.3206099073092143)\n",
      "     | > loss_dur: 0.23398613929748535  (0.17009243617455164)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: -0.12570859491825104  (-0.14697334596088954)\n",
      "     | > log_mle: -0.30084049701690674  (-0.3177857058388846)\n",
      "     | > loss_dur: 0.1751319020986557  (0.1708123598779951)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: -0.15595196187496185  (-0.14809567295014858)\n",
      "     | > log_mle: -0.3134268522262573  (-0.3172408491373062)\n",
      "     | > loss_dur: 0.15747489035129547  (0.16914517618715763)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: -0.130637526512146  (-0.14615587890148163)\n",
      "     | > log_mle: -0.32564449310302734  (-0.3181745873557197)\n",
      "     | > loss_dur: 0.19500696659088135  (0.17201870845423806)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: -0.11329443752765656  (-0.14286973476409912)\n",
      "     | > log_mle: -0.31115174293518066  (-0.3174723029136658)\n",
      "     | > loss_dur: 0.1978573054075241  (0.17460256814956665)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: -0.14148728549480438  (-0.1427440575577996)\n",
      "     | > log_mle: -0.32838308811187744  (-0.3184641924771396)\n",
      "     | > loss_dur: 0.18689580261707306  (0.17572013491933997)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: -0.1472155600786209  (-0.14311668276786804)\n",
      "     | > log_mle: -0.3138899803161621  (-0.3180830081303915)\n",
      "     | > loss_dur: 0.1666744202375412  (0.1749663253625234)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: -0.16905638575553894  (-0.14511204453615043)\n",
      "     | > log_mle: -0.3378254175186157  (-0.3196016550064087)\n",
      "     | > loss_dur: 0.16876903176307678  (0.17448961047025827)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: -0.13579480350017548  (-0.14444652731929505)\n",
      "     | > log_mle: -0.32585465908050537  (-0.32004829815455843)\n",
      "     | > loss_dur: 0.1900598555803299  (0.17560177083526338)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: -0.13475559651851654  (-0.14380046526590984)\n",
      "     | > log_mle: -0.3195542097091675  (-0.3200153589248657)\n",
      "     | > loss_dur: 0.18479861319065094  (0.1762148936589559)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: -0.1278344839811325  (-0.14280259143561125)\n",
      "     | > log_mle: -0.32182300090789795  (-0.32012833654880524)\n",
      "     | > loss_dur: 0.19398851692676544  (0.177325745113194)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: audio amplitude out of range, auto clipped.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.0033358782529830933 \u001b[0m(-0.00033599138259887695)\n",
      "     | > avg_loss:\u001b[92m -0.14280259143561125 \u001b[0m(-0.003066025674343109)\n",
      "     | > avg_log_mle:\u001b[92m -0.32012833654880524 \u001b[0m(-0.00428125262260437)\n",
      "     | > avg_loss_dur:\u001b[91m 0.177325745113194 \u001b[0m(+0.001215226948261261)\n",
      "\n",
      " > BEST MODEL : train/run-February-22-2025_10+59PM-fa84af3/best_model_48714.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 64/100\u001b[0m\n",
      " --> train/run-February-22-2025_10+59PM-fa84af3\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-23 04:30:27) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:30:34 -- STEP: 11/406 -- GLOBAL_STEP: 48725\u001b[0m\n",
      "     | > loss: -0.13883136212825775  (-0.13486190004782242)\n",
      "     | > log_mle: -0.2859393358230591  (-0.2899595824154941)\n",
      "     | > loss_dur: 0.14710797369480133  (0.15509768236767163)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(20.8893, device='cuda:0')  (tensor(25.5128, device='cuda:0'))\n",
      "     | > current_lr: 1.6e-05 \n",
      "     | > step_time: 0.422  (0.37866397337480023)\n",
      "     | > loader_time: 0.0032  (0.004225427454168146)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:30:47 -- STEP: 36/406 -- GLOBAL_STEP: 48750\u001b[0m\n",
      "     | > loss: -0.12836720049381256  (-0.1262930408120156)\n",
      "     | > log_mle: -0.2866874933242798  (-0.2890571918752459)\n",
      "     | > loss_dur: 0.15832029283046722  (0.1627641510632303)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(11.3559, device='cuda:0')  (tensor(24.0527, device='cuda:0'))\n",
      "     | > current_lr: 1.6e-05 \n",
      "     | > step_time: 0.4588  (0.48287370469835067)\n",
      "     | > loader_time: 0.0158  (0.009028587076399062)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:31:02 -- STEP: 61/406 -- GLOBAL_STEP: 48775\u001b[0m\n",
      "     | > loss: -0.09439633786678314  (-0.12143789793624256)\n",
      "     | > log_mle: -0.29262077808380127  (-0.2898276751158669)\n",
      "     | > loss_dur: 0.19822444021701813  (0.16838977717962425)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(29.0472, device='cuda:0')  (tensor(23.9390, device='cuda:0'))\n",
      "     | > current_lr: 1.6e-05 \n",
      "     | > step_time: 0.5873  (0.5141744965412577)\n",
      "     | > loader_time: 0.0048  (0.010300585480987048)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:31:17 -- STEP: 86/406 -- GLOBAL_STEP: 48800\u001b[0m\n",
      "     | > loss: -0.09651841223239899  (-0.12016866269499758)\n",
      "     | > log_mle: -0.2902185916900635  (-0.29202937802603096)\n",
      "     | > loss_dur: 0.1937001794576645  (0.1718607153310332)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(20.0135, device='cuda:0')  (tensor(24.3290, device='cuda:0'))\n",
      "     | > current_lr: 1.6e-05 \n",
      "     | > step_time: 0.5015  (0.538840235665787)\n",
      "     | > loader_time: 0.0049  (0.010713496873545093)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:31:32 -- STEP: 111/406 -- GLOBAL_STEP: 48825\u001b[0m\n",
      "     | > loss: -0.13696123659610748  (-0.11952894979769046)\n",
      "     | > log_mle: -0.32515227794647217  (-0.29481218956612254)\n",
      "     | > loss_dur: 0.18819104135036469  (0.17528323976843208)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(27.6528, device='cuda:0')  (tensor(25.1978, device='cuda:0'))\n",
      "     | > current_lr: 1.6e-05 \n",
      "     | > step_time: 0.6152  (0.5504978154156654)\n",
      "     | > loader_time: 0.0409  (0.010885601645117407)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:31:49 -- STEP: 136/406 -- GLOBAL_STEP: 48850\u001b[0m\n",
      "     | > loss: -0.10339805483818054  (-0.11911430122221217)\n",
      "     | > log_mle: -0.31328511238098145  (-0.2969862660940956)\n",
      "     | > loss_dur: 0.2098870575428009  (0.1778719648718834)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(35.5486, device='cuda:0')  (tensor(25.5373, device='cuda:0'))\n",
      "     | > current_lr: 1.6e-05 \n",
      "     | > step_time: 0.4955  (0.5663008847657371)\n",
      "     | > loader_time: 0.0055  (0.011441818054984598)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:32:06 -- STEP: 161/406 -- GLOBAL_STEP: 48875\u001b[0m\n",
      "     | > loss: -0.10478506982326508  (-0.117984600318885)\n",
      "     | > log_mle: -0.3046938180923462  (-0.2982339866413093)\n",
      "     | > loss_dur: 0.19990874826908112  (0.18024938632242438)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(15.5944, device='cuda:0')  (tensor(26.2958, device='cuda:0'))\n",
      "     | > current_lr: 1.6e-05 \n",
      "     | > step_time: 1.1043  (0.5817190860369189)\n",
      "     | > loader_time: 0.012  (0.01204821337824283)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:32:22 -- STEP: 186/406 -- GLOBAL_STEP: 48900\u001b[0m\n",
      "     | > loss: -0.12024335563182831  (-0.11782003770912847)\n",
      "     | > log_mle: -0.3139389753341675  (-0.29951050332797446)\n",
      "     | > loss_dur: 0.19369561970233917  (0.18169046561884636)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(47.2769, device='cuda:0')  (tensor(26.6720, device='cuda:0'))\n",
      "     | > current_lr: 1.6e-05 \n",
      "     | > step_time: 0.6324  (0.5884931702767648)\n",
      "     | > loader_time: 0.0153  (0.012489093247280331)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:32:40 -- STEP: 211/406 -- GLOBAL_STEP: 48925\u001b[0m\n",
      "     | > loss: -0.12158927321434021  (-0.11774708860293384)\n",
      "     | > log_mle: -0.3155639171600342  (-0.30074910078003486)\n",
      "     | > loss_dur: 0.19397464394569397  (0.18300201217710135)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(47.9086, device='cuda:0')  (tensor(27.5512, device='cuda:0'))\n",
      "     | > current_lr: 1.6e-05 \n",
      "     | > step_time: 0.5305  (0.5993594196735398)\n",
      "     | > loader_time: 0.0061  (0.01254349410251419)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:32:57 -- STEP: 236/406 -- GLOBAL_STEP: 48950\u001b[0m\n",
      "     | > loss: -0.11665572226047516  (-0.11794297794921924)\n",
      "     | > log_mle: -0.3014063835144043  (-0.30219932582418774)\n",
      "     | > loss_dur: 0.18475066125392914  (0.18425634787496883)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(24.0904, device='cuda:0')  (tensor(28.1222, device='cuda:0'))\n",
      "     | > current_lr: 1.6e-05 \n",
      "     | > step_time: 0.6178  (0.6065757042270593)\n",
      "     | > loader_time: 0.0252  (0.012641081365488346)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:33:15 -- STEP: 261/406 -- GLOBAL_STEP: 48975\u001b[0m\n",
      "     | > loss: -0.12029798328876495  (-0.11829329393375879)\n",
      "     | > log_mle: -0.31737804412841797  (-0.3035363817580356)\n",
      "     | > loss_dur: 0.19708006083965302  (0.18524308782427712)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(23.9559, device='cuda:0')  (tensor(28.3518, device='cuda:0'))\n",
      "     | > current_lr: 1.6e-05 \n",
      "     | > step_time: 1.0138  (0.6149567653392921)\n",
      "     | > loader_time: 0.0168  (0.012727407660064116)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:33:33 -- STEP: 286/406 -- GLOBAL_STEP: 49000\u001b[0m\n",
      "     | > loss: -0.11903621256351471  (-0.11838607734941936)\n",
      "     | > log_mle: -0.3105093240737915  (-0.304388122541921)\n",
      "     | > loss_dur: 0.1914731115102768  (0.18600204519250182)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(31.5590, device='cuda:0')  (tensor(29.0678, device='cuda:0'))\n",
      "     | > current_lr: 1.6e-05 \n",
      "     | > step_time: 0.7193  (0.6245303387408491)\n",
      "     | > loader_time: 0.0354  (0.01266877301089414)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:33:53 -- STEP: 311/406 -- GLOBAL_STEP: 49025\u001b[0m\n",
      "     | > loss: -0.11691251397132874  (-0.11827248655906444)\n",
      "     | > log_mle: -0.30875277519226074  (-0.30511292613970864)\n",
      "     | > loss_dur: 0.191840261220932  (0.18684043958064447)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(16.3944, device='cuda:0')  (tensor(29.0816, device='cuda:0'))\n",
      "     | > current_lr: 1.6e-05 \n",
      "     | > step_time: 0.7319  (0.6358409311227095)\n",
      "     | > loader_time: 0.0084  (0.012865019764547566)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:34:13 -- STEP: 336/406 -- GLOBAL_STEP: 49050\u001b[0m\n",
      "     | > loss: -0.11718469858169556  (-0.11808202056480306)\n",
      "     | > log_mle: -0.31495893001556396  (-0.30575067266112277)\n",
      "     | > loss_dur: 0.1977742314338684  (0.18766865209631983)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(33.6381, device='cuda:0')  (tensor(29.4966, device='cuda:0'))\n",
      "     | > current_lr: 1.6e-05 \n",
      "     | > step_time: 1.2346  (0.6478078365325926)\n",
      "     | > loader_time: 0.0122  (0.012860034193311422)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:34:33 -- STEP: 361/406 -- GLOBAL_STEP: 49075\u001b[0m\n",
      "     | > loss: -0.10676594078540802  (-0.11798594698020956)\n",
      "     | > log_mle: -0.3140066862106323  (-0.3064651938356522)\n",
      "     | > loss_dur: 0.2072407454252243  (0.18847924685544262)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(24.7826, device='cuda:0')  (tensor(29.9348, device='cuda:0'))\n",
      "     | > current_lr: 1.6e-05 \n",
      "     | > step_time: 0.7569  (0.6571363497969183)\n",
      "     | > loader_time: 0.0069  (0.01303679130744406)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:34:54 -- STEP: 386/406 -- GLOBAL_STEP: 49100\u001b[0m\n",
      "     | > loss: -0.1112004965543747  (-0.11816438553864474)\n",
      "     | > log_mle: -0.3147158622741699  (-0.30719596734318716)\n",
      "     | > loss_dur: 0.20351536571979523  (0.1890315818045424)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(63.1578, device='cuda:0')  (tensor(30.2221, device='cuda:0'))\n",
      "     | > current_lr: 1.6e-05 \n",
      "     | > step_time: 0.7413  (0.6664885591348835)\n",
      "     | > loader_time: 0.0064  (0.013290383037507845)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: -0.10146862268447876  (-0.10146862268447876)\n",
      "     | > log_mle: -0.2914848327636719  (-0.2914848327636719)\n",
      "     | > loss_dur: 0.19001621007919312  (0.19001621007919312)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: -0.16587243974208832  (-0.16587243974208832)\n",
      "     | > log_mle: -0.3329460620880127  (-0.3329460620880127)\n",
      "     | > loss_dur: 0.16707362234592438  (0.16707362234592438)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: -0.14443175494670868  (-0.1551520973443985)\n",
      "     | > log_mle: -0.29524970054626465  (-0.31409788131713867)\n",
      "     | > loss_dur: 0.15081794559955597  (0.15894578397274017)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: -0.156210258603096  (-0.15550481776396433)\n",
      "     | > log_mle: -0.30462467670440674  (-0.310940146446228)\n",
      "     | > loss_dur: 0.14841441810131073  (0.1554353286822637)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: -0.169042706489563  (-0.158889289945364)\n",
      "     | > log_mle: -0.33241403102874756  (-0.3163086175918579)\n",
      "     | > loss_dur: 0.16337132453918457  (0.1574193276464939)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: -0.1662474125623703  (-0.16036091446876527)\n",
      "     | > log_mle: -0.3316328525543213  (-0.31937346458435056)\n",
      "     | > loss_dur: 0.165385439991951  (0.15901255011558532)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: -0.11068642139434814  (-0.15208183228969574)\n",
      "     | > log_mle: -0.341677188873291  (-0.32309075196584064)\n",
      "     | > loss_dur: 0.23099076747894287  (0.17100891967614493)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: -0.13805237412452698  (-0.1500776239803859)\n",
      "     | > log_mle: -0.3026468753814697  (-0.3201701981680734)\n",
      "     | > loss_dur: 0.16459450125694275  (0.17009257418768747)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: -0.159382626414299  (-0.15124074928462505)\n",
      "     | > log_mle: -0.31668591499328613  (-0.319734662771225)\n",
      "     | > loss_dur: 0.15730328857898712  (0.16849391348659992)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: -0.14144811034202576  (-0.1501526782910029)\n",
      "     | > log_mle: -0.3284655809402466  (-0.32070476479000515)\n",
      "     | > loss_dur: 0.18701747059822083  (0.17055208649900225)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: -0.12390948832035065  (-0.14752835929393768)\n",
      "     | > log_mle: -0.3143199682235718  (-0.3200662851333618)\n",
      "     | > loss_dur: 0.19041047990322113  (0.17253792583942412)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: -0.13508903980255127  (-0.146397512067448)\n",
      "     | > log_mle: -0.33080554008483887  (-0.32104258103804156)\n",
      "     | > loss_dur: 0.1957165002822876  (0.17464506897059354)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: -0.1521209329366684  (-0.1468744638065497)\n",
      "     | > log_mle: -0.3171389102935791  (-0.3207172751426697)\n",
      "     | > loss_dur: 0.1650179773569107  (0.17384281133611998)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: -0.17130613327026367  (-0.14875382299606615)\n",
      "     | > log_mle: -0.33853018283843994  (-0.32208749881157506)\n",
      "     | > loss_dur: 0.16722404956817627  (0.1733336758155089)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: -0.1419520378112793  (-0.14826798119715281)\n",
      "     | > log_mle: -0.32904624938964844  (-0.3225845524242946)\n",
      "     | > loss_dur: 0.18709421157836914  (0.17431657122714178)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: -0.1413753479719162  (-0.14780847231547037)\n",
      "     | > log_mle: -0.3216973543167114  (-0.3225254058837891)\n",
      "     | > loss_dur: 0.18032200634479523  (0.1747169335683187)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: -0.13773901760578156  (-0.14717913139611483)\n",
      "     | > log_mle: -0.32416439056396484  (-0.32262784242630005)\n",
      "     | > loss_dur: 0.1864253729581833  (0.17544871103018522)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: audio amplitude out of range, auto clipped.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[91m 0.007779508829116821 \u001b[0m(+0.004443630576133728)\n",
      "     | > avg_loss:\u001b[92m -0.14717913139611483 \u001b[0m(-0.004376539960503578)\n",
      "     | > avg_log_mle:\u001b[92m -0.32262784242630005 \u001b[0m(-0.002499505877494812)\n",
      "     | > avg_loss_dur:\u001b[92m 0.17544871103018522 \u001b[0m(-0.0018770340830087662)\n",
      "\n",
      " > BEST MODEL : train/run-February-22-2025_10+59PM-fa84af3/best_model_49120.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 65/100\u001b[0m\n",
      " --> train/run-February-22-2025_10+59PM-fa84af3\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-23 04:35:22) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:35:26 -- STEP: 5/406 -- GLOBAL_STEP: 49125\u001b[0m\n",
      "     | > loss: -0.11874695122241974  (-0.1381382405757904)\n",
      "     | > log_mle: -0.28186511993408203  (-0.28751091957092284)\n",
      "     | > loss_dur: 0.1631181687116623  (0.14937267899513246)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(15.8163, device='cuda:0')  (tensor(14.7797, device='cuda:0'))\n",
      "     | > current_lr: 1.625e-05 \n",
      "     | > step_time: 0.2496  (0.4078331470489502)\n",
      "     | > loader_time: 0.0051  (0.0040608406066894535)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:35:38 -- STEP: 30/406 -- GLOBAL_STEP: 49150\u001b[0m\n",
      "     | > loss: -0.11033609509468079  (-0.122945865492026)\n",
      "     | > log_mle: -0.2776615619659424  (-0.28475943009058635)\n",
      "     | > loss_dur: 0.1673254668712616  (0.16181356459856036)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(20.4618, device='cuda:0')  (tensor(33.2869, device='cuda:0'))\n",
      "     | > current_lr: 1.625e-05 \n",
      "     | > step_time: 0.5751  (0.4672349452972412)\n",
      "     | > loader_time: 0.0042  (0.00623625914255778)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:35:54 -- STEP: 55/406 -- GLOBAL_STEP: 49175\u001b[0m\n",
      "     | > loss: -0.12230327725410461  (-0.11796599897471341)\n",
      "     | > log_mle: -0.30111658573150635  (-0.2858570489016445)\n",
      "     | > loss_dur: 0.17881330847740173  (0.16789104992693124)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(18.6325, device='cuda:0')  (tensor(26.4892, device='cuda:0'))\n",
      "     | > current_lr: 1.625e-05 \n",
      "     | > step_time: 0.7216  (0.5259019504893908)\n",
      "     | > loader_time: 0.0155  (0.007641220092773437)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:36:09 -- STEP: 80/406 -- GLOBAL_STEP: 49200\u001b[0m\n",
      "     | > loss: -0.11022743582725525  (-0.11728580053895712)\n",
      "     | > log_mle: -0.29404711723327637  (-0.28888821750879273)\n",
      "     | > loss_dur: 0.18381968140602112  (0.1716024169698358)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(11.8637, device='cuda:0')  (tensor(24.7033, device='cuda:0'))\n",
      "     | > current_lr: 1.625e-05 \n",
      "     | > step_time: 0.7042  (0.546666347980499)\n",
      "     | > loader_time: 0.0053  (0.009148767590522761)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:36:24 -- STEP: 105/406 -- GLOBAL_STEP: 49225\u001b[0m\n",
      "     | > loss: -0.13235655426979065  (-0.11736422805559067)\n",
      "     | > log_mle: -0.30177056789398193  (-0.2923365581603277)\n",
      "     | > loss_dur: 0.16941401362419128  (0.17497233010473712)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(18.9427, device='cuda:0')  (tensor(26.3602, device='cuda:0'))\n",
      "     | > current_lr: 1.625e-05 \n",
      "     | > step_time: 0.3204  (0.557291085379464)\n",
      "     | > loader_time: 0.0054  (0.009532199587140765)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:36:41 -- STEP: 130/406 -- GLOBAL_STEP: 49250\u001b[0m\n",
      "     | > loss: -0.11759905517101288  (-0.11755929680970999)\n",
      "     | > log_mle: -0.29558229446411133  (-0.2952233397043668)\n",
      "     | > loss_dur: 0.17798323929309845  (0.1776640428946569)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(14.8147, device='cuda:0')  (tensor(27.0121, device='cuda:0'))\n",
      "     | > current_lr: 1.625e-05 \n",
      "     | > step_time: 0.6004  (0.5764509842945975)\n",
      "     | > loader_time: 0.0114  (0.00978083427135761)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:36:58 -- STEP: 155/406 -- GLOBAL_STEP: 49275\u001b[0m\n",
      "     | > loss: -0.11917464435100555  (-0.11740819427274889)\n",
      "     | > log_mle: -0.3031802177429199  (-0.29730506327844436)\n",
      "     | > loss_dur: 0.18400557339191437  (0.17989686900569557)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(23.5728, device='cuda:0')  (tensor(28.4205, device='cuda:0'))\n",
      "     | > current_lr: 1.625e-05 \n",
      "     | > step_time: 0.7774  (0.5889673494523568)\n",
      "     | > loader_time: 0.007  (0.010175900305471114)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:37:14 -- STEP: 180/406 -- GLOBAL_STEP: 49300\u001b[0m\n",
      "     | > loss: -0.11782801151275635  (-0.1177329495549202)\n",
      "     | > log_mle: -0.31154966354370117  (-0.29894151488939935)\n",
      "     | > loss_dur: 0.19372165203094482  (0.1812085653344791)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(20.7962, device='cuda:0')  (tensor(28.3643, device='cuda:0'))\n",
      "     | > current_lr: 1.625e-05 \n",
      "     | > step_time: 1.0883  (0.5966356674830116)\n",
      "     | > loader_time: 0.042  (0.01032786104414198)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:37:32 -- STEP: 205/406 -- GLOBAL_STEP: 49325\u001b[0m\n",
      "     | > loss: -0.1058683693408966  (-0.117545143932831)\n",
      "     | > log_mle: -0.3168210983276367  (-0.3003642628832562)\n",
      "     | > loss_dur: 0.2109527289867401  (0.18281911895042519)\n",
      "     | > amp_scaler: 4096.0  (2277.7756097560978)\n",
      "     | > grad_norm: tensor(40.9621, device='cuda:0')  (tensor(29.3744, device='cuda:0'))\n",
      "     | > current_lr: 1.625e-05 \n",
      "     | > step_time: 0.9212  (0.6086508332229239)\n",
      "     | > loader_time: 0.0263  (0.010685567158024484)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:37:50 -- STEP: 230/406 -- GLOBAL_STEP: 49350\u001b[0m\n",
      "     | > loss: -0.11657944321632385  (-0.11797223564075388)\n",
      "     | > log_mle: -0.31218600273132324  (-0.3019820757534193)\n",
      "     | > loss_dur: 0.1956065595149994  (0.1840098401126655)\n",
      "     | > amp_scaler: 4096.0  (2475.408695652175)\n",
      "     | > grad_norm: tensor(46.2593, device='cuda:0')  (tensor(30.0335, device='cuda:0'))\n",
      "     | > current_lr: 1.625e-05 \n",
      "     | > step_time: 0.9734  (0.6193362661029979)\n",
      "     | > loader_time: 0.0048  (0.011005449295043943)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:38:09 -- STEP: 255/406 -- GLOBAL_STEP: 49375\u001b[0m\n",
      "     | > loss: -0.11577485501766205  (-0.11829822904923383)\n",
      "     | > log_mle: -0.30934834480285645  (-0.30340550179575004)\n",
      "     | > loss_dur: 0.1935734897851944  (0.18510727274651625)\n",
      "     | > amp_scaler: 4096.0  (2634.2901960784325)\n",
      "     | > grad_norm: tensor(52.1646, device='cuda:0')  (tensor(30.5826, device='cuda:0'))\n",
      "     | > current_lr: 1.625e-05 \n",
      "     | > step_time: 0.7448  (0.6292836946599621)\n",
      "     | > loader_time: 0.0058  (0.011619161157047045)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:38:27 -- STEP: 280/406 -- GLOBAL_STEP: 49400\u001b[0m\n",
      "     | > loss: -0.11806182563304901  (-0.11858486251107284)\n",
      "     | > log_mle: -0.32391345500946045  (-0.30444208809307644)\n",
      "     | > loss_dur: 0.20585162937641144  (0.18585722558200368)\n",
      "     | > amp_scaler: 4096.0  (2764.8000000000006)\n",
      "     | > grad_norm: tensor(51.4227, device='cuda:0')  (tensor(30.9709, device='cuda:0'))\n",
      "     | > current_lr: 1.625e-05 \n",
      "     | > step_time: 0.7505  (0.6373801921095164)\n",
      "     | > loader_time: 0.0411  (0.011787905863353182)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:38:47 -- STEP: 305/406 -- GLOBAL_STEP: 49425\u001b[0m\n",
      "     | > loss: -0.11663983762264252  (-0.11895871343182736)\n",
      "     | > log_mle: -0.3207658529281616  (-0.30554584206127733)\n",
      "     | > loss_dur: 0.2041260153055191  (0.18658712862945004)\n",
      "     | > amp_scaler: 4096.0  (2873.9147540983627)\n",
      "     | > grad_norm: tensor(40.5705, device='cuda:0')  (tensor(31.4718, device='cuda:0'))\n",
      "     | > current_lr: 1.625e-05 \n",
      "     | > step_time: 0.5019  (0.6468804773737171)\n",
      "     | > loader_time: 0.0189  (0.012217516977278912)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:39:05 -- STEP: 330/406 -- GLOBAL_STEP: 49450\u001b[0m\n",
      "     | > loss: -0.10338658094406128  (-0.11909460073167627)\n",
      "     | > log_mle: -0.31795716285705566  (-0.30627476157564115)\n",
      "     | > loss_dur: 0.21457058191299438  (0.18718016084396485)\n",
      "     | > amp_scaler: 4096.0  (2966.496969696971)\n",
      "     | > grad_norm: tensor(48.1121, device='cuda:0')  (tensor(31.2960, device='cuda:0'))\n",
      "     | > current_lr: 1.625e-05 \n",
      "     | > step_time: 1.0604  (0.6534587534991175)\n",
      "     | > loader_time: 0.0057  (0.012210783091458408)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:39:25 -- STEP: 355/406 -- GLOBAL_STEP: 49475\u001b[0m\n",
      "     | > loss: -0.12527090311050415  (-0.11899271208635519)\n",
      "     | > log_mle: -0.3275942802429199  (-0.3070811372407728)\n",
      "     | > loss_dur: 0.20232337713241577  (0.18808842515441745)\n",
      "     | > amp_scaler: 4096.0  (3046.0394366197183)\n",
      "     | > grad_norm: tensor(53.4408, device='cuda:0')  (tensor(31.7604, device='cuda:0'))\n",
      "     | > current_lr: 1.625e-05 \n",
      "     | > step_time: 0.7738  (0.6608114222405659)\n",
      "     | > loader_time: 0.017  (0.012381740355155837)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:39:45 -- STEP: 380/406 -- GLOBAL_STEP: 49500\u001b[0m\n",
      "     | > loss: -0.11487060785293579  (-0.1193337886349151)\n",
      "     | > log_mle: -0.31912028789520264  (-0.3079957017773079)\n",
      "     | > loss_dur: 0.20424968004226685  (0.1886619131423926)\n",
      "     | > amp_scaler: 4096.0  (3115.1157894736843)\n",
      "     | > grad_norm: tensor(35.5139, device='cuda:0')  (tensor(31.9829, device='cuda:0'))\n",
      "     | > current_lr: 1.625e-05 \n",
      "     | > step_time: 0.8017  (0.6681192222394439)\n",
      "     | > loader_time: 0.0061  (0.012835562856573808)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:40:01 -- STEP: 405/406 -- GLOBAL_STEP: 49525\u001b[0m\n",
      "     | > loss: -0.12663625180721283  (-0.11967298579804692)\n",
      "     | > log_mle: -0.3191324472427368  (-0.30880596519988274)\n",
      "     | > loss_dur: 0.192496195435524  (0.1891329794018358)\n",
      "     | > amp_scaler: 4096.0  (3175.6641975308644)\n",
      "     | > grad_norm: tensor(45.8635, device='cuda:0')  (tensor(32.4648, device='cuda:0'))\n",
      "     | > current_lr: 1.625e-05 \n",
      "     | > step_time: 0.3544  (0.6670702698789994)\n",
      "     | > loader_time: 0.0044  (0.0126639919516481)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: -0.10648238658905029  (-0.10648238658905029)\n",
      "     | > log_mle: -0.29086947441101074  (-0.29086947441101074)\n",
      "     | > loss_dur: 0.18438708782196045  (0.18438708782196045)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: -0.1653449982404709  (-0.1653449982404709)\n",
      "     | > log_mle: -0.33040666580200195  (-0.33040666580200195)\n",
      "     | > loss_dur: 0.16506166756153107  (0.16506166756153107)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: -0.1541038602590561  (-0.1597244292497635)\n",
      "     | > log_mle: -0.29560744762420654  (-0.31300705671310425)\n",
      "     | > loss_dur: 0.14150358736515045  (0.15328262746334076)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: -0.14610062539577484  (-0.15518316129843393)\n",
      "     | > log_mle: -0.3032468557357788  (-0.3097536563873291)\n",
      "     | > loss_dur: 0.15714623034000397  (0.15457049508889517)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: -0.15978780388832092  (-0.15633432194590569)\n",
      "     | > log_mle: -0.3281681537628174  (-0.31435728073120117)\n",
      "     | > loss_dur: 0.16838034987449646  (0.1580229587852955)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: -0.16215024888515472  (-0.1574975073337555)\n",
      "     | > log_mle: -0.32848191261291504  (-0.31718220710754397)\n",
      "     | > loss_dur: 0.16633166372776031  (0.15968469977378846)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: -0.09809628129005432  (-0.14759730299313864)\n",
      "     | > log_mle: -0.3339890241622925  (-0.3199833432833354)\n",
      "     | > loss_dur: 0.23589274287223816  (0.17238604029019675)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: -0.13575519621372223  (-0.145905573453222)\n",
      "     | > log_mle: -0.30039191246032715  (-0.31718456745147705)\n",
      "     | > loss_dur: 0.16463671624660492  (0.17127899399825505)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: -0.15463745594024658  (-0.14699705876410007)\n",
      "     | > log_mle: -0.3132028579711914  (-0.31668685376644135)\n",
      "     | > loss_dur: 0.15856540203094482  (0.16968979500234127)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: -0.1276724487543106  (-0.14484987987412346)\n",
      "     | > log_mle: -0.32295775413513184  (-0.31738362047407365)\n",
      "     | > loss_dur: 0.19528530538082123  (0.17253374059995016)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: -0.1155896931886673  (-0.14192386120557784)\n",
      "     | > log_mle: -0.310819149017334  (-0.31672717332839967)\n",
      "     | > loss_dur: 0.1952294558286667  (0.1748033121228218)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: -0.1359097808599472  (-0.14137712662870233)\n",
      "     | > log_mle: -0.3268929719924927  (-0.3176513368433172)\n",
      "     | > loss_dur: 0.19098319113254547  (0.17627421021461487)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: -0.14838214218616486  (-0.14196087792515755)\n",
      "     | > log_mle: -0.31465280055999756  (-0.3174014588197072)\n",
      "     | > loss_dur: 0.1662706583738327  (0.1754405808945497)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: -0.16747789084911346  (-0.14392372507315415)\n",
      "     | > log_mle: -0.3367743492126465  (-0.3188916811576256)\n",
      "     | > loss_dur: 0.16929645836353302  (0.1749679560844715)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: -0.13147366046905518  (-0.14303443474428995)\n",
      "     | > log_mle: -0.32461464405059814  (-0.3193004642214094)\n",
      "     | > loss_dur: 0.19314098358154297  (0.17626602947711945)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: -0.13321547210216522  (-0.14237983723481495)\n",
      "     | > log_mle: -0.3183732032775879  (-0.3192386468251546)\n",
      "     | > loss_dur: 0.18515773117542267  (0.17685880959033967)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: -0.1268676072359085  (-0.1414103228598833)\n",
      "     | > log_mle: -0.32064855098724365  (-0.3193267658352852)\n",
      "     | > loss_dur: 0.19378094375133514  (0.17791644297540188)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: audio amplitude out of range, auto clipped.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.004674792289733887 \u001b[0m(-0.0031047165393829346)\n",
      "     | > avg_loss:\u001b[91m -0.1414103228598833 \u001b[0m(+0.005768808536231518)\n",
      "     | > avg_log_mle:\u001b[91m -0.3193267658352852 \u001b[0m(+0.003301076591014862)\n",
      "     | > avg_loss_dur:\u001b[91m 0.17791644297540188 \u001b[0m(+0.0024677319452166557)\n",
      "\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 66/100\u001b[0m\n",
      " --> train/run-February-22-2025_10+59PM-fa84af3\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-23 04:40:17) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:40:29 -- STEP: 24/406 -- GLOBAL_STEP: 49550\u001b[0m\n",
      "     | > loss: -0.13413631916046143  (-0.13334787885348)\n",
      "     | > log_mle: -0.2921711206436157  (-0.29098385075728095)\n",
      "     | > loss_dur: 0.1580348014831543  (0.15763597190380096)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(12.7755, device='cuda:0')  (tensor(23.6069, device='cuda:0'))\n",
      "     | > current_lr: 1.65e-05 \n",
      "     | > step_time: 0.624  (0.4330865740776062)\n",
      "     | > loader_time: 0.0056  (0.0071305930614471436)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:40:44 -- STEP: 49/406 -- GLOBAL_STEP: 49575\u001b[0m\n",
      "     | > loss: -0.11684899032115936  (-0.12576321466844909)\n",
      "     | > log_mle: -0.2908954620361328  (-0.2899393281158136)\n",
      "     | > loss_dur: 0.17404647171497345  (0.1641761134473645)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(13.8583, device='cuda:0')  (tensor(23.7082, device='cuda:0'))\n",
      "     | > current_lr: 1.65e-05 \n",
      "     | > step_time: 0.6205  (0.5019517820708606)\n",
      "     | > loader_time: 0.0185  (0.008167738817176041)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:40:59 -- STEP: 74/406 -- GLOBAL_STEP: 49600\u001b[0m\n",
      "     | > loss: -0.12630833685398102  (-0.12376308924443011)\n",
      "     | > log_mle: -0.3206413984298706  (-0.2924408542143333)\n",
      "     | > loss_dur: 0.1943330615758896  (0.16867776496990308)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(43.0779, device='cuda:0')  (tensor(25.8839, device='cuda:0'))\n",
      "     | > current_lr: 1.65e-05 \n",
      "     | > step_time: 0.6033  (0.5389631148931142)\n",
      "     | > loader_time: 0.0081  (0.009227436942023198)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:41:14 -- STEP: 99/406 -- GLOBAL_STEP: 49625\u001b[0m\n",
      "     | > loss: -0.1178835928440094  (-0.12220410701602395)\n",
      "     | > log_mle: -0.2961084842681885  (-0.2949820335465249)\n",
      "     | > loss_dur: 0.17822489142417908  (0.17277792653050086)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(23.1621, device='cuda:0')  (tensor(26.0427, device='cuda:0'))\n",
      "     | > current_lr: 1.65e-05 \n",
      "     | > step_time: 0.6033  (0.5498397831964976)\n",
      "     | > loader_time: 0.0142  (0.009450084031230268)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:41:31 -- STEP: 124/406 -- GLOBAL_STEP: 49650\u001b[0m\n",
      "     | > loss: -0.1070825606584549  (-0.12229092515284014)\n",
      "     | > log_mle: -0.310436487197876  (-0.2978047920811562)\n",
      "     | > loss_dur: 0.20335392653942108  (0.17551386692831594)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(49.5190, device='cuda:0')  (tensor(26.7295, device='cuda:0'))\n",
      "     | > current_lr: 1.65e-05 \n",
      "     | > step_time: 0.6919  (0.5682790067888077)\n",
      "     | > loader_time: 0.0054  (0.009987863802140758)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:41:47 -- STEP: 149/406 -- GLOBAL_STEP: 49675\u001b[0m\n",
      "     | > loss: -0.1337515264749527  (-0.12211088476165029)\n",
      "     | > log_mle: -0.31990551948547363  (-0.3000305979043847)\n",
      "     | > loss_dur: 0.18615399301052094  (0.17791971314273425)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(30.9626, device='cuda:0')  (tensor(28.2108, device='cuda:0'))\n",
      "     | > current_lr: 1.65e-05 \n",
      "     | > step_time: 0.511  (0.5806309520798245)\n",
      "     | > loader_time: 0.0153  (0.010530931037544404)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:42:05 -- STEP: 174/406 -- GLOBAL_STEP: 49700\u001b[0m\n",
      "     | > loss: -0.13113585114479065  (-0.12179418841655228)\n",
      "     | > log_mle: -0.307428240776062  (-0.3013531387537376)\n",
      "     | > loss_dur: 0.17629238963127136  (0.17955895033718522)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(30.5444, device='cuda:0')  (tensor(29.5820, device='cuda:0'))\n",
      "     | > current_lr: 1.65e-05 \n",
      "     | > step_time: 0.9345  (0.5955612193578963)\n",
      "     | > loader_time: 0.0249  (0.010736596995386583)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:42:22 -- STEP: 199/406 -- GLOBAL_STEP: 49725\u001b[0m\n",
      "     | > loss: -0.12787286937236786  (-0.12193716740488407)\n",
      "     | > log_mle: -0.3106989860534668  (-0.30288526400848864)\n",
      "     | > loss_dur: 0.18282611668109894  (0.1809480966036044)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(14.8292, device='cuda:0')  (tensor(29.8291, device='cuda:0'))\n",
      "     | > current_lr: 1.65e-05 \n",
      "     | > step_time: 0.8283  (0.602919906827074)\n",
      "     | > loader_time: 0.0173  (0.011528494370043572)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:42:40 -- STEP: 224/406 -- GLOBAL_STEP: 49750\u001b[0m\n",
      "     | > loss: -0.1348414421081543  (-0.12216007789330822)\n",
      "     | > log_mle: -0.30896687507629395  (-0.30434986363564226)\n",
      "     | > loss_dur: 0.17412543296813965  (0.18218978574233394)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(32.3606, device='cuda:0')  (tensor(30.3477, device='cuda:0'))\n",
      "     | > current_lr: 1.65e-05 \n",
      "     | > step_time: 0.7301  (0.6146504400031912)\n",
      "     | > loader_time: 0.0055  (0.012191379708903173)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:42:59 -- STEP: 249/406 -- GLOBAL_STEP: 49775\u001b[0m\n",
      "     | > loss: -0.12237684428691864  (-0.12231144303059482)\n",
      "     | > log_mle: -0.3088308572769165  (-0.3057646765766374)\n",
      "     | > loss_dur: 0.18645401298999786  (0.1834532335460425)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(38.8279, device='cuda:0')  (tensor(30.8325, device='cuda:0'))\n",
      "     | > current_lr: 1.65e-05 \n",
      "     | > step_time: 0.5861  (0.6250459937206717)\n",
      "     | > loader_time: 0.0327  (0.01278549696068208)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:43:17 -- STEP: 274/406 -- GLOBAL_STEP: 49800\u001b[0m\n",
      "     | > loss: -0.12278738617897034  (-0.12288865447044373)\n",
      "     | > log_mle: -0.320615291595459  (-0.3070815484019092)\n",
      "     | > loss_dur: 0.19782790541648865  (0.18419289393146537)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(34.4871, device='cuda:0')  (tensor(31.1077, device='cuda:0'))\n",
      "     | > current_lr: 1.65e-05 \n",
      "     | > step_time: 0.7779  (0.6329030599037231)\n",
      "     | > loader_time: 0.0088  (0.013283730423363452)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:43:36 -- STEP: 299/406 -- GLOBAL_STEP: 49825\u001b[0m\n",
      "     | > loss: -0.14677152037620544  (-0.12285018789529004)\n",
      "     | > log_mle: -0.33900928497314453  (-0.307922623229266)\n",
      "     | > loss_dur: 0.1922377645969391  (0.18507243533397594)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(23.1526, device='cuda:0')  (tensor(31.0820, device='cuda:0'))\n",
      "     | > current_lr: 1.65e-05 \n",
      "     | > step_time: 0.5667  (0.6416890692950098)\n",
      "     | > loader_time: 0.0055  (0.013448571680381546)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:43:55 -- STEP: 324/406 -- GLOBAL_STEP: 49850\u001b[0m\n",
      "     | > loss: -0.12553729116916656  (-0.12264726237382417)\n",
      "     | > log_mle: -0.31984639167785645  (-0.3085319101810456)\n",
      "     | > loss_dur: 0.19430910050868988  (0.18588464780722128)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(31.6196, device='cuda:0')  (tensor(31.1146, device='cuda:0'))\n",
      "     | > current_lr: 1.65e-05 \n",
      "     | > step_time: 0.614  (0.6500231285154088)\n",
      "     | > loader_time: 0.007  (0.01355439939616639)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:44:14 -- STEP: 349/406 -- GLOBAL_STEP: 49875\u001b[0m\n",
      "     | > loss: -0.09442442655563354  (-0.12227758060724482)\n",
      "     | > log_mle: -0.30808305740356445  (-0.3090812818368731)\n",
      "     | > loss_dur: 0.2136586308479309  (0.18680370122962822)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(36.2165, device='cuda:0')  (tensor(31.5446, device='cuda:0'))\n",
      "     | > current_lr: 1.65e-05 \n",
      "     | > step_time: 0.5936  (0.6571660601990277)\n",
      "     | > loader_time: 0.0101  (0.013565644152184954)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:44:35 -- STEP: 374/406 -- GLOBAL_STEP: 49900\u001b[0m\n",
      "     | > loss: -0.11825044453144073  (-0.12244015796618028)\n",
      "     | > log_mle: -0.31645333766937256  (-0.309933847284572)\n",
      "     | > loss_dur: 0.19820289313793182  (0.18749368931839167)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(24.9204, device='cuda:0')  (tensor(32.0758, device='cuda:0'))\n",
      "     | > current_lr: 1.65e-05 \n",
      "     | > step_time: 0.626  (0.665745512686949)\n",
      "     | > loader_time: 0.0073  (0.01372837637835008)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:44:57 -- STEP: 399/406 -- GLOBAL_STEP: 49925\u001b[0m\n",
      "     | > loss: -0.11832226812839508  (-0.12276384947742137)\n",
      "     | > log_mle: -0.32264935970306396  (-0.3107784218656688)\n",
      "     | > loss_dur: 0.20432709157466888  (0.18801457238824737)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(29.2738, device='cuda:0')  (tensor(32.2661, device='cuda:0'))\n",
      "     | > current_lr: 1.65e-05 \n",
      "     | > step_time: 0.5672  (0.6779557696559976)\n",
      "     | > loader_time: 0.0089  (0.014029321216401599)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: -0.10893726348876953  (-0.10893726348876953)\n",
      "     | > log_mle: -0.2934582233428955  (-0.2934582233428955)\n",
      "     | > loss_dur: 0.18452095985412598  (0.18452095985412598)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: -0.1666448414325714  (-0.1666448414325714)\n",
      "     | > log_mle: -0.33355557918548584  (-0.33355557918548584)\n",
      "     | > loss_dur: 0.16691073775291443  (0.16691073775291443)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: -0.1563870757818222  (-0.1615159586071968)\n",
      "     | > log_mle: -0.29832005500793457  (-0.3159378170967102)\n",
      "     | > loss_dur: 0.14193297922611237  (0.1544218584895134)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: -0.158004030585289  (-0.16034531593322754)\n",
      "     | > log_mle: -0.3067840337753296  (-0.3128865559895833)\n",
      "     | > loss_dur: 0.1487800031900406  (0.1525412400563558)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: -0.16418825089931488  (-0.16130604967474937)\n",
      "     | > log_mle: -0.33298659324645996  (-0.3179115653038025)\n",
      "     | > loss_dur: 0.16879834234714508  (0.15660551562905312)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: -0.16707433760166168  (-0.16245970726013184)\n",
      "     | > log_mle: -0.3343011140823364  (-0.3211894750595093)\n",
      "     | > loss_dur: 0.16722677648067474  (0.15872976779937745)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: -0.11272962391376495  (-0.15417136003573736)\n",
      "     | > log_mle: -0.3400278091430664  (-0.3243291974067688)\n",
      "     | > loss_dur: 0.22729818522930145  (0.17015783737103143)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: -0.14166046679019928  (-0.15238408957208907)\n",
      "     | > log_mle: -0.30461573600769043  (-0.3215129886354719)\n",
      "     | > loss_dur: 0.16295526921749115  (0.16912889906338283)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: -0.15943923592567444  (-0.15326598286628723)\n",
      "     | > log_mle: -0.31726861000061035  (-0.3209824413061142)\n",
      "     | > loss_dur: 0.1578293740749359  (0.16771645843982697)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: -0.14323000609874725  (-0.15215087433656058)\n",
      "     | > log_mle: -0.329323410987854  (-0.3219092157151964)\n",
      "     | > loss_dur: 0.18609340488910675  (0.16975834137863582)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: -0.1211598664522171  (-0.1490517735481262)\n",
      "     | > log_mle: -0.314963698387146  (-0.32121466398239135)\n",
      "     | > loss_dur: 0.1938038319349289  (0.17216289043426514)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: -0.14510710537433624  (-0.14869316735050894)\n",
      "     | > log_mle: -0.3320878744125366  (-0.32220313765785913)\n",
      "     | > loss_dur: 0.18698076903820038  (0.17350997030735016)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: -0.15107573568820953  (-0.148891714711984)\n",
      "     | > log_mle: -0.3179817199707031  (-0.32185135285059613)\n",
      "     | > loss_dur: 0.1669059842824936  (0.17295963813861212)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: -0.1739969253540039  (-0.15082288476137015)\n",
      "     | > log_mle: -0.34120047092437744  (-0.3233397465485793)\n",
      "     | > loss_dur: 0.16720354557037354  (0.17251686178720915)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: -0.14319799840450287  (-0.15027825002159392)\n",
      "     | > log_mle: -0.3297766447067261  (-0.32379952498844694)\n",
      "     | > loss_dur: 0.1865786463022232  (0.17352127496685302)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: -0.14081823825836182  (-0.14964758257071178)\n",
      "     | > log_mle: -0.3230482339859009  (-0.3237494389216105)\n",
      "     | > loss_dur: 0.18222999572753906  (0.17410185635089875)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: -0.13858316838741302  (-0.1489560566842556)\n",
      "     | > log_mle: -0.32595598697662354  (-0.32388734817504883)\n",
      "     | > loss_dur: 0.1873728185892105  (0.17493129149079323)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: audio amplitude out of range, auto clipped.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.003737837076187134 \u001b[0m(-0.0009369552135467529)\n",
      "     | > avg_loss:\u001b[92m -0.1489560566842556 \u001b[0m(-0.0075457338243722916)\n",
      "     | > avg_log_mle:\u001b[92m -0.32388734817504883 \u001b[0m(-0.004560582339763641)\n",
      "     | > avg_loss_dur:\u001b[92m 0.17493129149079323 \u001b[0m(-0.00298515148460865)\n",
      "\n",
      " > BEST MODEL : train/run-February-22-2025_10+59PM-fa84af3/best_model_49932.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 67/100\u001b[0m\n",
      " --> train/run-February-22-2025_10+59PM-fa84af3\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-23 04:45:17) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:45:27 -- STEP: 18/406 -- GLOBAL_STEP: 49950\u001b[0m\n",
      "     | > loss: -0.13473673164844513  (-0.13975533677472007)\n",
      "     | > log_mle: -0.2887082099914551  (-0.2961366375287374)\n",
      "     | > loss_dur: 0.15397147834300995  (0.1563813007540173)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(14.4891, device='cuda:0')  (tensor(23.7206, device='cuda:0'))\n",
      "     | > current_lr: 1.675e-05 \n",
      "     | > step_time: 0.5152  (0.4367704259024726)\n",
      "     | > loader_time: 0.0053  (0.006979756885104709)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:45:42 -- STEP: 43/406 -- GLOBAL_STEP: 49975\u001b[0m\n",
      "     | > loss: -0.12626633048057556  (-0.13273884148098702)\n",
      "     | > log_mle: -0.2828637361526489  (-0.2934642475704814)\n",
      "     | > loss_dur: 0.15659740567207336  (0.16072540608949434)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(16.3634, device='cuda:0')  (tensor(23.6459, device='cuda:0'))\n",
      "     | > current_lr: 1.675e-05 \n",
      "     | > step_time: 0.6886  (0.5173735230468041)\n",
      "     | > loader_time: 0.0059  (0.009149146634478904)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:45:58 -- STEP: 68/406 -- GLOBAL_STEP: 50000\u001b[0m\n",
      "     | > loss: -0.12692569196224213  (-0.1285162539604832)\n",
      "     | > log_mle: -0.3028630018234253  (-0.29534226130036745)\n",
      "     | > loss_dur: 0.17593730986118317  (0.1668260073398842)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(30.4865, device='cuda:0')  (tensor(24.4151, device='cuda:0'))\n",
      "     | > current_lr: 1.675e-05 \n",
      "     | > step_time: 0.7208  (0.5550287997021395)\n",
      "     | > loader_time: 0.0161  (0.010221011498395136)\n",
      "\n",
      "\n",
      " > CHECKPOINT : train/run-February-22-2025_10+59PM-fa84af3/checkpoint_50000.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: audio amplitude out of range, auto clipped.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:46:16 -- STEP: 93/406 -- GLOBAL_STEP: 50025\u001b[0m\n",
      "     | > loss: -0.12235534191131592  (-0.12775209081429306)\n",
      "     | > log_mle: -0.324285626411438  (-0.29837177261229486)\n",
      "     | > loss_dur: 0.20193028450012207  (0.17061968179800174)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(27.8795, device='cuda:0')  (tensor(26.0891, device='cuda:0'))\n",
      "     | > current_lr: 1.675e-05 \n",
      "     | > step_time: 0.8672  (0.5621722795630012)\n",
      "     | > loader_time: 0.0063  (0.01027088011464765)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:46:32 -- STEP: 118/406 -- GLOBAL_STEP: 50050\u001b[0m\n",
      "     | > loss: -0.1150558739900589  (-0.12672268599271777)\n",
      "     | > log_mle: -0.31478452682495117  (-0.30039820933746075)\n",
      "     | > loss_dur: 0.19972865283489227  (0.17367552334474304)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(29.7210, device='cuda:0')  (tensor(25.9197, device='cuda:0'))\n",
      "     | > current_lr: 1.675e-05 \n",
      "     | > step_time: 0.5481  (0.57538101228617)\n",
      "     | > loader_time: 0.0262  (0.010642237582449185)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:46:49 -- STEP: 143/406 -- GLOBAL_STEP: 50075\u001b[0m\n",
      "     | > loss: -0.12766554951667786  (-0.1255345539404796)\n",
      "     | > log_mle: -0.312505841255188  (-0.3021172226725757)\n",
      "     | > loss_dur: 0.18484029173851013  (0.17658266873209624)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(90.9293, device='cuda:0')  (tensor(27.2292, device='cuda:0'))\n",
      "     | > current_lr: 1.675e-05 \n",
      "     | > step_time: 0.9534  (0.5846536876438381)\n",
      "     | > loader_time: 0.0098  (0.011049233950101413)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:47:06 -- STEP: 168/406 -- GLOBAL_STEP: 50100\u001b[0m\n",
      "     | > loss: -0.1277139037847519  (-0.12478072347030755)\n",
      "     | > log_mle: -0.3044852018356323  (-0.30328800848552157)\n",
      "     | > loss_dur: 0.17677129805088043  (0.178507285015214)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(21.0779, device='cuda:0')  (tensor(27.8490, device='cuda:0'))\n",
      "     | > current_lr: 1.675e-05 \n",
      "     | > step_time: 0.5983  (0.5968661535353886)\n",
      "     | > loader_time: 0.0288  (0.011053083907990232)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:47:24 -- STEP: 193/406 -- GLOBAL_STEP: 50125\u001b[0m\n",
      "     | > loss: -0.1215129941701889  (-0.1244528515968916)\n",
      "     | > log_mle: -0.3160736560821533  (-0.3045174111974053)\n",
      "     | > loss_dur: 0.19456066191196442  (0.18006455960051376)\n",
      "     | > amp_scaler: 2048.0  (3979.2746113989638)\n",
      "     | > grad_norm: tensor(33.5893, device='cuda:0')  (tensor(30.7670, device='cuda:0'))\n",
      "     | > current_lr: 1.675e-05 \n",
      "     | > step_time: 0.6872  (0.6108243539543348)\n",
      "     | > loader_time: 0.013  (0.01107570544425688)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:47:42 -- STEP: 218/406 -- GLOBAL_STEP: 50150\u001b[0m\n",
      "     | > loss: -0.12254834175109863  (-0.1242703474853017)\n",
      "     | > log_mle: -0.3167811632156372  (-0.305751293624213)\n",
      "     | > loss_dur: 0.19423282146453857  (0.18148094613891122)\n",
      "     | > amp_scaler: 2048.0  (3757.798165137615)\n",
      "     | > grad_norm: tensor(20.8270, device='cuda:0')  (tensor(30.8230, device='cuda:0'))\n",
      "     | > current_lr: 1.675e-05 \n",
      "     | > step_time: 0.5195  (0.6214236513190313)\n",
      "     | > loader_time: 0.0137  (0.01124842013787786)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:48:01 -- STEP: 243/406 -- GLOBAL_STEP: 50175\u001b[0m\n",
      "     | > loss: -0.12866024672985077  (-0.1242631863296768)\n",
      "     | > log_mle: -0.3343850374221802  (-0.30715758221630207)\n",
      "     | > loss_dur: 0.2057247906923294  (0.18289439588662523)\n",
      "     | > amp_scaler: 2048.0  (3581.893004115226)\n",
      "     | > grad_norm: tensor(54.1684, device='cuda:0')  (tensor(31.0783, device='cuda:0'))\n",
      "     | > current_lr: 1.675e-05 \n",
      "     | > step_time: 1.0062  (0.6348390952059271)\n",
      "     | > loader_time: 0.0046  (0.011400646633572051)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:48:20 -- STEP: 268/406 -- GLOBAL_STEP: 50200\u001b[0m\n",
      "     | > loss: -0.1374865025281906  (-0.12463143918274054)\n",
      "     | > log_mle: -0.3306725025177002  (-0.3081984110732577)\n",
      "     | > loss_dur: 0.19318599998950958  (0.18356697189051707)\n",
      "     | > amp_scaler: 2048.0  (3438.8059701492543)\n",
      "     | > grad_norm: tensor(21.6741, device='cuda:0')  (tensor(31.5057, device='cuda:0'))\n",
      "     | > current_lr: 1.675e-05 \n",
      "     | > step_time: 0.7509  (0.6455889379800256)\n",
      "     | > loader_time: 0.0292  (0.011719847793009745)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:48:39 -- STEP: 293/406 -- GLOBAL_STEP: 50225\u001b[0m\n",
      "     | > loss: -0.13992829620838165  (-0.1248282211429023)\n",
      "     | > log_mle: -0.32470691204071045  (-0.3091619511106314)\n",
      "     | > loss_dur: 0.1847786158323288  (0.18433372996772923)\n",
      "     | > amp_scaler: 2048.0  (3320.1365187713313)\n",
      "     | > grad_norm: tensor(22.6013, device='cuda:0')  (tensor(31.8637, device='cuda:0'))\n",
      "     | > current_lr: 1.675e-05 \n",
      "     | > step_time: 0.7771  (0.6531730951302693)\n",
      "     | > loader_time: 0.0222  (0.012288459738773698)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:49:00 -- STEP: 318/406 -- GLOBAL_STEP: 50250\u001b[0m\n",
      "     | > loss: -0.11505253612995148  (-0.12497768063777645)\n",
      "     | > log_mle: -0.3090463876724243  (-0.31005411065599425)\n",
      "     | > loss_dur: 0.19399385154247284  (0.18507643001821808)\n",
      "     | > amp_scaler: 2048.0  (3220.1257861635227)\n",
      "     | > grad_norm: tensor(64.0915, device='cuda:0')  (tensor(32.1068, device='cuda:0'))\n",
      "     | > current_lr: 1.675e-05 \n",
      "     | > step_time: 0.6769  (0.665098187308641)\n",
      "     | > loader_time: 0.0054  (0.012538916659805013)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:49:21 -- STEP: 343/406 -- GLOBAL_STEP: 50275\u001b[0m\n",
      "     | > loss: -0.1253587156534195  (-0.12478409972552305)\n",
      "     | > log_mle: -0.3316028118133545  (-0.3107058532731524)\n",
      "     | > loss_dur: 0.206244096159935  (0.18592175354762963)\n",
      "     | > amp_scaler: 2048.0  (3134.693877551021)\n",
      "     | > grad_norm: tensor(29.9019, device='cuda:0')  (tensor(32.7008, device='cuda:0'))\n",
      "     | > current_lr: 1.675e-05 \n",
      "     | > step_time: 0.777  (0.6769868104172861)\n",
      "     | > loader_time: 0.0113  (0.012734144144086034)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:49:42 -- STEP: 368/406 -- GLOBAL_STEP: 50300\u001b[0m\n",
      "     | > loss: -0.12058976292610168  (-0.12477163172772396)\n",
      "     | > log_mle: -0.3140326738357544  (-0.31134761707938224)\n",
      "     | > loss_dur: 0.1934429109096527  (0.18657598535165845)\n",
      "     | > amp_scaler: 2048.0  (3060.869565217392)\n",
      "     | > grad_norm: tensor(111.3028, device='cuda:0')  (tensor(33.0527, device='cuda:0'))\n",
      "     | > current_lr: 1.675e-05 \n",
      "     | > step_time: 0.7006  (0.68578302665897)\n",
      "     | > loader_time: 0.0159  (0.012957388940064806)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:50:04 -- STEP: 393/406 -- GLOBAL_STEP: 50325\u001b[0m\n",
      "     | > loss: -0.1289384365081787  (-0.12449323467474249)\n",
      "     | > log_mle: -0.32325828075408936  (-0.3116839198969094)\n",
      "     | > loss_dur: 0.19431984424591064  (0.18719068522216717)\n",
      "     | > amp_scaler: 2048.0  (2996.4376590330794)\n",
      "     | > grad_norm: tensor(30.6947, device='cuda:0')  (tensor(33.5639, device='cuda:0'))\n",
      "     | > current_lr: 1.675e-05 \n",
      "     | > step_time: 0.5637  (0.6972014928288733)\n",
      "     | > loader_time: 0.0086  (0.013334108672979227)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: -0.12763631343841553  (-0.12763631343841553)\n",
      "     | > log_mle: -0.29504430294036865  (-0.29504430294036865)\n",
      "     | > loss_dur: 0.16740798950195312  (0.16740798950195312)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: -0.169077068567276  (-0.169077068567276)\n",
      "     | > log_mle: -0.33685147762298584  (-0.33685147762298584)\n",
      "     | > loss_dur: 0.16777440905570984  (0.16777440905570984)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: -0.1548493504524231  (-0.16196320950984955)\n",
      "     | > log_mle: -0.2998998165130615  (-0.3183756470680237)\n",
      "     | > loss_dur: 0.14505046606063843  (0.15641243755817413)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: -0.15828290581703186  (-0.16073644161224365)\n",
      "     | > log_mle: -0.30965328216552734  (-0.3154681921005249)\n",
      "     | > loss_dur: 0.15137037634849548  (0.15473175048828125)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: -0.17030911147594452  (-0.16312960907816887)\n",
      "     | > log_mle: -0.3369179964065552  (-0.32083064317703247)\n",
      "     | > loss_dur: 0.16660888493061066  (0.1577010340988636)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: -0.17176704108715057  (-0.16485709547996522)\n",
      "     | > log_mle: -0.33780181407928467  (-0.3242248773574829)\n",
      "     | > loss_dur: 0.1660347729921341  (0.1593677818775177)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: -0.11384865641593933  (-0.15635568896929422)\n",
      "     | > log_mle: -0.34751904010772705  (-0.32810723781585693)\n",
      "     | > loss_dur: 0.23367038369178772  (0.1717515488465627)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: -0.14016401767730713  (-0.15404259307043894)\n",
      "     | > log_mle: -0.3075624704360962  (-0.32517227104731966)\n",
      "     | > loss_dur: 0.16739845275878906  (0.17112967797688075)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: -0.16487273573875427  (-0.15539636090397835)\n",
      "     | > log_mle: -0.3206329345703125  (-0.3246048539876938)\n",
      "     | > loss_dur: 0.15576019883155823  (0.16920849308371544)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: -0.1527666300535202  (-0.15510416858726078)\n",
      "     | > log_mle: -0.3337059020996094  (-0.3256160815556844)\n",
      "     | > loss_dur: 0.18093927204608917  (0.17051191296842363)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: -0.1290082335472107  (-0.15249457508325576)\n",
      "     | > log_mle: -0.31871604919433594  (-0.32492607831954956)\n",
      "     | > loss_dur: 0.18970781564712524  (0.1724315032362938)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: -0.14562438428401947  (-0.1518700122833252)\n",
      "     | > log_mle: -0.3356931209564209  (-0.32590490037744696)\n",
      "     | > loss_dur: 0.19006873667240143  (0.17403488809412176)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: -0.1641867309808731  (-0.15289640550812086)\n",
      "     | > log_mle: -0.3212374448776245  (-0.32551594575246173)\n",
      "     | > loss_dur: 0.1570507138967514  (0.1726195402443409)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: -0.18382886052131653  (-0.1552758251245205)\n",
      "     | > log_mle: -0.34435200691223145  (-0.3269648735339825)\n",
      "     | > loss_dur: 0.16052314639091492  (0.17168904840946198)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: -0.14444534480571747  (-0.15450221938746317)\n",
      "     | > log_mle: -0.33295226097106934  (-0.32739254406520296)\n",
      "     | > loss_dur: 0.18850691616535187  (0.17289032467773982)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: -0.14531902968883514  (-0.15389000674088796)\n",
      "     | > log_mle: -0.3259279727935791  (-0.32729490598042804)\n",
      "     | > loss_dur: 0.18060894310474396  (0.1734048992395401)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: -0.15192048251628876  (-0.1537669114768505)\n",
      "     | > log_mle: -0.3290739059448242  (-0.3274060934782028)\n",
      "     | > loss_dur: 0.17715342342853546  (0.1736391820013523)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: audio amplitude out of range, auto clipped.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.0031577497720718384 \u001b[0m(-0.0005800873041152954)\n",
      "     | > avg_loss:\u001b[92m -0.1537669114768505 \u001b[0m(-0.00481085479259491)\n",
      "     | > avg_log_mle:\u001b[92m -0.3274060934782028 \u001b[0m(-0.0035187453031539917)\n",
      "     | > avg_loss_dur:\u001b[92m 0.1736391820013523 \u001b[0m(-0.001292109489440918)\n",
      "\n",
      " > BEST MODEL : train/run-February-22-2025_10+59PM-fa84af3/best_model_50338.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 68/100\u001b[0m\n",
      " --> train/run-February-22-2025_10+59PM-fa84af3\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-23 04:50:28) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:50:35 -- STEP: 12/406 -- GLOBAL_STEP: 50350\u001b[0m\n",
      "     | > loss: -0.14496257901191711  (-0.1457968627413114)\n",
      "     | > log_mle: -0.3049297332763672  (-0.2962477008501689)\n",
      "     | > loss_dur: 0.15996715426445007  (0.15045083810885748)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(27.4425, device='cuda:0')  (tensor(36.0976, device='cuda:0'))\n",
      "     | > current_lr: 1.7e-05 \n",
      "     | > step_time: 0.298  (0.34672121206919354)\n",
      "     | > loader_time: 0.0039  (0.006265302499135335)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:50:50 -- STEP: 37/406 -- GLOBAL_STEP: 50375\u001b[0m\n",
      "     | > loss: -0.1331903487443924  (-0.1328694832486076)\n",
      "     | > log_mle: -0.28843963146209717  (-0.2930943837036957)\n",
      "     | > loss_dur: 0.15524928271770477  (0.16022490045508822)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(24.6406, device='cuda:0')  (tensor(29.3095, device='cuda:0'))\n",
      "     | > current_lr: 1.7e-05 \n",
      "     | > step_time: 0.3083  (0.5060602136560388)\n",
      "     | > loader_time: 0.0078  (0.007744080311543233)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:51:05 -- STEP: 62/406 -- GLOBAL_STEP: 50400\u001b[0m\n",
      "     | > loss: -0.12890329957008362  (-0.12646648984762932)\n",
      "     | > log_mle: -0.2929534912109375  (-0.2932004717088515)\n",
      "     | > loss_dur: 0.16405019164085388  (0.16673398186122224)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(23.7842, device='cuda:0')  (tensor(29.4645, device='cuda:0'))\n",
      "     | > current_lr: 1.7e-05 \n",
      "     | > step_time: 0.4411  (0.549406978391832)\n",
      "     | > loader_time: 0.0042  (0.007977631784254502)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:51:21 -- STEP: 87/406 -- GLOBAL_STEP: 50425\u001b[0m\n",
      "     | > loss: -0.13696423172950745  (-0.12670812969920278)\n",
      "     | > log_mle: -0.32599854469299316  (-0.2967639558616728)\n",
      "     | > loss_dur: 0.18903431296348572  (0.17005582616246986)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(25.0327, device='cuda:0')  (tensor(29.4847, device='cuda:0'))\n",
      "     | > current_lr: 1.7e-05 \n",
      "     | > step_time: 0.6489  (0.564620812733968)\n",
      "     | > loader_time: 0.0079  (0.008742214619428259)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:51:37 -- STEP: 112/406 -- GLOBAL_STEP: 50450\u001b[0m\n",
      "     | > loss: -0.12924344837665558  (-0.126815671899489)\n",
      "     | > log_mle: -0.3138892650604248  (-0.2998879402875902)\n",
      "     | > loss_dur: 0.18464581668376923  (0.17307226838810102)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(40.0383, device='cuda:0')  (tensor(30.2142, device='cuda:0'))\n",
      "     | > current_lr: 1.7e-05 \n",
      "     | > step_time: 0.5509  (0.5838023849896022)\n",
      "     | > loader_time: 0.0075  (0.01006312242576054)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:51:55 -- STEP: 137/406 -- GLOBAL_STEP: 50475\u001b[0m\n",
      "     | > loss: -0.12138767540454865  (-0.12639296457280208)\n",
      "     | > log_mle: -0.3129662275314331  (-0.3022002669146463)\n",
      "     | > loss_dur: 0.19157855212688446  (0.17580730234184405)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(26.2206, device='cuda:0')  (tensor(30.8639, device='cuda:0'))\n",
      "     | > current_lr: 1.7e-05 \n",
      "     | > step_time: 0.7809  (0.6016063307323595)\n",
      "     | > loader_time: 0.0117  (0.010483315391262082)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:52:13 -- STEP: 162/406 -- GLOBAL_STEP: 50500\u001b[0m\n",
      "     | > loss: -0.12469306588172913  (-0.12584278070264393)\n",
      "     | > log_mle: -0.31206512451171875  (-0.3037578397327001)\n",
      "     | > loss_dur: 0.18737205862998962  (0.17791505903005597)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(43.8928, device='cuda:0')  (tensor(30.8094, device='cuda:0'))\n",
      "     | > current_lr: 1.7e-05 \n",
      "     | > step_time: 1.0868  (0.6167596195950921)\n",
      "     | > loader_time: 0.0128  (0.010659790333406421)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:52:31 -- STEP: 187/406 -- GLOBAL_STEP: 50525\u001b[0m\n",
      "     | > loss: -0.13448983430862427  (-0.1261005418345253)\n",
      "     | > log_mle: -0.3171830177307129  (-0.3053736074723025)\n",
      "     | > loss_dur: 0.18269318342208862  (0.1792730656377772)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(32.0155, device='cuda:0')  (tensor(32.1239, device='cuda:0'))\n",
      "     | > current_lr: 1.7e-05 \n",
      "     | > step_time: 0.8739  (0.6279917082047082)\n",
      "     | > loader_time: 0.0809  (0.010958377052755916)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:52:49 -- STEP: 212/406 -- GLOBAL_STEP: 50550\u001b[0m\n",
      "     | > loss: -0.11496710777282715  (-0.12574678652410246)\n",
      "     | > log_mle: -0.3189585208892822  (-0.3064359977560225)\n",
      "     | > loss_dur: 0.20399141311645508  (0.18068921123191994)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(95.8009, device='cuda:0')  (tensor(32.8315, device='cuda:0'))\n",
      "     | > current_lr: 1.7e-05 \n",
      "     | > step_time: 0.4253  (0.6385169614036127)\n",
      "     | > loader_time: 0.0105  (0.01109796200158461)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:53:08 -- STEP: 237/406 -- GLOBAL_STEP: 50575\u001b[0m\n",
      "     | > loss: -0.13363707065582275  (-0.1255952754226918)\n",
      "     | > log_mle: -0.33222198486328125  (-0.3076876261063267)\n",
      "     | > loss_dur: 0.1985849142074585  (0.1820923506836348)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(43.3821, device='cuda:0')  (tensor(32.9442, device='cuda:0'))\n",
      "     | > current_lr: 1.7e-05 \n",
      "     | > step_time: 0.5564  (0.6466327689368009)\n",
      "     | > loader_time: 0.0074  (0.011317264178634193)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:53:27 -- STEP: 262/406 -- GLOBAL_STEP: 50600\u001b[0m\n",
      "     | > loss: -0.11895942687988281  (-0.12583611086579674)\n",
      "     | > log_mle: -0.2992633581161499  (-0.30880403018179753)\n",
      "     | > loss_dur: 0.1803039312362671  (0.18296791931600062)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(44.4353, device='cuda:0')  (tensor(33.4160, device='cuda:0'))\n",
      "     | > current_lr: 1.7e-05 \n",
      "     | > step_time: 0.7307  (0.6566537281939091)\n",
      "     | > loader_time: 0.0247  (0.01198971453513808)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:53:47 -- STEP: 287/406 -- GLOBAL_STEP: 50625\u001b[0m\n",
      "     | > loss: -0.11759594082832336  (-0.12617522337918488)\n",
      "     | > log_mle: -0.31498146057128906  (-0.3098592176669982)\n",
      "     | > loss_dur: 0.1973855197429657  (0.18368399428781312)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(19.9593, device='cuda:0')  (tensor(33.4966, device='cuda:0'))\n",
      "     | > current_lr: 1.7e-05 \n",
      "     | > step_time: 0.9062  (0.6683440515803959)\n",
      "     | > loader_time: 0.0079  (0.012182858762840776)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:54:07 -- STEP: 312/406 -- GLOBAL_STEP: 50650\u001b[0m\n",
      "     | > loss: -0.14030766487121582  (-0.12635139375925059)\n",
      "     | > log_mle: -0.324476957321167  (-0.3107120918157774)\n",
      "     | > loss_dur: 0.18416929244995117  (0.1843606980565266)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(26.0037, device='cuda:0')  (tensor(33.5650, device='cuda:0'))\n",
      "     | > current_lr: 1.7e-05 \n",
      "     | > step_time: 0.6806  (0.6772600526993092)\n",
      "     | > loader_time: 0.0086  (0.012417727555984108)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:54:28 -- STEP: 337/406 -- GLOBAL_STEP: 50675\u001b[0m\n",
      "     | > loss: -0.1248178482055664  (-0.12625675716987342)\n",
      "     | > log_mle: -0.3174457550048828  (-0.3114168141645212)\n",
      "     | > loss_dur: 0.1926279067993164  (0.18516005699464747)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(16.8474, device='cuda:0')  (tensor(33.4786, device='cuda:0'))\n",
      "     | > current_lr: 1.7e-05 \n",
      "     | > step_time: 0.8505  (0.687661661238628)\n",
      "     | > loader_time: 0.0306  (0.012716666880983982)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:54:50 -- STEP: 362/406 -- GLOBAL_STEP: 50700\u001b[0m\n",
      "     | > loss: -0.14503224194049835  (-0.12633591993243656)\n",
      "     | > log_mle: -0.3335531949996948  (-0.31231421429807993)\n",
      "     | > loss_dur: 0.18852095305919647  (0.18597829436564298)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(24.6685, device='cuda:0')  (tensor(33.9395, device='cuda:0'))\n",
      "     | > current_lr: 1.7e-05 \n",
      "     | > step_time: 0.8472  (0.6992303976037888)\n",
      "     | > loader_time: 0.0061  (0.013046742802825423)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:55:13 -- STEP: 387/406 -- GLOBAL_STEP: 50725\u001b[0m\n",
      "     | > loss: -0.1319044977426529  (-0.12655138615181893)\n",
      "     | > log_mle: -0.32630765438079834  (-0.31309351625368603)\n",
      "     | > loss_dur: 0.19440315663814545  (0.18654213010186665)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(44.0357, device='cuda:0')  (tensor(33.9916, device='cuda:0'))\n",
      "     | > current_lr: 1.7e-05 \n",
      "     | > step_time: 0.7872  (0.7104521068799717)\n",
      "     | > loader_time: 0.0065  (0.0131498966414183)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: -0.12081126868724823  (-0.12081126868724823)\n",
      "     | > log_mle: -0.29801321029663086  (-0.29801321029663086)\n",
      "     | > loss_dur: 0.17720194160938263  (0.17720194160938263)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: -0.17520402371883392  (-0.17520402371883392)\n",
      "     | > log_mle: -0.3388996124267578  (-0.3388996124267578)\n",
      "     | > loss_dur: 0.1636955887079239  (0.1636955887079239)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: -0.1641574501991272  (-0.16968073695898056)\n",
      "     | > log_mle: -0.30301976203918457  (-0.3209596872329712)\n",
      "     | > loss_dur: 0.13886231184005737  (0.15127895027399063)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: -0.16424229741096497  (-0.1678679237763087)\n",
      "     | > log_mle: -0.31240785121917725  (-0.31810907522837323)\n",
      "     | > loss_dur: 0.14816555380821228  (0.15024115145206451)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: -0.17639030516147614  (-0.16999851912260056)\n",
      "     | > log_mle: -0.33870387077331543  (-0.32325777411460876)\n",
      "     | > loss_dur: 0.1623135656118393  (0.1532592549920082)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: -0.17457005381584167  (-0.17091282606124877)\n",
      "     | > log_mle: -0.3388352394104004  (-0.3263732671737671)\n",
      "     | > loss_dur: 0.16426518559455872  (0.1554604411125183)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: -0.11468768119812012  (-0.16154196858406067)\n",
      "     | > log_mle: -0.34511494636535645  (-0.3294968803723653)\n",
      "     | > loss_dur: 0.23042726516723633  (0.16795491178830466)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: -0.14674612879753113  (-0.159428277185985)\n",
      "     | > log_mle: -0.30920660495758057  (-0.32659826959882465)\n",
      "     | > loss_dur: 0.16246047616004944  (0.1671699924128396)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: -0.1654721051454544  (-0.1601837556809187)\n",
      "     | > log_mle: -0.322870135307312  (-0.32613225281238556)\n",
      "     | > loss_dur: 0.1573980301618576  (0.16594849713146687)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: -0.14496274292469025  (-0.15849253204133776)\n",
      "     | > log_mle: -0.33380961418151855  (-0.32698529296451145)\n",
      "     | > loss_dur: 0.1888468712568283  (0.1684927609231737)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: -0.12252411246299744  (-0.15489569008350373)\n",
      "     | > log_mle: -0.31997644901275635  (-0.32628440856933594)\n",
      "     | > loss_dur: 0.1974523365497589  (0.1713887184858322)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: -0.15453073382377625  (-0.15486251224171033)\n",
      "     | > log_mle: -0.33731746673583984  (-0.32728741385719995)\n",
      "     | > loss_dur: 0.1827867329120636  (0.17242490161548962)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: -0.1618344634771347  (-0.15544350817799568)\n",
      "     | > log_mle: -0.3233579397201538  (-0.32695995767911273)\n",
      "     | > loss_dur: 0.1615234762430191  (0.17151644950111708)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: -0.17778731882572174  (-0.1571622628432054)\n",
      "     | > log_mle: -0.3460965156555176  (-0.32843200060037464)\n",
      "     | > loss_dur: 0.16830919682979584  (0.17126973775716928)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: -0.14532439410686493  (-0.15631670079060964)\n",
      "     | > log_mle: -0.3346635103225708  (-0.32887710843767437)\n",
      "     | > loss_dur: 0.18933911621570587  (0.17256040764706476)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: -0.14860141277313232  (-0.15580234825611114)\n",
      "     | > log_mle: -0.32804393768310547  (-0.32882156372070315)\n",
      "     | > loss_dur: 0.17944252490997314  (0.17301921546459198)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: -0.1406031847000122  (-0.15485240053385496)\n",
      "     | > log_mle: -0.33016443252563477  (-0.32890549302101135)\n",
      "     | > loss_dur: 0.18956124782562256  (0.1740530924871564)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: audio amplitude out of range, auto clipped.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[91m 0.0038919895887374887 \u001b[0m(+0.0007342398166656503)\n",
      "     | > avg_loss:\u001b[92m -0.15485240053385496 \u001b[0m(-0.0010854890570044518)\n",
      "     | > avg_log_mle:\u001b[92m -0.32890549302101135 \u001b[0m(-0.0014993995428085327)\n",
      "     | > avg_loss_dur:\u001b[91m 0.1740530924871564 \u001b[0m(+0.00041391048580408096)\n",
      "\n",
      " > BEST MODEL : train/run-February-22-2025_10+59PM-fa84af3/best_model_50744.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 69/100\u001b[0m\n",
      " --> train/run-February-22-2025_10+59PM-fa84af3\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-23 04:55:41) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:55:46 -- STEP: 6/406 -- GLOBAL_STEP: 50750\u001b[0m\n",
      "     | > loss: -0.1650433987379074  (-0.14810416350762048)\n",
      "     | > log_mle: -0.2978832721710205  (-0.2985902825991313)\n",
      "     | > loss_dur: 0.1328398734331131  (0.15048611909151077)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(23.1818, device='cuda:0')  (tensor(27.2755, device='cuda:0'))\n",
      "     | > current_lr: 1.725e-05 \n",
      "     | > step_time: 0.3925  (0.41896406809488934)\n",
      "     | > loader_time: 0.0036  (0.0068340301513671875)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:56:00 -- STEP: 31/406 -- GLOBAL_STEP: 50775\u001b[0m\n",
      "     | > loss: -0.12805579602718353  (-0.13881452285474344)\n",
      "     | > log_mle: -0.28636837005615234  (-0.2978540082131663)\n",
      "     | > loss_dur: 0.1583125740289688  (0.1590394853584228)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(22.6218, device='cuda:0')  (tensor(20.9327, device='cuda:0'))\n",
      "     | > current_lr: 1.725e-05 \n",
      "     | > step_time: 0.7301  (0.5197024499216386)\n",
      "     | > loader_time: 0.0059  (0.008364777411184004)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:56:15 -- STEP: 56/406 -- GLOBAL_STEP: 50800\u001b[0m\n",
      "     | > loss: -0.13841202855110168  (-0.13169646422777853)\n",
      "     | > log_mle: -0.30293703079223633  (-0.29742643662861423)\n",
      "     | > loss_dur: 0.16452500224113464  (0.16572997240083562)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(20.0647, device='cuda:0')  (tensor(22.8327, device='cuda:0'))\n",
      "     | > current_lr: 1.725e-05 \n",
      "     | > step_time: 1.0461  (0.5528565645217894)\n",
      "     | > loader_time: 0.0269  (0.009106320994240897)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:56:31 -- STEP: 81/406 -- GLOBAL_STEP: 50825\u001b[0m\n",
      "     | > loss: -0.14252038300037384  (-0.13050386052072785)\n",
      "     | > log_mle: -0.3104337453842163  (-0.2991539490075759)\n",
      "     | > loss_dur: 0.16791336238384247  (0.16865008848684807)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(33.7333, device='cuda:0')  (tensor(26.9762, device='cuda:0'))\n",
      "     | > current_lr: 1.725e-05 \n",
      "     | > step_time: 0.4826  (0.5719882882671592)\n",
      "     | > loader_time: 0.0068  (0.010465836819307302)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:56:47 -- STEP: 106/406 -- GLOBAL_STEP: 50850\u001b[0m\n",
      "     | > loss: -0.11973902583122253  (-0.13001287180297788)\n",
      "     | > log_mle: -0.30163323879241943  (-0.302007089245994)\n",
      "     | > loss_dur: 0.1818942129611969  (0.17199421744301635)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(25.7446, device='cuda:0')  (tensor(27.6040, device='cuda:0'))\n",
      "     | > current_lr: 1.725e-05 \n",
      "     | > step_time: 0.7901  (0.5835165235231505)\n",
      "     | > loader_time: 0.0256  (0.010727583237414086)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:57:04 -- STEP: 131/406 -- GLOBAL_STEP: 50875\u001b[0m\n",
      "     | > loss: -0.14318937063217163  (-0.13018822476609074)\n",
      "     | > log_mle: -0.3118307590484619  (-0.3045485319982047)\n",
      "     | > loss_dur: 0.16864138841629028  (0.17436030723211418)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(50.4761, device='cuda:0')  (tensor(28.4755, device='cuda:0'))\n",
      "     | > current_lr: 1.725e-05 \n",
      "     | > step_time: 0.9244  (0.6014973352883607)\n",
      "     | > loader_time: 0.0264  (0.010967014400103616)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:57:21 -- STEP: 156/406 -- GLOBAL_STEP: 50900\u001b[0m\n",
      "     | > loss: -0.10996520519256592  (-0.12887355809410425)\n",
      "     | > log_mle: -0.3165414333343506  (-0.30594743367953176)\n",
      "     | > loss_dur: 0.20657622814178467  (0.17707387558542764)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(68.7294, device='cuda:0')  (tensor(29.3336, device='cuda:0'))\n",
      "     | > current_lr: 1.725e-05 \n",
      "     | > step_time: 0.6242  (0.6078029702871274)\n",
      "     | > loader_time: 0.0214  (0.011568214648809177)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:57:39 -- STEP: 181/406 -- GLOBAL_STEP: 50925\u001b[0m\n",
      "     | > loss: -0.1055014580488205  (-0.12877314130245665)\n",
      "     | > log_mle: -0.31597673892974854  (-0.30719566476937815)\n",
      "     | > loss_dur: 0.21047528088092804  (0.17842252346692164)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(32.2653, device='cuda:0')  (tensor(30.0872, device='cuda:0'))\n",
      "     | > current_lr: 1.725e-05 \n",
      "     | > step_time: 1.0108  (0.6211902436630502)\n",
      "     | > loader_time: 0.0063  (0.011784182069051324)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:57:57 -- STEP: 206/406 -- GLOBAL_STEP: 50950\u001b[0m\n",
      "     | > loss: -0.12336309254169464  (-0.12871549654643524)\n",
      "     | > log_mle: -0.3142050504684448  (-0.3086158002464518)\n",
      "     | > loss_dur: 0.19084195792675018  (0.17990030370001653)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(49.8778, device='cuda:0')  (tensor(30.7942, device='cuda:0'))\n",
      "     | > current_lr: 1.725e-05 \n",
      "     | > step_time: 0.5316  (0.632769929552541)\n",
      "     | > loader_time: 0.0074  (0.011670620696058545)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:58:16 -- STEP: 231/406 -- GLOBAL_STEP: 50975\u001b[0m\n",
      "     | > loss: -0.13044244050979614  (-0.12903135576289476)\n",
      "     | > log_mle: -0.3326171636581421  (-0.31014987813445927)\n",
      "     | > loss_dur: 0.20217472314834595  (0.1811185223715646)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(36.9388, device='cuda:0')  (tensor(30.6750, device='cuda:0'))\n",
      "     | > current_lr: 1.725e-05 \n",
      "     | > step_time: 0.9076  (0.6419499085579081)\n",
      "     | > loader_time: 0.0146  (0.011814870875635182)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:58:35 -- STEP: 256/406 -- GLOBAL_STEP: 51000\u001b[0m\n",
      "     | > loss: -0.12736065685749054  (-0.12904387904563944)\n",
      "     | > log_mle: -0.322074294090271  (-0.311106505803764)\n",
      "     | > loss_dur: 0.19471363723278046  (0.18206262675812468)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(31.9336, device='cuda:0')  (tensor(32.2049, device='cuda:0'))\n",
      "     | > current_lr: 1.725e-05 \n",
      "     | > step_time: 0.6994  (0.6518217856064437)\n",
      "     | > loader_time: 0.0106  (0.011830803938210005)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:58:54 -- STEP: 281/406 -- GLOBAL_STEP: 51025\u001b[0m\n",
      "     | > loss: -0.14753273129463196  (-0.1291570993823091)\n",
      "     | > log_mle: -0.32922840118408203  (-0.31207046983929304)\n",
      "     | > loss_dur: 0.18169566988945007  (0.18291337045698403)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(23.0030, device='cuda:0')  (tensor(31.8236, device='cuda:0'))\n",
      "     | > current_lr: 1.725e-05 \n",
      "     | > step_time: 0.597  (0.6589015497431634)\n",
      "     | > loader_time: 0.0209  (0.012013248701536776)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:59:13 -- STEP: 306/406 -- GLOBAL_STEP: 51050\u001b[0m\n",
      "     | > loss: -0.10833193361759186  (-0.12922568000804394)\n",
      "     | > log_mle: -0.31500983238220215  (-0.3130134667446411)\n",
      "     | > loss_dur: 0.2066778987646103  (0.18378778673659735)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(39.2909, device='cuda:0')  (tensor(32.3846, device='cuda:0'))\n",
      "     | > current_lr: 1.725e-05 \n",
      "     | > step_time: 0.775  (0.667897328052645)\n",
      "     | > loader_time: 0.0087  (0.012075513796089515)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:59:34 -- STEP: 331/406 -- GLOBAL_STEP: 51075\u001b[0m\n",
      "     | > loss: -0.11966268718242645  (-0.12935201427547624)\n",
      "     | > log_mle: -0.3202497959136963  (-0.3137701148352955)\n",
      "     | > loss_dur: 0.20058710873126984  (0.18441810055981947)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(36.2114, device='cuda:0')  (tensor(32.9736, device='cuda:0'))\n",
      "     | > current_lr: 1.725e-05 \n",
      "     | > step_time: 0.8718  (0.6797717287461202)\n",
      "     | > loader_time: 0.0188  (0.012420808440608916)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 04:59:56 -- STEP: 356/406 -- GLOBAL_STEP: 51100\u001b[0m\n",
      "     | > loss: -0.12850500643253326  (-0.12930523424168677)\n",
      "     | > log_mle: -0.33329594135284424  (-0.3146774172782898)\n",
      "     | > loss_dur: 0.20479093492031097  (0.18537218303660333)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(61.6853, device='cuda:0')  (tensor(33.3445, device='cuda:0'))\n",
      "     | > current_lr: 1.725e-05 \n",
      "     | > step_time: 0.5148  (0.6899819923250861)\n",
      "     | > loader_time: 0.0199  (0.012558735488505841)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:00:17 -- STEP: 381/406 -- GLOBAL_STEP: 51125\u001b[0m\n",
      "     | > loss: -0.12054136395454407  (-0.12951287337801298)\n",
      "     | > log_mle: -0.3138328790664673  (-0.3154459331292181)\n",
      "     | > loss_dur: 0.19329151511192322  (0.18593305975120528)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(24.8580, device='cuda:0')  (tensor(33.5657, device='cuda:0'))\n",
      "     | > current_lr: 1.725e-05 \n",
      "     | > step_time: 0.6355  (0.7006666804236061)\n",
      "     | > loader_time: 0.0117  (0.012786748841052914)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: -0.12319853901863098  (-0.12319853901863098)\n",
      "     | > log_mle: -0.2999403476715088  (-0.2999403476715088)\n",
      "     | > loss_dur: 0.1767418086528778  (0.1767418086528778)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: -0.1787642538547516  (-0.1787642538547516)\n",
      "     | > log_mle: -0.34119439125061035  (-0.34119439125061035)\n",
      "     | > loss_dur: 0.16243013739585876  (0.16243013739585876)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: -0.16681711375713348  (-0.17279068380594254)\n",
      "     | > log_mle: -0.30488061904907227  (-0.3230375051498413)\n",
      "     | > loss_dur: 0.13806350529193878  (0.15024682134389877)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: -0.16747042536735535  (-0.17101726432641348)\n",
      "     | > log_mle: -0.3148975372314453  (-0.320324182510376)\n",
      "     | > loss_dur: 0.14742711186408997  (0.1493069181839625)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: -0.1778227984905243  (-0.17271864786744118)\n",
      "     | > log_mle: -0.3415682315826416  (-0.3256351947784424)\n",
      "     | > loss_dur: 0.1637454330921173  (0.1529165469110012)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: -0.1713973879814148  (-0.1724543958902359)\n",
      "     | > log_mle: -0.3422987461090088  (-0.32896790504455564)\n",
      "     | > loss_dur: 0.170901358127594  (0.15651350915431977)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: -0.11934101581573486  (-0.16360216587781906)\n",
      "     | > log_mle: -0.3484370708465576  (-0.33221276601155597)\n",
      "     | > loss_dur: 0.22909605503082275  (0.16861060013373694)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: -0.14950910210609436  (-0.16158887105328695)\n",
      "     | > log_mle: -0.31217479705810547  (-0.3293501990182059)\n",
      "     | > loss_dur: 0.1626656949520111  (0.16776132796491897)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: -0.16787728667259216  (-0.1623749230057001)\n",
      "     | > log_mle: -0.3250211477279663  (-0.32880906760692596)\n",
      "     | > loss_dur: 0.15714386105537415  (0.16643414460122585)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: -0.15477390587329865  (-0.1615303655465444)\n",
      "     | > log_mle: -0.33764564990997314  (-0.3297909100850423)\n",
      "     | > loss_dur: 0.1828717440366745  (0.16826054453849792)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: -0.12891080975532532  (-0.15826840996742247)\n",
      "     | > log_mle: -0.32268404960632324  (-0.3290802240371704)\n",
      "     | > loss_dur: 0.19377323985099792  (0.17081181406974794)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: -0.15346750617027283  (-0.1578319641676816)\n",
      "     | > log_mle: -0.3405536413192749  (-0.33012326197190717)\n",
      "     | > loss_dur: 0.18708613514900208  (0.17229129780422558)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: -0.16902722418308258  (-0.15876490250229836)\n",
      "     | > log_mle: -0.32556188106536865  (-0.3297431468963623)\n",
      "     | > loss_dur: 0.15653465688228607  (0.17097824439406395)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: -0.1857629120349884  (-0.16084167246635145)\n",
      "     | > log_mle: -0.34937310218811035  (-0.331253143457266)\n",
      "     | > loss_dur: 0.16361019015312195  (0.17041147099091455)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: -0.14797981083393097  (-0.1599229680640357)\n",
      "     | > log_mle: -0.3375304937362671  (-0.3317015256200518)\n",
      "     | > loss_dur: 0.18955068290233612  (0.1717785575560161)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: -0.1536189317703247  (-0.1595026989777883)\n",
      "     | > log_mle: -0.33089542388916016  (-0.331647785504659)\n",
      "     | > loss_dur: 0.17727649211883545  (0.17214508652687072)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: -0.1474669724702835  (-0.15875046607106924)\n",
      "     | > log_mle: -0.3342047929763794  (-0.33180759847164154)\n",
      "     | > loss_dur: 0.1867378205060959  (0.1730571324005723)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: audio amplitude out of range, auto clipped.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.0029001235961914062 \u001b[0m(-0.0009918659925460824)\n",
      "     | > avg_loss:\u001b[92m -0.15875046607106924 \u001b[0m(-0.003898065537214279)\n",
      "     | > avg_log_mle:\u001b[92m -0.33180759847164154 \u001b[0m(-0.002902105450630188)\n",
      "     | > avg_loss_dur:\u001b[92m 0.1730571324005723 \u001b[0m(-0.0009959600865840912)\n",
      "\n",
      " > BEST MODEL : train/run-February-22-2025_10+59PM-fa84af3/best_model_51150.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 70/100\u001b[0m\n",
      " --> train/run-February-22-2025_10+59PM-fa84af3\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-23 05:00:51) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:00:53 -- STEP: 0/406 -- GLOBAL_STEP: 51150\u001b[0m\n",
      "     | > loss: -0.15336504578590393  (-0.15336504578590393)\n",
      "     | > log_mle: -0.30114877223968506  (-0.30114877223968506)\n",
      "     | > loss_dur: 0.14778372645378113  (0.14778372645378113)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(12.0716, device='cuda:0')  (tensor(12.0716, device='cuda:0'))\n",
      "     | > current_lr: 1.7500000000000002e-05 \n",
      "     | > step_time: 1.1497  (1.1496505737304688)\n",
      "     | > loader_time: 0.893  (0.8929753303527832)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:01:06 -- STEP: 25/406 -- GLOBAL_STEP: 51175\u001b[0m\n",
      "     | > loss: -0.13102510571479797  (-0.13891919374465939)\n",
      "     | > log_mle: -0.30303049087524414  (-0.2981796169281005)\n",
      "     | > loss_dur: 0.17200538516044617  (0.15926042318344116)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(26.2468, device='cuda:0')  (tensor(23.1174, device='cuda:0'))\n",
      "     | > current_lr: 1.7500000000000002e-05 \n",
      "     | > step_time: 0.7722  (0.5290107822418213)\n",
      "     | > loader_time: 0.0047  (0.010066261291503906)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:01:21 -- STEP: 50/406 -- GLOBAL_STEP: 51200\u001b[0m\n",
      "     | > loss: -0.12590838968753815  (-0.1316290906071663)\n",
      "     | > log_mle: -0.32380056381225586  (-0.2969675612449645)\n",
      "     | > loss_dur: 0.1978921741247177  (0.16533847063779836)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(30.3414, device='cuda:0')  (tensor(23.8919, device='cuda:0'))\n",
      "     | > current_lr: 1.7500000000000002e-05 \n",
      "     | > step_time: 0.514  (0.5498555850982665)\n",
      "     | > loader_time: 0.014  (0.009530911445617676)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:01:37 -- STEP: 75/406 -- GLOBAL_STEP: 51225\u001b[0m\n",
      "     | > loss: -0.1348128765821457  (-0.1310607026020686)\n",
      "     | > log_mle: -0.31284332275390625  (-0.2999112304051716)\n",
      "     | > loss_dur: 0.17803044617176056  (0.16885052780310314)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(19.1688, device='cuda:0')  (tensor(25.8711, device='cuda:0'))\n",
      "     | > current_lr: 1.7500000000000002e-05 \n",
      "     | > step_time: 0.3748  (0.5805192279815673)\n",
      "     | > loader_time: 0.032  (0.009802570343017578)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:01:54 -- STEP: 100/406 -- GLOBAL_STEP: 51250\u001b[0m\n",
      "     | > loss: -0.12003231048583984  (-0.13038283765316006)\n",
      "     | > log_mle: -0.31305599212646484  (-0.3022998595237729)\n",
      "     | > loss_dur: 0.193023681640625  (0.17191702187061303)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(23.1615, device='cuda:0')  (tensor(27.3631, device='cuda:0'))\n",
      "     | > current_lr: 1.7500000000000002e-05 \n",
      "     | > step_time: 0.7824  (0.5966722893714903)\n",
      "     | > loader_time: 0.0128  (0.01009926080703735)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:02:11 -- STEP: 125/406 -- GLOBAL_STEP: 51275\u001b[0m\n",
      "     | > loss: -0.13113172352313995  (-0.1303126295804977)\n",
      "     | > log_mle: -0.3220623731613159  (-0.30465715503692603)\n",
      "     | > loss_dur: 0.19093064963817596  (0.17434452545642848)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(25.8979, device='cuda:0')  (tensor(28.5725, device='cuda:0'))\n",
      "     | > current_lr: 1.7500000000000002e-05 \n",
      "     | > step_time: 0.5384  (0.6097521896362302)\n",
      "     | > loader_time: 0.0408  (0.011187341690063475)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:02:29 -- STEP: 150/406 -- GLOBAL_STEP: 51300\u001b[0m\n",
      "     | > loss: -0.13466906547546387  (-0.12995425909757616)\n",
      "     | > log_mle: -0.31245362758636475  (-0.3065028524398801)\n",
      "     | > loss_dur: 0.17778456211090088  (0.17654859334230422)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(35.0866, device='cuda:0')  (tensor(29.4374, device='cuda:0'))\n",
      "     | > current_lr: 1.7500000000000002e-05 \n",
      "     | > step_time: 0.5365  (0.6216871070861815)\n",
      "     | > loader_time: 0.0159  (0.011433261235555011)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:02:46 -- STEP: 175/406 -- GLOBAL_STEP: 51325\u001b[0m\n",
      "     | > loss: -0.13632114231586456  (-0.12973657420703344)\n",
      "     | > log_mle: -0.321818470954895  (-0.307797596114022)\n",
      "     | > loss_dur: 0.18549732863903046  (0.17806102190698897)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(32.3951, device='cuda:0')  (tensor(29.9343, device='cuda:0'))\n",
      "     | > current_lr: 1.7500000000000002e-05 \n",
      "     | > step_time: 0.8864  (0.6282502855573382)\n",
      "     | > loader_time: 0.0063  (0.011882331030709398)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:03:04 -- STEP: 200/406 -- GLOBAL_STEP: 51350\u001b[0m\n",
      "     | > loss: -0.12644322216510773  (-0.12981153160333642)\n",
      "     | > log_mle: -0.3195232152938843  (-0.3092710781097409)\n",
      "     | > loss_dur: 0.19307999312877655  (0.1794595465064049)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(42.2340, device='cuda:0')  (tensor(31.0878, device='cuda:0'))\n",
      "     | > current_lr: 1.7500000000000002e-05 \n",
      "     | > step_time: 0.7539  (0.6391392123699189)\n",
      "     | > loader_time: 0.0135  (0.012421703338623042)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:03:24 -- STEP: 225/406 -- GLOBAL_STEP: 51375\u001b[0m\n",
      "     | > loss: -0.12768186628818512  (-0.1298980944024193)\n",
      "     | > log_mle: -0.32009994983673096  (-0.31056450366973853)\n",
      "     | > loss_dur: 0.19241808354854584  (0.18066640926731958)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(67.8807, device='cuda:0')  (tensor(31.8284, device='cuda:0'))\n",
      "     | > current_lr: 1.7500000000000002e-05 \n",
      "     | > step_time: 0.7847  (0.6509333027733697)\n",
      "     | > loader_time: 0.042  (0.013046777513292097)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:03:43 -- STEP: 250/406 -- GLOBAL_STEP: 51400\u001b[0m\n",
      "     | > loss: -0.13703690469264984  (-0.12981765031814585)\n",
      "     | > log_mle: -0.3301304578781128  (-0.31173468017578104)\n",
      "     | > loss_dur: 0.19309355318546295  (0.1819170298576355)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(43.4528, device='cuda:0')  (tensor(32.3606, device='cuda:0'))\n",
      "     | > current_lr: 1.7500000000000002e-05 \n",
      "     | > step_time: 0.5085  (0.6599818944931031)\n",
      "     | > loader_time: 0.0116  (0.012876322746276852)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:04:03 -- STEP: 275/406 -- GLOBAL_STEP: 51425\u001b[0m\n",
      "     | > loss: -0.12131078541278839  (-0.12997072945941587)\n",
      "     | > log_mle: -0.3187718391418457  (-0.3125976852937176)\n",
      "     | > loss_dur: 0.1974610537290573  (0.18262695583430202)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(23.5669, device='cuda:0')  (tensor(32.3952, device='cuda:0'))\n",
      "     | > current_lr: 1.7500000000000002e-05 \n",
      "     | > step_time: 0.7732  (0.6706129438226873)\n",
      "     | > loader_time: 0.0189  (0.013193600394509052)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:04:23 -- STEP: 300/406 -- GLOBAL_STEP: 51450\u001b[0m\n",
      "     | > loss: -0.12450183928012848  (-0.13006618663668648)\n",
      "     | > log_mle: -0.3094249963760376  (-0.3133865185578662)\n",
      "     | > loss_dur: 0.18492315709590912  (0.18332033192118005)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(40.4210, device='cuda:0')  (tensor(32.3541, device='cuda:0'))\n",
      "     | > current_lr: 1.7500000000000002e-05 \n",
      "     | > step_time: 0.8765  (0.6806053527196247)\n",
      "     | > loader_time: 0.0252  (0.013561315536499018)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:04:43 -- STEP: 325/406 -- GLOBAL_STEP: 51475\u001b[0m\n",
      "     | > loss: -0.13155680894851685  (-0.1301158707875473)\n",
      "     | > log_mle: -0.31288135051727295  (-0.31408425000997675)\n",
      "     | > loss_dur: 0.1813245415687561  (0.1839683792224297)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(49.5437, device='cuda:0')  (tensor(32.7224, device='cuda:0'))\n",
      "     | > current_lr: 1.7500000000000002e-05 \n",
      "     | > step_time: 0.8466  (0.6891073989868164)\n",
      "     | > loader_time: 0.0244  (0.013727056063138517)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:05:07 -- STEP: 350/406 -- GLOBAL_STEP: 51500\u001b[0m\n",
      "     | > loss: -0.140562504529953  (-0.1301447213973319)\n",
      "     | > log_mle: -0.32837724685668945  (-0.3148728517123631)\n",
      "     | > loss_dur: 0.18781474232673645  (0.18472813031503132)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(110.3522, device='cuda:0')  (tensor(33.1019, device='cuda:0'))\n",
      "     | > current_lr: 1.7500000000000002e-05 \n",
      "     | > step_time: 0.7404  (0.7050088221686228)\n",
      "     | > loader_time: 0.0218  (0.014105668067932123)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:05:31 -- STEP: 375/406 -- GLOBAL_STEP: 51525\u001b[0m\n",
      "     | > loss: -0.14582355320453644  (-0.13032241622606916)\n",
      "     | > log_mle: -0.33485937118530273  (-0.31571085739135746)\n",
      "     | > loss_dur: 0.1890358179807663  (0.1853884411652883)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(73.5404, device='cuda:0')  (tensor(33.8369, device='cuda:0'))\n",
      "     | > current_lr: 1.7500000000000002e-05 \n",
      "     | > step_time: 1.3284  (0.7216649691263834)\n",
      "     | > loader_time: 0.0251  (0.014381626764933264)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:05:51 -- STEP: 400/406 -- GLOBAL_STEP: 51550\u001b[0m\n",
      "     | > loss: -0.12231878936290741  (-0.13034675411880015)\n",
      "     | > log_mle: -0.3275332450866699  (-0.31638311356306076)\n",
      "     | > loss_dur: 0.2052144557237625  (0.18603635944426059)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(34.7902, device='cuda:0')  (tensor(34.4627, device='cuda:0'))\n",
      "     | > current_lr: 1.7500000000000002e-05 \n",
      "     | > step_time: 0.5826  (0.7249504232406616)\n",
      "     | > loader_time: 0.0102  (0.014500530362129206)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: -0.12042365968227386  (-0.12042365968227386)\n",
      "     | > log_mle: -0.30099475383758545  (-0.30099475383758545)\n",
      "     | > loss_dur: 0.18057109415531158  (0.18057109415531158)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: -0.18024271726608276  (-0.18024271726608276)\n",
      "     | > log_mle: -0.3431246280670166  (-0.3431246280670166)\n",
      "     | > loss_dur: 0.16288191080093384  (0.16288191080093384)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: -0.1657465398311615  (-0.17299462854862213)\n",
      "     | > log_mle: -0.30658531188964844  (-0.3248549699783325)\n",
      "     | > loss_dur: 0.14083877205848694  (0.1518603414297104)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: -0.17054365575313568  (-0.1721776376167933)\n",
      "     | > log_mle: -0.31629157066345215  (-0.32200050354003906)\n",
      "     | > loss_dur: 0.14574791491031647  (0.14982286592324576)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: -0.1808108687400818  (-0.17433594539761543)\n",
      "     | > log_mle: -0.3431605100631714  (-0.32729050517082214)\n",
      "     | > loss_dur: 0.1623496413230896  (0.1529545597732067)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: -0.179182231426239  (-0.17530520260334015)\n",
      "     | > log_mle: -0.344274640083313  (-0.3306873321533203)\n",
      "     | > loss_dur: 0.16509240865707397  (0.15538212954998015)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: -0.12506715953350067  (-0.16693219542503357)\n",
      "     | > log_mle: -0.3540560007095337  (-0.3345821102460225)\n",
      "     | > loss_dur: 0.22898884117603302  (0.16764991482098898)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: -0.1516178995370865  (-0.16474443886961257)\n",
      "     | > log_mle: -0.31371140480041504  (-0.33160058089665007)\n",
      "     | > loss_dur: 0.16209350526332855  (0.1668561420270375)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: -0.17165495455265045  (-0.1656082533299923)\n",
      "     | > log_mle: -0.3273659944534302  (-0.33107125759124756)\n",
      "     | > loss_dur: 0.15571103990077972  (0.16546300426125526)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: -0.1573769897222519  (-0.1646936684846878)\n",
      "     | > log_mle: -0.3400740623474121  (-0.3320715692308214)\n",
      "     | > loss_dur: 0.18269707262516022  (0.1673779007461336)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: -0.13170962035655975  (-0.161395263671875)\n",
      "     | > log_mle: -0.3252309560775757  (-0.3313875079154968)\n",
      "     | > loss_dur: 0.19352133572101593  (0.16999224424362183)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: -0.15753069519996643  (-0.16104393926533786)\n",
      "     | > log_mle: -0.34254562854766846  (-0.3324018825184215)\n",
      "     | > loss_dur: 0.18501493334770203  (0.17135794325308365)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: -0.16861537098884583  (-0.16167489190896353)\n",
      "     | > log_mle: -0.3273739814758301  (-0.33198289076487225)\n",
      "     | > loss_dur: 0.15875861048698425  (0.17030799885590872)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: -0.18710166215896606  (-0.16363079731280988)\n",
      "     | > log_mle: -0.3504312038421631  (-0.3334019917708177)\n",
      "     | > loss_dur: 0.16332954168319702  (0.1697711944580078)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: -0.15640996396541595  (-0.16311502350228174)\n",
      "     | > log_mle: -0.34025728702545166  (-0.33389165571757723)\n",
      "     | > loss_dur: 0.1838473230600357  (0.17077663221529552)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: -0.15812647342681885  (-0.16278245349725087)\n",
      "     | > log_mle: -0.33258140087127686  (-0.3338043053944906)\n",
      "     | > loss_dur: 0.174454927444458  (0.17102185189723967)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: -0.15076175332069397  (-0.16203115973621607)\n",
      "     | > log_mle: -0.3356729745864868  (-0.3339210972189903)\n",
      "     | > loss_dur: 0.18491122126579285  (0.17188993748277426)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: audio amplitude out of range, auto clipped.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[91m 0.005543708801269531 \u001b[0m(+0.002643585205078125)\n",
      "     | > avg_loss:\u001b[92m -0.16203115973621607 \u001b[0m(-0.0032806936651468277)\n",
      "     | > avg_log_mle:\u001b[92m -0.3339210972189903 \u001b[0m(-0.0021134987473487854)\n",
      "     | > avg_loss_dur:\u001b[92m 0.17188993748277426 \u001b[0m(-0.0011671949177980423)\n",
      "\n",
      " > BEST MODEL : train/run-February-22-2025_10+59PM-fa84af3/best_model_51556.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 71/100\u001b[0m\n",
      " --> train/run-February-22-2025_10+59PM-fa84af3\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-23 05:06:11) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:06:23 -- STEP: 19/406 -- GLOBAL_STEP: 51575\u001b[0m\n",
      "     | > loss: -0.13566072285175323  (-0.1491203331633618)\n",
      "     | > log_mle: -0.28561830520629883  (-0.3015897462242528)\n",
      "     | > loss_dur: 0.1499575823545456  (0.152469413060891)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(37.9091, device='cuda:0')  (tensor(24.7452, device='cuda:0'))\n",
      "     | > current_lr: 1.775e-05 \n",
      "     | > step_time: 0.7626  (0.4743221308055677)\n",
      "     | > loader_time: 0.0149  (0.006404349678441098)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:06:38 -- STEP: 44/406 -- GLOBAL_STEP: 51600\u001b[0m\n",
      "     | > loss: -0.10893699526786804  (-0.13971421461213715)\n",
      "     | > log_mle: -0.30295026302337646  (-0.2987927577712319)\n",
      "     | > loss_dur: 0.19401326775550842  (0.15907854315909462)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(32.0420, device='cuda:0')  (tensor(25.1171, device='cuda:0'))\n",
      "     | > current_lr: 1.775e-05 \n",
      "     | > step_time: 0.5606  (0.5338568849997087)\n",
      "     | > loader_time: 0.0072  (0.00862286307594993)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:06:55 -- STEP: 69/406 -- GLOBAL_STEP: 51625\u001b[0m\n",
      "     | > loss: -0.13034473359584808  (-0.1359591738901276)\n",
      "     | > log_mle: -0.3117995262145996  (-0.30118140966995904)\n",
      "     | > loss_dur: 0.18145479261875153  (0.1652222357798313)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(17.7456, device='cuda:0')  (tensor(26.7669, device='cuda:0'))\n",
      "     | > current_lr: 1.775e-05 \n",
      "     | > step_time: 0.9516  (0.5774247231690779)\n",
      "     | > loader_time: 0.0472  (0.010489536368328592)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:07:10 -- STEP: 94/406 -- GLOBAL_STEP: 51650\u001b[0m\n",
      "     | > loss: -0.13663887977600098  (-0.1352518086737774)\n",
      "     | > log_mle: -0.31331145763397217  (-0.3042655447696118)\n",
      "     | > loss_dur: 0.1766725778579712  (0.16901373609583425)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(16.6047, device='cuda:0')  (tensor(28.9028, device='cuda:0'))\n",
      "     | > current_lr: 1.775e-05 \n",
      "     | > step_time: 0.7109  (0.583916428241324)\n",
      "     | > loader_time: 0.0052  (0.011330211416203925)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:07:27 -- STEP: 119/406 -- GLOBAL_STEP: 51675\u001b[0m\n",
      "     | > loss: -0.13803015649318695  (-0.13460355120546677)\n",
      "     | > log_mle: -0.32586801052093506  (-0.30674086398437245)\n",
      "     | > loss_dur: 0.1878378540277481  (0.17213731277890562)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(47.5777, device='cuda:0')  (tensor(29.8094, device='cuda:0'))\n",
      "     | > current_lr: 1.775e-05 \n",
      "     | > step_time: 0.6562  (0.597305806745)\n",
      "     | > loader_time: 0.0526  (0.011907517409124295)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:07:44 -- STEP: 144/406 -- GLOBAL_STEP: 51700\u001b[0m\n",
      "     | > loss: -0.1260520964860916  (-0.13382731471210715)\n",
      "     | > log_mle: -0.3143507242202759  (-0.3085435993141598)\n",
      "     | > loss_dur: 0.18829862773418427  (0.1747162846020526)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(43.8403, device='cuda:0')  (tensor(30.0070, device='cuda:0'))\n",
      "     | > current_lr: 1.775e-05 \n",
      "     | > step_time: 0.6437  (0.6074415710237289)\n",
      "     | > loader_time: 0.0081  (0.012352264589733548)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:08:02 -- STEP: 169/406 -- GLOBAL_STEP: 51725\u001b[0m\n",
      "     | > loss: -0.13367754220962524  (-0.13286887567776895)\n",
      "     | > log_mle: -0.32263779640197754  (-0.3097651583203197)\n",
      "     | > loss_dur: 0.1889602541923523  (0.1768962826425507)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(20.3511, device='cuda:0')  (tensor(30.0379, device='cuda:0'))\n",
      "     | > current_lr: 1.775e-05 \n",
      "     | > step_time: 0.6875  (0.6214032215479561)\n",
      "     | > loader_time: 0.0082  (0.013496946300980608)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:08:20 -- STEP: 194/406 -- GLOBAL_STEP: 51750\u001b[0m\n",
      "     | > loss: -0.13193106651306152  (-0.13311038166284564)\n",
      "     | > log_mle: -0.32075977325439453  (-0.31120261150537065)\n",
      "     | > loss_dur: 0.188828706741333  (0.17809222984252518)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(37.2513, device='cuda:0')  (tensor(31.3704, device='cuda:0'))\n",
      "     | > current_lr: 1.775e-05 \n",
      "     | > step_time: 0.7499  (0.6331090570725113)\n",
      "     | > loader_time: 0.0102  (0.013110576216707524)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:08:39 -- STEP: 219/406 -- GLOBAL_STEP: 51775\u001b[0m\n",
      "     | > loss: -0.14683692157268524  (-0.13321798801694287)\n",
      "     | > log_mle: -0.3234708309173584  (-0.3125375384065113)\n",
      "     | > loss_dur: 0.17663390934467316  (0.17931955038956857)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(36.0311, device='cuda:0')  (tensor(32.6367, device='cuda:0'))\n",
      "     | > current_lr: 1.775e-05 \n",
      "     | > step_time: 0.4913  (0.6439069612929808)\n",
      "     | > loader_time: 0.0091  (0.013461061808616604)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:08:59 -- STEP: 244/406 -- GLOBAL_STEP: 51800\u001b[0m\n",
      "     | > loss: -0.1460159420967102  (-0.1335052190134761)\n",
      "     | > log_mle: -0.3291289806365967  (-0.31409855406792425)\n",
      "     | > loss_dur: 0.18311303853988647  (0.18059333505444838)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(31.7049, device='cuda:0')  (tensor(33.4375, device='cuda:0'))\n",
      "     | > current_lr: 1.775e-05 \n",
      "     | > step_time: 0.7518  (0.6561895354849391)\n",
      "     | > loader_time: 0.0058  (0.01347123990293409)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:09:19 -- STEP: 269/406 -- GLOBAL_STEP: 51825\u001b[0m\n",
      "     | > loss: -0.14388065040111542  (-0.13391194406716808)\n",
      "     | > log_mle: -0.3256031274795532  (-0.3151835052497324)\n",
      "     | > loss_dur: 0.1817224770784378  (0.18127156118256452)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(34.3196, device='cuda:0')  (tensor(33.7391, device='cuda:0'))\n",
      "     | > current_lr: 1.775e-05 \n",
      "     | > step_time: 1.0925  (0.6680675244242726)\n",
      "     | > loader_time: 0.0214  (0.013879369182657574)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:09:38 -- STEP: 294/406 -- GLOBAL_STEP: 51850\u001b[0m\n",
      "     | > loss: -0.13318981230258942  (-0.13408992910871714)\n",
      "     | > log_mle: -0.3308131694793701  (-0.31618928301091087)\n",
      "     | > loss_dur: 0.1976233571767807  (0.18209935390219392)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(32.2677, device='cuda:0')  (tensor(33.6844, device='cuda:0'))\n",
      "     | > current_lr: 1.775e-05 \n",
      "     | > step_time: 0.581  (0.6742892954625238)\n",
      "     | > loader_time: 0.0112  (0.013922620792778164)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:10:00 -- STEP: 319/406 -- GLOBAL_STEP: 51875\u001b[0m\n",
      "     | > loss: -0.12514960765838623  (-0.13398615917815698)\n",
      "     | > log_mle: -0.324426531791687  (-0.31687338225146466)\n",
      "     | > loss_dur: 0.19927692413330078  (0.18288722307330757)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(27.9740, device='cuda:0')  (tensor(33.4387, device='cuda:0'))\n",
      "     | > current_lr: 1.775e-05 \n",
      "     | > step_time: 1.1719  (0.6876483920225901)\n",
      "     | > loader_time: 0.0105  (0.013887884474847005)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:10:20 -- STEP: 344/406 -- GLOBAL_STEP: 51900\u001b[0m\n",
      "     | > loss: -0.1316089928150177  (-0.13379661219064595)\n",
      "     | > log_mle: -0.3174099922180176  (-0.31748880030110843)\n",
      "     | > loss_dur: 0.18580099940299988  (0.18369218811046242)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(16.4490, device='cuda:0')  (tensor(33.6151, device='cuda:0'))\n",
      "     | > current_lr: 1.775e-05 \n",
      "     | > step_time: 0.5819  (0.6961962372757667)\n",
      "     | > loader_time: 0.0221  (0.013829737208610353)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:10:41 -- STEP: 369/406 -- GLOBAL_STEP: 51925\u001b[0m\n",
      "     | > loss: -0.13145586848258972  (-0.13398293322987043)\n",
      "     | > log_mle: -0.32558000087738037  (-0.3183362151226056)\n",
      "     | > loss_dur: 0.19412413239479065  (0.18435328189273514)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(40.8622, device='cuda:0')  (tensor(34.1037, device='cuda:0'))\n",
      "     | > current_lr: 1.775e-05 \n",
      "     | > step_time: 0.8922  (0.702847200357494)\n",
      "     | > loader_time: 0.0255  (0.01393554074977471)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:11:02 -- STEP: 394/406 -- GLOBAL_STEP: 51950\u001b[0m\n",
      "     | > loss: -0.13298435509204865  (-0.13417553803339838)\n",
      "     | > log_mle: -0.3298393487930298  (-0.31910168337943007)\n",
      "     | > loss_dur: 0.19685499370098114  (0.18492614534603158)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(47.7952, device='cuda:0')  (tensor(34.3834, device='cuda:0'))\n",
      "     | > current_lr: 1.775e-05 \n",
      "     | > step_time: 0.5633  (0.7108782330140244)\n",
      "     | > loader_time: 0.0078  (0.01404868769766715)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: -0.12361666560173035  (-0.12361666560173035)\n",
      "     | > log_mle: -0.3020298480987549  (-0.3020298480987549)\n",
      "     | > loss_dur: 0.17841318249702454  (0.17841318249702454)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: -0.17948006093502045  (-0.17948006093502045)\n",
      "     | > log_mle: -0.34309566020965576  (-0.34309566020965576)\n",
      "     | > loss_dur: 0.16361559927463531  (0.16361559927463531)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: -0.17130491137504578  (-0.1753924861550331)\n",
      "     | > log_mle: -0.30766761302948  (-0.32538163661956787)\n",
      "     | > loss_dur: 0.1363627016544342  (0.14998915046453476)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: -0.17278386652469635  (-0.17452294627825418)\n",
      "     | > log_mle: -0.3163611888885498  (-0.3223748207092285)\n",
      "     | > loss_dur: 0.14357732236385345  (0.14785187443097433)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: -0.1801902800798416  (-0.17593977972865105)\n",
      "     | > log_mle: -0.3424406051635742  (-0.32739126682281494)\n",
      "     | > loss_dur: 0.1622503250837326  (0.1514514870941639)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: -0.1746843457221985  (-0.17568869292736053)\n",
      "     | > log_mle: -0.34126460552215576  (-0.3301659345626831)\n",
      "     | > loss_dur: 0.16658025979995728  (0.15447724163532256)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: -0.12097278237342834  (-0.16656937450170517)\n",
      "     | > log_mle: -0.3491840362548828  (-0.33333561817804974)\n",
      "     | > loss_dur: 0.22821125388145447  (0.16676624367634454)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: -0.1525542289018631  (-0.16456721084458487)\n",
      "     | > log_mle: -0.31288909912109375  (-0.3304146868841989)\n",
      "     | > loss_dur: 0.16033487021923065  (0.165847476039614)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: -0.16622444987297058  (-0.1647743657231331)\n",
      "     | > log_mle: -0.3264327049255371  (-0.32991693913936615)\n",
      "     | > loss_dur: 0.16020825505256653  (0.16514257341623306)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: -0.15578536689281464  (-0.16377558807531992)\n",
      "     | > log_mle: -0.3375682830810547  (-0.33076708846622044)\n",
      "     | > loss_dur: 0.18178291618824005  (0.1669915003909005)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: -0.13127250969409943  (-0.16052528023719786)\n",
      "     | > log_mle: -0.3239802122116089  (-0.3300884008407593)\n",
      "     | > loss_dur: 0.19270770251750946  (0.1695631206035614)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: -0.1563561111688614  (-0.1601462648673491)\n",
      "     | > log_mle: -0.3412266969680786  (-0.33110097321597015)\n",
      "     | > loss_dur: 0.18487058579921722  (0.17095470834862103)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: -0.16618193686008453  (-0.16064923753341037)\n",
      "     | > log_mle: -0.32678210735321045  (-0.33074106772740686)\n",
      "     | > loss_dur: 0.16060017049312592  (0.17009183019399643)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: -0.18982619047164917  (-0.16289361852865952)\n",
      "     | > log_mle: -0.3486565351486206  (-0.33211918060596174)\n",
      "     | > loss_dur: 0.15883034467697144  (0.1692255620773022)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: -0.14865368604660034  (-0.16187648049422673)\n",
      "     | > log_mle: -0.3380866050720215  (-0.33254542521068026)\n",
      "     | > loss_dur: 0.18943291902542114  (0.17066894471645355)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: -0.1545550376176834  (-0.16138838430245717)\n",
      "     | > log_mle: -0.3316495418548584  (-0.3324856996536255)\n",
      "     | > loss_dur: 0.177094504237175  (0.17109731535116832)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: -0.15557684004306793  (-0.16102516278624535)\n",
      "     | > log_mle: -0.3340492248535156  (-0.3325834199786186)\n",
      "     | > loss_dur: 0.1784723848104477  (0.17155825719237328)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: audio amplitude out of range, auto clipped.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.003611251711845398 \u001b[0m(-0.0019324570894241333)\n",
      "     | > avg_loss:\u001b[91m -0.16102516278624535 \u001b[0m(+0.0010059969499707222)\n",
      "     | > avg_log_mle:\u001b[91m -0.3325834199786186 \u001b[0m(+0.001337677240371704)\n",
      "     | > avg_loss_dur:\u001b[92m 0.17155825719237328 \u001b[0m(-0.0003316802904009819)\n",
      "\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 72/100\u001b[0m\n",
      " --> train/run-February-22-2025_10+59PM-fa84af3\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-23 05:11:25) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:11:33 -- STEP: 13/406 -- GLOBAL_STEP: 51975\u001b[0m\n",
      "     | > loss: -0.12792937457561493  (-0.15318731619761541)\n",
      "     | > log_mle: -0.3030017614364624  (-0.303181529045105)\n",
      "     | > loss_dur: 0.17507238686084747  (0.14999421284748957)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(50.1143, device='cuda:0')  (tensor(31.3990, device='cuda:0'))\n",
      "     | > current_lr: 1.8e-05 \n",
      "     | > step_time: 0.4989  (0.3791739023648776)\n",
      "     | > loader_time: 0.0043  (0.0066986083984375)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:11:47 -- STEP: 38/406 -- GLOBAL_STEP: 52000\u001b[0m\n",
      "     | > loss: -0.13010472059249878  (-0.142399032649241)\n",
      "     | > log_mle: -0.3069056272506714  (-0.3007695549412778)\n",
      "     | > loss_dur: 0.1768009066581726  (0.1583705222920367)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(20.9969, device='cuda:0')  (tensor(24.6190, device='cuda:0'))\n",
      "     | > current_lr: 1.8e-05 \n",
      "     | > step_time: 0.4661  (0.5044131404475162)\n",
      "     | > loader_time: 0.0046  (0.007553677809865851)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:12:03 -- STEP: 63/406 -- GLOBAL_STEP: 52025\u001b[0m\n",
      "     | > loss: -0.12907715141773224  (-0.1367304483576427)\n",
      "     | > log_mle: -0.30165326595306396  (-0.30092788121056935)\n",
      "     | > loss_dur: 0.17257611453533173  (0.16419743285292665)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(28.8912, device='cuda:0')  (tensor(26.0759, device='cuda:0'))\n",
      "     | > current_lr: 1.8e-05 \n",
      "     | > step_time: 0.8062  (0.5483418911222427)\n",
      "     | > loader_time: 0.0068  (0.008917316557869077)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:12:20 -- STEP: 88/406 -- GLOBAL_STEP: 52050\u001b[0m\n",
      "     | > loss: -0.12519267201423645  (-0.13647020134058868)\n",
      "     | > log_mle: -0.2978307008743286  (-0.30374956537376774)\n",
      "     | > loss_dur: 0.17263802886009216  (0.16727936403317878)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(18.3924, device='cuda:0')  (tensor(26.4507, device='cuda:0'))\n",
      "     | > current_lr: 1.8e-05 \n",
      "     | > step_time: 0.8376  (0.5816775343634867)\n",
      "     | > loader_time: 0.0077  (0.009215539151971987)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:12:37 -- STEP: 113/406 -- GLOBAL_STEP: 52075\u001b[0m\n",
      "     | > loss: -0.13611674308776855  (-0.13605153534264694)\n",
      "     | > log_mle: -0.31197142601013184  (-0.3066376827459422)\n",
      "     | > loss_dur: 0.17585468292236328  (0.170586147403295)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(41.7709, device='cuda:0')  (tensor(27.9871, device='cuda:0'))\n",
      "     | > current_lr: 1.8e-05 \n",
      "     | > step_time: 0.5165  (0.5981070636647992)\n",
      "     | > loader_time: 0.0066  (0.009535135421077758)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:12:54 -- STEP: 138/406 -- GLOBAL_STEP: 52100\u001b[0m\n",
      "     | > loss: -0.10357806086540222  (-0.13525531257408252)\n",
      "     | > log_mle: -0.31584930419921875  (-0.30886243996412877)\n",
      "     | > loss_dur: 0.21227124333381653  (0.173607127390046)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(54.8002, device='cuda:0')  (tensor(28.6829, device='cuda:0'))\n",
      "     | > current_lr: 1.8e-05 \n",
      "     | > step_time: 0.542  (0.610100986301035)\n",
      "     | > loader_time: 0.0366  (0.009985336358996401)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:13:11 -- STEP: 163/406 -- GLOBAL_STEP: 52125\u001b[0m\n",
      "     | > loss: -0.13116693496704102  (-0.13429004858973564)\n",
      "     | > log_mle: -0.3295184373855591  (-0.31000998927040346)\n",
      "     | > loss_dur: 0.19835150241851807  (0.17571994068066762)\n",
      "     | > amp_scaler: 4096.0  (2186.208588957054)\n",
      "     | > grad_norm: tensor(55.3856, device='cuda:0')  (tensor(29.5805, device='cuda:0'))\n",
      "     | > current_lr: 1.8e-05 \n",
      "     | > step_time: 0.813  (0.6197402462637495)\n",
      "     | > loader_time: 0.0045  (0.010660603002536514)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:13:29 -- STEP: 188/406 -- GLOBAL_STEP: 52150\u001b[0m\n",
      "     | > loss: -0.12578390538692474  (-0.1342281990070293)\n",
      "     | > log_mle: -0.32543110847473145  (-0.3111746330210505)\n",
      "     | > loss_dur: 0.1996472030878067  (0.17694643401402108)\n",
      "     | > amp_scaler: 4096.0  (2440.170212765956)\n",
      "     | > grad_norm: tensor(51.7779, device='cuda:0')  (tensor(30.0396, device='cuda:0'))\n",
      "     | > current_lr: 1.8e-05 \n",
      "     | > step_time: 0.5959  (0.6298898116071171)\n",
      "     | > loader_time: 0.0094  (0.010862623123412437)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:13:47 -- STEP: 213/406 -- GLOBAL_STEP: 52175\u001b[0m\n",
      "     | > loss: -0.1409434974193573  (-0.13383594868888324)\n",
      "     | > log_mle: -0.32972633838653564  (-0.3122461312253711)\n",
      "     | > loss_dur: 0.18878284096717834  (0.17841018253648785)\n",
      "     | > amp_scaler: 4096.0  (2634.5164319248815)\n",
      "     | > grad_norm: tensor(19.1354, device='cuda:0')  (tensor(30.2293, device='cuda:0'))\n",
      "     | > current_lr: 1.8e-05 \n",
      "     | > step_time: 0.6691  (0.6379236604126406)\n",
      "     | > loader_time: 0.0071  (0.011534205065086975)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:14:07 -- STEP: 238/406 -- GLOBAL_STEP: 52200\u001b[0m\n",
      "     | > loss: -0.14109891653060913  (-0.13393521621948534)\n",
      "     | > log_mle: -0.33631134033203125  (-0.3137069089072092)\n",
      "     | > loss_dur: 0.19521242380142212  (0.1797716926877238)\n",
      "     | > amp_scaler: 4096.0  (2788.0336134453773)\n",
      "     | > grad_norm: tensor(42.3575, device='cuda:0')  (tensor(31.4008, device='cuda:0'))\n",
      "     | > current_lr: 1.8e-05 \n",
      "     | > step_time: 0.8019  (0.651210763875176)\n",
      "     | > loader_time: 0.0235  (0.011835418829396992)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:14:26 -- STEP: 263/406 -- GLOBAL_STEP: 52225\u001b[0m\n",
      "     | > loss: -0.14792416989803314  (-0.1344049344611259)\n",
      "     | > log_mle: -0.3360856771469116  (-0.3149889295092101)\n",
      "     | > loss_dur: 0.18816150724887848  (0.1805839950480842)\n",
      "     | > amp_scaler: 4096.0  (2912.365019011406)\n",
      "     | > grad_norm: tensor(45.7579, device='cuda:0')  (tensor(32.0063, device='cuda:0'))\n",
      "     | > current_lr: 1.8e-05 \n",
      "     | > step_time: 0.8496  (0.6624247619860979)\n",
      "     | > loader_time: 0.0112  (0.012130385569293236)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:14:46 -- STEP: 288/406 -- GLOBAL_STEP: 52250\u001b[0m\n",
      "     | > loss: -0.14345499873161316  (-0.13490576773054075)\n",
      "     | > log_mle: -0.32190823554992676  (-0.31613742063442873)\n",
      "     | > loss_dur: 0.1784532368183136  (0.18123165290388793)\n",
      "     | > amp_scaler: 4096.0  (3015.1111111111095)\n",
      "     | > grad_norm: tensor(32.8413, device='cuda:0')  (tensor(32.2972, device='cuda:0'))\n",
      "     | > current_lr: 1.8e-05 \n",
      "     | > step_time: 0.4595  (0.6711706883377501)\n",
      "     | > loader_time: 0.0118  (0.012456660469373068)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:15:07 -- STEP: 313/406 -- GLOBAL_STEP: 52275\u001b[0m\n",
      "     | > loss: -0.13818489015102386  (-0.13511382928861979)\n",
      "     | > log_mle: -0.3230125904083252  (-0.3170811516789204)\n",
      "     | > loss_dur: 0.18482770025730133  (0.18196732239030047)\n",
      "     | > amp_scaler: 4096.0  (3101.4440894568675)\n",
      "     | > grad_norm: tensor(24.7576, device='cuda:0')  (tensor(32.6886, device='cuda:0'))\n",
      "     | > current_lr: 1.8e-05 \n",
      "     | > step_time: 0.8566  (0.6812359517374742)\n",
      "     | > loader_time: 0.0156  (0.012687486581528148)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:15:27 -- STEP: 338/406 -- GLOBAL_STEP: 52300\u001b[0m\n",
      "     | > loss: -0.13924171030521393  (-0.1351206302642822)\n",
      "     | > log_mle: -0.33064937591552734  (-0.3178881889969643)\n",
      "     | > loss_dur: 0.19140766561031342  (0.18276755873268177)\n",
      "     | > amp_scaler: 4096.0  (3175.0059171597627)\n",
      "     | > grad_norm: tensor(36.2382, device='cuda:0')  (tensor(32.8957, device='cuda:0'))\n",
      "     | > current_lr: 1.8e-05 \n",
      "     | > step_time: 0.7819  (0.6909834654373536)\n",
      "     | > loader_time: 0.0114  (0.01288992342864268)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:15:48 -- STEP: 363/406 -- GLOBAL_STEP: 52325\u001b[0m\n",
      "     | > loss: -0.1448225975036621  (-0.1352034211979753)\n",
      "     | > log_mle: -0.3341425657272339  (-0.3186657763709711)\n",
      "     | > loss_dur: 0.18931996822357178  (0.18346235517299536)\n",
      "     | > amp_scaler: 2048.0  (3187.658402203856)\n",
      "     | > grad_norm: tensor(27.4888, device='cuda:0')  (tensor(33.3854, device='cuda:0'))\n",
      "     | > current_lr: 1.8e-05 \n",
      "     | > step_time: 0.8328  (0.6998059565699138)\n",
      "     | > loader_time: 0.0184  (0.013314949907875587)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:16:10 -- STEP: 388/406 -- GLOBAL_STEP: 52350\u001b[0m\n",
      "     | > loss: -0.1335688829421997  (-0.13507968552180163)\n",
      "     | > log_mle: -0.33310234546661377  (-0.31925792915304946)\n",
      "     | > loss_dur: 0.19953346252441406  (0.18417824363124738)\n",
      "     | > amp_scaler: 2048.0  (3114.2268041237107)\n",
      "     | > grad_norm: tensor(33.6209, device='cuda:0')  (tensor(33.4805, device='cuda:0'))\n",
      "     | > current_lr: 1.8e-05 \n",
      "     | > step_time: 0.9129  (0.708123230442559)\n",
      "     | > loader_time: 0.019  (0.013363906403177792)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: -0.11882378160953522  (-0.11882378160953522)\n",
      "     | > log_mle: -0.300584077835083  (-0.300584077835083)\n",
      "     | > loss_dur: 0.1817602962255478  (0.1817602962255478)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: -0.17550049722194672  (-0.17550049722194672)\n",
      "     | > log_mle: -0.3399006128311157  (-0.3399006128311157)\n",
      "     | > loss_dur: 0.164400115609169  (0.164400115609169)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: -0.1720341145992279  (-0.1737673059105873)\n",
      "     | > log_mle: -0.30532264709472656  (-0.32261162996292114)\n",
      "     | > loss_dur: 0.13328853249549866  (0.14884432405233383)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: -0.16541454195976257  (-0.1709830512603124)\n",
      "     | > log_mle: -0.31118619441986084  (-0.3188031514485677)\n",
      "     | > loss_dur: 0.14577165246009827  (0.1478201001882553)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: -0.177169531583786  (-0.1725296713411808)\n",
      "     | > log_mle: -0.3367033004760742  (-0.32327818870544434)\n",
      "     | > loss_dur: 0.1595337688922882  (0.15074851736426353)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: -0.16095571219921112  (-0.17021487951278685)\n",
      "     | > log_mle: -0.33549249172210693  (-0.3257210493087769)\n",
      "     | > loss_dur: 0.1745367795228958  (0.15550616979599)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: -0.12066766619682312  (-0.1619570106267929)\n",
      "     | > log_mle: -0.342753529548645  (-0.32855979601542157)\n",
      "     | > loss_dur: 0.2220858633518219  (0.16660278538862863)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: -0.15835915505886078  (-0.16144303125994547)\n",
      "     | > log_mle: -0.3080095052719116  (-0.32562404019492014)\n",
      "     | > loss_dur: 0.14965035021305084  (0.16418100893497467)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: -0.16418209671974182  (-0.16178541444242)\n",
      "     | > log_mle: -0.32133615016937256  (-0.3250880539417267)\n",
      "     | > loss_dur: 0.15715405344963074  (0.16330263949930668)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: -0.15413396060466766  (-0.16093525290489197)\n",
      "     | > log_mle: -0.3324638605117798  (-0.3259075880050659)\n",
      "     | > loss_dur: 0.17832989990711212  (0.16497233510017395)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: -0.13267011940479279  (-0.15810873955488206)\n",
      "     | > log_mle: -0.3200652599334717  (-0.3253233551979065)\n",
      "     | > loss_dur: 0.1873951405286789  (0.16721461564302445)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: -0.14649762213230133  (-0.15705318342555652)\n",
      "     | > log_mle: -0.3353308439254761  (-0.32623312690041284)\n",
      "     | > loss_dur: 0.18883322179317474  (0.1691799434748563)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: -0.17290107905864716  (-0.15837384139498076)\n",
      "     | > log_mle: -0.3232405185699463  (-0.32598374287287396)\n",
      "     | > loss_dur: 0.15033943951129913  (0.1676099014778932)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: -0.18066489696502686  (-0.160088537977292)\n",
      "     | > log_mle: -0.3435858488082886  (-0.327337751021752)\n",
      "     | > loss_dur: 0.16292095184326172  (0.16724921304446)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: -0.15399761497974396  (-0.1596534720488957)\n",
      "     | > log_mle: -0.3342447280883789  (-0.32783110652651104)\n",
      "     | > loss_dur: 0.18024711310863495  (0.16817763447761536)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: -0.15527579188346863  (-0.15936162670453388)\n",
      "     | > log_mle: -0.3267132043838501  (-0.32775657971700034)\n",
      "     | > loss_dur: 0.17143741250038147  (0.16839495301246643)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: -0.1456712931394577  (-0.15850598085671663)\n",
      "     | > log_mle: -0.3293670415878296  (-0.32785723358392715)\n",
      "     | > loss_dur: 0.1836957484483719  (0.16935125272721052)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: audio amplitude out of range, auto clipped.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[91m 0.004387393593788147 \u001b[0m(+0.000776141881942749)\n",
      "     | > avg_loss:\u001b[91m -0.15850598085671663 \u001b[0m(+0.0025191819295287132)\n",
      "     | > avg_log_mle:\u001b[91m -0.32785723358392715 \u001b[0m(+0.004726186394691467)\n",
      "     | > avg_loss_dur:\u001b[92m 0.16935125272721052 \u001b[0m(-0.002207004465162754)\n",
      "\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 73/100\u001b[0m\n",
      " --> train/run-February-22-2025_10+59PM-fa84af3\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-23 05:16:35) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:16:40 -- STEP: 7/406 -- GLOBAL_STEP: 52375\u001b[0m\n",
      "     | > loss: -0.16361106932163239  (-0.1635994975055967)\n",
      "     | > log_mle: -0.29872190952301025  (-0.3040471758161272)\n",
      "     | > loss_dur: 0.13511084020137787  (0.14044767831053054)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(27.7337, device='cuda:0')  (tensor(31.1818, device='cuda:0'))\n",
      "     | > current_lr: 1.825e-05 \n",
      "     | > step_time: 0.3416  (0.40532915932791574)\n",
      "     | > loader_time: 0.0031  (0.009284734725952148)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:16:55 -- STEP: 32/406 -- GLOBAL_STEP: 52400\u001b[0m\n",
      "     | > loss: -0.13941466808319092  (-0.1482837963849306)\n",
      "     | > log_mle: -0.30443668365478516  (-0.3034178465604781)\n",
      "     | > loss_dur: 0.16502201557159424  (0.15513405017554763)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(17.3636, device='cuda:0')  (tensor(24.5661, device='cuda:0'))\n",
      "     | > current_lr: 1.825e-05 \n",
      "     | > step_time: 0.4978  (0.531430512666702)\n",
      "     | > loader_time: 0.0112  (0.010245926678180695)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:17:10 -- STEP: 57/406 -- GLOBAL_STEP: 52425\u001b[0m\n",
      "     | > loss: -0.12755374610424042  (-0.14105988699093203)\n",
      "     | > log_mle: -0.3005025386810303  (-0.3031251869703594)\n",
      "     | > loss_dur: 0.17294879257678986  (0.1620652999794274)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(15.5536, device='cuda:0')  (tensor(26.6851, device='cuda:0'))\n",
      "     | > current_lr: 1.825e-05 \n",
      "     | > step_time: 0.5809  (0.5639997532493193)\n",
      "     | > loader_time: 0.0342  (0.010945207194278116)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:17:26 -- STEP: 82/406 -- GLOBAL_STEP: 52450\u001b[0m\n",
      "     | > loss: -0.13781805336475372  (-0.13926098532066122)\n",
      "     | > log_mle: -0.31166374683380127  (-0.30509494862905356)\n",
      "     | > loss_dur: 0.17384569346904755  (0.16583396330839253)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(31.6310, device='cuda:0')  (tensor(26.6775, device='cuda:0'))\n",
      "     | > current_lr: 1.825e-05 \n",
      "     | > step_time: 0.3481  (0.57679940433037)\n",
      "     | > loader_time: 0.0144  (0.010850217284225836)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:17:42 -- STEP: 107/406 -- GLOBAL_STEP: 52475\u001b[0m\n",
      "     | > loss: -0.15135347843170166  (-0.13785935283821327)\n",
      "     | > log_mle: -0.32099974155426025  (-0.3070653041946554)\n",
      "     | > loss_dur: 0.1696462631225586  (0.16920595135644223)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(25.0384, device='cuda:0')  (tensor(29.3921, device='cuda:0'))\n",
      "     | > current_lr: 1.825e-05 \n",
      "     | > step_time: 0.7196  (0.5845541686655205)\n",
      "     | > loader_time: 0.0071  (0.01097540766279274)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:17:58 -- STEP: 132/406 -- GLOBAL_STEP: 52500\u001b[0m\n",
      "     | > loss: -0.1545892208814621  (-0.1376414218861046)\n",
      "     | > log_mle: -0.33766400814056396  (-0.3096312338655645)\n",
      "     | > loss_dur: 0.18307478725910187  (0.17198981197946006)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(21.4470, device='cuda:0')  (tensor(28.2106, device='cuda:0'))\n",
      "     | > current_lr: 1.825e-05 \n",
      "     | > step_time: 0.4546  (0.5939071268746345)\n",
      "     | > loader_time: 0.0068  (0.01131596529122555)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:18:15 -- STEP: 157/406 -- GLOBAL_STEP: 52525\u001b[0m\n",
      "     | > loss: -0.12537012994289398  (-0.1365485601364428)\n",
      "     | > log_mle: -0.30610501766204834  (-0.31113935428060546)\n",
      "     | > loss_dur: 0.18073488771915436  (0.1745907941441627)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(119.5596, device='cuda:0')  (tensor(31.4212, device='cuda:0'))\n",
      "     | > current_lr: 1.825e-05 \n",
      "     | > step_time: 0.6114  (0.6033069647041852)\n",
      "     | > loader_time: 0.0299  (0.011411522604097987)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:18:33 -- STEP: 182/406 -- GLOBAL_STEP: 52550\u001b[0m\n",
      "     | > loss: -0.1464834362268448  (-0.13679405727556784)\n",
      "     | > log_mle: -0.3222222328186035  (-0.312691514308636)\n",
      "     | > loss_dur: 0.17573879659175873  (0.17589745703306828)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(21.2315, device='cuda:0')  (tensor(32.1587, device='cuda:0'))\n",
      "     | > current_lr: 1.825e-05 \n",
      "     | > step_time: 0.8275  (0.6187689317451728)\n",
      "     | > loader_time: 0.0098  (0.011964097127809633)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:18:51 -- STEP: 207/406 -- GLOBAL_STEP: 52575\u001b[0m\n",
      "     | > loss: -0.12606212496757507  (-0.13650595349966055)\n",
      "     | > log_mle: -0.3182637691497803  (-0.3140212458688854)\n",
      "     | > loss_dur: 0.1922016441822052  (0.17751529236922517)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(16.3105, device='cuda:0')  (tensor(31.6575, device='cuda:0'))\n",
      "     | > current_lr: 1.825e-05 \n",
      "     | > step_time: 0.7887  (0.6295024738219628)\n",
      "     | > loader_time: 0.0245  (0.012129226168572618)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:19:10 -- STEP: 232/406 -- GLOBAL_STEP: 52600\u001b[0m\n",
      "     | > loss: -0.13231784105300903  (-0.13664545009619217)\n",
      "     | > log_mle: -0.3264429569244385  (-0.31546884158561955)\n",
      "     | > loss_dur: 0.19412511587142944  (0.17882339148942766)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(29.9542, device='cuda:0')  (tensor(31.1008, device='cuda:0'))\n",
      "     | > current_lr: 1.825e-05 \n",
      "     | > step_time: 0.6021  (0.6405257089384674)\n",
      "     | > loader_time: 0.0101  (0.012618424563572327)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:19:30 -- STEP: 257/406 -- GLOBAL_STEP: 52625\u001b[0m\n",
      "     | > loss: -0.14826805889606476  (-0.13703634430462297)\n",
      "     | > log_mle: -0.33220815658569336  (-0.3167429642918508)\n",
      "     | > loss_dur: 0.1839400976896286  (0.17970661998722803)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(11.6274, device='cuda:0')  (tensor(31.3465, device='cuda:0'))\n",
      "     | > current_lr: 1.825e-05 \n",
      "     | > step_time: 0.6586  (0.6520236011609032)\n",
      "     | > loader_time: 0.0084  (0.012890255404817457)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:19:49 -- STEP: 282/406 -- GLOBAL_STEP: 52650\u001b[0m\n",
      "     | > loss: -0.16077788174152374  (-0.1372253948703727)\n",
      "     | > log_mle: -0.3444397449493408  (-0.31776260695558906)\n",
      "     | > loss_dur: 0.18366186320781708  (0.18053721208521664)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(56.0437, device='cuda:0')  (tensor(33.0882, device='cuda:0'))\n",
      "     | > current_lr: 1.825e-05 \n",
      "     | > step_time: 0.8524  (0.6610623006279589)\n",
      "     | > loader_time: 0.0132  (0.013347635032437376)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:20:10 -- STEP: 307/406 -- GLOBAL_STEP: 52675\u001b[0m\n",
      "     | > loss: -0.14364580810070038  (-0.1373093196642905)\n",
      "     | > log_mle: -0.3258521556854248  (-0.31877357835490067)\n",
      "     | > loss_dur: 0.18220634758472443  (0.18146425869061042)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(33.4754, device='cuda:0')  (tensor(33.6030, device='cuda:0'))\n",
      "     | > current_lr: 1.825e-05 \n",
      "     | > step_time: 0.998  (0.6737681056466865)\n",
      "     | > loader_time: 0.0331  (0.013480281208547787)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:20:31 -- STEP: 332/406 -- GLOBAL_STEP: 52700\u001b[0m\n",
      "     | > loss: -0.13934363424777985  (-0.1375057156455806)\n",
      "     | > log_mle: -0.3203907012939453  (-0.31957977579300656)\n",
      "     | > loss_dur: 0.18104706704616547  (0.18207406014742625)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(43.8310, device='cuda:0')  (tensor(33.9552, device='cuda:0'))\n",
      "     | > current_lr: 1.825e-05 \n",
      "     | > step_time: 0.7097  (0.6838254332542422)\n",
      "     | > loader_time: 0.0086  (0.013735920549875285)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:20:52 -- STEP: 357/406 -- GLOBAL_STEP: 52725\u001b[0m\n",
      "     | > loss: -0.1302596777677536  (-0.13754678803498688)\n",
      "     | > log_mle: -0.32515549659729004  (-0.32050602676487766)\n",
      "     | > loss_dur: 0.19489581882953644  (0.18295923872989106)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(29.8205, device='cuda:0')  (tensor(34.0985, device='cuda:0'))\n",
      "     | > current_lr: 1.825e-05 \n",
      "     | > step_time: 0.7347  (0.6936729802470918)\n",
      "     | > loader_time: 0.0077  (0.013836984874821514)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:21:14 -- STEP: 382/406 -- GLOBAL_STEP: 52750\u001b[0m\n",
      "     | > loss: -0.13009758293628693  (-0.13775197638891146)\n",
      "     | > log_mle: -0.33366668224334717  (-0.3212888293865462)\n",
      "     | > loss_dur: 0.20356909930706024  (0.1835368529976351)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(29.2355, device='cuda:0')  (tensor(33.6744, device='cuda:0'))\n",
      "     | > current_lr: 1.825e-05 \n",
      "     | > step_time: 0.946  (0.7042004188317903)\n",
      "     | > loader_time: 0.0133  (0.014230163309586612)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: -0.12023065984249115  (-0.12023065984249115)\n",
      "     | > log_mle: -0.30455684661865234  (-0.30455684661865234)\n",
      "     | > loss_dur: 0.1843261867761612  (0.1843261867761612)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: -0.1798093467950821  (-0.1798093467950821)\n",
      "     | > log_mle: -0.34605538845062256  (-0.34605538845062256)\n",
      "     | > loss_dur: 0.16624604165554047  (0.16624604165554047)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: -0.17592519521713257  (-0.17786727100610733)\n",
      "     | > log_mle: -0.3096632957458496  (-0.3278593420982361)\n",
      "     | > loss_dur: 0.13373810052871704  (0.14999207109212875)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: -0.17420296370983124  (-0.17664583524068198)\n",
      "     | > log_mle: -0.318253755569458  (-0.32465747992197674)\n",
      "     | > loss_dur: 0.14405079185962677  (0.14801164468129477)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: -0.18591567873954773  (-0.1789632961153984)\n",
      "     | > log_mle: -0.34517204761505127  (-0.32978612184524536)\n",
      "     | > loss_dur: 0.15925636887550354  (0.15082282572984695)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: -0.16974380612373352  (-0.17711939811706542)\n",
      "     | > log_mle: -0.3436383008956909  (-0.3325565576553345)\n",
      "     | > loss_dur: 0.1738944947719574  (0.15543715953826903)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: -0.12214434146881104  (-0.1679568886756897)\n",
      "     | > log_mle: -0.3528738021850586  (-0.33594276507695514)\n",
      "     | > loss_dur: 0.23072946071624756  (0.16798587640126547)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: -0.1629447191953659  (-0.16724086446421488)\n",
      "     | > log_mle: -0.3151208162307739  (-0.3329682009560721)\n",
      "     | > loss_dur: 0.15217609703540802  (0.16572733649185725)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: -0.17426763474941254  (-0.16811921074986458)\n",
      "     | > log_mle: -0.3290679454803467  (-0.33248066902160645)\n",
      "     | > loss_dur: 0.15480031073093414  (0.16436145827174187)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: -0.149216428399086  (-0.16601890159977806)\n",
      "     | > log_mle: -0.3409792184829712  (-0.3334249522950914)\n",
      "     | > loss_dur: 0.1917627900838852  (0.16740605069531334)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: -0.13935725390911102  (-0.16335273683071136)\n",
      "     | > log_mle: -0.3272387981414795  (-0.3328063368797302)\n",
      "     | > loss_dur: 0.18788154423236847  (0.16945360004901885)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: -0.16222622990608215  (-0.16325032711029053)\n",
      "     | > log_mle: -0.3437548875808716  (-0.3338016596707431)\n",
      "     | > loss_dur: 0.18152865767478943  (0.17055133256045255)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: -0.17499569058418274  (-0.16422910739978155)\n",
      "     | > log_mle: -0.3293581008911133  (-0.3334313631057739)\n",
      "     | > loss_dur: 0.15436241030693054  (0.16920225570599237)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: -0.18353581428527832  (-0.16571423869866592)\n",
      "     | > log_mle: -0.35103607177734375  (-0.33478557146512544)\n",
      "     | > loss_dur: 0.16750025749206543  (0.16907133276645953)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: -0.15887343883514404  (-0.16522561013698578)\n",
      "     | > log_mle: -0.34128475189208984  (-0.33524979863848003)\n",
      "     | > loss_dur: 0.1824113130569458  (0.17002418850149428)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: -0.15619124472141266  (-0.1646233191092809)\n",
      "     | > log_mle: -0.3340270519256592  (-0.3351682821909587)\n",
      "     | > loss_dur: 0.17783580720424652  (0.17054496308167774)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: -0.15627767145633698  (-0.1641017161309719)\n",
      "     | > log_mle: -0.33706343173980713  (-0.3352867290377617)\n",
      "     | > loss_dur: 0.18078576028347015  (0.17118501290678978)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: audio amplitude out of range, auto clipped.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[91m 0.004943251609802246 \u001b[0m(+0.0005558580160140991)\n",
      "     | > avg_loss:\u001b[92m -0.1641017161309719 \u001b[0m(-0.005595735274255276)\n",
      "     | > avg_log_mle:\u001b[92m -0.3352867290377617 \u001b[0m(-0.007429495453834534)\n",
      "     | > avg_loss_dur:\u001b[91m 0.17118501290678978 \u001b[0m(+0.001833760179579258)\n",
      "\n",
      " > BEST MODEL : train/run-February-22-2025_10+59PM-fa84af3/best_model_52774.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 74/100\u001b[0m\n",
      " --> train/run-February-22-2025_10+59PM-fa84af3\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-23 05:21:49) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:21:52 -- STEP: 1/406 -- GLOBAL_STEP: 52775\u001b[0m\n",
      "     | > loss: -0.16468513011932373  (-0.16468513011932373)\n",
      "     | > log_mle: -0.3067495822906494  (-0.3067495822906494)\n",
      "     | > loss_dur: 0.14206445217132568  (0.14206445217132568)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(16.7525, device='cuda:0')  (tensor(16.7525, device='cuda:0'))\n",
      "     | > current_lr: 1.8500000000000002e-05 \n",
      "     | > step_time: 0.4681  (0.4681396484375)\n",
      "     | > loader_time: 0.0049  (0.004893302917480469)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:22:06 -- STEP: 26/406 -- GLOBAL_STEP: 52800\u001b[0m\n",
      "     | > loss: -0.15155592560768127  (-0.15162062186461225)\n",
      "     | > log_mle: -0.30648088455200195  (-0.30524075948275053)\n",
      "     | > loss_dur: 0.15492495894432068  (0.15362013761813825)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(51.6887, device='cuda:0')  (tensor(33.0899, device='cuda:0'))\n",
      "     | > current_lr: 1.8500000000000002e-05 \n",
      "     | > step_time: 0.9019  (0.545680201970614)\n",
      "     | > loader_time: 0.0099  (0.009324027941777155)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:22:23 -- STEP: 51/406 -- GLOBAL_STEP: 52825\u001b[0m\n",
      "     | > loss: -0.14875176548957825  (-0.14413657141666786)\n",
      "     | > log_mle: -0.3198283910751343  (-0.3046146864984549)\n",
      "     | > loss_dur: 0.17107662558555603  (0.1604781150817871)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(30.4536, device='cuda:0')  (tensor(28.7359, device='cuda:0'))\n",
      "     | > current_lr: 1.8500000000000002e-05 \n",
      "     | > step_time: 0.7173  (0.5993433980380789)\n",
      "     | > loader_time: 0.0053  (0.010179781446269914)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:22:41 -- STEP: 76/406 -- GLOBAL_STEP: 52850\u001b[0m\n",
      "     | > loss: -0.13192878663539886  (-0.1429473338158507)\n",
      "     | > log_mle: -0.3087671995162964  (-0.3071732113235875)\n",
      "     | > loss_dur: 0.17683841288089752  (0.16422587750773684)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(21.5519, device='cuda:0')  (tensor(26.3608, device='cuda:0'))\n",
      "     | > current_lr: 1.8500000000000002e-05 \n",
      "     | > step_time: 0.8116  (0.6383459379798487)\n",
      "     | > loader_time: 0.0219  (0.01066333996622186)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:23:00 -- STEP: 101/406 -- GLOBAL_STEP: 52875\u001b[0m\n",
      "     | > loss: -0.12910446524620056  (-0.14107221084656102)\n",
      "     | > log_mle: -0.3143199682235718  (-0.3094629804686744)\n",
      "     | > loss_dur: 0.18521550297737122  (0.16839076962211352)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(49.4877, device='cuda:0')  (tensor(28.3863, device='cuda:0'))\n",
      "     | > current_lr: 1.8500000000000002e-05 \n",
      "     | > step_time: 0.8791  (0.6603754699820339)\n",
      "     | > loader_time: 0.0151  (0.012064086328638658)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:23:16 -- STEP: 126/406 -- GLOBAL_STEP: 52900\u001b[0m\n",
      "     | > loss: -0.13890855014324188  (-0.14100994418064752)\n",
      "     | > log_mle: -0.3184342384338379  (-0.31202801825508236)\n",
      "     | > loss_dur: 0.179525688290596  (0.17101807407443492)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(25.1185, device='cuda:0')  (tensor(30.4320, device='cuda:0'))\n",
      "     | > current_lr: 1.8500000000000002e-05 \n",
      "     | > step_time: 0.5634  (0.6525964907237461)\n",
      "     | > loader_time: 0.0075  (0.011944534286620121)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:23:33 -- STEP: 151/406 -- GLOBAL_STEP: 52925\u001b[0m\n",
      "     | > loss: -0.10713763535022736  (-0.14030453089057215)\n",
      "     | > log_mle: -0.312771201133728  (-0.3138784896459011)\n",
      "     | > loss_dur: 0.20563356578350067  (0.173573958755329)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(62.3565, device='cuda:0')  (tensor(31.2845, device='cuda:0'))\n",
      "     | > current_lr: 1.8500000000000002e-05 \n",
      "     | > step_time: 0.743  (0.6538300072120515)\n",
      "     | > loader_time: 0.021  (0.011914401654376102)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:23:51 -- STEP: 176/406 -- GLOBAL_STEP: 52950\u001b[0m\n",
      "     | > loss: -0.1354455202817917  (-0.1400918409397656)\n",
      "     | > log_mle: -0.32017064094543457  (-0.31517314301295724)\n",
      "     | > loss_dur: 0.18472512066364288  (0.1750813020731915)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(24.4435, device='cuda:0')  (tensor(30.8492, device='cuda:0'))\n",
      "     | > current_lr: 1.8500000000000002e-05 \n",
      "     | > step_time: 1.0861  (0.6595290411602367)\n",
      "     | > loader_time: 0.0055  (0.011751401153477758)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:24:09 -- STEP: 201/406 -- GLOBAL_STEP: 52975\u001b[0m\n",
      "     | > loss: -0.14378029108047485  (-0.14010877462465363)\n",
      "     | > log_mle: -0.3160243034362793  (-0.3164133598555382)\n",
      "     | > loss_dur: 0.17224401235580444  (0.17630458523088427)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(31.1078, device='cuda:0')  (tensor(32.0801, device='cuda:0'))\n",
      "     | > current_lr: 1.8500000000000002e-05 \n",
      "     | > step_time: 0.675  (0.6630928255432281)\n",
      "     | > loader_time: 0.0089  (0.011690766064088738)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:24:27 -- STEP: 226/406 -- GLOBAL_STEP: 53000\u001b[0m\n",
      "     | > loss: -0.14459364116191864  (-0.14013496872070605)\n",
      "     | > log_mle: -0.3351161479949951  (-0.317770544934062)\n",
      "     | > loss_dur: 0.19052250683307648  (0.1776355762133556)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(45.9307, device='cuda:0')  (tensor(32.7460, device='cuda:0'))\n",
      "     | > current_lr: 1.8500000000000002e-05 \n",
      "     | > step_time: 0.6432  (0.6697364475874774)\n",
      "     | > loader_time: 0.0105  (0.011333457136576157)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:24:46 -- STEP: 251/406 -- GLOBAL_STEP: 53025\u001b[0m\n",
      "     | > loss: -0.14991125464439392  (-0.1403908324669081)\n",
      "     | > log_mle: -0.33090734481811523  (-0.3191584676385402)\n",
      "     | > loss_dur: 0.1809960901737213  (0.17876763517163188)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(37.5099, device='cuda:0')  (tensor(33.2253, device='cuda:0'))\n",
      "     | > current_lr: 1.8500000000000002e-05 \n",
      "     | > step_time: 0.6368  (0.6765917696325903)\n",
      "     | > loader_time: 0.0204  (0.011716917691477743)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:25:06 -- STEP: 276/406 -- GLOBAL_STEP: 53050\u001b[0m\n",
      "     | > loss: -0.1306505650281906  (-0.14078877871667123)\n",
      "     | > log_mle: -0.3307567834854126  (-0.32025105193041387)\n",
      "     | > loss_dur: 0.20010621845722198  (0.17946227321374247)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(21.8401, device='cuda:0')  (tensor(33.3023, device='cuda:0'))\n",
      "     | > current_lr: 1.8500000000000002e-05 \n",
      "     | > step_time: 0.4849  (0.6862756722215292)\n",
      "     | > loader_time: 0.007  (0.01161386051039765)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:25:28 -- STEP: 301/406 -- GLOBAL_STEP: 53075\u001b[0m\n",
      "     | > loss: -0.1541416496038437  (-0.14089249524959294)\n",
      "     | > log_mle: -0.3466942310333252  (-0.3210816708118024)\n",
      "     | > loss_dur: 0.1925525814294815  (0.1801891755622091)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(46.5435, device='cuda:0')  (tensor(34.0714, device='cuda:0'))\n",
      "     | > current_lr: 1.8500000000000002e-05 \n",
      "     | > step_time: 0.6264  (0.7005104630492454)\n",
      "     | > loader_time: 0.0068  (0.011858030015051958)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:25:50 -- STEP: 326/406 -- GLOBAL_STEP: 53100\u001b[0m\n",
      "     | > loss: -0.14003899693489075  (-0.14091212188173646)\n",
      "     | > log_mle: -0.3214864730834961  (-0.3217696086760683)\n",
      "     | > loss_dur: 0.18144747614860535  (0.18085748679433125)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(51.7240, device='cuda:0')  (tensor(34.2151, device='cuda:0'))\n",
      "     | > current_lr: 1.8500000000000002e-05 \n",
      "     | > step_time: 1.1979  (0.7115486019228134)\n",
      "     | > loader_time: 0.0496  (0.012494970684402565)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:26:14 -- STEP: 351/406 -- GLOBAL_STEP: 53125\u001b[0m\n",
      "     | > loss: -0.1155649870634079  (-0.14081836676495701)\n",
      "     | > log_mle: -0.32226765155792236  (-0.3225885072664661)\n",
      "     | > loss_dur: 0.20670266449451447  (0.18177014050150864)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(73.6994, device='cuda:0')  (tensor(34.2882, device='cuda:0'))\n",
      "     | > current_lr: 1.8500000000000002e-05 \n",
      "     | > step_time: 1.2625  (0.7288177964354511)\n",
      "     | > loader_time: 0.0348  (0.012825645272888014)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:26:37 -- STEP: 376/406 -- GLOBAL_STEP: 53150\u001b[0m\n",
      "     | > loss: -0.1378094106912613  (-0.14109848621994886)\n",
      "     | > log_mle: -0.3351724147796631  (-0.32336064982921564)\n",
      "     | > loss_dur: 0.1973630040884018  (0.18226216360926625)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(35.8823, device='cuda:0')  (tensor(34.6074, device='cuda:0'))\n",
      "     | > current_lr: 1.8500000000000002e-05 \n",
      "     | > step_time: 0.8915  (0.7384316274460324)\n",
      "     | > loader_time: 0.0253  (0.012938008029410185)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:26:56 -- STEP: 401/406 -- GLOBAL_STEP: 53175\u001b[0m\n",
      "     | > loss: -0.1358262300491333  (-0.14119112331819644)\n",
      "     | > log_mle: -0.32757413387298584  (-0.324057745517341)\n",
      "     | > loss_dur: 0.19174790382385254  (0.18286662219914412)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(62.6641, device='cuda:0')  (tensor(34.6605, device='cuda:0'))\n",
      "     | > current_lr: 1.8500000000000002e-05 \n",
      "     | > step_time: 0.5927  (0.7386800951493945)\n",
      "     | > loader_time: 0.0091  (0.013007407771084379)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: -0.12418736517429352  (-0.12418736517429352)\n",
      "     | > log_mle: -0.3050975799560547  (-0.3050975799560547)\n",
      "     | > loss_dur: 0.18091021478176117  (0.18091021478176117)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: -0.1703847199678421  (-0.1703847199678421)\n",
      "     | > log_mle: -0.34599316120147705  (-0.34599316120147705)\n",
      "     | > loss_dur: 0.17560844123363495  (0.17560844123363495)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: -0.17703905701637268  (-0.1737118884921074)\n",
      "     | > log_mle: -0.3111034631729126  (-0.3285483121871948)\n",
      "     | > loss_dur: 0.13406440615653992  (0.15483642369508743)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: -0.17209556698799133  (-0.17317311465740204)\n",
      "     | > log_mle: -0.3176521062850952  (-0.3249162435531616)\n",
      "     | > loss_dur: 0.14555653929710388  (0.15174312889575958)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: -0.18210388720035553  (-0.1754058077931404)\n",
      "     | > log_mle: -0.34290850162506104  (-0.3294143080711365)\n",
      "     | > loss_dur: 0.1608046144247055  (0.15400850027799606)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: -0.17561914026737213  (-0.17544847428798677)\n",
      "     | > log_mle: -0.3420637845993042  (-0.33194420337677)\n",
      "     | > loss_dur: 0.16644464433193207  (0.15649572908878326)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: -0.11677809059619904  (-0.16567007700602213)\n",
      "     | > log_mle: -0.34917759895324707  (-0.33481643597284955)\n",
      "     | > loss_dur: 0.23239950835704803  (0.1691463589668274)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: -0.15852709114551544  (-0.16464965045452118)\n",
      "     | > log_mle: -0.3148984909057617  (-0.3319710152489798)\n",
      "     | > loss_dur: 0.15637139976024628  (0.16732136479445867)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: -0.17254742980003357  (-0.16563687287271023)\n",
      "     | > log_mle: -0.3284180164337158  (-0.33152689039707184)\n",
      "     | > loss_dur: 0.15587058663368225  (0.1658900175243616)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: -0.16112986207008362  (-0.1651360938946406)\n",
      "     | > log_mle: -0.33893871307373047  (-0.3323504262500339)\n",
      "     | > loss_dur: 0.17780885100364685  (0.1672143323553933)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: -0.1332443505525589  (-0.16194691956043245)\n",
      "     | > log_mle: -0.32533836364746094  (-0.3316492199897766)\n",
      "     | > loss_dur: 0.19209401309490204  (0.16970230042934417)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: -0.15315541625022888  (-0.16114769198677756)\n",
      "     | > log_mle: -0.3423351049423218  (-0.33262066407637164)\n",
      "     | > loss_dur: 0.1891796886920929  (0.17147297208959406)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: -0.17226102948188782  (-0.16207380344470343)\n",
      "     | > log_mle: -0.32878077030181885  (-0.33230067292849225)\n",
      "     | > loss_dur: 0.15651974081993103  (0.17022686948378882)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: -0.1927039474248886  (-0.16442996836625612)\n",
      "     | > log_mle: -0.3506201505661011  (-0.3337098635160006)\n",
      "     | > loss_dur: 0.15791620314121246  (0.16927989514974448)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: -0.15362124145030975  (-0.16365791644368852)\n",
      "     | > log_mle: -0.3397728204727173  (-0.3341429318700518)\n",
      "     | > loss_dur: 0.18615157902240753  (0.17048501542636327)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: -0.16331635415554047  (-0.16363514562447865)\n",
      "     | > log_mle: -0.3330906629562378  (-0.33407278060913087)\n",
      "     | > loss_dur: 0.16977430880069733  (0.1704376349846522)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: -0.15805327892303467  (-0.1632862789556384)\n",
      "     | > log_mle: -0.3359262943267822  (-0.33418862521648407)\n",
      "     | > loss_dur: 0.17787301540374756  (0.17090234626084566)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: audio amplitude out of range, auto clipped.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.004894331097602844 \u001b[0m(-4.8920512199401855e-05)\n",
      "     | > avg_loss:\u001b[91m -0.1632862789556384 \u001b[0m(+0.0008154371753334999)\n",
      "     | > avg_log_mle:\u001b[91m -0.33418862521648407 \u001b[0m(+0.0010981038212776184)\n",
      "     | > avg_loss_dur:\u001b[92m 0.17090234626084566 \u001b[0m(-0.0002826666459441185)\n",
      "\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 75/100\u001b[0m\n",
      " --> train/run-February-22-2025_10+59PM-fa84af3\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-23 05:27:13) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:27:24 -- STEP: 20/406 -- GLOBAL_STEP: 53200\u001b[0m\n",
      "     | > loss: -0.146598681807518  (-0.15489529371261596)\n",
      "     | > log_mle: -0.2902425527572632  (-0.30665205121040345)\n",
      "     | > loss_dur: 0.14364387094974518  (0.1517567578703165)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(12.9080, device='cuda:0')  (tensor(39.1838, device='cuda:0'))\n",
      "     | > current_lr: 1.875e-05 \n",
      "     | > step_time: 0.8156  (0.45069730281829834)\n",
      "     | > loader_time: 0.0063  (0.006329643726348877)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:27:39 -- STEP: 45/406 -- GLOBAL_STEP: 53225\u001b[0m\n",
      "     | > loss: -0.14511249959468842  (-0.14898375107182396)\n",
      "     | > log_mle: -0.3043506145477295  (-0.30625798437330454)\n",
      "     | > loss_dur: 0.15923811495304108  (0.15727423346704908)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(24.2051, device='cuda:0')  (tensor(32.6352, device='cuda:0'))\n",
      "     | > current_lr: 1.875e-05 \n",
      "     | > step_time: 0.6507  (0.5223527802361383)\n",
      "     | > loader_time: 0.0063  (0.007464652591281467)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:27:55 -- STEP: 70/406 -- GLOBAL_STEP: 53250\u001b[0m\n",
      "     | > loss: -0.170069620013237  (-0.14554922580718993)\n",
      "     | > log_mle: -0.315761923789978  (-0.3080174360956464)\n",
      "     | > loss_dur: 0.14569230377674103  (0.1624682103948934)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(41.0953, device='cuda:0')  (tensor(29.2379, device='cuda:0'))\n",
      "     | > current_lr: 1.875e-05 \n",
      "     | > step_time: 0.5803  (0.5572284596306937)\n",
      "     | > loader_time: 0.0182  (0.011068906102861677)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:28:11 -- STEP: 95/406 -- GLOBAL_STEP: 53275\u001b[0m\n",
      "     | > loss: -0.11780962347984314  (-0.14378357937461445)\n",
      "     | > log_mle: -0.3123816251754761  (-0.3103892815740483)\n",
      "     | > loss_dur: 0.19457200169563293  (0.16660570227786112)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(17.7284, device='cuda:0')  (tensor(30.4736, device='cuda:0'))\n",
      "     | > current_lr: 1.875e-05 \n",
      "     | > step_time: 0.8799  (0.5766491940146997)\n",
      "     | > loader_time: 0.0084  (0.010899521175183748)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:28:28 -- STEP: 120/406 -- GLOBAL_STEP: 53300\u001b[0m\n",
      "     | > loss: -0.12360312044620514  (-0.14305779933929438)\n",
      "     | > log_mle: -0.31898033618927  (-0.31282989879449197)\n",
      "     | > loss_dur: 0.19537721574306488  (0.16977209951728583)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(26.0348, device='cuda:0')  (tensor(31.3610, device='cuda:0'))\n",
      "     | > current_lr: 1.875e-05 \n",
      "     | > step_time: 0.9521  (0.5952478031317392)\n",
      "     | > loader_time: 0.0042  (0.01048067609469096)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:28:44 -- STEP: 145/406 -- GLOBAL_STEP: 53325\u001b[0m\n",
      "     | > loss: -0.14420147240161896  (-0.14280371840657854)\n",
      "     | > log_mle: -0.30617403984069824  (-0.31485794659318583)\n",
      "     | > loss_dur: 0.16197256743907928  (0.1720542282379907)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(21.9599, device='cuda:0')  (tensor(32.3677, device='cuda:0'))\n",
      "     | > current_lr: 1.875e-05 \n",
      "     | > step_time: 0.4842  (0.6021362781524656)\n",
      "     | > loader_time: 0.006  (0.010444432291491279)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:29:03 -- STEP: 170/406 -- GLOBAL_STEP: 53350\u001b[0m\n",
      "     | > loss: -0.1512535959482193  (-0.14234279630815272)\n",
      "     | > log_mle: -0.32015538215637207  (-0.31619151550180763)\n",
      "     | > loss_dur: 0.16890178620815277  (0.1738487192374818)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(45.3498, device='cuda:0')  (tensor(31.8409, device='cuda:0'))\n",
      "     | > current_lr: 1.875e-05 \n",
      "     | > step_time: 0.7752  (0.6182900190353391)\n",
      "     | > loader_time: 0.0159  (0.010536174213185028)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:29:21 -- STEP: 195/406 -- GLOBAL_STEP: 53375\u001b[0m\n",
      "     | > loss: -0.13595129549503326  (-0.14259521334599212)\n",
      "     | > log_mle: -0.3179861307144165  (-0.3178079323890881)\n",
      "     | > loss_dur: 0.18203483521938324  (0.17521271908130395)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(41.5620, device='cuda:0')  (tensor(32.2970, device='cuda:0'))\n",
      "     | > current_lr: 1.875e-05 \n",
      "     | > step_time: 0.6368  (0.6327230318998681)\n",
      "     | > loader_time: 0.0191  (0.010912826733711434)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:29:40 -- STEP: 220/406 -- GLOBAL_STEP: 53400\u001b[0m\n",
      "     | > loss: -0.15840141475200653  (-0.14272711100903412)\n",
      "     | > log_mle: -0.3510931730270386  (-0.31923445625738667)\n",
      "     | > loss_dur: 0.19269175827503204  (0.17650734528221862)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(18.5554, device='cuda:0')  (tensor(32.7968, device='cuda:0'))\n",
      "     | > current_lr: 1.875e-05 \n",
      "     | > step_time: 0.8426  (0.643681009249254)\n",
      "     | > loader_time: 0.0052  (0.011216237328269261)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:29:59 -- STEP: 245/406 -- GLOBAL_STEP: 53425\u001b[0m\n",
      "     | > loss: -0.14569087326526642  (-0.14267136849919138)\n",
      "     | > log_mle: -0.3296931982040405  (-0.32055592293642005)\n",
      "     | > loss_dur: 0.1840023249387741  (0.1778845544676391)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(48.9934, device='cuda:0')  (tensor(33.5036, device='cuda:0'))\n",
      "     | > current_lr: 1.875e-05 \n",
      "     | > step_time: 0.7053  (0.6516363114726789)\n",
      "     | > loader_time: 0.0159  (0.011482800269613456)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:30:18 -- STEP: 270/406 -- GLOBAL_STEP: 53450\u001b[0m\n",
      "     | > loss: -0.1506647914648056  (-0.143148703817968)\n",
      "     | > log_mle: -0.335335373878479  (-0.3216385364532471)\n",
      "     | > loss_dur: 0.1846705824136734  (0.17848983266287374)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(108.8949, device='cuda:0')  (tensor(34.0742, device='cuda:0'))\n",
      "     | > current_lr: 1.875e-05 \n",
      "     | > step_time: 0.5042  (0.6617938889397517)\n",
      "     | > loader_time: 0.0087  (0.011494266545331035)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:30:37 -- STEP: 295/406 -- GLOBAL_STEP: 53475\u001b[0m\n",
      "     | > loss: -0.1369151920080185  (-0.14291569393570142)\n",
      "     | > log_mle: -0.33009231090545654  (-0.32232818078186554)\n",
      "     | > loss_dur: 0.19317711889743805  (0.17941248687142028)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(45.3300, device='cuda:0')  (tensor(34.1699, device='cuda:0'))\n",
      "     | > current_lr: 1.875e-05 \n",
      "     | > step_time: 0.7143  (0.6691314842741372)\n",
      "     | > loader_time: 0.0095  (0.011632775452177401)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:30:57 -- STEP: 320/406 -- GLOBAL_STEP: 53500\u001b[0m\n",
      "     | > loss: -0.13406793773174286  (-0.14294836334884178)\n",
      "     | > log_mle: -0.3258002996444702  (-0.3231537815183401)\n",
      "     | > loss_dur: 0.19173236191272736  (0.1802054181927814)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(28.8971, device='cuda:0')  (tensor(34.1949, device='cuda:0'))\n",
      "     | > current_lr: 1.875e-05 \n",
      "     | > step_time: 0.8729  (0.6770576693117623)\n",
      "     | > loader_time: 0.0553  (0.012019640952348705)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:31:19 -- STEP: 345/406 -- GLOBAL_STEP: 53525\u001b[0m\n",
      "     | > loss: -0.14731046557426453  (-0.14274403547895137)\n",
      "     | > log_mle: -0.33479034900665283  (-0.32379176063814014)\n",
      "     | > loss_dur: 0.1874798834323883  (0.18104772518078474)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(51.3677, device='cuda:0')  (tensor(34.8823, device='cuda:0'))\n",
      "     | > current_lr: 1.875e-05 \n",
      "     | > step_time: 0.7963  (0.690092566393424)\n",
      "     | > loader_time: 0.0216  (0.012251637638479035)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:31:41 -- STEP: 370/406 -- GLOBAL_STEP: 53550\u001b[0m\n",
      "     | > loss: -0.15462420880794525  (-0.1429519869185783)\n",
      "     | > log_mle: -0.3557783365249634  (-0.324716863761077)\n",
      "     | > loss_dur: 0.20115412771701813  (0.18176487686263537)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(70.1843, device='cuda:0')  (tensor(34.8511, device='cuda:0'))\n",
      "     | > current_lr: 1.875e-05 \n",
      "     | > step_time: 0.6888  (0.7021478949366392)\n",
      "     | > loader_time: 0.0065  (0.012635814177023393)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:32:03 -- STEP: 395/406 -- GLOBAL_STEP: 53575\u001b[0m\n",
      "     | > loss: -0.15025874972343445  (-0.14304327908196032)\n",
      "     | > log_mle: -0.3401520252227783  (-0.32536254713806917)\n",
      "     | > loss_dur: 0.18989327549934387  (0.1823192680749711)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(76.3609, device='cuda:0')  (tensor(35.1438, device='cuda:0'))\n",
      "     | > current_lr: 1.875e-05 \n",
      "     | > step_time: 0.6607  (0.7100164896325223)\n",
      "     | > loader_time: 0.0083  (0.01289733512492119)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: -0.12838906049728394  (-0.12838906049728394)\n",
      "     | > log_mle: -0.3084909915924072  (-0.3084909915924072)\n",
      "     | > loss_dur: 0.1801019310951233  (0.1801019310951233)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: -0.18790021538734436  (-0.18790021538734436)\n",
      "     | > log_mle: -0.350394606590271  (-0.350394606590271)\n",
      "     | > loss_dur: 0.16249439120292664  (0.16249439120292664)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: -0.1865568608045578  (-0.18722853809595108)\n",
      "     | > log_mle: -0.3147376775741577  (-0.33256614208221436)\n",
      "     | > loss_dur: 0.12818081676959991  (0.14533760398626328)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: -0.17777644097805023  (-0.1840778390566508)\n",
      "     | > log_mle: -0.32336413860321045  (-0.32949880758921307)\n",
      "     | > loss_dur: 0.14558769762516022  (0.14542096853256226)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: -0.19119367003440857  (-0.18585679680109024)\n",
      "     | > log_mle: -0.34957122802734375  (-0.3345169126987457)\n",
      "     | > loss_dur: 0.15837755799293518  (0.1486601158976555)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: -0.17958317697048187  (-0.18460207283496857)\n",
      "     | > log_mle: -0.35039567947387695  (-0.33769266605377196)\n",
      "     | > loss_dur: 0.17081250250339508  (0.15309059321880342)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: -0.13133029639720917  (-0.17572344342867532)\n",
      "     | > log_mle: -0.3604549169540405  (-0.3414863745371501)\n",
      "     | > loss_dur: 0.22912462055683136  (0.16576293110847473)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: -0.16934876143932343  (-0.17481277457305364)\n",
      "     | > log_mle: -0.3208116292953491  (-0.3385328395026071)\n",
      "     | > loss_dur: 0.1514628678560257  (0.16372006492955343)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: -0.17912282049655914  (-0.17535153031349182)\n",
      "     | > log_mle: -0.3337523937225342  (-0.33793528378009796)\n",
      "     | > loss_dur: 0.15462957322597504  (0.16258375346660614)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: -0.16926121711730957  (-0.17467482884724936)\n",
      "     | > log_mle: -0.34646856784820557  (-0.3388834264543321)\n",
      "     | > loss_dur: 0.177207350730896  (0.16420859760708278)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: -0.1414017230272293  (-0.17134751826524736)\n",
      "     | > log_mle: -0.3321523666381836  (-0.33821032047271726)\n",
      "     | > loss_dur: 0.19075064361095428  (0.16686280220746993)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: -0.16357390582561493  (-0.17064082622528076)\n",
      "     | > log_mle: -0.3485991954803467  (-0.33915476365522906)\n",
      "     | > loss_dur: 0.18502528965473175  (0.16851393742994827)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: -0.17967398464679718  (-0.1713935894270738)\n",
      "     | > log_mle: -0.3343604803085327  (-0.33875524004300434)\n",
      "     | > loss_dur: 0.15468649566173553  (0.16736165061593056)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: -0.19379058480262756  (-0.17311643522519332)\n",
      "     | > log_mle: -0.35809528827667236  (-0.34024293606097883)\n",
      "     | > loss_dur: 0.1643047034740448  (0.1671265008357855)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: -0.17081581056118011  (-0.1729521048920495)\n",
      "     | > log_mle: -0.34664928913116455  (-0.3407005327088492)\n",
      "     | > loss_dur: 0.17583347856998444  (0.16774842781679972)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: -0.16491809487342834  (-0.17241650422414143)\n",
      "     | > log_mle: -0.33913612365722656  (-0.3405962387720744)\n",
      "     | > loss_dur: 0.17421802878379822  (0.16817973454793295)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: -0.16132603585720062  (-0.17172334995120764)\n",
      "     | > log_mle: -0.3426191806793213  (-0.3407226726412773)\n",
      "     | > loss_dur: 0.18129314482212067  (0.16899932269006968)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: audio amplitude out of range, auto clipped.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.003397807478904724 \u001b[0m(-0.0014965236186981201)\n",
      "     | > avg_loss:\u001b[92m -0.17172334995120764 \u001b[0m(-0.008437070995569229)\n",
      "     | > avg_log_mle:\u001b[92m -0.3407226726412773 \u001b[0m(-0.006534047424793243)\n",
      "     | > avg_loss_dur:\u001b[92m 0.16899932269006968 \u001b[0m(-0.0019030235707759857)\n",
      "\n",
      " > BEST MODEL : train/run-February-22-2025_10+59PM-fa84af3/best_model_53586.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 76/100\u001b[0m\n",
      " --> train/run-February-22-2025_10+59PM-fa84af3\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-23 05:32:26) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:32:34 -- STEP: 14/406 -- GLOBAL_STEP: 53600\u001b[0m\n",
      "     | > loss: -0.13623479008674622  (-0.16303448379039762)\n",
      "     | > log_mle: -0.31828927993774414  (-0.3105431539671762)\n",
      "     | > loss_dur: 0.18205448985099792  (0.14750867017677852)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(15.3273, device='cuda:0')  (tensor(30.6104, device='cuda:0'))\n",
      "     | > current_lr: 1.8999999999999998e-05 \n",
      "     | > step_time: 0.7703  (0.4063695328576224)\n",
      "     | > loader_time: 0.015  (0.006892033985682896)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:32:49 -- STEP: 39/406 -- GLOBAL_STEP: 53625\u001b[0m\n",
      "     | > loss: -0.1251678615808487  (-0.15220538125588343)\n",
      "     | > log_mle: -0.3002910614013672  (-0.3076936923540555)\n",
      "     | > loss_dur: 0.1751231998205185  (0.1554883110981721)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(33.9024, device='cuda:0')  (tensor(29.8423, device='cuda:0'))\n",
      "     | > current_lr: 1.8999999999999998e-05 \n",
      "     | > step_time: 0.5292  (0.5313357328757261)\n",
      "     | > loader_time: 0.0039  (0.009507992328741614)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:33:05 -- STEP: 64/406 -- GLOBAL_STEP: 53650\u001b[0m\n",
      "     | > loss: -0.16301241517066956  (-0.14874098380096257)\n",
      "     | > log_mle: -0.3217339515686035  (-0.30902627483010287)\n",
      "     | > loss_dur: 0.15872153639793396  (0.16028529102914033)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(32.8576, device='cuda:0')  (tensor(29.0773, device='cuda:0'))\n",
      "     | > current_lr: 1.8999999999999998e-05 \n",
      "     | > step_time: 0.6242  (0.5698350071907043)\n",
      "     | > loader_time: 0.0112  (0.009797647595405579)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:33:22 -- STEP: 89/406 -- GLOBAL_STEP: 53675\u001b[0m\n",
      "     | > loss: -0.12317594885826111  (-0.1469982530963555)\n",
      "     | > log_mle: -0.3110322952270508  (-0.3113834081071146)\n",
      "     | > loss_dur: 0.18785634636878967  (0.16438515501075915)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(23.5022, device='cuda:0')  (tensor(28.3405, device='cuda:0'))\n",
      "     | > current_lr: 1.8999999999999998e-05 \n",
      "     | > step_time: 0.8327  (0.5884278275993434)\n",
      "     | > loader_time: 0.0125  (0.010097155410252263)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:33:37 -- STEP: 114/406 -- GLOBAL_STEP: 53700\u001b[0m\n",
      "     | > loss: -0.17123283445835114  (-0.14669362913098255)\n",
      "     | > log_mle: -0.3520246744155884  (-0.31449780024980245)\n",
      "     | > loss_dur: 0.18079183995723724  (0.16780417111881987)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(26.7278, device='cuda:0')  (tensor(29.4749, device='cuda:0'))\n",
      "     | > current_lr: 1.8999999999999998e-05 \n",
      "     | > step_time: 0.3794  (0.5931391883314704)\n",
      "     | > loader_time: 0.0039  (0.01025662087557609)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:33:55 -- STEP: 139/406 -- GLOBAL_STEP: 53725\u001b[0m\n",
      "     | > loss: -0.13634859025478363  (-0.14522498417243684)\n",
      "     | > log_mle: -0.3199887275695801  (-0.3162108496796313)\n",
      "     | > loss_dur: 0.18364013731479645  (0.1709858655071944)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(54.2934, device='cuda:0')  (tensor(31.4103, device='cuda:0'))\n",
      "     | > current_lr: 1.8999999999999998e-05 \n",
      "     | > step_time: 0.4305  (0.6078425139831984)\n",
      "     | > loader_time: 0.0129  (0.010781615758113726)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:34:12 -- STEP: 164/406 -- GLOBAL_STEP: 53750\u001b[0m\n",
      "     | > loss: -0.13002514839172363  (-0.1440338436059836)\n",
      "     | > log_mle: -0.31315040588378906  (-0.3172931205935593)\n",
      "     | > loss_dur: 0.18312525749206543  (0.17325927698757587)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(20.2006, device='cuda:0')  (tensor(31.8696, device='cuda:0'))\n",
      "     | > current_lr: 1.8999999999999998e-05 \n",
      "     | > step_time: 0.6807  (0.6200118559162793)\n",
      "     | > loader_time: 0.0062  (0.011404357305387176)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:34:30 -- STEP: 189/406 -- GLOBAL_STEP: 53775\u001b[0m\n",
      "     | > loss: -0.1342146247625351  (-0.14401112709726616)\n",
      "     | > log_mle: -0.3219994306564331  (-0.3185360753347002)\n",
      "     | > loss_dur: 0.187784805893898  (0.17452494823743434)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(43.9655, device='cuda:0')  (tensor(34.2223, device='cuda:0'))\n",
      "     | > current_lr: 1.8999999999999998e-05 \n",
      "     | > step_time: 0.4295  (0.6291584312600432)\n",
      "     | > loader_time: 0.0104  (0.011358957442026295)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:34:49 -- STEP: 214/406 -- GLOBAL_STEP: 53800\u001b[0m\n",
      "     | > loss: -0.15687163174152374  (-0.14346650152284418)\n",
      "     | > log_mle: -0.33598268032073975  (-0.3194440965340515)\n",
      "     | > loss_dur: 0.179111048579216  (0.1759775950112076)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(13.3580, device='cuda:0')  (tensor(34.7619, device='cuda:0'))\n",
      "     | > current_lr: 1.8999999999999998e-05 \n",
      "     | > step_time: 0.8061  (0.6411324973418331)\n",
      "     | > loader_time: 0.0084  (0.011457582500493418)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:35:08 -- STEP: 239/406 -- GLOBAL_STEP: 53825\u001b[0m\n",
      "     | > loss: -0.12997440993785858  (-0.143417767338673)\n",
      "     | > log_mle: -0.32425737380981445  (-0.320760963850939)\n",
      "     | > loss_dur: 0.19428296387195587  (0.17734319651226624)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(82.3240, device='cuda:0')  (tensor(34.4733, device='cuda:0'))\n",
      "     | > current_lr: 1.8999999999999998e-05 \n",
      "     | > step_time: 1.0717  (0.652360735578018)\n",
      "     | > loader_time: 0.0156  (0.011685006289302559)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:35:27 -- STEP: 264/406 -- GLOBAL_STEP: 53850\u001b[0m\n",
      "     | > loss: -0.13018876314163208  (-0.1436959247697484)\n",
      "     | > log_mle: -0.32563459873199463  (-0.321820016611706)\n",
      "     | > loss_dur: 0.19544583559036255  (0.17812409184195785)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(24.8629, device='cuda:0')  (tensor(35.1181, device='cuda:0'))\n",
      "     | > current_lr: 1.8999999999999998e-05 \n",
      "     | > step_time: 0.5986  (0.6605379111839061)\n",
      "     | > loader_time: 0.0056  (0.012337098519007366)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:35:47 -- STEP: 289/406 -- GLOBAL_STEP: 53875\u001b[0m\n",
      "     | > loss: -0.13438409566879272  (-0.14392381947758293)\n",
      "     | > log_mle: -0.3190685510635376  (-0.32283447894258055)\n",
      "     | > loss_dur: 0.18468445539474487  (0.17891065946499782)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(83.9997, device='cuda:0')  (tensor(35.5312, device='cuda:0'))\n",
      "     | > current_lr: 1.8999999999999998e-05 \n",
      "     | > step_time: 0.4987  (0.6700582446524014)\n",
      "     | > loader_time: 0.0073  (0.012335824306448437)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:36:08 -- STEP: 314/406 -- GLOBAL_STEP: 53900\u001b[0m\n",
      "     | > loss: -0.1572173535823822  (-0.14427073409033445)\n",
      "     | > log_mle: -0.3430899381637573  (-0.32390423299400656)\n",
      "     | > loss_dur: 0.18587258458137512  (0.1796334989036725)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(26.7714, device='cuda:0')  (tensor(36.0342, device='cuda:0'))\n",
      "     | > current_lr: 1.8999999999999998e-05 \n",
      "     | > step_time: 0.5337  (0.681272676795911)\n",
      "     | > loader_time: 0.0206  (0.012340487188594354)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:36:29 -- STEP: 339/406 -- GLOBAL_STEP: 53925\u001b[0m\n",
      "     | > loss: -0.14776408672332764  (-0.14429610594008185)\n",
      "     | > log_mle: -0.33987748622894287  (-0.3247062217521105)\n",
      "     | > loss_dur: 0.19211339950561523  (0.18041011581202882)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(22.5199, device='cuda:0')  (tensor(35.6891, device='cuda:0'))\n",
      "     | > current_lr: 1.8999999999999998e-05 \n",
      "     | > step_time: 0.8615  (0.691279186260032)\n",
      "     | > loader_time: 0.0055  (0.012812853562796715)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:36:51 -- STEP: 364/406 -- GLOBAL_STEP: 53950\u001b[0m\n",
      "     | > loss: -0.14587970077991486  (-0.14430309643784725)\n",
      "     | > log_mle: -0.3322213888168335  (-0.32551115227269606)\n",
      "     | > loss_dur: 0.18634168803691864  (0.18120805583484884)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(51.9419, device='cuda:0')  (tensor(36.3033, device='cuda:0'))\n",
      "     | > current_lr: 1.8999999999999998e-05 \n",
      "     | > step_time: 1.0072  (0.7025447566430647)\n",
      "     | > loader_time: 0.0215  (0.012841340604719224)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:37:12 -- STEP: 389/406 -- GLOBAL_STEP: 53975\u001b[0m\n",
      "     | > loss: -0.15260329842567444  (-0.1445214755277708)\n",
      "     | > log_mle: -0.3333073854446411  (-0.3263031296374557)\n",
      "     | > loss_dur: 0.18070408701896667  (0.1817816541096852)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(35.9725, device='cuda:0')  (tensor(36.5877, device='cuda:0'))\n",
      "     | > current_lr: 1.8999999999999998e-05 \n",
      "     | > step_time: 0.7397  (0.7116517898049637)\n",
      "     | > loader_time: 0.0096  (0.012962479211370866)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: -0.13305455446243286  (-0.13305455446243286)\n",
      "     | > log_mle: -0.3099483251571655  (-0.3099483251571655)\n",
      "     | > loss_dur: 0.17689377069473267  (0.17689377069473267)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: -0.1844416856765747  (-0.1844416856765747)\n",
      "     | > log_mle: -0.35165953636169434  (-0.35165953636169434)\n",
      "     | > loss_dur: 0.16721785068511963  (0.16721785068511963)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: -0.19438579678535461  (-0.18941374123096466)\n",
      "     | > log_mle: -0.3153928518295288  (-0.3335261940956116)\n",
      "     | > loss_dur: 0.12100706249475479  (0.1441124565899372)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: -0.1661611646413803  (-0.18166288236776987)\n",
      "     | > log_mle: -0.32282280921936035  (-0.32995839913686115)\n",
      "     | > loss_dur: 0.15666164457798004  (0.14829551925261816)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: -0.18563619256019592  (-0.1826562099158764)\n",
      "     | > log_mle: -0.3506650924682617  (-0.3351350724697113)\n",
      "     | > loss_dur: 0.1650288999080658  (0.15247886441648006)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: -0.17064501345157623  (-0.18025397062301635)\n",
      "     | > log_mle: -0.3466973304748535  (-0.33744752407073975)\n",
      "     | > loss_dur: 0.17605231702327728  (0.1571935549378395)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: -0.10833437740802765  (-0.16826737175385156)\n",
      "     | > log_mle: -0.3582324981689453  (-0.3409116864204407)\n",
      "     | > loss_dur: 0.24989812076091766  (0.17264431590835252)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: -0.1559222936630249  (-0.16650378916944777)\n",
      "     | > log_mle: -0.32011616230010986  (-0.3379408972603934)\n",
      "     | > loss_dur: 0.16419386863708496  (0.17143710915531432)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: -0.1791158765554428  (-0.16808030009269714)\n",
      "     | > log_mle: -0.3346741199493408  (-0.33753255009651184)\n",
      "     | > loss_dur: 0.155558243393898  (0.16945225093513727)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: -0.14741824567317963  (-0.16578451626830631)\n",
      "     | > log_mle: -0.3460313081741333  (-0.3384768565495809)\n",
      "     | > loss_dur: 0.19861306250095367  (0.17269234110911688)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: -0.13620194792747498  (-0.1628262594342232)\n",
      "     | > log_mle: -0.3327779769897461  (-0.3379069685935974)\n",
      "     | > loss_dur: 0.19657602906227112  (0.1750807099044323)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: -0.15405824780464172  (-0.16202916746789758)\n",
      "     | > log_mle: -0.3486446142196655  (-0.3388831181959672)\n",
      "     | > loss_dur: 0.1945863664150238  (0.17685395140539517)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: -0.1792251020669937  (-0.16346216201782227)\n",
      "     | > log_mle: -0.33493494987487793  (-0.3385541041692098)\n",
      "     | > loss_dur: 0.15570984780788422  (0.17509194277226925)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: -0.18382737040519714  (-0.1650287165091588)\n",
      "     | > log_mle: -0.356253981590271  (-0.3399156332015991)\n",
      "     | > loss_dur: 0.17242661118507385  (0.1748869172655619)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: -0.1638496220111847  (-0.16494449547358922)\n",
      "     | > log_mle: -0.34581100940704346  (-0.340336731501988)\n",
      "     | > loss_dur: 0.18196138739585876  (0.17539223656058311)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: -0.1628062129020691  (-0.16480194330215453)\n",
      "     | > log_mle: -0.33908140659332275  (-0.34025304317474364)\n",
      "     | > loss_dur: 0.17627519369125366  (0.17545110036929448)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: -0.1464795023202896  (-0.16365679074078798)\n",
      "     | > log_mle: -0.3422192335128784  (-0.3403759300708771)\n",
      "     | > loss_dur: 0.1957397311925888  (0.17671913979575038)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: audio amplitude out of range, auto clipped.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[91m 0.004057079553604126 \u001b[0m(+0.0006592720746994019)\n",
      "     | > avg_loss:\u001b[91m -0.16365679074078798 \u001b[0m(+0.008066559210419655)\n",
      "     | > avg_log_mle:\u001b[91m -0.3403759300708771 \u001b[0m(+0.00034674257040023804)\n",
      "     | > avg_loss_dur:\u001b[91m 0.17671913979575038 \u001b[0m(+0.007719817105680704)\n",
      "\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 77/100\u001b[0m\n",
      " --> train/run-February-22-2025_10+59PM-fa84af3\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-23 05:37:38) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:37:43 -- STEP: 8/406 -- GLOBAL_STEP: 54000\u001b[0m\n",
      "     | > loss: -0.17183007299900055  (-0.1701611652970314)\n",
      "     | > log_mle: -0.3179757595062256  (-0.31081423163414)\n",
      "     | > loss_dur: 0.14614568650722504  (0.1406530663371086)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(56.3408, device='cuda:0')  (tensor(34.2547, device='cuda:0'))\n",
      "     | > current_lr: 1.925e-05 \n",
      "     | > step_time: 0.3555  (0.3952004015445709)\n",
      "     | > loader_time: 0.007  (0.005542576313018799)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:37:57 -- STEP: 33/406 -- GLOBAL_STEP: 54025\u001b[0m\n",
      "     | > loss: -0.12216687202453613  (-0.15689869766885584)\n",
      "     | > log_mle: -0.2973414659500122  (-0.30990310509999597)\n",
      "     | > loss_dur: 0.17517459392547607  (0.15300440743114008)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(20.1142, device='cuda:0')  (tensor(26.3698, device='cuda:0'))\n",
      "     | > current_lr: 1.925e-05 \n",
      "     | > step_time: 0.3132  (0.5082595998590643)\n",
      "     | > loader_time: 0.0039  (0.008167216272065134)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:38:14 -- STEP: 58/406 -- GLOBAL_STEP: 54050\u001b[0m\n",
      "     | > loss: -0.1466515213251114  (-0.1506620452835642)\n",
      "     | > log_mle: -0.3127189874649048  (-0.3096808256774113)\n",
      "     | > loss_dur: 0.1660674661397934  (0.15901878039384704)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(47.9131, device='cuda:0')  (tensor(28.1189, device='cuda:0'))\n",
      "     | > current_lr: 1.925e-05 \n",
      "     | > step_time: 0.3833  (0.5697002657528583)\n",
      "     | > loader_time: 0.0102  (0.00931557704662455)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:38:29 -- STEP: 83/406 -- GLOBAL_STEP: 54075\u001b[0m\n",
      "     | > loss: -0.14635170996189117  (-0.14897023572261076)\n",
      "     | > log_mle: -0.32379114627838135  (-0.3119172216897987)\n",
      "     | > loss_dur: 0.17743943631649017  (0.1629469859671879)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(22.3775, device='cuda:0')  (tensor(28.8713, device='cuda:0'))\n",
      "     | > current_lr: 1.925e-05 \n",
      "     | > step_time: 0.4951  (0.5783196070108071)\n",
      "     | > loader_time: 0.0076  (0.010291254664041915)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:38:46 -- STEP: 108/406 -- GLOBAL_STEP: 54100\u001b[0m\n",
      "     | > loss: -0.15159699320793152  (-0.14777651939679073)\n",
      "     | > log_mle: -0.3166862726211548  (-0.31405878177395574)\n",
      "     | > loss_dur: 0.16508927941322327  (0.1662822623771649)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(30.3767, device='cuda:0')  (tensor(31.2428, device='cuda:0'))\n",
      "     | > current_lr: 1.925e-05 \n",
      "     | > step_time: 0.5527  (0.5911548844090214)\n",
      "     | > loader_time: 0.0195  (0.01158890459272597)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:39:02 -- STEP: 133/406 -- GLOBAL_STEP: 54125\u001b[0m\n",
      "     | > loss: -0.15340490639209747  (-0.1470919559548672)\n",
      "     | > log_mle: -0.32987213134765625  (-0.3162824883496851)\n",
      "     | > loss_dur: 0.17646722495555878  (0.1691905323948178)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(24.4345, device='cuda:0')  (tensor(30.9630, device='cuda:0'))\n",
      "     | > current_lr: 1.925e-05 \n",
      "     | > step_time: 0.4133  (0.6012875424291855)\n",
      "     | > loader_time: 0.0047  (0.011838963157252264)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:39:20 -- STEP: 158/406 -- GLOBAL_STEP: 54150\u001b[0m\n",
      "     | > loss: -0.14039495587348938  (-0.14596229933107951)\n",
      "     | > log_mle: -0.33347463607788086  (-0.3177595953398113)\n",
      "     | > loss_dur: 0.19307968020439148  (0.17179729600873167)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(37.4542, device='cuda:0')  (tensor(31.8154, device='cuda:0'))\n",
      "     | > current_lr: 1.925e-05 \n",
      "     | > step_time: 0.6542  (0.6131759685806081)\n",
      "     | > loader_time: 0.0052  (0.011785667153853407)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:39:38 -- STEP: 183/406 -- GLOBAL_STEP: 54175\u001b[0m\n",
      "     | > loss: -0.15495669841766357  (-0.1462227373989553)\n",
      "     | > log_mle: -0.33518803119659424  (-0.3194357645316202)\n",
      "     | > loss_dur: 0.18023133277893066  (0.17321302713266487)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(62.4463, device='cuda:0')  (tensor(32.3147, device='cuda:0'))\n",
      "     | > current_lr: 1.925e-05 \n",
      "     | > step_time: 0.5116  (0.6277602552716197)\n",
      "     | > loader_time: 0.0102  (0.011998025445990228)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:39:56 -- STEP: 208/406 -- GLOBAL_STEP: 54200\u001b[0m\n",
      "     | > loss: -0.1546131670475006  (-0.14615749295514358)\n",
      "     | > log_mle: -0.33795928955078125  (-0.320863727766734)\n",
      "     | > loss_dur: 0.18334612250328064  (0.17470623481159026)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(33.0072, device='cuda:0')  (tensor(32.9815, device='cuda:0'))\n",
      "     | > current_lr: 1.925e-05 \n",
      "     | > step_time: 1.2294  (0.6358597542230898)\n",
      "     | > loader_time: 0.0119  (0.012180455602132361)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:40:14 -- STEP: 233/406 -- GLOBAL_STEP: 54225\u001b[0m\n",
      "     | > loss: -0.14350368082523346  (-0.1464386265165304)\n",
      "     | > log_mle: -0.3411083221435547  (-0.3224705079082768)\n",
      "     | > loss_dur: 0.19760464131832123  (0.1760318813917463)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(28.7225, device='cuda:0')  (tensor(33.8186, device='cuda:0'))\n",
      "     | > current_lr: 1.925e-05 \n",
      "     | > step_time: 0.757  (0.6433216911528754)\n",
      "     | > loader_time: 0.0066  (0.012149319628277566)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:40:34 -- STEP: 258/406 -- GLOBAL_STEP: 54250\u001b[0m\n",
      "     | > loss: -0.1345314234495163  (-0.1466668674419092)\n",
      "     | > log_mle: -0.31916844844818115  (-0.3236097905986993)\n",
      "     | > loss_dur: 0.18463702499866486  (0.17694292315679003)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(37.5140, device='cuda:0')  (tensor(33.9050, device='cuda:0'))\n",
      "     | > current_lr: 1.925e-05 \n",
      "     | > step_time: 0.8723  (0.654685899268749)\n",
      "     | > loader_time: 0.0263  (0.012585237968799684)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:40:53 -- STEP: 283/406 -- GLOBAL_STEP: 54275\u001b[0m\n",
      "     | > loss: -0.15094813704490662  (-0.14716356013351947)\n",
      "     | > log_mle: -0.33593475818634033  (-0.32481220290854623)\n",
      "     | > loss_dur: 0.18498662114143372  (0.1776486427750268)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(53.8039, device='cuda:0')  (tensor(34.6349, device='cuda:0'))\n",
      "     | > current_lr: 1.925e-05 \n",
      "     | > step_time: 0.7047  (0.6633680490217443)\n",
      "     | > loader_time: 0.0085  (0.012620245188790584)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:41:14 -- STEP: 308/406 -- GLOBAL_STEP: 54300\u001b[0m\n",
      "     | > loss: -0.14496338367462158  (-0.14723488669116772)\n",
      "     | > log_mle: -0.3389112949371338  (-0.32580158191841924)\n",
      "     | > loss_dur: 0.1939479112625122  (0.17856669522725155)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(36.6906, device='cuda:0')  (tensor(35.0089, device='cuda:0'))\n",
      "     | > current_lr: 1.925e-05 \n",
      "     | > step_time: 0.8918  (0.6749415722760286)\n",
      "     | > loader_time: 0.0095  (0.012698011738913405)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:41:34 -- STEP: 333/406 -- GLOBAL_STEP: 54325\u001b[0m\n",
      "     | > loss: -0.15220271050930023  (-0.1472686186835572)\n",
      "     | > log_mle: -0.34804630279541016  (-0.3265818722613223)\n",
      "     | > loss_dur: 0.19584359228610992  (0.1793132535777651)\n",
      "     | > amp_scaler: 4096.0  (2103.3513513513512)\n",
      "     | > grad_norm: tensor(51.0027, device='cuda:0')  (tensor(35.1600, device='cuda:0'))\n",
      "     | > current_lr: 1.925e-05 \n",
      "     | > step_time: 0.9121  (0.6839887759349011)\n",
      "     | > loader_time: 0.0242  (0.012977158343111793)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:41:55 -- STEP: 358/406 -- GLOBAL_STEP: 54350\u001b[0m\n",
      "     | > loss: -0.1694127470254898  (-0.14735958159136364)\n",
      "     | > log_mle: -0.355283260345459  (-0.32748476286840167)\n",
      "     | > loss_dur: 0.18587051331996918  (0.18012518127703808)\n",
      "     | > amp_scaler: 4096.0  (2242.5027932960897)\n",
      "     | > grad_norm: tensor(40.0192, device='cuda:0')  (tensor(35.3788, device='cuda:0'))\n",
      "     | > current_lr: 1.925e-05 \n",
      "     | > step_time: 0.8942  (0.6938841549377867)\n",
      "     | > loader_time: 0.0237  (0.013280452296720542)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:42:16 -- STEP: 383/406 -- GLOBAL_STEP: 54375\u001b[0m\n",
      "     | > loss: -0.1418856382369995  (-0.14749864689208186)\n",
      "     | > log_mle: -0.329068660736084  (-0.3281414013929838)\n",
      "     | > loss_dur: 0.18718302249908447  (0.18064275450090211)\n",
      "     | > amp_scaler: 4096.0  (2363.488250652743)\n",
      "     | > grad_norm: tensor(29.5681, device='cuda:0')  (tensor(35.5155, device='cuda:0'))\n",
      "     | > current_lr: 1.925e-05 \n",
      "     | > step_time: 0.7906  (0.7017168892892782)\n",
      "     | > loader_time: 0.0421  (0.013520388316859158)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: -0.1348160356283188  (-0.1348160356283188)\n",
      "     | > log_mle: -0.311393141746521  (-0.311393141746521)\n",
      "     | > loss_dur: 0.1765771061182022  (0.1765771061182022)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: -0.18494193255901337  (-0.18494193255901337)\n",
      "     | > log_mle: -0.3533670902252197  (-0.3533670902252197)\n",
      "     | > loss_dur: 0.16842515766620636  (0.16842515766620636)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: -0.19191017746925354  (-0.18842605501413345)\n",
      "     | > log_mle: -0.317851185798645  (-0.3356091380119324)\n",
      "     | > loss_dur: 0.12594100832939148  (0.14718308299779892)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: -0.17226991057395935  (-0.1830406735340754)\n",
      "     | > log_mle: -0.3259164094924927  (-0.33237822850545246)\n",
      "     | > loss_dur: 0.15364649891853333  (0.14933755497137705)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: -0.19266383349895477  (-0.18544646352529526)\n",
      "     | > log_mle: -0.35226988792419434  (-0.33735114336013794)\n",
      "     | > loss_dur: 0.15960605442523956  (0.15190467983484268)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: -0.18938739597797394  (-0.186234650015831)\n",
      "     | > log_mle: -0.3505491018295288  (-0.3399907350540161)\n",
      "     | > loss_dur: 0.16116170585155487  (0.1537560850381851)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: -0.13151094317436218  (-0.17711403220891953)\n",
      "     | > log_mle: -0.3603323698043823  (-0.34338100751241046)\n",
      "     | > loss_dur: 0.22882142663002014  (0.16626697530349097)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: -0.16954533755779266  (-0.1760327901159014)\n",
      "     | > log_mle: -0.3229100704193115  (-0.3404565879276821)\n",
      "     | > loss_dur: 0.15336473286151886  (0.16442379781178065)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: -0.1867343634366989  (-0.1773704867810011)\n",
      "     | > log_mle: -0.33678293228149414  (-0.33999738097190857)\n",
      "     | > loss_dur: 0.15004856884479523  (0.16262689419090748)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: -0.16764920949935913  (-0.17629034486081865)\n",
      "     | > log_mle: -0.34795570373535156  (-0.3408816390567356)\n",
      "     | > loss_dur: 0.18030649423599243  (0.16459129419591692)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: -0.1439417451620102  (-0.1730554848909378)\n",
      "     | > log_mle: -0.3342851400375366  (-0.34022198915481566)\n",
      "     | > loss_dur: 0.19034339487552643  (0.16716650426387786)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: -0.1695306897163391  (-0.17273504896597427)\n",
      "     | > log_mle: -0.35070252418518066  (-0.34117476506666705)\n",
      "     | > loss_dur: 0.18117183446884155  (0.16843971610069275)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: -0.1788429319858551  (-0.173244039217631)\n",
      "     | > log_mle: -0.33708298206329346  (-0.34083378314971924)\n",
      "     | > loss_dur: 0.15824005007743835  (0.16758974393208823)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: -0.19480060040950775  (-0.17490223623239076)\n",
      "     | > log_mle: -0.35951972007751465  (-0.3422711629133958)\n",
      "     | > loss_dur: 0.1647191196680069  (0.16736892668100503)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: -0.164613738656044  (-0.174167343548366)\n",
      "     | > log_mle: -0.3477548360824585  (-0.34266285385404316)\n",
      "     | > loss_dur: 0.1831410974264145  (0.16849551030567714)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: -0.16692882776260376  (-0.17368477582931519)\n",
      "     | > log_mle: -0.3410564661026001  (-0.3425557613372803)\n",
      "     | > loss_dur: 0.17412763833999634  (0.1688709855079651)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: -0.16571800410747528  (-0.1731868525967002)\n",
      "     | > log_mle: -0.3447742462158203  (-0.342694416642189)\n",
      "     | > loss_dur: 0.17905624210834503  (0.16950756404548883)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: audio amplitude out of range, auto clipped.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.0036727339029312134 \u001b[0m(-0.0003843456506729126)\n",
      "     | > avg_loss:\u001b[92m -0.1731868525967002 \u001b[0m(-0.009530061855912209)\n",
      "     | > avg_log_mle:\u001b[92m -0.342694416642189 \u001b[0m(-0.0023184865713119507)\n",
      "     | > avg_loss_dur:\u001b[92m 0.16950756404548883 \u001b[0m(-0.007211575750261545)\n",
      "\n",
      " > BEST MODEL : train/run-February-22-2025_10+59PM-fa84af3/best_model_54398.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 78/100\u001b[0m\n",
      " --> train/run-February-22-2025_10+59PM-fa84af3\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-23 05:42:48) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:42:51 -- STEP: 2/406 -- GLOBAL_STEP: 54400\u001b[0m\n",
      "     | > loss: -0.20585092902183533  (-0.1959747076034546)\n",
      "     | > log_mle: -0.3293813467025757  (-0.321320116519928)\n",
      "     | > loss_dur: 0.12353041023015976  (0.1253454051911831)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(39.9396, device='cuda:0')  (tensor(33.4641, device='cuda:0'))\n",
      "     | > current_lr: 1.95e-05 \n",
      "     | > step_time: 0.4704  (0.5035659074783325)\n",
      "     | > loader_time: 0.0029  (0.00787341594696045)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:43:04 -- STEP: 27/406 -- GLOBAL_STEP: 54425\u001b[0m\n",
      "     | > loss: -0.1516294926404953  (-0.15399495319083886)\n",
      "     | > log_mle: -0.3063710927963257  (-0.30615260424437346)\n",
      "     | > loss_dur: 0.15474160015583038  (0.15215765050163976)\n",
      "     | > amp_scaler: 2048.0  (2654.8148148148143)\n",
      "     | > grad_norm: tensor(9.2383, device='cuda:0')  (tensor(33.3007, device='cuda:0'))\n",
      "     | > current_lr: 1.95e-05 \n",
      "     | > step_time: 0.3064  (0.47686605983310276)\n",
      "     | > loader_time: 0.0063  (0.0068117159384268305)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:43:19 -- STEP: 52/406 -- GLOBAL_STEP: 54450\u001b[0m\n",
      "     | > loss: -0.1183740645647049  (-0.14655156032397196)\n",
      "     | > log_mle: -0.30744874477386475  (-0.30682552548555225)\n",
      "     | > loss_dur: 0.18907468020915985  (0.16027396487501952)\n",
      "     | > amp_scaler: 2048.0  (2363.076923076923)\n",
      "     | > grad_norm: tensor(18.7119, device='cuda:0')  (tensor(30.6454, device='cuda:0'))\n",
      "     | > current_lr: 1.95e-05 \n",
      "     | > step_time: 0.4386  (0.5341243652197033)\n",
      "     | > loader_time: 0.007  (0.006984316385709322)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:43:36 -- STEP: 77/406 -- GLOBAL_STEP: 54475\u001b[0m\n",
      "     | > loss: -0.12860217690467834  (-0.1461262426206044)\n",
      "     | > log_mle: -0.308530330657959  (-0.3098419440257085)\n",
      "     | > loss_dur: 0.17992815375328064  (0.16371570121158252)\n",
      "     | > amp_scaler: 2048.0  (2260.7792207792213)\n",
      "     | > grad_norm: tensor(20.0384, device='cuda:0')  (tensor(31.4651, device='cuda:0'))\n",
      "     | > current_lr: 1.95e-05 \n",
      "     | > step_time: 0.6905  (0.5777090462771332)\n",
      "     | > loader_time: 0.0054  (0.008886783153979809)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:43:53 -- STEP: 102/406 -- GLOBAL_STEP: 54500\u001b[0m\n",
      "     | > loss: -0.1646091639995575  (-0.14678857928397604)\n",
      "     | > log_mle: -0.33690619468688965  (-0.3136789810423758)\n",
      "     | > loss_dur: 0.17229703068733215  (0.1668904016123099)\n",
      "     | > amp_scaler: 2048.0  (2208.627450980392)\n",
      "     | > grad_norm: tensor(46.0739, device='cuda:0')  (tensor(32.0593, device='cuda:0'))\n",
      "     | > current_lr: 1.95e-05 \n",
      "     | > step_time: 0.7348  (0.594261029187371)\n",
      "     | > loader_time: 0.0173  (0.008906773492401722)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:44:10 -- STEP: 127/406 -- GLOBAL_STEP: 54525\u001b[0m\n",
      "     | > loss: -0.13881386816501617  (-0.14743261567250945)\n",
      "     | > log_mle: -0.330936074256897  (-0.3167715354228583)\n",
      "     | > loss_dur: 0.1921222060918808  (0.16933891963301684)\n",
      "     | > amp_scaler: 2048.0  (2177.007874015749)\n",
      "     | > grad_norm: tensor(26.3426, device='cuda:0')  (tensor(32.1222, device='cuda:0'))\n",
      "     | > current_lr: 1.95e-05 \n",
      "     | > step_time: 0.6219  (0.6139863288308695)\n",
      "     | > loader_time: 0.0046  (0.009285823566707102)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:44:28 -- STEP: 152/406 -- GLOBAL_STEP: 54550\u001b[0m\n",
      "     | > loss: -0.13404007256031036  (-0.1471221605805974)\n",
      "     | > log_mle: -0.32305896282196045  (-0.31882767614565405)\n",
      "     | > loss_dur: 0.18901889026165009  (0.17170551546702262)\n",
      "     | > amp_scaler: 2048.0  (2155.789473684211)\n",
      "     | > grad_norm: tensor(28.5266, device='cuda:0')  (tensor(31.6362, device='cuda:0'))\n",
      "     | > current_lr: 1.95e-05 \n",
      "     | > step_time: 1.027  (0.6236185964785127)\n",
      "     | > loader_time: 0.0207  (0.009828921995664899)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:44:46 -- STEP: 177/406 -- GLOBAL_STEP: 54575\u001b[0m\n",
      "     | > loss: -0.1448727548122406  (-0.14701711129670758)\n",
      "     | > log_mle: -0.32866907119750977  (-0.32017623637355663)\n",
      "     | > loss_dur: 0.18379631638526917  (0.17315912499266156)\n",
      "     | > amp_scaler: 2048.0  (2140.564971751414)\n",
      "     | > grad_norm: tensor(36.4143, device='cuda:0')  (tensor(31.9025, device='cuda:0'))\n",
      "     | > current_lr: 1.95e-05 \n",
      "     | > step_time: 0.7961  (0.6360319509344589)\n",
      "     | > loader_time: 0.0085  (0.0102251788317147)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:45:04 -- STEP: 202/406 -- GLOBAL_STEP: 54600\u001b[0m\n",
      "     | > loss: -0.11357420682907104  (-0.14678038155088333)\n",
      "     | > log_mle: -0.3194999694824219  (-0.32142082771452346)\n",
      "     | > loss_dur: 0.20592576265335083  (0.17464044608987203)\n",
      "     | > amp_scaler: 2048.0  (2129.10891089109)\n",
      "     | > grad_norm: tensor(39.4574, device='cuda:0')  (tensor(32.8489, device='cuda:0'))\n",
      "     | > current_lr: 1.95e-05 \n",
      "     | > step_time: 0.4363  (0.6459934085902602)\n",
      "     | > loader_time: 0.0064  (0.01031676849516312)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:45:24 -- STEP: 227/406 -- GLOBAL_STEP: 54625\u001b[0m\n",
      "     | > loss: -0.12748472392559052  (-0.1468387348536353)\n",
      "     | > log_mle: -0.32323741912841797  (-0.32275115603392346)\n",
      "     | > loss_dur: 0.19575269520282745  (0.17591242111464428)\n",
      "     | > amp_scaler: 2048.0  (2120.176211453745)\n",
      "     | > grad_norm: tensor(79.2971, device='cuda:0')  (tensor(33.1996, device='cuda:0'))\n",
      "     | > current_lr: 1.95e-05 \n",
      "     | > step_time: 0.7897  (0.6589071435550237)\n",
      "     | > loader_time: 0.0064  (0.010719471565952389)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:45:43 -- STEP: 252/406 -- GLOBAL_STEP: 54650\u001b[0m\n",
      "     | > loss: -0.14905254542827606  (-0.1470768511413582)\n",
      "     | > log_mle: -0.3316532373428345  (-0.323975109864795)\n",
      "     | > loss_dur: 0.1826006919145584  (0.17689825866430525)\n",
      "     | > amp_scaler: 2048.0  (2113.0158730158723)\n",
      "     | > grad_norm: tensor(43.1028, device='cuda:0')  (tensor(34.2483, device='cuda:0'))\n",
      "     | > current_lr: 1.95e-05 \n",
      "     | > step_time: 0.5034  (0.6663356243617952)\n",
      "     | > loader_time: 0.0093  (0.010782707305181598)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:46:03 -- STEP: 277/406 -- GLOBAL_STEP: 54675\u001b[0m\n",
      "     | > loss: -0.16181312501430511  (-0.14776839595624255)\n",
      "     | > log_mle: -0.33531808853149414  (-0.3252742217335891)\n",
      "     | > loss_dur: 0.17350496351718903  (0.17750582572355167)\n",
      "     | > amp_scaler: 2048.0  (2107.148014440433)\n",
      "     | > grad_norm: tensor(37.0666, device='cuda:0')  (tensor(34.6555, device='cuda:0'))\n",
      "     | > current_lr: 1.95e-05 \n",
      "     | > step_time: 0.664  (0.6767143557648366)\n",
      "     | > loader_time: 0.0217  (0.011308169967431028)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:46:24 -- STEP: 302/406 -- GLOBAL_STEP: 54700\u001b[0m\n",
      "     | > loss: -0.14477790892124176  (-0.14804990515606292)\n",
      "     | > log_mle: -0.34384214878082275  (-0.3263785246981691)\n",
      "     | > loss_dur: 0.199064239859581  (0.17832861949276452)\n",
      "     | > amp_scaler: 2048.0  (2102.2516556291393)\n",
      "     | > grad_norm: tensor(23.3553, device='cuda:0')  (tensor(34.6120, device='cuda:0'))\n",
      "     | > current_lr: 1.95e-05 \n",
      "     | > step_time: 1.4093  (0.688446494917206)\n",
      "     | > loader_time: 0.014  (0.011388403690413927)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:46:45 -- STEP: 327/406 -- GLOBAL_STEP: 54725\u001b[0m\n",
      "     | > loss: -0.13620755076408386  (-0.14813298392551028)\n",
      "     | > log_mle: -0.3309248685836792  (-0.32711089386487957)\n",
      "     | > loss_dur: 0.19471731781959534  (0.17897790989380008)\n",
      "     | > amp_scaler: 2048.0  (2098.1039755351694)\n",
      "     | > grad_norm: tensor(23.8751, device='cuda:0')  (tensor(34.9157, device='cuda:0'))\n",
      "     | > current_lr: 1.95e-05 \n",
      "     | > step_time: 1.0453  (0.7002273335004796)\n",
      "     | > loader_time: 0.0134  (0.011743641045479966)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:47:08 -- STEP: 352/406 -- GLOBAL_STEP: 54750\u001b[0m\n",
      "     | > loss: -0.1457587629556656  (-0.14800142090428967)\n",
      "     | > log_mle: -0.3327670097351074  (-0.3279174403710799)\n",
      "     | > loss_dur: 0.18700824677944183  (0.1799160194244575)\n",
      "     | > amp_scaler: 2048.0  (2094.5454545454545)\n",
      "     | > grad_norm: tensor(20.1000, device='cuda:0')  (tensor(35.3942, device='cuda:0'))\n",
      "     | > current_lr: 1.95e-05 \n",
      "     | > step_time: 0.8552  (0.7134166827256027)\n",
      "     | > loader_time: 0.03  (0.012156418101354084)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:47:31 -- STEP: 377/406 -- GLOBAL_STEP: 54775\u001b[0m\n",
      "     | > loss: -0.14403925836086273  (-0.14831456213952385)\n",
      "     | > log_mle: -0.3374195098876953  (-0.32882845022317897)\n",
      "     | > loss_dur: 0.19338025152683258  (0.18051388804412968)\n",
      "     | > amp_scaler: 2048.0  (2091.4588859416453)\n",
      "     | > grad_norm: tensor(45.3076, device='cuda:0')  (tensor(35.8635, device='cuda:0'))\n",
      "     | > current_lr: 1.95e-05 \n",
      "     | > step_time: 0.9013  (0.7246143223436187)\n",
      "     | > loader_time: 0.0107  (0.012341405731929713)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:47:50 -- STEP: 402/406 -- GLOBAL_STEP: 54800\u001b[0m\n",
      "     | > loss: -0.15407980978488922  (-0.14855055214457252)\n",
      "     | > log_mle: -0.3486059904098511  (-0.32959924823609166)\n",
      "     | > loss_dur: 0.19452618062496185  (0.18104869605445154)\n",
      "     | > amp_scaler: 2048.0  (2088.756218905475)\n",
      "     | > grad_norm: tensor(27.0109, device='cuda:0')  (tensor(36.1215, device='cuda:0'))\n",
      "     | > current_lr: 1.95e-05 \n",
      "     | > step_time: 0.5841  (0.7261199749524319)\n",
      "     | > loader_time: 0.0091  (0.012381232793058333)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: -0.14089760184288025  (-0.14089760184288025)\n",
      "     | > log_mle: -0.3124217987060547  (-0.3124217987060547)\n",
      "     | > loss_dur: 0.17152419686317444  (0.17152419686317444)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: -0.1855131983757019  (-0.1855131983757019)\n",
      "     | > log_mle: -0.35467374324798584  (-0.35467374324798584)\n",
      "     | > loss_dur: 0.16916054487228394  (0.16916054487228394)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: -0.19863516092300415  (-0.19207417964935303)\n",
      "     | > log_mle: -0.31929445266723633  (-0.3369840979576111)\n",
      "     | > loss_dur: 0.12065929919481277  (0.14490992203354836)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: -0.1740623414516449  (-0.18607023358345032)\n",
      "     | > log_mle: -0.3261590003967285  (-0.3333757321039836)\n",
      "     | > loss_dur: 0.15209665894508362  (0.14730550100406012)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: -0.19140811264514923  (-0.18740470334887505)\n",
      "     | > log_mle: -0.3517998456954956  (-0.3379817605018616)\n",
      "     | > loss_dur: 0.16039173305034637  (0.15057705901563168)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: -0.1890631467103958  (-0.1877363920211792)\n",
      "     | > log_mle: -0.35212039947509766  (-0.3408094882965088)\n",
      "     | > loss_dur: 0.16305725276470184  (0.1530730977654457)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: -0.12591436505317688  (-0.1774327208598455)\n",
      "     | > log_mle: -0.3600344657897949  (-0.34401365121205646)\n",
      "     | > loss_dur: 0.23412010073661804  (0.16658093159397444)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: -0.16465730965137482  (-0.17560766211577825)\n",
      "     | > log_mle: -0.32327473163604736  (-0.3410509484154837)\n",
      "     | > loss_dur: 0.15861742198467255  (0.16544328736407415)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: -0.18379896879196167  (-0.17663157545030117)\n",
      "     | > log_mle: -0.33741700649261475  (-0.3405967056751251)\n",
      "     | > loss_dur: 0.15361803770065308  (0.16396513115614653)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: -0.15508174896240234  (-0.17423715028497908)\n",
      "     | > log_mle: -0.3481861352920532  (-0.34143997563256157)\n",
      "     | > loss_dur: 0.19310438632965088  (0.16720282617542478)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: -0.14357589185237885  (-0.17117102444171906)\n",
      "     | > log_mle: -0.335176944732666  (-0.340813672542572)\n",
      "     | > loss_dur: 0.19160105288028717  (0.16964264884591101)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: -0.174117773771286  (-0.17143891074440695)\n",
      "     | > log_mle: -0.35188329219818115  (-0.34182000160217285)\n",
      "     | > loss_dur: 0.17776551842689514  (0.1703810915350914)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: -0.18392014503479004  (-0.17247901360193887)\n",
      "     | > log_mle: -0.3375735282897949  (-0.34146612882614136)\n",
      "     | > loss_dur: 0.15365338325500488  (0.1689871158450842)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: -0.188324436545372  (-0.17369789228989527)\n",
      "     | > log_mle: -0.36053431034088135  (-0.34293291201958287)\n",
      "     | > loss_dur: 0.17220987379550934  (0.1692350203028092)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: -0.16329896450042725  (-0.1729551117335047)\n",
      "     | > log_mle: -0.3485020399093628  (-0.34333070686885286)\n",
      "     | > loss_dur: 0.18520307540893555  (0.17037559566753252)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: -0.16793233156204224  (-0.17262025972207387)\n",
      "     | > log_mle: -0.34148526191711426  (-0.3432076772054036)\n",
      "     | > loss_dur: 0.17355293035507202  (0.17058741798003516)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: -0.16509342193603516  (-0.17214983236044645)\n",
      "     | > log_mle: -0.34589672088623047  (-0.3433757424354553)\n",
      "     | > loss_dur: 0.1808032989501953  (0.17122591054067016)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: audio amplitude out of range, auto clipped.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[91m 0.0046873539686203 \u001b[0m(+0.001014620065689087)\n",
      "     | > avg_loss:\u001b[91m -0.17214983236044645 \u001b[0m(+0.0010370202362537384)\n",
      "     | > avg_log_mle:\u001b[92m -0.3433757424354553 \u001b[0m(-0.0006813257932662964)\n",
      "     | > avg_loss_dur:\u001b[91m 0.17122591054067016 \u001b[0m(+0.001718346495181322)\n",
      "\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 79/100\u001b[0m\n",
      " --> train/run-February-22-2025_10+59PM-fa84af3\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-23 05:48:06) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:48:18 -- STEP: 21/406 -- GLOBAL_STEP: 54825\u001b[0m\n",
      "     | > loss: -0.15756218135356903  (-0.16632794766199022)\n",
      "     | > log_mle: -0.3117849826812744  (-0.3135868197395688)\n",
      "     | > loss_dur: 0.15422280132770538  (0.14725887243236815)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(37.9866, device='cuda:0')  (tensor(37.4502, device='cuda:0'))\n",
      "     | > current_lr: 1.975e-05 \n",
      "     | > step_time: 0.4787  (0.4539408116113572)\n",
      "     | > loader_time: 0.0121  (0.010563907169160388)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:48:33 -- STEP: 46/406 -- GLOBAL_STEP: 54850\u001b[0m\n",
      "     | > loss: -0.129023015499115  (-0.15527111777792807)\n",
      "     | > log_mle: -0.3032788038253784  (-0.3110480412192967)\n",
      "     | > loss_dur: 0.17425578832626343  (0.15577692360333775)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(17.3230, device='cuda:0')  (tensor(28.4626, device='cuda:0'))\n",
      "     | > current_lr: 1.975e-05 \n",
      "     | > step_time: 0.4723  (0.5251532171083534)\n",
      "     | > loader_time: 0.0344  (0.010218506274016007)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:48:49 -- STEP: 71/406 -- GLOBAL_STEP: 54875\u001b[0m\n",
      "     | > loss: -0.1410345733165741  (-0.15272818421813802)\n",
      "     | > log_mle: -0.3285447359085083  (-0.3134774154340717)\n",
      "     | > loss_dur: 0.1875101625919342  (0.16074923132087143)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(10.6790, device='cuda:0')  (tensor(27.0395, device='cuda:0'))\n",
      "     | > current_lr: 1.975e-05 \n",
      "     | > step_time: 0.6207  (0.5500326996118249)\n",
      "     | > loader_time: 0.0052  (0.010735696470233756)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:49:05 -- STEP: 96/406 -- GLOBAL_STEP: 54900\u001b[0m\n",
      "     | > loss: -0.13711047172546387  (-0.1511713971073429)\n",
      "     | > log_mle: -0.3223714828491211  (-0.31560639167825383)\n",
      "     | > loss_dur: 0.18526101112365723  (0.16443499464852113)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(44.3094, device='cuda:0')  (tensor(28.7925, device='cuda:0'))\n",
      "     | > current_lr: 1.975e-05 \n",
      "     | > step_time: 0.7168  (0.5688308402895929)\n",
      "     | > loader_time: 0.0052  (0.011019632220268244)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:49:21 -- STEP: 121/406 -- GLOBAL_STEP: 54925\u001b[0m\n",
      "     | > loss: -0.15973937511444092  (-0.15096210300429794)\n",
      "     | > log_mle: -0.3260948657989502  (-0.31801432912999933)\n",
      "     | > loss_dur: 0.16635549068450928  (0.16705222618727644)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(29.8137, device='cuda:0')  (tensor(30.8417, device='cuda:0'))\n",
      "     | > current_lr: 1.975e-05 \n",
      "     | > step_time: 0.7623  (0.5858493107409518)\n",
      "     | > loader_time: 0.0093  (0.011177971343363608)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:49:38 -- STEP: 146/406 -- GLOBAL_STEP: 54950\u001b[0m\n",
      "     | > loss: -0.14404965937137604  (-0.15063631085500326)\n",
      "     | > log_mle: -0.3224979639053345  (-0.32022836600264454)\n",
      "     | > loss_dur: 0.17844830453395844  (0.1695920551986727)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(38.3243, device='cuda:0')  (tensor(31.5005, device='cuda:0'))\n",
      "     | > current_lr: 1.975e-05 \n",
      "     | > step_time: 0.8361  (0.5976884185451352)\n",
      "     | > loader_time: 0.0298  (0.011522541307423207)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:49:56 -- STEP: 171/406 -- GLOBAL_STEP: 54975\u001b[0m\n",
      "     | > loss: -0.165083110332489  (-0.1500843070578157)\n",
      "     | > log_mle: -0.3379272222518921  (-0.32174109924606403)\n",
      "     | > loss_dur: 0.17284411191940308  (0.17165679223181907)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(56.3408, device='cuda:0')  (tensor(32.9797, device='cuda:0'))\n",
      "     | > current_lr: 1.975e-05 \n",
      "     | > step_time: 0.5984  (0.6100078465645772)\n",
      "     | > loader_time: 0.0065  (0.011594434927778632)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:50:14 -- STEP: 196/406 -- GLOBAL_STEP: 55000\u001b[0m\n",
      "     | > loss: -0.15201717615127563  (-0.14959721632149756)\n",
      "     | > log_mle: -0.33018290996551514  (-0.3227847516536712)\n",
      "     | > loss_dur: 0.1781657338142395  (0.1731875353701868)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(15.8680, device='cuda:0')  (tensor(33.5573, device='cuda:0'))\n",
      "     | > current_lr: 1.975e-05 \n",
      "     | > step_time: 0.7329  (0.6217052681105474)\n",
      "     | > loader_time: 0.0078  (0.011774834321469675)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:50:33 -- STEP: 221/406 -- GLOBAL_STEP: 55025\u001b[0m\n",
      "     | > loss: -0.12958180904388428  (-0.14963671423461097)\n",
      "     | > log_mle: -0.33422160148620605  (-0.3241342408624709)\n",
      "     | > loss_dur: 0.20463979244232178  (0.1744975266615729)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(34.4008, device='cuda:0')  (tensor(33.9471, device='cuda:0'))\n",
      "     | > current_lr: 1.975e-05 \n",
      "     | > step_time: 0.5557  (0.6346928393678962)\n",
      "     | > loader_time: 0.0054  (0.011652345571043263)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:50:52 -- STEP: 246/406 -- GLOBAL_STEP: 55050\u001b[0m\n",
      "     | > loss: -0.16017015278339386  (-0.14986925814452204)\n",
      "     | > log_mle: -0.33210551738739014  (-0.32554553727793495)\n",
      "     | > loss_dur: 0.17193536460399628  (0.17567627916369974)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(23.0385, device='cuda:0')  (tensor(34.5740, device='cuda:0'))\n",
      "     | > current_lr: 1.975e-05 \n",
      "     | > step_time: 0.7436  (0.6457170655087722)\n",
      "     | > loader_time: 0.0072  (0.011766431777457878)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:51:12 -- STEP: 271/406 -- GLOBAL_STEP: 55075\u001b[0m\n",
      "     | > loss: -0.1650959849357605  (-0.15039501462915283)\n",
      "     | > log_mle: -0.3460754156112671  (-0.3267012852144417)\n",
      "     | > loss_dur: 0.1809794306755066  (0.17630627061278173)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(41.4499, device='cuda:0')  (tensor(34.8329, device='cuda:0'))\n",
      "     | > current_lr: 1.975e-05 \n",
      "     | > step_time: 0.6102  (0.6586648538103839)\n",
      "     | > loader_time: 0.046  (0.012098865755369741)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:51:32 -- STEP: 296/406 -- GLOBAL_STEP: 55100\u001b[0m\n",
      "     | > loss: -0.1472730040550232  (-0.15056015963892683)\n",
      "     | > log_mle: -0.3438223600387573  (-0.32761584020949697)\n",
      "     | > loss_dur: 0.19654935598373413  (0.1770556805957411)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(37.7848, device='cuda:0')  (tensor(35.1896, device='cuda:0'))\n",
      "     | > current_lr: 1.975e-05 \n",
      "     | > step_time: 0.6501  (0.6686610007608255)\n",
      "     | > loader_time: 0.0269  (0.012303773615811323)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:51:52 -- STEP: 321/406 -- GLOBAL_STEP: 55125\u001b[0m\n",
      "     | > loss: -0.14315862953662872  (-0.15065592053894689)\n",
      "     | > log_mle: -0.3317629098892212  (-0.3285214633585136)\n",
      "     | > loss_dur: 0.18860428035259247  (0.17786554284277734)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(42.5073, device='cuda:0')  (tensor(35.6579, device='cuda:0'))\n",
      "     | > current_lr: 1.975e-05 \n",
      "     | > step_time: 0.8454  (0.6772359732155481)\n",
      "     | > loader_time: 0.0107  (0.0126108276509793)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:52:13 -- STEP: 346/406 -- GLOBAL_STEP: 55150\u001b[0m\n",
      "     | > loss: -0.1581897884607315  (-0.1506080185574604)\n",
      "     | > log_mle: -0.34517741203308105  (-0.3292777252335081)\n",
      "     | > loss_dur: 0.18698762357234955  (0.17866970669758106)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(17.3170, device='cuda:0')  (tensor(35.8865, device='cuda:0'))\n",
      "     | > current_lr: 1.975e-05 \n",
      "     | > step_time: 0.9192  (0.6877512256534104)\n",
      "     | > loader_time: 0.0079  (0.012782444154596053)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:52:35 -- STEP: 371/406 -- GLOBAL_STEP: 55175\u001b[0m\n",
      "     | > loss: -0.15597379207611084  (-0.15082728698086556)\n",
      "     | > log_mle: -0.3414449691772461  (-0.3301305179647361)\n",
      "     | > loss_dur: 0.18547117710113525  (0.17930323100395273)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(32.0112, device='cuda:0')  (tensor(36.2330, device='cuda:0'))\n",
      "     | > current_lr: 1.975e-05 \n",
      "     | > step_time: 0.7062  (0.6991360258220655)\n",
      "     | > loader_time: 0.0186  (0.012961016832336261)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:52:55 -- STEP: 396/406 -- GLOBAL_STEP: 55200\u001b[0m\n",
      "     | > loss: -0.15865573287010193  (-0.15110094694778178)\n",
      "     | > log_mle: -0.34827864170074463  (-0.3309132071456527)\n",
      "     | > loss_dur: 0.1896229088306427  (0.17981226021668517)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(31.8220, device='cuda:0')  (tensor(35.8296, device='cuda:0'))\n",
      "     | > current_lr: 1.975e-05 \n",
      "     | > step_time: 0.6201  (0.7044659738588808)\n",
      "     | > loader_time: 0.0083  (0.013068473098253963)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: -0.14433683454990387  (-0.14433683454990387)\n",
      "     | > log_mle: -0.3135547637939453  (-0.3135547637939453)\n",
      "     | > loss_dur: 0.16921792924404144  (0.16921792924404144)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: -0.18711765110492706  (-0.18711765110492706)\n",
      "     | > log_mle: -0.35591673851013184  (-0.35591673851013184)\n",
      "     | > loss_dur: 0.16879908740520477  (0.16879908740520477)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: -0.19885388016700745  (-0.19298576563596725)\n",
      "     | > log_mle: -0.32091331481933594  (-0.3384150266647339)\n",
      "     | > loss_dur: 0.12205944210290909  (0.14542926475405693)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: -0.1814834326505661  (-0.18915165464083353)\n",
      "     | > log_mle: -0.3276735544204712  (-0.3348345359166463)\n",
      "     | > loss_dur: 0.1461901217699051  (0.14568288375933966)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: -0.19431616365909576  (-0.1904427818953991)\n",
      "     | > log_mle: -0.35369551181793213  (-0.3395497798919678)\n",
      "     | > loss_dur: 0.15937934815883636  (0.14910699985921383)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: -0.19036564230918884  (-0.19042735397815705)\n",
      "     | > log_mle: -0.3551666736602783  (-0.34267315864562986)\n",
      "     | > loss_dur: 0.16480103135108948  (0.15224580615758895)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: -0.1346648633480072  (-0.18113360553979874)\n",
      "     | > log_mle: -0.36457204818725586  (-0.3463229735692342)\n",
      "     | > loss_dur: 0.22990718483924866  (0.1651893692711989)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: -0.1690242737531662  (-0.17940370099885122)\n",
      "     | > log_mle: -0.3249986171722412  (-0.34327663694109234)\n",
      "     | > loss_dur: 0.155974343419075  (0.1638729370066098)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: -0.18734358251094818  (-0.18039618618786335)\n",
      "     | > log_mle: -0.33830809593200684  (-0.34265556931495667)\n",
      "     | > loss_dur: 0.15096451342105865  (0.1622593840584159)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: -0.16762106120586395  (-0.17897672785653007)\n",
      "     | > log_mle: -0.3514136075973511  (-0.3436286846796672)\n",
      "     | > loss_dur: 0.18379254639148712  (0.16465195765097937)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: -0.14629340171813965  (-0.17570839524269105)\n",
      "     | > log_mle: -0.33701300621032715  (-0.3429671168327332)\n",
      "     | > loss_dur: 0.1907196044921875  (0.16725872233510017)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: -0.16826632618904114  (-0.17503184351054105)\n",
      "     | > log_mle: -0.3538515567779541  (-0.34395661137320777)\n",
      "     | > loss_dur: 0.18558523058891296  (0.16892476853999225)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: -0.18230608105659485  (-0.1756380299727122)\n",
      "     | > log_mle: -0.33907389640808105  (-0.3435497184594472)\n",
      "     | > loss_dur: 0.1567678153514862  (0.16791168910761675)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: -0.19557435810565948  (-0.1771715936752466)\n",
      "     | > log_mle: -0.3630819320678711  (-0.345052196429326)\n",
      "     | > loss_dur: 0.1675075739622116  (0.16788060332720095)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: -0.1701640486717224  (-0.17667105474642344)\n",
      "     | > log_mle: -0.3508412837982178  (-0.3454657026699611)\n",
      "     | > loss_dur: 0.18067723512649536  (0.16879464845572198)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: -0.17581525444984436  (-0.17661400139331818)\n",
      "     | > log_mle: -0.34397268295288086  (-0.34536616802215575)\n",
      "     | > loss_dur: 0.1681574285030365  (0.16875216712554295)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: -0.16725166141986847  (-0.17602885514497757)\n",
      "     | > log_mle: -0.34808218479156494  (-0.34553591907024384)\n",
      "     | > loss_dur: 0.18083052337169647  (0.16950706439092755)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: audio amplitude out of range, auto clipped.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.003938347101211548 \u001b[0m(-0.0007490068674087524)\n",
      "     | > avg_loss:\u001b[92m -0.17602885514497757 \u001b[0m(-0.0038790227845311165)\n",
      "     | > avg_log_mle:\u001b[92m -0.34553591907024384 \u001b[0m(-0.002160176634788513)\n",
      "     | > avg_loss_dur:\u001b[92m 0.16950706439092755 \u001b[0m(-0.0017188461497426033)\n",
      "\n",
      " > BEST MODEL : train/run-February-22-2025_10+59PM-fa84af3/best_model_55210.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 80/100\u001b[0m\n",
      " --> train/run-February-22-2025_10+59PM-fa84af3\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-23 05:53:18) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:53:26 -- STEP: 15/406 -- GLOBAL_STEP: 55225\u001b[0m\n",
      "     | > loss: -0.15588431060314178  (-0.17403334975242615)\n",
      "     | > log_mle: -0.31775975227355957  (-0.318018118540446)\n",
      "     | > loss_dur: 0.16187544167041779  (0.14398476878801986)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(40.5282, device='cuda:0')  (tensor(41.1512, device='cuda:0'))\n",
      "     | > current_lr: 1.9999999999999998e-05 \n",
      "     | > step_time: 0.6587  (0.4056229750315348)\n",
      "     | > loader_time: 0.013  (0.007097816467285157)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:53:42 -- STEP: 40/406 -- GLOBAL_STEP: 55250\u001b[0m\n",
      "     | > loss: -0.1474679559469223  (-0.1643302194774151)\n",
      "     | > log_mle: -0.29739534854888916  (-0.31572172939777376)\n",
      "     | > loss_dur: 0.14992739260196686  (0.1513915099203587)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(21.1315, device='cuda:0')  (tensor(33.8115, device='cuda:0'))\n",
      "     | > current_lr: 1.9999999999999998e-05 \n",
      "     | > step_time: 0.4712  (0.5267943739891052)\n",
      "     | > loader_time: 0.0045  (0.009371179342269897)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:53:57 -- STEP: 65/406 -- GLOBAL_STEP: 55275\u001b[0m\n",
      "     | > loss: -0.1540246605873108  (-0.1594844428392557)\n",
      "     | > log_mle: -0.31411290168762207  (-0.31713733489696794)\n",
      "     | > loss_dur: 0.16008824110031128  (0.15765289205771232)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(23.1504, device='cuda:0')  (tensor(32.1810, device='cuda:0'))\n",
      "     | > current_lr: 1.9999999999999998e-05 \n",
      "     | > step_time: 0.8457  (0.5584708360525273)\n",
      "     | > loader_time: 0.0106  (0.009925035329965448)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:54:12 -- STEP: 90/406 -- GLOBAL_STEP: 55300\u001b[0m\n",
      "     | > loss: -0.15946754813194275  (-0.1579777682820955)\n",
      "     | > log_mle: -0.33274292945861816  (-0.3194461146990457)\n",
      "     | > loss_dur: 0.17327538132667542  (0.16146834641695026)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(34.0193, device='cuda:0')  (tensor(32.9423, device='cuda:0'))\n",
      "     | > current_lr: 1.9999999999999998e-05 \n",
      "     | > step_time: 0.776  (0.5663553979661725)\n",
      "     | > loader_time: 0.004  (0.00992354551951091)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:54:29 -- STEP: 115/406 -- GLOBAL_STEP: 55325\u001b[0m\n",
      "     | > loss: -0.13467799127101898  (-0.1567911426658215)\n",
      "     | > log_mle: -0.3159703016281128  (-0.32189487374347187)\n",
      "     | > loss_dur: 0.1812923103570938  (0.1651037310776504)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(16.2727, device='cuda:0')  (tensor(31.1399, device='cuda:0'))\n",
      "     | > current_lr: 1.9999999999999998e-05 \n",
      "     | > step_time: 0.8078  (0.5860500045444652)\n",
      "     | > loader_time: 0.0226  (0.010653622254081398)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:54:46 -- STEP: 140/406 -- GLOBAL_STEP: 55350\u001b[0m\n",
      "     | > loss: -0.15620961785316467  (-0.15540451354214116)\n",
      "     | > log_mle: -0.3389146327972412  (-0.32360039779118127)\n",
      "     | > loss_dur: 0.18270501494407654  (0.1681958842490401)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(27.3917, device='cuda:0')  (tensor(33.3614, device='cuda:0'))\n",
      "     | > current_lr: 1.9999999999999998e-05 \n",
      "     | > step_time: 0.5052  (0.5958829913820536)\n",
      "     | > loader_time: 0.0069  (0.011072213309151788)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:55:04 -- STEP: 165/406 -- GLOBAL_STEP: 55375\u001b[0m\n",
      "     | > loss: -0.16443698108196259  (-0.15416843367345398)\n",
      "     | > log_mle: -0.35255706310272217  (-0.32477361577929875)\n",
      "     | > loss_dur: 0.18812008202075958  (0.17060518210584466)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(80.5889, device='cuda:0')  (tensor(34.7779, device='cuda:0'))\n",
      "     | > current_lr: 1.9999999999999998e-05 \n",
      "     | > step_time: 0.5299  (0.612464755954164)\n",
      "     | > loader_time: 0.008  (0.011784059351140803)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:55:22 -- STEP: 190/406 -- GLOBAL_STEP: 55400\u001b[0m\n",
      "     | > loss: -0.14359141886234283  (-0.15393745428637443)\n",
      "     | > log_mle: -0.3409309387207031  (-0.32585382147839204)\n",
      "     | > loss_dur: 0.1973395198583603  (0.17191636719201742)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(40.4650, device='cuda:0')  (tensor(34.4768, device='cuda:0'))\n",
      "     | > current_lr: 1.9999999999999998e-05 \n",
      "     | > step_time: 0.6849  (0.6245071185262575)\n",
      "     | > loader_time: 0.007  (0.01195331749163176)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:55:40 -- STEP: 215/406 -- GLOBAL_STEP: 55425\u001b[0m\n",
      "     | > loss: -0.149883434176445  (-0.15378090455088494)\n",
      "     | > log_mle: -0.3314330577850342  (-0.32688383834306584)\n",
      "     | > loss_dur: 0.18154962360858917  (0.17310293379218078)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(33.9102, device='cuda:0')  (tensor(35.1217, device='cuda:0'))\n",
      "     | > current_lr: 1.9999999999999998e-05 \n",
      "     | > step_time: 0.6056  (0.6346881123476248)\n",
      "     | > loader_time: 0.0071  (0.012364831081656523)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:56:00 -- STEP: 240/406 -- GLOBAL_STEP: 55450\u001b[0m\n",
      "     | > loss: -0.17578968405723572  (-0.15395344899346422)\n",
      "     | > log_mle: -0.35106217861175537  (-0.32840286642313005)\n",
      "     | > loss_dur: 0.17527249455451965  (0.17444941742966572)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(42.9270, device='cuda:0')  (tensor(35.6926, device='cuda:0'))\n",
      "     | > current_lr: 1.9999999999999998e-05 \n",
      "     | > step_time: 0.7993  (0.6474574397007622)\n",
      "     | > loader_time: 0.0195  (0.012804097930590312)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:56:21 -- STEP: 265/406 -- GLOBAL_STEP: 55475\u001b[0m\n",
      "     | > loss: -0.15465810894966125  (-0.15417696721148932)\n",
      "     | > log_mle: -0.3420771360397339  (-0.329568911948294)\n",
      "     | > loss_dur: 0.18741902709007263  (0.1753919447368046)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(37.7609, device='cuda:0')  (tensor(36.0258, device='cuda:0'))\n",
      "     | > current_lr: 1.9999999999999998e-05 \n",
      "     | > step_time: 0.8251  (0.6621055405094937)\n",
      "     | > loader_time: 0.0098  (0.01284723551768177)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:56:40 -- STEP: 290/406 -- GLOBAL_STEP: 55500\u001b[0m\n",
      "     | > loss: -0.1725628823041916  (-0.15433572273829882)\n",
      "     | > log_mle: -0.35132408142089844  (-0.33047090111107663)\n",
      "     | > loss_dur: 0.17876119911670685  (0.17613517837277773)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(26.8737, device='cuda:0')  (tensor(35.9879, device='cuda:0'))\n",
      "     | > current_lr: 1.9999999999999998e-05 \n",
      "     | > step_time: 0.5781  (0.6697176678427332)\n",
      "     | > loader_time: 0.0145  (0.013170251353033657)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:57:00 -- STEP: 315/406 -- GLOBAL_STEP: 55525\u001b[0m\n",
      "     | > loss: -0.1493043452501297  (-0.15437243916685617)\n",
      "     | > log_mle: -0.33743226528167725  (-0.3313277721405029)\n",
      "     | > loss_dur: 0.18812792003154755  (0.1769553329736467)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(49.4649, device='cuda:0')  (tensor(35.9773, device='cuda:0'))\n",
      "     | > current_lr: 1.9999999999999998e-05 \n",
      "     | > step_time: 0.6113  (0.6795401997036401)\n",
      "     | > loader_time: 0.0061  (0.013329921449933732)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:57:21 -- STEP: 340/406 -- GLOBAL_STEP: 55550\u001b[0m\n",
      "     | > loss: -0.14553487300872803  (-0.1539772444349878)\n",
      "     | > log_mle: -0.33079779148101807  (-0.3318696123712202)\n",
      "     | > loss_dur: 0.18526291847229004  (0.1778923679362325)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(18.8171, device='cuda:0')  (tensor(36.5495, device='cuda:0'))\n",
      "     | > current_lr: 1.9999999999999998e-05 \n",
      "     | > step_time: 0.7546  (0.6892162393121155)\n",
      "     | > loader_time: 0.0637  (0.01371625311234418)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:57:43 -- STEP: 365/406 -- GLOBAL_STEP: 55575\u001b[0m\n",
      "     | > loss: -0.1611667275428772  (-0.1539807048154203)\n",
      "     | > log_mle: -0.34413647651672363  (-0.33259475655751675)\n",
      "     | > loss_dur: 0.18296974897384644  (0.17861405174209644)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(31.7913, device='cuda:0')  (tensor(36.3549, device='cuda:0'))\n",
      "     | > current_lr: 1.9999999999999998e-05 \n",
      "     | > step_time: 0.8716  (0.7003427877818067)\n",
      "     | > loader_time: 0.0217  (0.013900624236015425)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:58:06 -- STEP: 390/406 -- GLOBAL_STEP: 55600\u001b[0m\n",
      "     | > loss: -0.1571064442396164  (-0.15407529992934985)\n",
      "     | > log_mle: -0.34786713123321533  (-0.333255832011883)\n",
      "     | > loss_dur: 0.19076068699359894  (0.17918053208253318)\n",
      "     | > amp_scaler: 1024.0  (2045.374358974359)\n",
      "     | > grad_norm: 0  (tensor(36.9332, device='cuda:0'))\n",
      "     | > current_lr: 1.9999999999999998e-05 \n",
      "     | > step_time: 0.5698  (0.7116049931599542)\n",
      "     | > loader_time: 0.0172  (0.01412978233435215)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: -0.1472592055797577  (-0.1472592055797577)\n",
      "     | > log_mle: -0.3150373697280884  (-0.3150373697280884)\n",
      "     | > loss_dur: 0.1677781641483307  (0.1677781641483307)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: -0.1900804340839386  (-0.1900804340839386)\n",
      "     | > log_mle: -0.35680198669433594  (-0.35680198669433594)\n",
      "     | > loss_dur: 0.16672155261039734  (0.16672155261039734)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: -0.1971583068370819  (-0.19361937046051025)\n",
      "     | > log_mle: -0.32226014137268066  (-0.3395310640335083)\n",
      "     | > loss_dur: 0.12510183453559875  (0.14591169357299805)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: -0.18402566015720367  (-0.19042146702607474)\n",
      "     | > log_mle: -0.3296985626220703  (-0.336253563563029)\n",
      "     | > loss_dur: 0.14567290246486664  (0.14583209653695425)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: -0.20047791302204132  (-0.19293557852506638)\n",
      "     | > log_mle: -0.35415661334991455  (-0.34072932600975037)\n",
      "     | > loss_dur: 0.15367870032787323  (0.147793747484684)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: -0.1879488080739975  (-0.1919382244348526)\n",
      "     | > log_mle: -0.3564326763153076  (-0.3438699960708618)\n",
      "     | > loss_dur: 0.16848386824131012  (0.1519317716360092)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: -0.14011569321155548  (-0.1833011358976364)\n",
      "     | > log_mle: -0.3657418489456177  (-0.3475153048833211)\n",
      "     | > loss_dur: 0.2256261557340622  (0.16421416898568472)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: -0.17402777075767517  (-0.18197636944907053)\n",
      "     | > log_mle: -0.3264862298965454  (-0.34451115131378174)\n",
      "     | > loss_dur: 0.15245845913887024  (0.1625347818647112)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: -0.18454042077064514  (-0.18229687586426735)\n",
      "     | > log_mle: -0.3398393392562866  (-0.34392717480659485)\n",
      "     | > loss_dur: 0.15529891848564148  (0.1616302989423275)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: -0.17246270179748535  (-0.18120418985684714)\n",
      "     | > log_mle: -0.3517948389053345  (-0.3448013597064548)\n",
      "     | > loss_dur: 0.17933213710784912  (0.16359716984960768)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: -0.15156908333301544  (-0.17824067920446396)\n",
      "     | > log_mle: -0.33800947666168213  (-0.34412217140197754)\n",
      "     | > loss_dur: 0.1864403933286667  (0.16588149219751358)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: -0.17878352105617523  (-0.17829002846371045)\n",
      "     | > log_mle: -0.35441720485687256  (-0.3450580835342407)\n",
      "     | > loss_dur: 0.17563368380069733  (0.16676805507053027)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: -0.1887803077697754  (-0.1791642184058825)\n",
      "     | > log_mle: -0.34048545360565186  (-0.34467703104019165)\n",
      "     | > loss_dur: 0.15170514583587646  (0.16551281263430914)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: -0.19801059365272522  (-0.18061393957871658)\n",
      "     | > log_mle: -0.36445140838623047  (-0.34619813698988694)\n",
      "     | > loss_dur: 0.16644081473350525  (0.16558419741117036)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: -0.17595314979553223  (-0.18028102602277482)\n",
      "     | > log_mle: -0.3518242835998535  (-0.34660000460488455)\n",
      "     | > loss_dur: 0.1758711338043213  (0.16631897858210973)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: -0.17597846686840057  (-0.17999418874581655)\n",
      "     | > log_mle: -0.3449573516845703  (-0.3464904944101969)\n",
      "     | > loss_dur: 0.16897888481616974  (0.1664963056643804)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: -0.17711634933948517  (-0.17981432378292084)\n",
      "     | > log_mle: -0.3490297794342041  (-0.3466491997241974)\n",
      "     | > loss_dur: 0.17191343009471893  (0.16683487594127655)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: audio amplitude out of range, auto clipped.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.0035561025142669678 \u001b[0m(-0.0003822445869445801)\n",
      "     | > avg_loss:\u001b[92m -0.17981432378292084 \u001b[0m(-0.003785468637943268)\n",
      "     | > avg_log_mle:\u001b[92m -0.3466491997241974 \u001b[0m(-0.0011132806539535522)\n",
      "     | > avg_loss_dur:\u001b[92m 0.16683487594127655 \u001b[0m(-0.002672188449651003)\n",
      "\n",
      " > BEST MODEL : train/run-February-22-2025_10+59PM-fa84af3/best_model_55616.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 81/100\u001b[0m\n",
      " --> train/run-February-22-2025_10+59PM-fa84af3\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-23 05:58:31) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:58:38 -- STEP: 9/406 -- GLOBAL_STEP: 55625\u001b[0m\n",
      "     | > loss: -0.15091855823993683  (-0.17899363570743138)\n",
      "     | > log_mle: -0.320245623588562  (-0.3178691864013672)\n",
      "     | > loss_dur: 0.16932706534862518  (0.13887554903825125)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(20.4426, device='cuda:0')  (tensor(32.7755, device='cuda:0'))\n",
      "     | > current_lr: 2.025e-05 \n",
      "     | > step_time: 0.2924  (0.41957105530632866)\n",
      "     | > loader_time: 0.0113  (0.005313105053371853)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:58:53 -- STEP: 34/406 -- GLOBAL_STEP: 55650\u001b[0m\n",
      "     | > loss: -0.15171606838703156  (-0.16686954568414128)\n",
      "     | > log_mle: -0.31039202213287354  (-0.3170101046562195)\n",
      "     | > loss_dur: 0.15867595374584198  (0.15014055853380873)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(6.1070, device='cuda:0')  (tensor(26.6017, device='cuda:0'))\n",
      "     | > current_lr: 2.025e-05 \n",
      "     | > step_time: 0.6415  (0.5310369940365062)\n",
      "     | > loader_time: 0.0256  (0.010622220880845017)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:59:09 -- STEP: 59/406 -- GLOBAL_STEP: 55675\u001b[0m\n",
      "     | > loss: -0.13802817463874817  (-0.15619840662358164)\n",
      "     | > log_mle: -0.31084907054901123  (-0.3142812757168786)\n",
      "     | > loss_dur: 0.17282089591026306  (0.15808286884073483)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(38.2510, device='cuda:0')  (tensor(28.9518, device='cuda:0'))\n",
      "     | > current_lr: 2.025e-05 \n",
      "     | > step_time: 0.5466  (0.5689155489711436)\n",
      "     | > loader_time: 0.0068  (0.012247897810855156)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:59:25 -- STEP: 84/406 -- GLOBAL_STEP: 55700\u001b[0m\n",
      "     | > loss: -0.15634596347808838  (-0.15504645822303623)\n",
      "     | > log_mle: -0.33033502101898193  (-0.31687525482404805)\n",
      "     | > loss_dur: 0.17398905754089355  (0.1618287964236169)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(13.8446, device='cuda:0')  (tensor(31.0710, device='cuda:0'))\n",
      "     | > current_lr: 2.025e-05 \n",
      "     | > step_time: 0.7243  (0.5833733081817625)\n",
      "     | > loader_time: 0.0066  (0.011568358966282439)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:59:41 -- STEP: 109/406 -- GLOBAL_STEP: 55725\u001b[0m\n",
      "     | > loss: -0.15518704056739807  (-0.15467142703336303)\n",
      "     | > log_mle: -0.3395015001296997  (-0.3196098946650095)\n",
      "     | > loss_dur: 0.18431445956230164  (0.16493846749493837)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(47.5373, device='cuda:0')  (tensor(33.4924, device='cuda:0'))\n",
      "     | > current_lr: 2.025e-05 \n",
      "     | > step_time: 0.4064  (0.5952113527770436)\n",
      "     | > loader_time: 0.0084  (0.011199953359201415)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 05:59:59 -- STEP: 134/406 -- GLOBAL_STEP: 55750\u001b[0m\n",
      "     | > loss: -0.12608681619167328  (-0.15412841414782533)\n",
      "     | > log_mle: -0.3200109004974365  (-0.321780841741989)\n",
      "     | > loss_dur: 0.19392408430576324  (0.16765242748296083)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(50.9627, device='cuda:0')  (tensor(34.8724, device='cuda:0'))\n",
      "     | > current_lr: 2.025e-05 \n",
      "     | > step_time: 0.4865  (0.6095988163307532)\n",
      "     | > loader_time: 0.0091  (0.011365225065999959)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:00:16 -- STEP: 159/406 -- GLOBAL_STEP: 55775\u001b[0m\n",
      "     | > loss: -0.14847910404205322  (-0.15282654865357853)\n",
      "     | > log_mle: -0.33207619190216064  (-0.3232027022343763)\n",
      "     | > loss_dur: 0.18359708786010742  (0.17037615348707955)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(23.2421, device='cuda:0')  (tensor(33.6040, device='cuda:0'))\n",
      "     | > current_lr: 2.025e-05 \n",
      "     | > step_time: 0.6044  (0.6231465819496781)\n",
      "     | > loader_time: 0.0246  (0.0118284210468988)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:00:34 -- STEP: 184/406 -- GLOBAL_STEP: 55800\u001b[0m\n",
      "     | > loss: -0.13321880996227264  (-0.15276120044291014)\n",
      "     | > log_mle: -0.337505578994751  (-0.3245110252629158)\n",
      "     | > loss_dur: 0.20428676903247833  (0.17174982473902078)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(39.3232, device='cuda:0')  (tensor(34.5826, device='cuda:0'))\n",
      "     | > current_lr: 2.025e-05 \n",
      "     | > step_time: 0.6592  (0.6335519837296532)\n",
      "     | > loader_time: 0.0053  (0.012140376412350199)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:00:54 -- STEP: 209/406 -- GLOBAL_STEP: 55825\u001b[0m\n",
      "     | > loss: -0.1655011773109436  (-0.15266476550170674)\n",
      "     | > log_mle: -0.33961379528045654  (-0.3257986695002142)\n",
      "     | > loss_dur: 0.17411261796951294  (0.17313390392720984)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(50.5137, device='cuda:0')  (tensor(34.9937, device='cuda:0'))\n",
      "     | > current_lr: 2.025e-05 \n",
      "     | > step_time: 1.1763  (0.6465851929769567)\n",
      "     | > loader_time: 0.0081  (0.012990856855109548)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:01:12 -- STEP: 234/406 -- GLOBAL_STEP: 55850\u001b[0m\n",
      "     | > loss: -0.14833132922649384  (-0.15306706522774485)\n",
      "     | > log_mle: -0.34866249561309814  (-0.3275355340069177)\n",
      "     | > loss_dur: 0.2003311663866043  (0.1744684687154925)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(30.3514, device='cuda:0')  (tensor(35.3556, device='cuda:0'))\n",
      "     | > current_lr: 2.025e-05 \n",
      "     | > step_time: 0.7289  (0.6541687596557492)\n",
      "     | > loader_time: 0.0109  (0.013230802666427743)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:01:32 -- STEP: 259/406 -- GLOBAL_STEP: 55875\u001b[0m\n",
      "     | > loss: -0.15604695677757263  (-0.1535141003753227)\n",
      "     | > log_mle: -0.35753297805786133  (-0.3289484103213867)\n",
      "     | > loss_dur: 0.2014860212802887  (0.17543430988853043)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(58.5084, device='cuda:0')  (tensor(35.9289, device='cuda:0'))\n",
      "     | > current_lr: 2.025e-05 \n",
      "     | > step_time: 0.7123  (0.6644057288593311)\n",
      "     | > loader_time: 0.0091  (0.01399383949957299)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:01:52 -- STEP: 284/406 -- GLOBAL_STEP: 55900\u001b[0m\n",
      "     | > loss: -0.14667250216007233  (-0.15420516407195942)\n",
      "     | > log_mle: -0.3492546081542969  (-0.3302620481437361)\n",
      "     | > loss_dur: 0.20258210599422455  (0.17605688401930764)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(36.9892, device='cuda:0')  (tensor(35.9886, device='cuda:0'))\n",
      "     | > current_lr: 2.025e-05 \n",
      "     | > step_time: 0.7658  (0.6762419477315021)\n",
      "     | > loader_time: 0.0216  (0.014311032395967292)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:02:13 -- STEP: 309/406 -- GLOBAL_STEP: 55925\u001b[0m\n",
      "     | > loss: -0.1717626303434372  (-0.15436048974497021)\n",
      "     | > log_mle: -0.3439204692840576  (-0.33119782082085475)\n",
      "     | > loss_dur: 0.17215783894062042  (0.1768373310276605)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(62.8380, device='cuda:0')  (tensor(35.6123, device='cuda:0'))\n",
      "     | > current_lr: 2.025e-05 \n",
      "     | > step_time: 0.7917  (0.6876878607234528)\n",
      "     | > loader_time: 0.0125  (0.014356620103410144)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:02:34 -- STEP: 334/406 -- GLOBAL_STEP: 55950\u001b[0m\n",
      "     | > loss: -0.1549815684556961  (-0.1543177364918285)\n",
      "     | > log_mle: -0.3513423204421997  (-0.3319255752477818)\n",
      "     | > loss_dur: 0.1963607519865036  (0.1776078387113388)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(38.3313, device='cuda:0')  (tensor(36.6734, device='cuda:0'))\n",
      "     | > current_lr: 2.025e-05 \n",
      "     | > step_time: 0.8028  (0.6966679124775053)\n",
      "     | > loader_time: 0.0144  (0.014703230943508488)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:02:56 -- STEP: 359/406 -- GLOBAL_STEP: 55975\u001b[0m\n",
      "     | > loss: -0.14926716685295105  (-0.15448782146807155)\n",
      "     | > log_mle: -0.3355386257171631  (-0.33285084640747337)\n",
      "     | > loss_dur: 0.18627145886421204  (0.17836302489789416)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(39.1068, device='cuda:0')  (tensor(37.0605, device='cuda:0'))\n",
      "     | > current_lr: 2.025e-05 \n",
      "     | > step_time: 0.7905  (0.7080068037038398)\n",
      "     | > loader_time: 0.0518  (0.015051747430997969)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:03:19 -- STEP: 384/406 -- GLOBAL_STEP: 56000\u001b[0m\n",
      "     | > loss: -0.156979039311409  (-0.15465009010707326)\n",
      "     | > log_mle: -0.34551775455474854  (-0.3336041495203972)\n",
      "     | > loss_dur: 0.18853871524333954  (0.1789540593745187)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(43.2927, device='cuda:0')  (tensor(37.2423, device='cuda:0'))\n",
      "     | > current_lr: 2.025e-05 \n",
      "     | > step_time: 0.7327  (0.7195451818406587)\n",
      "     | > loader_time: 0.0098  (0.015419902900854744)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: -0.14664997160434723  (-0.14664997160434723)\n",
      "     | > log_mle: -0.3165297508239746  (-0.3165297508239746)\n",
      "     | > loss_dur: 0.16987977921962738  (0.16987977921962738)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: -0.18853749334812164  (-0.18853749334812164)\n",
      "     | > log_mle: -0.36009275913238525  (-0.36009275913238525)\n",
      "     | > loss_dur: 0.1715552657842636  (0.1715552657842636)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: -0.20395472645759583  (-0.19624610990285873)\n",
      "     | > log_mle: -0.3239189386367798  (-0.3420058488845825)\n",
      "     | > loss_dur: 0.11996421217918396  (0.14575973898172379)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: -0.17770950496196747  (-0.1900672415892283)\n",
      "     | > log_mle: -0.3315340280532837  (-0.3385152419408162)\n",
      "     | > loss_dur: 0.15382452309131622  (0.14844800035158792)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: -0.19692115485668182  (-0.1917807199060917)\n",
      "     | > log_mle: -0.35765206813812256  (-0.3432994484901428)\n",
      "     | > loss_dur: 0.16073091328144073  (0.15151872858405113)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: -0.20071198046207428  (-0.1935669720172882)\n",
      "     | > log_mle: -0.3595771789550781  (-0.3465549945831299)\n",
      "     | > loss_dur: 0.15886519849300385  (0.15298802256584168)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: -0.14576959609985352  (-0.18560074269771576)\n",
      "     | > log_mle: -0.36931324005126953  (-0.3503480354944865)\n",
      "     | > loss_dur: 0.22354364395141602  (0.16474729279677072)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: -0.16922377049922943  (-0.18326117524078914)\n",
      "     | > log_mle: -0.3292884826660156  (-0.34733952794756207)\n",
      "     | > loss_dur: 0.1600647121667862  (0.16407835270677293)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: -0.1891648769378662  (-0.18399913795292377)\n",
      "     | > log_mle: -0.34292030334472656  (-0.34678712487220764)\n",
      "     | > loss_dur: 0.15375542640686035  (0.16278798691928387)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: -0.18068274855613708  (-0.1836306502421697)\n",
      "     | > log_mle: -0.354949951171875  (-0.3476941055721707)\n",
      "     | > loss_dur: 0.17426720261573792  (0.164063455330001)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: -0.1586383581161499  (-0.18113142102956772)\n",
      "     | > log_mle: -0.3411902189254761  (-0.34704371690750124)\n",
      "     | > loss_dur: 0.18255186080932617  (0.1659122958779335)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: -0.1810169816017151  (-0.18112101744521747)\n",
      "     | > log_mle: -0.35758495330810547  (-0.348002011125738)\n",
      "     | > loss_dur: 0.17656797170639038  (0.16688099368052048)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: -0.19829551875591278  (-0.18255222588777542)\n",
      "     | > log_mle: -0.3432624340057373  (-0.3476070463657379)\n",
      "     | > loss_dur: 0.14496691524982452  (0.16505482047796247)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: -0.2032410204410553  (-0.1841436716226431)\n",
      "     | > log_mle: -0.36730897426605225  (-0.3491225792811467)\n",
      "     | > loss_dur: 0.16406795382499695  (0.16497890765850357)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: -0.1781042367219925  (-0.1837122834154538)\n",
      "     | > log_mle: -0.3544270992279053  (-0.34950147356305805)\n",
      "     | > loss_dur: 0.17632286250591278  (0.16578919014760424)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: -0.1748162806034088  (-0.18311921656131744)\n",
      "     | > log_mle: -0.3472275733947754  (-0.3493498802185059)\n",
      "     | > loss_dur: 0.17241129279136658  (0.1662306636571884)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: -0.1738995462656021  (-0.18254298716783524)\n",
      "     | > log_mle: -0.35213255882263184  (-0.34952379763126373)\n",
      "     | > loss_dur: 0.17823301255702972  (0.16698081046342847)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: audio amplitude out of range, auto clipped.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[91m 0.004763677716255188 \u001b[0m(+0.0012075752019882202)\n",
      "     | > avg_loss:\u001b[92m -0.18254298716783524 \u001b[0m(-0.002728663384914398)\n",
      "     | > avg_log_mle:\u001b[92m -0.34952379763126373 \u001b[0m(-0.002874597907066345)\n",
      "     | > avg_loss_dur:\u001b[91m 0.16698081046342847 \u001b[0m(+0.00014593452215191927)\n",
      "\n",
      " > BEST MODEL : train/run-February-22-2025_10+59PM-fa84af3/best_model_56022.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 82/100\u001b[0m\n",
      " --> train/run-February-22-2025_10+59PM-fa84af3\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-23 06:03:52) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:03:56 -- STEP: 3/406 -- GLOBAL_STEP: 56025\u001b[0m\n",
      "     | > loss: -0.17343711853027344  (-0.1892613818248113)\n",
      "     | > log_mle: -0.32447731494903564  (-0.3258732557296753)\n",
      "     | > loss_dur: 0.1510401964187622  (0.13661187390486398)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(55.6301, device='cuda:0')  (tensor(35.9005, device='cuda:0'))\n",
      "     | > current_lr: 2.05e-05 \n",
      "     | > step_time: 0.3659  (0.47834014892578125)\n",
      "     | > loader_time: 0.0051  (0.018703381220499676)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:04:09 -- STEP: 28/406 -- GLOBAL_STEP: 56050\u001b[0m\n",
      "     | > loss: -0.14598338305950165  (-0.16883559791105135)\n",
      "     | > log_mle: -0.3177868127822876  (-0.31697726249694824)\n",
      "     | > loss_dur: 0.17180342972278595  (0.14814166485198907)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(20.9610, device='cuda:0')  (tensor(34.0488, device='cuda:0'))\n",
      "     | > current_lr: 2.05e-05 \n",
      "     | > step_time: 0.3567  (0.5014485801969256)\n",
      "     | > loader_time: 0.0053  (0.00819070850099836)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:04:25 -- STEP: 53/406 -- GLOBAL_STEP: 56075\u001b[0m\n",
      "     | > loss: -0.16095879673957825  (-0.15999736707165557)\n",
      "     | > log_mle: -0.31255459785461426  (-0.3155029404838132)\n",
      "     | > loss_dur: 0.151595801115036  (0.15550557355273445)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(33.4064, device='cuda:0')  (tensor(29.9234, device='cuda:0'))\n",
      "     | > current_lr: 2.05e-05 \n",
      "     | > step_time: 0.4829  (0.5580348158782382)\n",
      "     | > loader_time: 0.0055  (0.008461664307792235)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:04:40 -- STEP: 78/406 -- GLOBAL_STEP: 56100\u001b[0m\n",
      "     | > loss: -0.1717449128627777  (-0.15858473265782377)\n",
      "     | > log_mle: -0.3239719867706299  (-0.31777018155807124)\n",
      "     | > loss_dur: 0.15222707390785217  (0.1591854489957675)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(39.2807, device='cuda:0')  (tensor(30.6435, device='cuda:0'))\n",
      "     | > current_lr: 2.05e-05 \n",
      "     | > step_time: 0.5863  (0.5756403391177839)\n",
      "     | > loader_time: 0.0175  (0.008733617953765092)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:04:56 -- STEP: 103/406 -- GLOBAL_STEP: 56125\u001b[0m\n",
      "     | > loss: -0.16454273462295532  (-0.15809890642328167)\n",
      "     | > log_mle: -0.3405340909957886  (-0.3213263530175663)\n",
      "     | > loss_dur: 0.17599135637283325  (0.1632274466666203)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(43.0378, device='cuda:0')  (tensor(31.5681, device='cuda:0'))\n",
      "     | > current_lr: 2.05e-05 \n",
      "     | > step_time: 0.6739  (0.5877744364506992)\n",
      "     | > loader_time: 0.0076  (0.009625645517145547)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:05:13 -- STEP: 128/406 -- GLOBAL_STEP: 56150\u001b[0m\n",
      "     | > loss: -0.16198042035102844  (-0.15780972514767197)\n",
      "     | > log_mle: -0.33001065254211426  (-0.3238142291083932)\n",
      "     | > loss_dur: 0.16803023219108582  (0.16600450401892886)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(71.1580, device='cuda:0')  (tensor(32.6677, device='cuda:0'))\n",
      "     | > current_lr: 2.05e-05 \n",
      "     | > step_time: 0.4664  (0.6015427839010954)\n",
      "     | > loader_time: 0.0075  (0.009762302041053772)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:05:31 -- STEP: 153/406 -- GLOBAL_STEP: 56175\u001b[0m\n",
      "     | > loss: -0.16446706652641296  (-0.15720345975916367)\n",
      "     | > log_mle: -0.3414754867553711  (-0.3257080176297356)\n",
      "     | > loss_dur: 0.17700842022895813  (0.16850455791926852)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(32.2559, device='cuda:0')  (tensor(32.7502, device='cuda:0'))\n",
      "     | > current_lr: 2.05e-05 \n",
      "     | > step_time: 0.6425  (0.6147262987747691)\n",
      "     | > loader_time: 0.0193  (0.010103521783367483)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:05:48 -- STEP: 178/406 -- GLOBAL_STEP: 56200\u001b[0m\n",
      "     | > loss: -0.1536165326833725  (-0.15693812315048794)\n",
      "     | > log_mle: -0.32355964183807373  (-0.3268988460637211)\n",
      "     | > loss_dur: 0.16994310915470123  (0.16996072295509027)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(32.0512, device='cuda:0')  (tensor(33.5373, device='cuda:0'))\n",
      "     | > current_lr: 2.05e-05 \n",
      "     | > step_time: 0.8313  (0.6241305584318181)\n",
      "     | > loader_time: 0.0071  (0.010548303636272302)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:06:06 -- STEP: 203/406 -- GLOBAL_STEP: 56225\u001b[0m\n",
      "     | > loss: -0.14611594378948212  (-0.15664801941129378)\n",
      "     | > log_mle: -0.33394062519073486  (-0.32824631688630057)\n",
      "     | > loss_dur: 0.18782468140125275  (0.17159829751170916)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(30.0435, device='cuda:0')  (tensor(34.1075, device='cuda:0'))\n",
      "     | > current_lr: 2.05e-05 \n",
      "     | > step_time: 0.9187  (0.6328555433620966)\n",
      "     | > loader_time: 0.0111  (0.010868980379527425)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:06:25 -- STEP: 228/406 -- GLOBAL_STEP: 56250\u001b[0m\n",
      "     | > loss: -0.16128109395503998  (-0.15662887901590586)\n",
      "     | > log_mle: -0.33704066276550293  (-0.3295852039989673)\n",
      "     | > loss_dur: 0.17575956881046295  (0.1729563250157394)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(49.7087, device='cuda:0')  (tensor(33.9761, device='cuda:0'))\n",
      "     | > current_lr: 2.05e-05 \n",
      "     | > step_time: 0.9708  (0.6449793828161144)\n",
      "     | > loader_time: 0.006  (0.011042631509011252)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:06:44 -- STEP: 253/406 -- GLOBAL_STEP: 56275\u001b[0m\n",
      "     | > loss: -0.16851413249969482  (-0.15642750858082605)\n",
      "     | > log_mle: -0.35180485248565674  (-0.3306184964688871)\n",
      "     | > loss_dur: 0.18329071998596191  (0.17419098791750995)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(62.1018, device='cuda:0')  (tensor(34.6878, device='cuda:0'))\n",
      "     | > current_lr: 2.05e-05 \n",
      "     | > step_time: 0.6308  (0.6529991221522159)\n",
      "     | > loader_time: 0.0097  (0.011133801795748383)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:07:04 -- STEP: 278/406 -- GLOBAL_STEP: 56300\u001b[0m\n",
      "     | > loss: -0.15092387795448303  (-0.1564154262594182)\n",
      "     | > log_mle: -0.3321441411972046  (-0.33141698382741264)\n",
      "     | > loss_dur: 0.18122026324272156  (0.17500155759479502)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(21.5841, device='cuda:0')  (tensor(35.4107, device='cuda:0'))\n",
      "     | > current_lr: 2.05e-05 \n",
      "     | > step_time: 1.1632  (0.663752901468346)\n",
      "     | > loader_time: 0.0197  (0.011486420528494197)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:07:24 -- STEP: 303/406 -- GLOBAL_STEP: 56325\u001b[0m\n",
      "     | > loss: -0.13627755641937256  (-0.15627560855531852)\n",
      "     | > log_mle: -0.33849000930786133  (-0.3322545522116987)\n",
      "     | > loss_dur: 0.20221245288848877  (0.17597894368096928)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(102.7133, device='cuda:0')  (tensor(36.4435, device='cuda:0'))\n",
      "     | > current_lr: 2.05e-05 \n",
      "     | > step_time: 0.6567  (0.6745777555031357)\n",
      "     | > loader_time: 0.0066  (0.011655701269017587)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:07:45 -- STEP: 328/406 -- GLOBAL_STEP: 56350\u001b[0m\n",
      "     | > loss: -0.1514207273721695  (-0.1561601823877271)\n",
      "     | > log_mle: -0.35406041145324707  (-0.3328116935927697)\n",
      "     | > loss_dur: 0.20263968408107758  (0.17665151122775738)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(33.4863, device='cuda:0')  (tensor(36.4540, device='cuda:0'))\n",
      "     | > current_lr: 2.05e-05 \n",
      "     | > step_time: 1.0023  (0.6850951277628184)\n",
      "     | > loader_time: 0.0081  (0.011913059688195945)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:08:06 -- STEP: 353/406 -- GLOBAL_STEP: 56375\u001b[0m\n",
      "     | > loss: -0.15985797345638275  (-0.15587622986805677)\n",
      "     | > log_mle: -0.35714852809906006  (-0.3334695688388169)\n",
      "     | > loss_dur: 0.1972905546426773  (0.17759333899186613)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(41.3643, device='cuda:0')  (tensor(36.6982, device='cuda:0'))\n",
      "     | > current_lr: 2.05e-05 \n",
      "     | > step_time: 0.6683  (0.6941236233913872)\n",
      "     | > loader_time: 0.0211  (0.012240193720917522)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:08:28 -- STEP: 378/406 -- GLOBAL_STEP: 56400\u001b[0m\n",
      "     | > loss: -0.1459471583366394  (-0.1562452634412145)\n",
      "     | > log_mle: -0.3375340700149536  (-0.3343584171678658)\n",
      "     | > loss_dur: 0.1915869116783142  (0.1781131537463613)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(36.4755, device='cuda:0')  (tensor(37.3262, device='cuda:0'))\n",
      "     | > current_lr: 2.05e-05 \n",
      "     | > step_time: 0.8322  (0.7048240660359623)\n",
      "     | > loader_time: 0.0182  (0.012375871340433752)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:08:47 -- STEP: 403/406 -- GLOBAL_STEP: 56425\u001b[0m\n",
      "     | > loss: -0.16881471872329712  (-0.15635314997904945)\n",
      "     | > log_mle: -0.33794164657592773  (-0.3350176823050453)\n",
      "     | > loss_dur: 0.16912692785263062  (0.17866453234448312)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(24.2724, device='cuda:0')  (tensor(37.3277, device='cuda:0'))\n",
      "     | > current_lr: 2.05e-05 \n",
      "     | > step_time: 0.5962  (0.7071954162777508)\n",
      "     | > loader_time: 0.0097  (0.012403254473475601)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: -0.14377352595329285  (-0.14377352595329285)\n",
      "     | > log_mle: -0.3183577060699463  (-0.3183577060699463)\n",
      "     | > loss_dur: 0.17458418011665344  (0.17458418011665344)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: -0.19256015121936798  (-0.19256015121936798)\n",
      "     | > log_mle: -0.3615764379501343  (-0.3615764379501343)\n",
      "     | > loss_dur: 0.1690162867307663  (0.1690162867307663)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: -0.19966699182987213  (-0.19611357152462006)\n",
      "     | > log_mle: -0.32495343685150146  (-0.34326493740081787)\n",
      "     | > loss_dur: 0.12528644502162933  (0.14715136587619781)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: -0.18557561933994293  (-0.19260092079639435)\n",
      "     | > log_mle: -0.3326157331466675  (-0.3397152026494344)\n",
      "     | > loss_dur: 0.14704011380672455  (0.14711428185304007)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: -0.19924308359622955  (-0.19426146149635315)\n",
      "     | > log_mle: -0.35881364345550537  (-0.34448981285095215)\n",
      "     | > loss_dur: 0.15957055985927582  (0.150228351354599)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: -0.1991642713546753  (-0.19524202346801758)\n",
      "     | > log_mle: -0.3595341444015503  (-0.3474986791610718)\n",
      "     | > loss_dur: 0.160369873046875  (0.1522566556930542)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: -0.14339926838874817  (-0.18660156428813934)\n",
      "     | > log_mle: -0.3701363801956177  (-0.3512716293334961)\n",
      "     | > loss_dur: 0.2267371118068695  (0.16467006504535675)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: -0.17413316667079926  (-0.18482036462851933)\n",
      "     | > log_mle: -0.3301030397415161  (-0.34824754510607037)\n",
      "     | > loss_dur: 0.15596987307071686  (0.16342718047755106)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: -0.18802379071712494  (-0.18522079288959503)\n",
      "     | > log_mle: -0.3440309762954712  (-0.3477204740047455)\n",
      "     | > loss_dur: 0.15600718557834625  (0.16249968111515045)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: -0.1838621199131012  (-0.18506982922554016)\n",
      "     | > log_mle: -0.3565385341644287  (-0.34870025846693253)\n",
      "     | > loss_dur: 0.17267641425132751  (0.16363042924139234)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: -0.15868450701236725  (-0.18243129700422286)\n",
      "     | > log_mle: -0.3425295352935791  (-0.34808318614959716)\n",
      "     | > loss_dur: 0.18384502828121185  (0.1656518891453743)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: -0.18191944062709808  (-0.18238476460630243)\n",
      "     | > log_mle: -0.3591064214706421  (-0.3490852984515103)\n",
      "     | > loss_dur: 0.177186980843544  (0.16670053384520792)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: -0.19956804811954498  (-0.18381670489907265)\n",
      "     | > log_mle: -0.34400928020477295  (-0.3486622969309489)\n",
      "     | > loss_dur: 0.14444123208522797  (0.16484559203187624)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: -0.19712211191654205  (-0.1848401977465703)\n",
      "     | > log_mle: -0.3678992986679077  (-0.35014206629533035)\n",
      "     | > loss_dur: 0.17077718675136566  (0.16530186854876006)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: -0.17916780710220337  (-0.18443502698625838)\n",
      "     | > log_mle: -0.35614025592803955  (-0.3505705084119524)\n",
      "     | > loss_dur: 0.17697244882583618  (0.16613548142569406)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: -0.17949937283992767  (-0.184105983376503)\n",
      "     | > log_mle: -0.34841668605804443  (-0.35042692025502525)\n",
      "     | > loss_dur: 0.16891731321811676  (0.16632093687852223)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: -0.18321162462234497  (-0.18405008595436811)\n",
      "     | > log_mle: -0.35293567180633545  (-0.3505837172269821)\n",
      "     | > loss_dur: 0.16972404718399048  (0.166533631272614)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: audio amplitude out of range, auto clipped.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.004628106951713562 \u001b[0m(-0.00013557076454162598)\n",
      "     | > avg_loss:\u001b[92m -0.18405008595436811 \u001b[0m(-0.0015070987865328789)\n",
      "     | > avg_log_mle:\u001b[92m -0.3505837172269821 \u001b[0m(-0.0010599195957183838)\n",
      "     | > avg_loss_dur:\u001b[92m 0.166533631272614 \u001b[0m(-0.00044717919081446733)\n",
      "\n",
      " > BEST MODEL : train/run-February-22-2025_10+59PM-fa84af3/best_model_56428.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 83/100\u001b[0m\n",
      " --> train/run-February-22-2025_10+59PM-fa84af3\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-23 06:09:04) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:09:17 -- STEP: 22/406 -- GLOBAL_STEP: 56450\u001b[0m\n",
      "     | > loss: -0.15524403750896454  (-0.17300861396572806)\n",
      "     | > log_mle: -0.3062649965286255  (-0.3187147704037754)\n",
      "     | > loss_dur: 0.15102095901966095  (0.14570615609938448)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(56.8284, device='cuda:0')  (tensor(30.0324, device='cuda:0'))\n",
      "     | > current_lr: 2.075e-05 \n",
      "     | > step_time: 0.8294  (0.4773535836826671)\n",
      "     | > loader_time: 0.0173  (0.007553154771978205)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:09:33 -- STEP: 47/406 -- GLOBAL_STEP: 56475\u001b[0m\n",
      "     | > loss: -0.16438788175582886  (-0.16472853625074346)\n",
      "     | > log_mle: -0.3384655714035034  (-0.3174088407070079)\n",
      "     | > loss_dur: 0.17407768964767456  (0.15268030429774138)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(26.8489, device='cuda:0')  (tensor(28.3081, device='cuda:0'))\n",
      "     | > current_lr: 2.075e-05 \n",
      "     | > step_time: 0.8311  (0.5563620303539519)\n",
      "     | > loader_time: 0.0388  (0.008617583741532993)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:09:49 -- STEP: 72/406 -- GLOBAL_STEP: 56500\u001b[0m\n",
      "     | > loss: -0.16474708914756775  (-0.16131824627518654)\n",
      "     | > log_mle: -0.3110806941986084  (-0.319013570745786)\n",
      "     | > loss_dur: 0.14633360505104065  (0.1576953243671192)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(17.3602, device='cuda:0')  (tensor(27.2465, device='cuda:0'))\n",
      "     | > current_lr: 2.075e-05 \n",
      "     | > step_time: 0.4392  (0.5819774005148146)\n",
      "     | > loader_time: 0.0118  (0.00948151283793979)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:10:06 -- STEP: 97/406 -- GLOBAL_STEP: 56525\u001b[0m\n",
      "     | > loss: -0.14731772243976593  (-0.1595636114631732)\n",
      "     | > log_mle: -0.3236532211303711  (-0.32169871846425174)\n",
      "     | > loss_dur: 0.17633549869060516  (0.16213510692426836)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(38.9154, device='cuda:0')  (tensor(31.6587, device='cuda:0'))\n",
      "     | > current_lr: 2.075e-05 \n",
      "     | > step_time: 0.394  (0.5967235221076257)\n",
      "     | > loader_time: 0.005  (0.009705725404405102)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:10:23 -- STEP: 122/406 -- GLOBAL_STEP: 56550\u001b[0m\n",
      "     | > loss: -0.15686526894569397  (-0.15869141003636067)\n",
      "     | > log_mle: -0.31971991062164307  (-0.32370109929413104)\n",
      "     | > loss_dur: 0.1628546416759491  (0.16500968919669995)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(15.3799, device='cuda:0')  (tensor(30.3907, device='cuda:0'))\n",
      "     | > current_lr: 2.075e-05 \n",
      "     | > step_time: 1.289  (0.6101722932252728)\n",
      "     | > loader_time: 0.0087  (0.010309709877264305)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:10:40 -- STEP: 147/406 -- GLOBAL_STEP: 56575\u001b[0m\n",
      "     | > loss: -0.14952105283737183  (-0.1576587875075892)\n",
      "     | > log_mle: -0.33224689960479736  (-0.32549953541788124)\n",
      "     | > loss_dur: 0.18272584676742554  (0.16784074785960776)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(19.5654, device='cuda:0')  (tensor(31.6052, device='cuda:0'))\n",
      "     | > current_lr: 2.075e-05 \n",
      "     | > step_time: 0.6805  (0.6212445554279146)\n",
      "     | > loader_time: 0.0211  (0.010886481019104418)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:10:58 -- STEP: 172/406 -- GLOBAL_STEP: 56600\u001b[0m\n",
      "     | > loss: -0.15579864382743835  (-0.15711306702605518)\n",
      "     | > log_mle: -0.33604276180267334  (-0.3269993420257127)\n",
      "     | > loss_dur: 0.18024411797523499  (0.16988627495633998)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(41.4901, device='cuda:0')  (tensor(33.0036, device='cuda:0'))\n",
      "     | > current_lr: 2.075e-05 \n",
      "     | > step_time: 0.6435  (0.632694550724917)\n",
      "     | > loader_time: 0.0054  (0.011061752951422402)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:11:15 -- STEP: 197/406 -- GLOBAL_STEP: 56625\u001b[0m\n",
      "     | > loss: -0.1698465347290039  (-0.15734481085375487)\n",
      "     | > log_mle: -0.33882391452789307  (-0.3285150080162863)\n",
      "     | > loss_dur: 0.16897737979888916  (0.17117019712471115)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(34.7689, device='cuda:0')  (tensor(33.5739, device='cuda:0'))\n",
      "     | > current_lr: 2.075e-05 \n",
      "     | > step_time: 0.522  (0.6376584556502133)\n",
      "     | > loader_time: 0.0106  (0.011067988303712176)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:11:33 -- STEP: 222/406 -- GLOBAL_STEP: 56650\u001b[0m\n",
      "     | > loss: -0.1663084775209427  (-0.1573076629423881)\n",
      "     | > log_mle: -0.3359133005142212  (-0.3299447856507861)\n",
      "     | > loss_dur: 0.1696048229932785  (0.17263712267483677)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(31.4153, device='cuda:0')  (tensor(33.9039, device='cuda:0'))\n",
      "     | > current_lr: 2.075e-05 \n",
      "     | > step_time: 0.7397  (0.6446844253454121)\n",
      "     | > loader_time: 0.0129  (0.011300713092357188)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:11:53 -- STEP: 247/406 -- GLOBAL_STEP: 56675\u001b[0m\n",
      "     | > loss: -0.14800289273262024  (-0.15738849565085136)\n",
      "     | > log_mle: -0.33256709575653076  (-0.33114247573049455)\n",
      "     | > loss_dur: 0.18456420302391052  (0.17375398004947887)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(31.5775, device='cuda:0')  (tensor(34.7243, device='cuda:0'))\n",
      "     | > current_lr: 2.075e-05 \n",
      "     | > step_time: 0.673  (0.6566863890118926)\n",
      "     | > loader_time: 0.0073  (0.011467311063758758)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:12:13 -- STEP: 272/406 -- GLOBAL_STEP: 56700\u001b[0m\n",
      "     | > loss: -0.17799293994903564  (-0.15786972137935026)\n",
      "     | > log_mle: -0.35540103912353516  (-0.33241083472967164)\n",
      "     | > loss_dur: 0.1774080991744995  (0.17454111332292943)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(18.5823, device='cuda:0')  (tensor(34.9482, device='cuda:0'))\n",
      "     | > current_lr: 2.075e-05 \n",
      "     | > step_time: 0.7174  (0.669513570035205)\n",
      "     | > loader_time: 0.0078  (0.011893111993284786)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:12:34 -- STEP: 297/406 -- GLOBAL_STEP: 56725\u001b[0m\n",
      "     | > loss: -0.15695524215698242  (-0.15781957558309195)\n",
      "     | > log_mle: -0.34324491024017334  (-0.3332209807855113)\n",
      "     | > loss_dur: 0.18628966808319092  (0.17540140517733316)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(57.7496, device='cuda:0')  (tensor(36.0515, device='cuda:0'))\n",
      "     | > current_lr: 2.075e-05 \n",
      "     | > step_time: 0.8496  (0.6812056989380807)\n",
      "     | > loader_time: 0.0075  (0.012222195313835785)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:12:55 -- STEP: 322/406 -- GLOBAL_STEP: 56750\u001b[0m\n",
      "     | > loss: -0.17742137610912323  (-0.15797681967664218)\n",
      "     | > log_mle: -0.34987688064575195  (-0.33409054271923105)\n",
      "     | > loss_dur: 0.17245550453662872  (0.17611372301945044)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(12.1149, device='cuda:0')  (tensor(35.9952, device='cuda:0'))\n",
      "     | > current_lr: 2.075e-05 \n",
      "     | > step_time: 0.7464  (0.6921153016712357)\n",
      "     | > loader_time: 0.006  (0.012443663911049414)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:13:16 -- STEP: 347/406 -- GLOBAL_STEP: 56775\u001b[0m\n",
      "     | > loss: -0.16774187982082367  (-0.15796010599871535)\n",
      "     | > log_mle: -0.34259939193725586  (-0.33483844566070387)\n",
      "     | > loss_dur: 0.1748575121164322  (0.17687833964051705)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(51.9482, device='cuda:0')  (tensor(36.7118, device='cuda:0'))\n",
      "     | > current_lr: 2.075e-05 \n",
      "     | > step_time: 0.9239  (0.7014573891499544)\n",
      "     | > loader_time: 0.0077  (0.012965696345832233)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:13:39 -- STEP: 372/406 -- GLOBAL_STEP: 56800\u001b[0m\n",
      "     | > loss: -0.15284843742847443  (-0.15822916834424913)\n",
      "     | > log_mle: -0.3394508361816406  (-0.3357695164859937)\n",
      "     | > loss_dur: 0.1866023987531662  (0.17754034812171618)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(19.2524, device='cuda:0')  (tensor(36.6771, device='cuda:0'))\n",
      "     | > current_lr: 2.075e-05 \n",
      "     | > step_time: 0.8861  (0.713567210781959)\n",
      "     | > loader_time: 0.0155  (0.013188178821276595)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:14:00 -- STEP: 397/406 -- GLOBAL_STEP: 56825\u001b[0m\n",
      "     | > loss: -0.17076420783996582  (-0.1584878534979425)\n",
      "     | > log_mle: -0.35603249073028564  (-0.33648458596140685)\n",
      "     | > loss_dur: 0.18526828289031982  (0.17799673244469716)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(64.9788, device='cuda:0')  (tensor(37.4221, device='cuda:0'))\n",
      "     | > current_lr: 2.075e-05 \n",
      "     | > step_time: 0.5887  (0.7203154966272697)\n",
      "     | > loader_time: 0.0091  (0.013221046486189145)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: -0.1446227729320526  (-0.1446227729320526)\n",
      "     | > log_mle: -0.32178688049316406  (-0.32178688049316406)\n",
      "     | > loss_dur: 0.17716410756111145  (0.17716410756111145)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: -0.19213008880615234  (-0.19213008880615234)\n",
      "     | > log_mle: -0.3667724132537842  (-0.3667724132537842)\n",
      "     | > loss_dur: 0.17464232444763184  (0.17464232444763184)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: -0.205246239900589  (-0.19868816435337067)\n",
      "     | > log_mle: -0.32929062843322754  (-0.34803152084350586)\n",
      "     | > loss_dur: 0.12404439598321915  (0.1493433602154255)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: -0.1908741444349289  (-0.19608349104722342)\n",
      "     | > log_mle: -0.3379777669906616  (-0.34468026955922443)\n",
      "     | > loss_dur: 0.14710362255573273  (0.1485967809955279)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: -0.20467709004878998  (-0.19823189079761505)\n",
      "     | > log_mle: -0.365791916847229  (-0.3499581813812256)\n",
      "     | > loss_dur: 0.16111482679843903  (0.15172629244625568)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: -0.2027626782655716  (-0.19913804829120635)\n",
      "     | > log_mle: -0.36590754985809326  (-0.35314805507659913)\n",
      "     | > loss_dur: 0.16314487159252167  (0.15401000827550887)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: -0.15866443514823914  (-0.19239244610071182)\n",
      "     | > log_mle: -0.37901175022125244  (-0.3574586709340413)\n",
      "     | > loss_dur: 0.2203473150730133  (0.16506622607509294)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: -0.18150562047958374  (-0.19083718529769353)\n",
      "     | > log_mle: -0.3356916904449463  (-0.354349102292742)\n",
      "     | > loss_dur: 0.15418606996536255  (0.16351191805941717)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: -0.1963823139667511  (-0.19153032638132572)\n",
      "     | > log_mle: -0.3502833843231201  (-0.3538408875465393)\n",
      "     | > loss_dur: 0.15390107035636902  (0.16231056209653616)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: -0.19736400246620178  (-0.1921785126129786)\n",
      "     | > log_mle: -0.36280977725982666  (-0.35483743084801567)\n",
      "     | > loss_dur: 0.16544577479362488  (0.16265891906287935)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: -0.17122013866901398  (-0.19008267521858216)\n",
      "     | > log_mle: -0.34827709197998047  (-0.35418139696121215)\n",
      "     | > loss_dur: 0.1770569533109665  (0.16409872248768806)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: -0.1872570812702179  (-0.18982580304145813)\n",
      "     | > log_mle: -0.36552929878234863  (-0.3552130243994973)\n",
      "     | > loss_dur: 0.17827221751213074  (0.16538722203536468)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: -0.20809373259544373  (-0.19134813050429025)\n",
      "     | > log_mle: -0.34991419315338135  (-0.3547714551289876)\n",
      "     | > loss_dur: 0.14182046055793762  (0.1634233252455791)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: -0.21853257715702057  (-0.19343924178526953)\n",
      "     | > log_mle: -0.3731640577316284  (-0.35618627071380615)\n",
      "     | > loss_dur: 0.15463148057460785  (0.16274702950165823)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: -0.19135016202926636  (-0.19329002180269786)\n",
      "     | > log_mle: -0.3622533082962036  (-0.3566196305411203)\n",
      "     | > loss_dur: 0.17090314626693726  (0.16332960927060672)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: -0.19017423689365387  (-0.1930823028087616)\n",
      "     | > log_mle: -0.35391485691070557  (-0.3564393122990926)\n",
      "     | > loss_dur: 0.1637406200170517  (0.1633570099870364)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: -0.18240594863891602  (-0.19241503067314625)\n",
      "     | > log_mle: -0.35872960090637207  (-0.3565824553370476)\n",
      "     | > loss_dur: 0.17632365226745605  (0.16416742512956262)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: audio amplitude out of range, auto clipped.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.004302874207496644 \u001b[0m(-0.0003252327442169181)\n",
      "     | > avg_loss:\u001b[92m -0.19241503067314625 \u001b[0m(-0.008364944718778133)\n",
      "     | > avg_log_mle:\u001b[92m -0.3565824553370476 \u001b[0m(-0.00599873811006546)\n",
      "     | > avg_loss_dur:\u001b[92m 0.16416742512956262 \u001b[0m(-0.002366206143051386)\n",
      "\n",
      " > BEST MODEL : train/run-February-22-2025_10+59PM-fa84af3/best_model_56834.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 84/100\u001b[0m\n",
      " --> train/run-February-22-2025_10+59PM-fa84af3\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-23 06:14:22) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:14:31 -- STEP: 16/406 -- GLOBAL_STEP: 56850\u001b[0m\n",
      "     | > loss: -0.16377857327461243  (-0.18056170269846916)\n",
      "     | > log_mle: -0.32369303703308105  (-0.3236074820160866)\n",
      "     | > loss_dur: 0.15991446375846863  (0.14304577931761742)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(18.6698, device='cuda:0')  (tensor(34.4568, device='cuda:0'))\n",
      "     | > current_lr: 2.1e-05 \n",
      "     | > step_time: 0.8184  (0.4468677192926407)\n",
      "     | > loader_time: 0.0072  (0.008472681045532227)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:14:46 -- STEP: 41/406 -- GLOBAL_STEP: 56875\u001b[0m\n",
      "     | > loss: -0.15399044752120972  (-0.16944920362495794)\n",
      "     | > log_mle: -0.3114680051803589  (-0.31910143247464806)\n",
      "     | > loss_dur: 0.15747755765914917  (0.14965222884969012)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(26.6056, device='cuda:0')  (tensor(31.0112, device='cuda:0'))\n",
      "     | > current_lr: 2.1e-05 \n",
      "     | > step_time: 0.3725  (0.5269628908576033)\n",
      "     | > loader_time: 0.0105  (0.0082529637871719)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:15:03 -- STEP: 66/406 -- GLOBAL_STEP: 56900\u001b[0m\n",
      "     | > loss: -0.13534995913505554  (-0.16317403971245795)\n",
      "     | > log_mle: -0.3229553699493408  (-0.31949780023459234)\n",
      "     | > loss_dur: 0.18760541081428528  (0.15632376052213437)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(57.0453, device='cuda:0')  (tensor(27.5809, device='cuda:0'))\n",
      "     | > current_lr: 2.1e-05 \n",
      "     | > step_time: 0.6722  (0.570427721196955)\n",
      "     | > loader_time: 0.0072  (0.009171265544313374)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:15:20 -- STEP: 91/406 -- GLOBAL_STEP: 56925\u001b[0m\n",
      "     | > loss: -0.16536517441272736  (-0.16130263104543582)\n",
      "     | > log_mle: -0.34068775177001953  (-0.32196908075730885)\n",
      "     | > loss_dur: 0.17532257735729218  (0.160666449711873)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(23.5077, device='cuda:0')  (tensor(29.5325, device='cuda:0'))\n",
      "     | > current_lr: 2.1e-05 \n",
      "     | > step_time: 0.8009  (0.5976577722109282)\n",
      "     | > loader_time: 0.0238  (0.00922857798062838)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:15:36 -- STEP: 116/406 -- GLOBAL_STEP: 56950\u001b[0m\n",
      "     | > loss: -0.13090723752975464  (-0.15990999675002596)\n",
      "     | > log_mle: -0.3203754425048828  (-0.32448219328091077)\n",
      "     | > loss_dur: 0.18946820497512817  (0.1645721965308847)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(46.4531, device='cuda:0')  (tensor(36.2524, device='cuda:0'))\n",
      "     | > current_lr: 2.1e-05 \n",
      "     | > step_time: 0.5563  (0.6050183259207627)\n",
      "     | > loader_time: 0.0269  (0.009428649113096038)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:15:53 -- STEP: 141/406 -- GLOBAL_STEP: 56975\u001b[0m\n",
      "     | > loss: -0.14153167605400085  (-0.15864477671207267)\n",
      "     | > log_mle: -0.3369954824447632  (-0.32633695534780527)\n",
      "     | > loss_dur: 0.19546380639076233  (0.16769217863573246)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(28.8752, device='cuda:0')  (tensor(36.9608, device='cuda:0'))\n",
      "     | > current_lr: 2.1e-05 \n",
      "     | > step_time: 0.7472  (0.6183886544924255)\n",
      "     | > loader_time: 0.011  (0.009582188112515929)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:16:10 -- STEP: 166/406 -- GLOBAL_STEP: 57000\u001b[0m\n",
      "     | > loss: -0.1700655221939087  (-0.15812868562089386)\n",
      "     | > log_mle: -0.34354913234710693  (-0.3278228015784759)\n",
      "     | > loss_dur: 0.17348361015319824  (0.16969411595758171)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(45.4180, device='cuda:0')  (tensor(35.8603, device='cuda:0'))\n",
      "     | > current_lr: 2.1e-05 \n",
      "     | > step_time: 0.6832  (0.6262713857443934)\n",
      "     | > loader_time: 0.0053  (0.009779279490551318)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:16:27 -- STEP: 191/406 -- GLOBAL_STEP: 57025\u001b[0m\n",
      "     | > loss: -0.15703396499156952  (-0.15855040007236737)\n",
      "     | > log_mle: -0.3348788022994995  (-0.329432780830024)\n",
      "     | > loss_dur: 0.17784483730793  (0.17088238075765624)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(19.8005, device='cuda:0')  (tensor(35.1973, device='cuda:0'))\n",
      "     | > current_lr: 2.1e-05 \n",
      "     | > step_time: 0.5073  (0.6307250829267252)\n",
      "     | > loader_time: 0.0084  (0.010170765572193404)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:16:46 -- STEP: 216/406 -- GLOBAL_STEP: 57050\u001b[0m\n",
      "     | > loss: -0.16112801432609558  (-0.15876051542107705)\n",
      "     | > log_mle: -0.35410451889038086  (-0.3309318147323751)\n",
      "     | > loss_dur: 0.19297650456428528  (0.1721712993112978)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(35.7086, device='cuda:0')  (tensor(36.1488, device='cuda:0'))\n",
      "     | > current_lr: 2.1e-05 \n",
      "     | > step_time: 0.5567  (0.6420515444543626)\n",
      "     | > loader_time: 0.0162  (0.010341291074399595)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:17:05 -- STEP: 241/406 -- GLOBAL_STEP: 57075\u001b[0m\n",
      "     | > loss: -0.1557188779115677  (-0.1591095732702754)\n",
      "     | > log_mle: -0.33982908725738525  (-0.3324751977603961)\n",
      "     | > loss_dur: 0.18411020934581757  (0.17336562449012047)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(18.4494, device='cuda:0')  (tensor(36.7009, device='cuda:0'))\n",
      "     | > current_lr: 2.1e-05 \n",
      "     | > step_time: 0.5236  (0.6515866503181299)\n",
      "     | > loader_time: 0.006  (0.010471911845860144)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:17:25 -- STEP: 266/406 -- GLOBAL_STEP: 57100\u001b[0m\n",
      "     | > loss: -0.1738939732313156  (-0.1595235403655167)\n",
      "     | > log_mle: -0.34875619411468506  (-0.3336100936832286)\n",
      "     | > loss_dur: 0.17486222088336945  (0.17408655331771167)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(47.6806, device='cuda:0')  (tensor(37.0874, device='cuda:0'))\n",
      "     | > current_lr: 2.1e-05 \n",
      "     | > step_time: 0.8692  (0.6632239424196402)\n",
      "     | > loader_time: 0.0374  (0.011139572114872754)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:17:44 -- STEP: 291/406 -- GLOBAL_STEP: 57125\u001b[0m\n",
      "     | > loss: -0.15727345645427704  (-0.16003571998622412)\n",
      "     | > log_mle: -0.3417853116989136  (-0.33479821968734064)\n",
      "     | > loss_dur: 0.18451185524463654  (0.17476249970111632)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(35.6326, device='cuda:0')  (tensor(37.4268, device='cuda:0'))\n",
      "     | > current_lr: 2.1e-05 \n",
      "     | > step_time: 0.4546  (0.670410474141439)\n",
      "     | > loader_time: 0.0086  (0.011611528822646516)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:18:03 -- STEP: 316/406 -- GLOBAL_STEP: 57150\u001b[0m\n",
      "     | > loss: -0.16685637831687927  (-0.16033720871127102)\n",
      "     | > log_mle: -0.35048234462738037  (-0.33588979100879235)\n",
      "     | > loss_dur: 0.1836259663105011  (0.17555258229752113)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(55.3027, device='cuda:0')  (tensor(37.7026, device='cuda:0'))\n",
      "     | > current_lr: 2.1e-05 \n",
      "     | > step_time: 0.6134  (0.6775815645350687)\n",
      "     | > loader_time: 0.008  (0.011646344691892213)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:18:23 -- STEP: 341/406 -- GLOBAL_STEP: 57175\u001b[0m\n",
      "     | > loss: -0.16181275248527527  (-0.16018289620400875)\n",
      "     | > log_mle: -0.34608352184295654  (-0.33655424726324007)\n",
      "     | > loss_dur: 0.18427076935768127  (0.17637135105923102)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(29.4213, device='cuda:0')  (tensor(37.2479, device='cuda:0'))\n",
      "     | > current_lr: 2.1e-05 \n",
      "     | > step_time: 0.6345  (0.6838292285494094)\n",
      "     | > loader_time: 0.0095  (0.01197844027074551)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:18:44 -- STEP: 366/406 -- GLOBAL_STEP: 57200\u001b[0m\n",
      "     | > loss: -0.1718682497739792  (-0.16027158567977084)\n",
      "     | > log_mle: -0.35483086109161377  (-0.33735860566623876)\n",
      "     | > loss_dur: 0.18296261131763458  (0.17708701998646778)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(42.4784, device='cuda:0')  (tensor(37.6158, device='cuda:0'))\n",
      "     | > current_lr: 2.1e-05 \n",
      "     | > step_time: 0.6227  (0.6924927117394624)\n",
      "     | > loader_time: 0.0251  (0.01240305952687081)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:19:06 -- STEP: 391/406 -- GLOBAL_STEP: 57225\u001b[0m\n",
      "     | > loss: -0.16286537051200867  (-0.16037064382944569)\n",
      "     | > log_mle: -0.35301780700683594  (-0.3380715563474105)\n",
      "     | > loss_dur: 0.19015243649482727  (0.17770091251796455)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(88.1686, device='cuda:0')  (tensor(38.2133, device='cuda:0'))\n",
      "     | > current_lr: 2.1e-05 \n",
      "     | > step_time: 0.7686  (0.7041922804644654)\n",
      "     | > loader_time: 0.0071  (0.01261196112083962)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: -0.15432900190353394  (-0.15432900190353394)\n",
      "     | > log_mle: -0.32096803188323975  (-0.32096803188323975)\n",
      "     | > loss_dur: 0.1666390299797058  (0.1666390299797058)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: -0.19447793066501617  (-0.19447793066501617)\n",
      "     | > log_mle: -0.36338114738464355  (-0.36338114738464355)\n",
      "     | > loss_dur: 0.16890321671962738  (0.16890321671962738)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: -0.20364299416542053  (-0.19906046241521835)\n",
      "     | > log_mle: -0.3280574083328247  (-0.34571927785873413)\n",
      "     | > loss_dur: 0.12441442161798477  (0.14665881916880608)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: -0.19185276329517365  (-0.19665789604187012)\n",
      "     | > log_mle: -0.3356243371963501  (-0.34235429763793945)\n",
      "     | > loss_dur: 0.14377157390117645  (0.1456964040795962)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: -0.20724433660507202  (-0.1993045061826706)\n",
      "     | > log_mle: -0.36177265644073486  (-0.3472088873386383)\n",
      "     | > loss_dur: 0.15452831983566284  (0.14790438301861286)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: -0.19920714199543  (-0.19928503334522246)\n",
      "     | > log_mle: -0.3619804382324219  (-0.350163197517395)\n",
      "     | > loss_dur: 0.16277329623699188  (0.15087816566228868)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: -0.14743466675281525  (-0.19064330557982126)\n",
      "     | > log_mle: -0.3739287853240967  (-0.35412412881851196)\n",
      "     | > loss_dur: 0.22649411857128143  (0.16348082448045412)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: -0.18657556176185608  (-0.19006219932011195)\n",
      "     | > log_mle: -0.3331916332244873  (-0.35113377230507986)\n",
      "     | > loss_dur: 0.14661607146263123  (0.16107157404933656)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: -0.18908122181892395  (-0.18993957713246346)\n",
      "     | > log_mle: -0.3464670181274414  (-0.35055042803287506)\n",
      "     | > loss_dur: 0.15738579630851746  (0.16061085183173418)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: -0.19001996517181396  (-0.18994850913683572)\n",
      "     | > log_mle: -0.3594701290130615  (-0.35154150591956246)\n",
      "     | > loss_dur: 0.16945016384124756  (0.161592997610569)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: -0.16356325149536133  (-0.18730998337268828)\n",
      "     | > log_mle: -0.34514951705932617  (-0.3509023070335388)\n",
      "     | > loss_dur: 0.18158626556396484  (0.1635923244059086)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: -0.19307735562324524  (-0.18783428994092075)\n",
      "     | > log_mle: -0.36180078983306885  (-0.35189307819713245)\n",
      "     | > loss_dur: 0.1687234342098236  (0.16405878893353723)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: -0.20109766721725464  (-0.18893957138061523)\n",
      "     | > log_mle: -0.3468332290649414  (-0.3514714241027832)\n",
      "     | > loss_dur: 0.14573556184768677  (0.16253185334304968)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: -0.20624393224716187  (-0.1902706760626573)\n",
      "     | > log_mle: -0.37046778202056885  (-0.3529326824041513)\n",
      "     | > loss_dur: 0.16422384977340698  (0.16266200691461563)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: -0.1875126212835312  (-0.19007367214986257)\n",
      "     | > log_mle: -0.35862088203430176  (-0.3533389823777335)\n",
      "     | > loss_dur: 0.17110826075077057  (0.16326531076005527)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: -0.18194465339183807  (-0.18953173756599426)\n",
      "     | > log_mle: -0.35099899768829346  (-0.3531829833984375)\n",
      "     | > loss_dur: 0.16905434429645538  (0.1636512463291486)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: -0.1826954036951065  (-0.18910446669906378)\n",
      "     | > log_mle: -0.3557901382446289  (-0.35334593057632446)\n",
      "     | > loss_dur: 0.1730947345495224  (0.16424146434292197)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: audio amplitude out of range, auto clipped.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.0038348138332366943 \u001b[0m(-0.0004680603742599496)\n",
      "     | > avg_loss:\u001b[91m -0.18910446669906378 \u001b[0m(+0.00331056397408247)\n",
      "     | > avg_log_mle:\u001b[91m -0.35334593057632446 \u001b[0m(+0.003236524760723114)\n",
      "     | > avg_loss_dur:\u001b[91m 0.16424146434292197 \u001b[0m(+7.403921335935593e-05)\n",
      "\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 85/100\u001b[0m\n",
      " --> train/run-February-22-2025_10+59PM-fa84af3\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-23 06:19:29) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:19:37 -- STEP: 10/406 -- GLOBAL_STEP: 57250\u001b[0m\n",
      "     | > loss: -0.19485749304294586  (-0.1892242342233658)\n",
      "     | > log_mle: -0.33021867275238037  (-0.32445459365844725)\n",
      "     | > loss_dur: 0.1353611797094345  (0.13523036018013954)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(35.6709, device='cuda:0')  (tensor(42.8134, device='cuda:0'))\n",
      "     | > current_lr: 2.125e-05 \n",
      "     | > step_time: 0.3969  (0.4345935583114624)\n",
      "     | > loader_time: 0.0158  (0.00798494815826416)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:19:51 -- STEP: 35/406 -- GLOBAL_STEP: 57275\u001b[0m\n",
      "     | > loss: -0.1827809065580368  (-0.17533746021134514)\n",
      "     | > log_mle: -0.33348703384399414  (-0.3235559804098947)\n",
      "     | > loss_dur: 0.15070612728595734  (0.14821852041142328)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(23.2967, device='cuda:0')  (tensor(30.7563, device='cuda:0'))\n",
      "     | > current_lr: 2.125e-05 \n",
      "     | > step_time: 0.4638  (0.5232743740081787)\n",
      "     | > loader_time: 0.0076  (0.008212566375732424)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:20:07 -- STEP: 60/406 -- GLOBAL_STEP: 57300\u001b[0m\n",
      "     | > loss: -0.16281160712242126  (-0.16910088434815407)\n",
      "     | > log_mle: -0.32446420192718506  (-0.3232923448085785)\n",
      "     | > loss_dur: 0.1616525948047638  (0.15419146058460081)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(36.5110, device='cuda:0')  (tensor(29.7157, device='cuda:0'))\n",
      "     | > current_lr: 2.125e-05 \n",
      "     | > step_time: 0.8805  (0.5695372184117635)\n",
      "     | > loader_time: 0.0203  (0.009106683731079101)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:20:23 -- STEP: 85/406 -- GLOBAL_STEP: 57325\u001b[0m\n",
      "     | > loss: -0.18717747926712036  (-0.1671084339127821)\n",
      "     | > log_mle: -0.3420219421386719  (-0.32545670902027807)\n",
      "     | > loss_dur: 0.1548444628715515  (0.15834827519514985)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(60.7277, device='cuda:0')  (tensor(30.0632, device='cuda:0'))\n",
      "     | > current_lr: 2.125e-05 \n",
      "     | > step_time: 0.4146  (0.5813585982603185)\n",
      "     | > loader_time: 0.0098  (0.010120251599480126)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:20:40 -- STEP: 110/406 -- GLOBAL_STEP: 57350\u001b[0m\n",
      "     | > loss: -0.15480317175388336  (-0.165985379029404)\n",
      "     | > log_mle: -0.35196781158447266  (-0.3277472571893173)\n",
      "     | > loss_dur: 0.1971646398305893  (0.1617618782276457)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(31.5785, device='cuda:0')  (tensor(30.1798, device='cuda:0'))\n",
      "     | > current_lr: 2.125e-05 \n",
      "     | > step_time: 0.764  (0.5987237171693284)\n",
      "     | > loader_time: 0.0494  (0.011068550023165617)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:20:57 -- STEP: 135/406 -- GLOBAL_STEP: 57375\u001b[0m\n",
      "     | > loss: -0.15738193690776825  (-0.16560050127682857)\n",
      "     | > log_mle: -0.34810900688171387  (-0.3301228823485199)\n",
      "     | > loss_dur: 0.19072706997394562  (0.16452238112688064)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(39.2975, device='cuda:0')  (tensor(32.3239, device='cuda:0'))\n",
      "     | > current_lr: 2.125e-05 \n",
      "     | > step_time: 0.7884  (0.6084436045752634)\n",
      "     | > loader_time: 0.0103  (0.011415981363367151)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:21:14 -- STEP: 160/406 -- GLOBAL_STEP: 57400\u001b[0m\n",
      "     | > loss: -0.15654154121875763  (-0.16438053054735058)\n",
      "     | > log_mle: -0.3447619676589966  (-0.33163038790225985)\n",
      "     | > loss_dur: 0.18822042644023895  (0.1672498574014754)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(39.8452, device='cuda:0')  (tensor(33.5857, device='cuda:0'))\n",
      "     | > current_lr: 2.125e-05 \n",
      "     | > step_time: 0.5133  (0.6207483410835269)\n",
      "     | > loader_time: 0.0254  (0.011538124084472653)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:21:33 -- STEP: 185/406 -- GLOBAL_STEP: 57425\u001b[0m\n",
      "     | > loss: -0.16829057037830353  (-0.1638700387767843)\n",
      "     | > log_mle: -0.3500019311904907  (-0.33257967330314003)\n",
      "     | > loss_dur: 0.1817113608121872  (0.16870963456662938)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(27.6840, device='cuda:0')  (tensor(34.4500, device='cuda:0'))\n",
      "     | > current_lr: 2.125e-05 \n",
      "     | > step_time: 0.9388  (0.6329831638851684)\n",
      "     | > loader_time: 0.0359  (0.012015688097154767)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:21:51 -- STEP: 210/406 -- GLOBAL_STEP: 57450\u001b[0m\n",
      "     | > loss: -0.1717158406972885  (-0.16370448690085182)\n",
      "     | > log_mle: -0.3454025983810425  (-0.3337793810026985)\n",
      "     | > loss_dur: 0.17368675768375397  (0.17007489413732582)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(36.4849, device='cuda:0')  (tensor(34.7514, device='cuda:0'))\n",
      "     | > current_lr: 2.125e-05 \n",
      "     | > step_time: 0.6755  (0.6411022163572768)\n",
      "     | > loader_time: 0.0094  (0.012425779160999113)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:22:09 -- STEP: 235/406 -- GLOBAL_STEP: 57475\u001b[0m\n",
      "     | > loss: -0.1600605696439743  (-0.1638560057954585)\n",
      "     | > log_mle: -0.3433433771133423  (-0.33531940997915055)\n",
      "     | > loss_dur: 0.18328280746936798  (0.17146340421539677)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(28.6172, device='cuda:0')  (tensor(34.9731, device='cuda:0'))\n",
      "     | > current_lr: 2.125e-05 \n",
      "     | > step_time: 0.5018  (0.6478273868560793)\n",
      "     | > loader_time: 0.0069  (0.012611264370857397)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:22:28 -- STEP: 260/406 -- GLOBAL_STEP: 57500\u001b[0m\n",
      "     | > loss: -0.17068180441856384  (-0.16406343344312446)\n",
      "     | > log_mle: -0.35131728649139404  (-0.33650434475678653)\n",
      "     | > loss_dur: 0.1806354820728302  (0.1724409113423183)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(97.1519, device='cuda:0')  (tensor(35.0223, device='cuda:0'))\n",
      "     | > current_lr: 2.125e-05 \n",
      "     | > step_time: 1.0196  (0.6567127979718724)\n",
      "     | > loader_time: 0.0307  (0.013136421717130217)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:22:47 -- STEP: 285/406 -- GLOBAL_STEP: 57525\u001b[0m\n",
      "     | > loss: -0.15140464901924133  (-0.16424699530266873)\n",
      "     | > log_mle: -0.3390834331512451  (-0.3374239724979065)\n",
      "     | > loss_dur: 0.18767878413200378  (0.17317697722138026)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(27.9658, device='cuda:0')  (tensor(35.7740, device='cuda:0'))\n",
      "     | > current_lr: 2.125e-05 \n",
      "     | > step_time: 0.8286  (0.6650018650188783)\n",
      "     | > loader_time: 0.0263  (0.01330579874808328)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:23:08 -- STEP: 310/406 -- GLOBAL_STEP: 57550\u001b[0m\n",
      "     | > loss: -0.16724687814712524  (-0.16423401842194216)\n",
      "     | > log_mle: -0.34978461265563965  (-0.3382248005559367)\n",
      "     | > loss_dur: 0.1825377345085144  (0.17399078215802874)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(21.6473, device='cuda:0')  (tensor(35.4966, device='cuda:0'))\n",
      "     | > current_lr: 2.125e-05 \n",
      "     | > step_time: 0.7909  (0.6754019037369758)\n",
      "     | > loader_time: 0.0093  (0.013508083743433796)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:23:28 -- STEP: 335/406 -- GLOBAL_STEP: 57575\u001b[0m\n",
      "     | > loss: -0.14210690557956696  (-0.16381300020573744)\n",
      "     | > log_mle: -0.3440990447998047  (-0.33866995270572486)\n",
      "     | > loss_dur: 0.20199213922023773  (0.17485695252222813)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(51.5905, device='cuda:0')  (tensor(36.0447, device='cuda:0'))\n",
      "     | > current_lr: 2.125e-05 \n",
      "     | > step_time: 0.6002  (0.6845175714635138)\n",
      "     | > loader_time: 0.0104  (0.0137036821735439)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:23:50 -- STEP: 360/406 -- GLOBAL_STEP: 57600\u001b[0m\n",
      "     | > loss: -0.1841021180152893  (-0.16392595643798502)\n",
      "     | > log_mle: -0.35143208503723145  (-0.33945264485147264)\n",
      "     | > loss_dur: 0.16732996702194214  (0.17552668843418376)\n",
      "     | > amp_scaler: 2048.0  (1026.8444444444444)\n",
      "     | > grad_norm: tensor(32.1041, device='cuda:0')  (tensor(35.9087, device='cuda:0'))\n",
      "     | > current_lr: 2.125e-05 \n",
      "     | > step_time: 0.7117  (0.6957006110085381)\n",
      "     | > loader_time: 0.0082  (0.013955057329601709)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:24:12 -- STEP: 385/406 -- GLOBAL_STEP: 57625\u001b[0m\n",
      "     | > loss: -0.16279909014701843  (-0.16379669746021158)\n",
      "     | > log_mle: -0.342107892036438  (-0.34003257751464844)\n",
      "     | > loss_dur: 0.17930880188941956  (0.17623588007378901)\n",
      "     | > amp_scaler: 2048.0  (1093.1532467532468)\n",
      "     | > grad_norm: tensor(29.8782, device='cuda:0')  (tensor(36.4304, device='cuda:0'))\n",
      "     | > current_lr: 2.125e-05 \n",
      "     | > step_time: 0.6556  (0.7065919783208278)\n",
      "     | > loader_time: 0.0247  (0.014130666039206763)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: -0.15798750519752502  (-0.15798750519752502)\n",
      "     | > log_mle: -0.3240004777908325  (-0.3240004777908325)\n",
      "     | > loss_dur: 0.1660129725933075  (0.1660129725933075)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: -0.19535207748413086  (-0.19535207748413086)\n",
      "     | > log_mle: -0.36967527866363525  (-0.36967527866363525)\n",
      "     | > loss_dur: 0.1743232011795044  (0.1743232011795044)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: -0.2057458609342575  (-0.20054896920919418)\n",
      "     | > log_mle: -0.33218348026275635  (-0.3509293794631958)\n",
      "     | > loss_dur: 0.12643761932849884  (0.15038041025400162)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: -0.1971091479063034  (-0.1994023621082306)\n",
      "     | > log_mle: -0.3415948152542114  (-0.347817858060201)\n",
      "     | > loss_dur: 0.14448566734790802  (0.14841549595197043)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: -0.21215872466564178  (-0.2025914527475834)\n",
      "     | > log_mle: -0.36860060691833496  (-0.3530135452747345)\n",
      "     | > loss_dur: 0.15644188225269318  (0.1504220925271511)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: -0.20687708258628845  (-0.2034485787153244)\n",
      "     | > log_mle: -0.3708832263946533  (-0.3565874814987183)\n",
      "     | > loss_dur: 0.16400614380836487  (0.15313890278339387)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: -0.16575650870800018  (-0.19716656704743704)\n",
      "     | > log_mle: -0.3829759359359741  (-0.3609855572382609)\n",
      "     | > loss_dur: 0.21721942722797394  (0.16381899019082388)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: -0.17939506471157074  (-0.19462778099945613)\n",
      "     | > log_mle: -0.3398061990737915  (-0.3579599346433367)\n",
      "     | > loss_dur: 0.16041113436222076  (0.16333215364388057)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: -0.19674250483512878  (-0.19489212147891521)\n",
      "     | > log_mle: -0.3534044027328491  (-0.35739049315452576)\n",
      "     | > loss_dur: 0.15666189789772034  (0.16249837167561054)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: -0.20056314766407013  (-0.195522235499488)\n",
      "     | > log_mle: -0.3662458658218384  (-0.3583744234508938)\n",
      "     | > loss_dur: 0.16568271815776825  (0.16285218795140585)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: -0.1713012009859085  (-0.19310013204813004)\n",
      "     | > log_mle: -0.35148847103118896  (-0.35768582820892336)\n",
      "     | > loss_dur: 0.18018727004528046  (0.1645856961607933)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: -0.19927841424942017  (-0.19366179406642914)\n",
      "     | > log_mle: -0.36883842945098877  (-0.3586997010491111)\n",
      "     | > loss_dur: 0.1695600152015686  (0.16503790698268198)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: -0.20491746068000793  (-0.19459976628422737)\n",
      "     | > log_mle: -0.3530064821243286  (-0.3582252661387126)\n",
      "     | > loss_dur: 0.14808902144432068  (0.16362549985448518)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: -0.2158028930425644  (-0.1962307760348687)\n",
      "     | > log_mle: -0.37821269035339355  (-0.3597627603090726)\n",
      "     | > loss_dur: 0.16240979731082916  (0.16353198427420396)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: -0.19868507981300354  (-0.1964060834475926)\n",
      "     | > log_mle: -0.36539196968078613  (-0.36016484669276644)\n",
      "     | > loss_dur: 0.1667068898677826  (0.16375876324517386)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: -0.1896219104528427  (-0.19595380524794262)\n",
      "     | > log_mle: -0.3573942184448242  (-0.35998013814290364)\n",
      "     | > loss_dur: 0.1677723079919815  (0.16402633289496105)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: -0.18712973594665527  (-0.19540230091661215)\n",
      "     | > log_mle: -0.36223268508911133  (-0.3601209223270416)\n",
      "     | > loss_dur: 0.17510294914245605  (0.16471862141042948)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: audio amplitude out of range, auto clipped.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[91m 0.003972500562667847 \u001b[0m(+0.00013768672943115234)\n",
      "     | > avg_loss:\u001b[92m -0.19540230091661215 \u001b[0m(-0.00629783421754837)\n",
      "     | > avg_log_mle:\u001b[92m -0.3601209223270416 \u001b[0m(-0.006774991750717163)\n",
      "     | > avg_loss_dur:\u001b[91m 0.16471862141042948 \u001b[0m(+0.0004771570675075054)\n",
      "\n",
      " > BEST MODEL : train/run-February-22-2025_10+59PM-fa84af3/best_model_57646.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 86/100\u001b[0m\n",
      " --> train/run-February-22-2025_10+59PM-fa84af3\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-23 06:24:43) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:24:47 -- STEP: 4/406 -- GLOBAL_STEP: 57650\u001b[0m\n",
      "     | > loss: -0.17283087968826294  (-0.1907222792506218)\n",
      "     | > log_mle: -0.3068023920059204  (-0.3260882794857025)\n",
      "     | > loss_dur: 0.13397151231765747  (0.13536600023508072)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(12.0253, device='cuda:0')  (tensor(18.5789, device='cuda:0'))\n",
      "     | > current_lr: 2.15e-05 \n",
      "     | > step_time: 0.3358  (0.456088125705719)\n",
      "     | > loader_time: 0.0076  (0.015339672565460205)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:25:00 -- STEP: 29/406 -- GLOBAL_STEP: 57675\u001b[0m\n",
      "     | > loss: -0.17062251269817352  (-0.17740274965763092)\n",
      "     | > log_mle: -0.3327401876449585  (-0.3239851614524578)\n",
      "     | > loss_dur: 0.16211767494678497  (0.14658241205174347)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(23.8139, device='cuda:0')  (tensor(27.5139, device='cuda:0'))\n",
      "     | > current_lr: 2.15e-05 \n",
      "     | > step_time: 0.9571  (0.5090339019380766)\n",
      "     | > loader_time: 0.0066  (0.00713384562525256)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:25:16 -- STEP: 54/406 -- GLOBAL_STEP: 57700\u001b[0m\n",
      "     | > loss: -0.16891050338745117  (-0.1690567193759813)\n",
      "     | > log_mle: -0.32596898078918457  (-0.3228817847039964)\n",
      "     | > loss_dur: 0.1570584774017334  (0.15382506546598892)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(40.0144, device='cuda:0')  (tensor(27.0039, device='cuda:0'))\n",
      "     | > current_lr: 2.15e-05 \n",
      "     | > step_time: 0.4532  (0.550443477100796)\n",
      "     | > loader_time: 0.0464  (0.00897105093355532)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:25:31 -- STEP: 79/406 -- GLOBAL_STEP: 57725\u001b[0m\n",
      "     | > loss: -0.15274015069007874  (-0.16689511379109156)\n",
      "     | > log_mle: -0.32926344871520996  (-0.32465911666049224)\n",
      "     | > loss_dur: 0.17652329802513123  (0.15776400296371193)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(39.3353, device='cuda:0')  (tensor(30.3945, device='cuda:0'))\n",
      "     | > current_lr: 2.15e-05 \n",
      "     | > step_time: 0.5716  (0.5689066995548293)\n",
      "     | > loader_time: 0.0104  (0.00894532626188254)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:25:48 -- STEP: 104/406 -- GLOBAL_STEP: 57750\u001b[0m\n",
      "     | > loss: -0.15885530412197113  (-0.16594999369520408)\n",
      "     | > log_mle: -0.3309396505355835  (-0.32744543139751126)\n",
      "     | > loss_dur: 0.17208434641361237  (0.16149543777394745)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(21.7688, device='cuda:0')  (tensor(31.9174, device='cuda:0'))\n",
      "     | > current_lr: 2.15e-05 \n",
      "     | > step_time: 0.617  (0.5838254896494056)\n",
      "     | > loader_time: 0.0172  (0.009545317062964805)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:26:04 -- STEP: 129/406 -- GLOBAL_STEP: 57775\u001b[0m\n",
      "     | > loss: -0.15602824091911316  (-0.16500252762506173)\n",
      "     | > log_mle: -0.33724725246429443  (-0.32924070007117207)\n",
      "     | > loss_dur: 0.18121901154518127  (0.16423817250386682)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(23.0057, device='cuda:0')  (tensor(32.6798, device='cuda:0'))\n",
      "     | > current_lr: 2.15e-05 \n",
      "     | > step_time: 0.3934  (0.5947880985200865)\n",
      "     | > loader_time: 0.006  (0.009634446728137111)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:26:21 -- STEP: 154/406 -- GLOBAL_STEP: 57800\u001b[0m\n",
      "     | > loss: -0.13884000480175018  (-0.16333797961086427)\n",
      "     | > log_mle: -0.3181523084640503  (-0.330328536498082)\n",
      "     | > loss_dur: 0.1793123036623001  (0.16699055693559828)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(24.7537, device='cuda:0')  (tensor(33.4418, device='cuda:0'))\n",
      "     | > current_lr: 2.15e-05 \n",
      "     | > step_time: 0.5901  (0.6063606599708655)\n",
      "     | > loader_time: 0.0106  (0.009618218843038977)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:26:39 -- STEP: 179/406 -- GLOBAL_STEP: 57825\u001b[0m\n",
      "     | > loss: -0.19027367234230042  (-0.16347484448768582)\n",
      "     | > log_mle: -0.35403895378112793  (-0.3316487153815156)\n",
      "     | > loss_dur: 0.16376528143882751  (0.16817387093545336)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(41.8810, device='cuda:0')  (tensor(35.5838, device='cuda:0'))\n",
      "     | > current_lr: 2.15e-05 \n",
      "     | > step_time: 0.8008  (0.6186761496453311)\n",
      "     | > loader_time: 0.0071  (0.009875582583123741)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:26:57 -- STEP: 204/406 -- GLOBAL_STEP: 57850\u001b[0m\n",
      "     | > loss: -0.1751304268836975  (-0.16347170007579467)\n",
      "     | > log_mle: -0.3470519781112671  (-0.33320641576075066)\n",
      "     | > loss_dur: 0.17192155122756958  (0.16973471572147858)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(19.5281, device='cuda:0')  (tensor(35.8276, device='cuda:0'))\n",
      "     | > current_lr: 2.15e-05 \n",
      "     | > step_time: 0.6741  (0.6283794992110308)\n",
      "     | > loader_time: 0.0195  (0.010109457315183158)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:27:15 -- STEP: 229/406 -- GLOBAL_STEP: 57875\u001b[0m\n",
      "     | > loss: -0.16526086628437042  (-0.16343126956812679)\n",
      "     | > log_mle: -0.34162044525146484  (-0.3345314373616046)\n",
      "     | > loss_dur: 0.17635957896709442  (0.1711001678260132)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(22.8938, device='cuda:0')  (tensor(36.9010, device='cuda:0'))\n",
      "     | > current_lr: 2.15e-05 \n",
      "     | > step_time: 0.6977  (0.6393696116568218)\n",
      "     | > loader_time: 0.0103  (0.010377735029662024)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:27:35 -- STEP: 254/406 -- GLOBAL_STEP: 57900\u001b[0m\n",
      "     | > loss: -0.1658947467803955  (-0.16351439416643201)\n",
      "     | > log_mle: -0.3361612558364868  (-0.33580046469771)\n",
      "     | > loss_dur: 0.1702665090560913  (0.17228607056061107)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(59.6996, device='cuda:0')  (tensor(36.9965, device='cuda:0'))\n",
      "     | > current_lr: 2.15e-05 \n",
      "     | > step_time: 0.8328  (0.6506163773574227)\n",
      "     | > loader_time: 0.0317  (0.0106913085997574)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:27:55 -- STEP: 279/406 -- GLOBAL_STEP: 57925\u001b[0m\n",
      "     | > loss: -0.13800422847270966  (-0.1635726890576783)\n",
      "     | > log_mle: -0.32815849781036377  (-0.3366058261591045)\n",
      "     | > loss_dur: 0.1901542693376541  (0.17303313712813093)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(30.5548, device='cuda:0')  (tensor(37.3276, device='cuda:0'))\n",
      "     | > current_lr: 2.15e-05 \n",
      "     | > step_time: 0.9265  (0.6646200380017683)\n",
      "     | > loader_time: 0.0132  (0.010941859214536609)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:28:16 -- STEP: 304/406 -- GLOBAL_STEP: 57950\u001b[0m\n",
      "     | > loss: -0.1732531040906906  (-0.16367379227947243)\n",
      "     | > log_mle: -0.347481369972229  (-0.33752164793641926)\n",
      "     | > loss_dur: 0.1742282658815384  (0.17384785568145542)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(47.2645, device='cuda:0')  (tensor(37.6245, device='cuda:0'))\n",
      "     | > current_lr: 2.15e-05 \n",
      "     | > step_time: 0.789  (0.6754165856461777)\n",
      "     | > loader_time: 0.0077  (0.011078507492416787)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:28:36 -- STEP: 329/406 -- GLOBAL_STEP: 57975\u001b[0m\n",
      "     | > loss: -0.1633407324552536  (-0.16345881922085592)\n",
      "     | > log_mle: -0.3348221778869629  (-0.3380497143261336)\n",
      "     | > loss_dur: 0.1714814454317093  (0.17459089512792403)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(45.6003, device='cuda:0')  (tensor(37.7106, device='cuda:0'))\n",
      "     | > current_lr: 2.15e-05 \n",
      "     | > step_time: 1.4907  (0.6840106266972505)\n",
      "     | > loader_time: 0.0121  (0.011524977292695672)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:28:56 -- STEP: 354/406 -- GLOBAL_STEP: 58000\u001b[0m\n",
      "     | > loss: -0.1584274023771286  (-0.1633010649748441)\n",
      "     | > log_mle: -0.33904826641082764  (-0.33876352626725076)\n",
      "     | > loss_dur: 0.18062086403369904  (0.1754624613134538)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(98.4748, device='cuda:0')  (tensor(37.9556, device='cuda:0'))\n",
      "     | > current_lr: 2.15e-05 \n",
      "     | > step_time: 0.6205  (0.6905843154185234)\n",
      "     | > loader_time: 0.0063  (0.011956919384541485)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:29:17 -- STEP: 379/406 -- GLOBAL_STEP: 58025\u001b[0m\n",
      "     | > loss: -0.17167538404464722  (-0.16342190902748957)\n",
      "     | > log_mle: -0.3492107391357422  (-0.33949854506037136)\n",
      "     | > loss_dur: 0.17753535509109497  (0.17607663605254062)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(41.1418, device='cuda:0')  (tensor(37.9441, device='cuda:0'))\n",
      "     | > current_lr: 2.15e-05 \n",
      "     | > step_time: 0.9559  (0.6992382393034279)\n",
      "     | > loader_time: 0.0149  (0.01218814963086614)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:29:35 -- STEP: 404/406 -- GLOBAL_STEP: 58050\u001b[0m\n",
      "     | > loss: -0.18342652916908264  (-0.16384082117883286)\n",
      "     | > log_mle: -0.3529709577560425  (-0.3403194720792295)\n",
      "     | > loss_dur: 0.16954442858695984  (0.17647865091883908)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(21.0512, device='cuda:0')  (tensor(38.3347, device='cuda:0'))\n",
      "     | > current_lr: 2.15e-05 \n",
      "     | > step_time: 0.5472  (0.6994829537844894)\n",
      "     | > loader_time: 0.0101  (0.012229230144236347)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: -0.15496543049812317  (-0.15496543049812317)\n",
      "     | > log_mle: -0.32360589504241943  (-0.32360589504241943)\n",
      "     | > loss_dur: 0.16864046454429626  (0.16864046454429626)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: -0.19822034239768982  (-0.19822034239768982)\n",
      "     | > log_mle: -0.3666071891784668  (-0.3666071891784668)\n",
      "     | > loss_dur: 0.16838684678077698  (0.16838684678077698)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: -0.20504708588123322  (-0.20163371413946152)\n",
      "     | > log_mle: -0.33194053173065186  (-0.3492738604545593)\n",
      "     | > loss_dur: 0.12689344584941864  (0.1476401463150978)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: -0.1932181715965271  (-0.1988285332918167)\n",
      "     | > log_mle: -0.3387417793273926  (-0.3457631667455037)\n",
      "     | > loss_dur: 0.14552360773086548  (0.14693463345368704)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: -0.2115085870027542  (-0.2019985467195511)\n",
      "     | > log_mle: -0.36412274837493896  (-0.35035306215286255)\n",
      "     | > loss_dur: 0.15261416137218475  (0.14835451543331146)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: -0.2011500597000122  (-0.20182884931564332)\n",
      "     | > log_mle: -0.36364901065826416  (-0.35301225185394286)\n",
      "     | > loss_dur: 0.16249895095825195  (0.15118340253829957)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: -0.15303686261177063  (-0.19369685153166452)\n",
      "     | > log_mle: -0.37470829486846924  (-0.3566282590230306)\n",
      "     | > loss_dur: 0.2216714322566986  (0.16293140749136606)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: -0.1773492842912674  (-0.19136148478303636)\n",
      "     | > log_mle: -0.3351616859436035  (-0.35356160572596956)\n",
      "     | > loss_dur: 0.15781240165233612  (0.1622001209429332)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: -0.19121499359607697  (-0.19134317338466644)\n",
      "     | > log_mle: -0.34964704513549805  (-0.35307228565216064)\n",
      "     | > loss_dur: 0.15843205153942108  (0.1617291122674942)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: -0.18972526490688324  (-0.19116340577602386)\n",
      "     | > log_mle: -0.3610597848892212  (-0.3539597855673896)\n",
      "     | > loss_dur: 0.17133451998233795  (0.16279637979136574)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: -0.1608087569475174  (-0.18812794089317322)\n",
      "     | > log_mle: -0.3470515012741089  (-0.3532689571380615)\n",
      "     | > loss_dur: 0.1862427443265915  (0.1651410162448883)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: -0.1960543543100357  (-0.1888485239310698)\n",
      "     | > log_mle: -0.3634061813354492  (-0.3541905229741877)\n",
      "     | > loss_dur: 0.1673518270254135  (0.16534199904311786)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: -0.1984207183122635  (-0.18964620679616928)\n",
      "     | > log_mle: -0.34941816329956055  (-0.35379282633463544)\n",
      "     | > loss_dur: 0.15099744498729706  (0.16414661953846613)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: -0.2097548097372055  (-0.19119302240701821)\n",
      "     | > log_mle: -0.37281668186187744  (-0.35525619983673096)\n",
      "     | > loss_dur: 0.16306187212467194  (0.16406317742971274)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: -0.18762198090553284  (-0.19093794801405498)\n",
      "     | > log_mle: -0.3608736991882324  (-0.35565744979040964)\n",
      "     | > loss_dur: 0.17325171828269958  (0.16471950177635467)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: -0.19070063531398773  (-0.19092212716738383)\n",
      "     | > log_mle: -0.3533276319503784  (-0.3555021286010742)\n",
      "     | > loss_dur: 0.16262699663639069  (0.1645800014336904)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: -0.186346635222435  (-0.19063615892082453)\n",
      "     | > log_mle: -0.3574320077896118  (-0.3556227460503578)\n",
      "     | > loss_dur: 0.17108537256717682  (0.1649865871295333)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: audio amplitude out of range, auto clipped.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[91m 0.00601997971534729 \u001b[0m(+0.0020474791526794434)\n",
      "     | > avg_loss:\u001b[91m -0.19063615892082453 \u001b[0m(+0.0047661419957876205)\n",
      "     | > avg_log_mle:\u001b[91m -0.3556227460503578 \u001b[0m(+0.004498176276683807)\n",
      "     | > avg_loss_dur:\u001b[91m 0.1649865871295333 \u001b[0m(+0.00026796571910381317)\n",
      "\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 87/100\u001b[0m\n",
      " --> train/run-February-22-2025_10+59PM-fa84af3\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-23 06:29:51) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:30:04 -- STEP: 23/406 -- GLOBAL_STEP: 58075\u001b[0m\n",
      "     | > loss: -0.1655040681362152  (-0.17871891091699182)\n",
      "     | > log_mle: -0.3228820562362671  (-0.32242045195206354)\n",
      "     | > loss_dur: 0.15737798810005188  (0.14370154103507166)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(24.7883, device='cuda:0')  (tensor(26.1379, device='cuda:0'))\n",
      "     | > current_lr: 2.175e-05 \n",
      "     | > step_time: 0.4988  (0.47400788638902747)\n",
      "     | > loader_time: 0.0046  (0.010643534038377846)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:30:19 -- STEP: 48/406 -- GLOBAL_STEP: 58100\u001b[0m\n",
      "     | > loss: -0.1318061500787735  (-0.1716984317948421)\n",
      "     | > log_mle: -0.31407904624938965  (-0.32226125895977026)\n",
      "     | > loss_dur: 0.18227289617061615  (0.1505628271649281)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(42.3376, device='cuda:0')  (tensor(29.9925, device='cuda:0'))\n",
      "     | > current_lr: 2.175e-05 \n",
      "     | > step_time: 0.4696  (0.5297166407108308)\n",
      "     | > loader_time: 0.0262  (0.010764867067337036)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:30:35 -- STEP: 73/406 -- GLOBAL_STEP: 58125\u001b[0m\n",
      "     | > loss: -0.1747494786977768  (-0.17019629417216947)\n",
      "     | > log_mle: -0.3432931900024414  (-0.325622952147706)\n",
      "     | > loss_dur: 0.1685437113046646  (0.1554266579755365)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(37.7886, device='cuda:0')  (tensor(30.7769, device='cuda:0'))\n",
      "     | > current_lr: 2.175e-05 \n",
      "     | > step_time: 0.5148  (0.558723655465531)\n",
      "     | > loader_time: 0.0082  (0.010936488843943977)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:30:52 -- STEP: 98/406 -- GLOBAL_STEP: 58150\u001b[0m\n",
      "     | > loss: -0.14172421395778656  (-0.1690115869349363)\n",
      "     | > log_mle: -0.3252885341644287  (-0.3289825952782924)\n",
      "     | > loss_dur: 0.18356432020664215  (0.15997100834335604)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(19.8617, device='cuda:0')  (tensor(30.7662, device='cuda:0'))\n",
      "     | > current_lr: 2.175e-05 \n",
      "     | > step_time: 0.5392  (0.584314516612462)\n",
      "     | > loader_time: 0.0182  (0.010843673530890021)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:31:08 -- STEP: 123/406 -- GLOBAL_STEP: 58175\u001b[0m\n",
      "     | > loss: -0.15673120319843292  (-0.16835777437299249)\n",
      "     | > log_mle: -0.34521961212158203  (-0.33118584485557995)\n",
      "     | > loss_dur: 0.1884884089231491  (0.16282807048258746)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(29.3043, device='cuda:0')  (tensor(35.0564, device='cuda:0'))\n",
      "     | > current_lr: 2.175e-05 \n",
      "     | > step_time: 0.6762  (0.5941268176567266)\n",
      "     | > loader_time: 0.0093  (0.01139401614181395)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:31:25 -- STEP: 148/406 -- GLOBAL_STEP: 58200\u001b[0m\n",
      "     | > loss: -0.1638786643743515  (-0.1675967722124344)\n",
      "     | > log_mle: -0.3537454605102539  (-0.3330795104439195)\n",
      "     | > loss_dur: 0.1898667961359024  (0.16548273823148504)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(28.4411, device='cuda:0')  (tensor(34.6289, device='cuda:0'))\n",
      "     | > current_lr: 2.175e-05 \n",
      "     | > step_time: 0.6851  (0.60369530561808)\n",
      "     | > loader_time: 0.0059  (0.01150378826502208)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:31:43 -- STEP: 173/406 -- GLOBAL_STEP: 58225\u001b[0m\n",
      "     | > loss: -0.17106331884860992  (-0.16714571778140305)\n",
      "     | > log_mle: -0.33877623081207275  (-0.3343949628014097)\n",
      "     | > loss_dur: 0.16771291196346283  (0.16724924502000663)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(28.3939, device='cuda:0')  (tensor(34.6301, device='cuda:0'))\n",
      "     | > current_lr: 2.175e-05 \n",
      "     | > step_time: 0.7955  (0.6172441843617171)\n",
      "     | > loader_time: 0.0165  (0.012092220989954963)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:32:01 -- STEP: 198/406 -- GLOBAL_STEP: 58250\u001b[0m\n",
      "     | > loss: -0.16726462543010712  (-0.16698956790596542)\n",
      "     | > log_mle: -0.3491661548614502  (-0.3356783775368125)\n",
      "     | > loss_dur: 0.18190152943134308  (0.16868880963084695)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(27.8700, device='cuda:0')  (tensor(34.4573, device='cuda:0'))\n",
      "     | > current_lr: 2.175e-05 \n",
      "     | > step_time: 0.735  (0.6293689421933109)\n",
      "     | > loader_time: 0.0084  (0.012150550129437694)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:32:20 -- STEP: 223/406 -- GLOBAL_STEP: 58275\u001b[0m\n",
      "     | > loss: -0.1678294688463211  (-0.16668553817432552)\n",
      "     | > log_mle: -0.338778018951416  (-0.336705326499426)\n",
      "     | > loss_dur: 0.1709485501050949  (0.1700197883251004)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(160.7389, device='cuda:0')  (tensor(37.3729, device='cuda:0'))\n",
      "     | > current_lr: 2.175e-05 \n",
      "     | > step_time: 0.6509  (0.6424433629074441)\n",
      "     | > loader_time: 0.0084  (0.012041436182543842)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:32:39 -- STEP: 248/406 -- GLOBAL_STEP: 58300\u001b[0m\n",
      "     | > loss: -0.17382539808750153  (-0.16605111535999076)\n",
      "     | > log_mle: -0.3456275463104248  (-0.33742514108457894)\n",
      "     | > loss_dur: 0.17180214822292328  (0.17137402572458807)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(64.0653, device='cuda:0')  (tensor(38.1401, device='cuda:0'))\n",
      "     | > current_lr: 2.175e-05 \n",
      "     | > step_time: 0.6707  (0.6519571244716647)\n",
      "     | > loader_time: 0.0061  (0.012329346710635776)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:32:58 -- STEP: 273/406 -- GLOBAL_STEP: 58325\u001b[0m\n",
      "     | > loss: -0.16823001205921173  (-0.16648491976898663)\n",
      "     | > log_mle: -0.35029077529907227  (-0.3385267270790354)\n",
      "     | > loss_dur: 0.18206076323986053  (0.17204180731004864)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(61.9375, device='cuda:0')  (tensor(37.3864, device='cuda:0'))\n",
      "     | > current_lr: 2.175e-05 \n",
      "     | > step_time: 0.6626  (0.6607481044727369)\n",
      "     | > loader_time: 0.0137  (0.012542261745466859)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:33:18 -- STEP: 298/406 -- GLOBAL_STEP: 58350\u001b[0m\n",
      "     | > loss: -0.1617349237203598  (-0.16637729178339036)\n",
      "     | > log_mle: -0.34075915813446045  (-0.3392581987701009)\n",
      "     | > loss_dur: 0.17902423441410065  (0.17288090698671033)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(43.7384, device='cuda:0')  (tensor(37.7922, device='cuda:0'))\n",
      "     | > current_lr: 2.175e-05 \n",
      "     | > step_time: 0.6173  (0.6702617054817661)\n",
      "     | > loader_time: 0.0108  (0.01276540676219352)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:33:39 -- STEP: 323/406 -- GLOBAL_STEP: 58375\u001b[0m\n",
      "     | > loss: -0.175492525100708  (-0.1666286157288418)\n",
      "     | > log_mle: -0.3566272258758545  (-0.34024316902869284)\n",
      "     | > loss_dur: 0.18113470077514648  (0.17361455329985084)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(38.8265, device='cuda:0')  (tensor(37.9403, device='cuda:0'))\n",
      "     | > current_lr: 2.175e-05 \n",
      "     | > step_time: 0.9009  (0.6797582010735669)\n",
      "     | > loader_time: 0.0175  (0.012946673591070506)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:33:59 -- STEP: 348/406 -- GLOBAL_STEP: 58400\u001b[0m\n",
      "     | > loss: -0.16595666110515594  (-0.16660361201769996)\n",
      "     | > log_mle: -0.3554542064666748  (-0.3410607785329052)\n",
      "     | > loss_dur: 0.18949754536151886  (0.17445716651520513)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(37.6253, device='cuda:0')  (tensor(37.9098, device='cuda:0'))\n",
      "     | > current_lr: 2.175e-05 \n",
      "     | > step_time: 0.7605  (0.6885308123182977)\n",
      "     | > loader_time: 0.0246  (0.013190314687531575)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:34:22 -- STEP: 373/406 -- GLOBAL_STEP: 58425\u001b[0m\n",
      "     | > loss: -0.18399912118911743  (-0.16679451332974363)\n",
      "     | > log_mle: -0.35628950595855713  (-0.3419158848616779)\n",
      "     | > loss_dur: 0.1722903847694397  (0.17512137153193402)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(66.9633, device='cuda:0')  (tensor(38.0408, device='cuda:0'))\n",
      "     | > current_lr: 2.175e-05 \n",
      "     | > step_time: 1.0346  (0.70094339905092)\n",
      "     | > loader_time: 0.0063  (0.01321745685853524)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:34:41 -- STEP: 398/406 -- GLOBAL_STEP: 58450\u001b[0m\n",
      "     | > loss: -0.1736181229352951  (-0.1668653166174289)\n",
      "     | > log_mle: -0.355444073677063  (-0.34256371930616014)\n",
      "     | > loss_dur: 0.18182595074176788  (0.17569840268873096)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(29.7109, device='cuda:0')  (tensor(38.5837, device='cuda:0'))\n",
      "     | > current_lr: 2.175e-05 \n",
      "     | > step_time: 0.5272  (0.7053673758578662)\n",
      "     | > loader_time: 0.0091  (0.013477446445867649)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: -0.15647366642951965  (-0.15647366642951965)\n",
      "     | > log_mle: -0.32597339153289795  (-0.32597339153289795)\n",
      "     | > loss_dur: 0.1694997251033783  (0.1694997251033783)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: -0.20058764517307281  (-0.20058764517307281)\n",
      "     | > log_mle: -0.3695094585418701  (-0.3695094585418701)\n",
      "     | > loss_dur: 0.1689218133687973  (0.1689218133687973)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: -0.2069750428199768  (-0.2037813439965248)\n",
      "     | > log_mle: -0.3340280055999756  (-0.35176873207092285)\n",
      "     | > loss_dur: 0.12705296277999878  (0.14798738807439804)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: -0.19789715111255646  (-0.20181994636853537)\n",
      "     | > log_mle: -0.3411613702774048  (-0.3482329448064168)\n",
      "     | > loss_dur: 0.14326421916484833  (0.14641299843788147)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: -0.20239779353141785  (-0.20196440815925598)\n",
      "     | > log_mle: -0.3669133186340332  (-0.3529030382633209)\n",
      "     | > loss_dur: 0.16451552510261536  (0.15093863010406494)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: -0.20434324443340302  (-0.20244017541408538)\n",
      "     | > log_mle: -0.3656129837036133  (-0.3554450273513794)\n",
      "     | > loss_dur: 0.16126973927021027  (0.15300485193729402)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: -0.15491652488708496  (-0.19451956699291864)\n",
      "     | > log_mle: -0.3776746988296509  (-0.359149972597758)\n",
      "     | > loss_dur: 0.22275817394256592  (0.16463040560483932)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: -0.17765581607818604  (-0.19211045971938542)\n",
      "     | > log_mle: -0.3380056619644165  (-0.3561293567929949)\n",
      "     | > loss_dur: 0.16034984588623047  (0.16401889707360948)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: -0.19662636518478394  (-0.19267494790256023)\n",
      "     | > log_mle: -0.3527698516845703  (-0.35570941865444183)\n",
      "     | > loss_dur: 0.15614348649978638  (0.1630344707518816)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: -0.19614841043949127  (-0.19306088818444145)\n",
      "     | > log_mle: -0.3637704849243164  (-0.3566050926844279)\n",
      "     | > loss_dur: 0.16762207448482513  (0.16354420449998644)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: -0.16740253567695618  (-0.19049505293369293)\n",
      "     | > log_mle: -0.35003185272216797  (-0.3559477686882019)\n",
      "     | > loss_dur: 0.1826293170452118  (0.16545271575450898)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: -0.19833332300186157  (-0.19120762293989008)\n",
      "     | > log_mle: -0.36722564697265625  (-0.35697303035042505)\n",
      "     | > loss_dur: 0.16889232397079468  (0.16576540741053494)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: -0.2092951536178589  (-0.19271491716305414)\n",
      "     | > log_mle: -0.35219478607177734  (-0.3565748433272044)\n",
      "     | > loss_dur: 0.14289963245391846  (0.16385992616415024)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: -0.21390654146671295  (-0.19434504210948944)\n",
      "     | > log_mle: -0.3744393587112427  (-0.35794903681828427)\n",
      "     | > loss_dur: 0.16053281724452972  (0.1636039947087948)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: -0.18934234976768494  (-0.1939877069422177)\n",
      "     | > log_mle: -0.3633333444595337  (-0.35833363022123066)\n",
      "     | > loss_dur: 0.17399099469184875  (0.16434592327901296)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: -0.19370350241661072  (-0.19396875997384389)\n",
      "     | > log_mle: -0.3559694290161133  (-0.3581760168075562)\n",
      "     | > loss_dur: 0.16226592659950256  (0.16420725683371226)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: -0.18820501863956451  (-0.19360852614045143)\n",
      "     | > log_mle: -0.36051011085510254  (-0.3583218976855278)\n",
      "     | > loss_dur: 0.17230509221553802  (0.16471337154507637)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: audio amplitude out of range, auto clipped.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.004264920949935913 \u001b[0m(-0.001755058765411377)\n",
      "     | > avg_loss:\u001b[92m -0.19360852614045143 \u001b[0m(-0.0029723672196269035)\n",
      "     | > avg_log_mle:\u001b[92m -0.3583218976855278 \u001b[0m(-0.002699151635169983)\n",
      "     | > avg_loss_dur:\u001b[92m 0.16471337154507637 \u001b[0m(-0.0002732155844569206)\n",
      "\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 88/100\u001b[0m\n",
      " --> train/run-February-22-2025_10+59PM-fa84af3\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-23 06:35:01) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:35:10 -- STEP: 17/406 -- GLOBAL_STEP: 58475\u001b[0m\n",
      "     | > loss: -0.16938742995262146  (-0.18674863699604483)\n",
      "     | > log_mle: -0.3288954496383667  (-0.3301240416134105)\n",
      "     | > loss_dur: 0.15950801968574524  (0.14337540417909622)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(17.7008, device='cuda:0')  (tensor(30.1697, device='cuda:0'))\n",
      "     | > current_lr: 2.2e-05 \n",
      "     | > step_time: 0.4378  (0.4373334435855641)\n",
      "     | > loader_time: 0.0149  (0.00760342093075023)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:35:26 -- STEP: 42/406 -- GLOBAL_STEP: 58500\u001b[0m\n",
      "     | > loss: -0.1735612452030182  (-0.17706470475310376)\n",
      "     | > log_mle: -0.3315136432647705  (-0.32581926243645803)\n",
      "     | > loss_dur: 0.15795239806175232  (0.1487545575059596)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(28.5538, device='cuda:0')  (tensor(30.3225, device='cuda:0'))\n",
      "     | > current_lr: 2.2e-05 \n",
      "     | > step_time: 0.8293  (0.5363052288691202)\n",
      "     | > loader_time: 0.0157  (0.009330391883850096)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:35:42 -- STEP: 67/406 -- GLOBAL_STEP: 58525\u001b[0m\n",
      "     | > loss: -0.1573590785264969  (-0.17157155742396174)\n",
      "     | > log_mle: -0.33769094944000244  (-0.32673601605998936)\n",
      "     | > loss_dur: 0.18033187091350555  (0.155164458524825)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(36.2620, device='cuda:0')  (tensor(28.4234, device='cuda:0'))\n",
      "     | > current_lr: 2.2e-05 \n",
      "     | > step_time: 0.7457  (0.5663920979001628)\n",
      "     | > loader_time: 0.005  (0.01008370029392527)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:35:58 -- STEP: 92/406 -- GLOBAL_STEP: 58550\u001b[0m\n",
      "     | > loss: -0.16674067080020905  (-0.17004773749605476)\n",
      "     | > log_mle: -0.3498023748397827  (-0.3288743936497233)\n",
      "     | > loss_dur: 0.18306170403957367  (0.15882665607268398)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(27.6400, device='cuda:0')  (tensor(30.2237, device='cuda:0'))\n",
      "     | > current_lr: 2.2e-05 \n",
      "     | > step_time: 0.5272  (0.5857512510341144)\n",
      "     | > loader_time: 0.008  (0.010065609994141952)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:36:15 -- STEP: 117/406 -- GLOBAL_STEP: 58575\u001b[0m\n",
      "     | > loss: -0.14593303203582764  (-0.1684259563429743)\n",
      "     | > log_mle: -0.32353413105010986  (-0.3308856038965732)\n",
      "     | > loss_dur: 0.17760109901428223  (0.1624596474899186)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(170.6748, device='cuda:0')  (tensor(34.1193, device='cuda:0'))\n",
      "     | > current_lr: 2.2e-05 \n",
      "     | > step_time: 0.8271  (0.5989235853537532)\n",
      "     | > loader_time: 0.0078  (0.01019524509071285)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:36:32 -- STEP: 142/406 -- GLOBAL_STEP: 58600\u001b[0m\n",
      "     | > loss: -0.17811450362205505  (-0.16748791828121942)\n",
      "     | > log_mle: -0.34780144691467285  (-0.3326775465213079)\n",
      "     | > loss_dur: 0.1696869432926178  (0.16518962818761945)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(48.0008, device='cuda:0')  (tensor(36.4110, device='cuda:0'))\n",
      "     | > current_lr: 2.2e-05 \n",
      "     | > step_time: 0.5218  (0.6110857154282046)\n",
      "     | > loader_time: 0.0193  (0.01034403183090855)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:36:50 -- STEP: 167/406 -- GLOBAL_STEP: 58625\u001b[0m\n",
      "     | > loss: -0.16567423939704895  (-0.16670012545442872)\n",
      "     | > log_mle: -0.3369600772857666  (-0.3339291404107375)\n",
      "     | > loss_dur: 0.17128583788871765  (0.16722901491169437)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(20.4283, device='cuda:0')  (tensor(36.8151, device='cuda:0'))\n",
      "     | > current_lr: 2.2e-05 \n",
      "     | > step_time: 0.5216  (0.6222668636344864)\n",
      "     | > loader_time: 0.0218  (0.010948176869375263)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:37:07 -- STEP: 192/406 -- GLOBAL_STEP: 58650\u001b[0m\n",
      "     | > loss: -0.17967046797275543  (-0.16730147150034713)\n",
      "     | > log_mle: -0.35002779960632324  (-0.33551510112981003)\n",
      "     | > loss_dur: 0.1703573316335678  (0.16821362959065786)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(49.8492, device='cuda:0')  (tensor(36.0188, device='cuda:0'))\n",
      "     | > current_lr: 2.2e-05 \n",
      "     | > step_time: 0.8166  (0.6315699157615501)\n",
      "     | > loader_time: 0.0075  (0.011324788133303322)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:37:25 -- STEP: 217/406 -- GLOBAL_STEP: 58675\u001b[0m\n",
      "     | > loss: -0.16622430086135864  (-0.16716259525668242)\n",
      "     | > log_mle: -0.3540356159210205  (-0.336895698226542)\n",
      "     | > loss_dur: 0.18781131505966187  (0.16973310293552513)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(26.1173, device='cuda:0')  (tensor(35.9331, device='cuda:0'))\n",
      "     | > current_lr: 2.2e-05 \n",
      "     | > step_time: 0.7938  (0.6373860220755295)\n",
      "     | > loader_time: 0.0148  (0.01163275560475714)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:37:43 -- STEP: 242/406 -- GLOBAL_STEP: 58700\u001b[0m\n",
      "     | > loss: -0.16624067723751068  (-0.16727621471586313)\n",
      "     | > log_mle: -0.3568274974822998  (-0.3383158105464021)\n",
      "     | > loss_dur: 0.19058682024478912  (0.17103959579975153)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(54.8873, device='cuda:0')  (tensor(36.7306, device='cuda:0'))\n",
      "     | > current_lr: 2.2e-05 \n",
      "     | > step_time: 0.7272  (0.6443087719688726)\n",
      "     | > loader_time: 0.0062  (0.012003125238024498)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:38:02 -- STEP: 267/406 -- GLOBAL_STEP: 58725\u001b[0m\n",
      "     | > loss: -0.16923946142196655  (-0.16780148424236074)\n",
      "     | > log_mle: -0.34196579456329346  (-0.3394861167736268)\n",
      "     | > loss_dur: 0.1727263331413269  (0.1716846325033613)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(46.7784, device='cuda:0')  (tensor(36.7700, device='cuda:0'))\n",
      "     | > current_lr: 2.2e-05 \n",
      "     | > step_time: 0.51  (0.6511787475271613)\n",
      "     | > loader_time: 0.0137  (0.012181416879432477)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:38:22 -- STEP: 292/406 -- GLOBAL_STEP: 58750\u001b[0m\n",
      "     | > loss: -0.16257430613040924  (-0.16746465035089078)\n",
      "     | > log_mle: -0.3404608964920044  (-0.34004830007683745)\n",
      "     | > loss_dur: 0.17788659036159515  (0.17258364970043097)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(57.8195, device='cuda:0')  (tensor(37.4147, device='cuda:0'))\n",
      "     | > current_lr: 2.2e-05 \n",
      "     | > step_time: 0.8819  (0.6626352455518012)\n",
      "     | > loader_time: 0.0384  (0.01251310844943948)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:38:42 -- STEP: 317/406 -- GLOBAL_STEP: 58775\u001b[0m\n",
      "     | > loss: -0.17084352672100067  (-0.16755107534044553)\n",
      "     | > log_mle: -0.3533860445022583  (-0.3409708843622298)\n",
      "     | > loss_dur: 0.18254251778125763  (0.17341980899828088)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(37.2058, device='cuda:0')  (tensor(37.4289, device='cuda:0'))\n",
      "     | > current_lr: 2.2e-05 \n",
      "     | > step_time: 0.7948  (0.6709747194115668)\n",
      "     | > loader_time: 0.0267  (0.012822928112764087)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:39:02 -- STEP: 342/406 -- GLOBAL_STEP: 58800\u001b[0m\n",
      "     | > loss: -0.1669524610042572  (-0.16732063131374228)\n",
      "     | > log_mle: -0.3627089262008667  (-0.3415620598876685)\n",
      "     | > loss_dur: 0.1957564651966095  (0.17424142855214106)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(55.7647, device='cuda:0')  (tensor(37.8517, device='cuda:0'))\n",
      "     | > current_lr: 2.2e-05 \n",
      "     | > step_time: 0.9634  (0.6806691020552873)\n",
      "     | > loader_time: 0.0088  (0.012993567171152572)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:39:24 -- STEP: 367/406 -- GLOBAL_STEP: 58825\u001b[0m\n",
      "     | > loss: -0.17625629901885986  (-0.1675661931002173)\n",
      "     | > log_mle: -0.3586604595184326  (-0.3424673473477689)\n",
      "     | > loss_dur: 0.18240416049957275  (0.17490115422725036)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(53.2350, device='cuda:0')  (tensor(38.3096, device='cuda:0'))\n",
      "     | > current_lr: 2.2e-05 \n",
      "     | > step_time: 0.6884  (0.6903987203696765)\n",
      "     | > loader_time: 0.0115  (0.013411270500203893)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:39:44 -- STEP: 392/406 -- GLOBAL_STEP: 58850\u001b[0m\n",
      "     | > loss: -0.17846699059009552  (-0.16791500246190305)\n",
      "     | > log_mle: -0.35275566577911377  (-0.34331699354308)\n",
      "     | > loss_dur: 0.17428867518901825  (0.17540199106217047)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(19.5446, device='cuda:0')  (tensor(38.3194, device='cuda:0'))\n",
      "     | > current_lr: 2.2e-05 \n",
      "     | > step_time: 0.7248  (0.6982286608948998)\n",
      "     | > loader_time: 0.0146  (0.013365940780055766)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: -0.15706861019134521  (-0.15706861019134521)\n",
      "     | > log_mle: -0.32726824283599854  (-0.32726824283599854)\n",
      "     | > loss_dur: 0.17019963264465332  (0.17019963264465332)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: -0.1976860761642456  (-0.1976860761642456)\n",
      "     | > log_mle: -0.37097227573394775  (-0.37097227573394775)\n",
      "     | > loss_dur: 0.17328619956970215  (0.17328619956970215)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: -0.2070411741733551  (-0.20236362516880035)\n",
      "     | > log_mle: -0.3357466459274292  (-0.3533594608306885)\n",
      "     | > loss_dur: 0.1287054717540741  (0.15099583566188812)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: -0.19860801100730896  (-0.20111175378163657)\n",
      "     | > log_mle: -0.3428231477737427  (-0.34984735647837323)\n",
      "     | > loss_dur: 0.14421513676643372  (0.14873560269673666)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: -0.21970050036907196  (-0.2057589404284954)\n",
      "     | > log_mle: -0.36927008628845215  (-0.35470303893089294)\n",
      "     | > loss_dur: 0.1495695859193802  (0.14894409850239754)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: -0.20547674596309662  (-0.20570250153541564)\n",
      "     | > log_mle: -0.37111330032348633  (-0.35798509120941163)\n",
      "     | > loss_dur: 0.1656365543603897  (0.15228258967399597)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: -0.15531572699546814  (-0.19730470577875772)\n",
      "     | > log_mle: -0.38164353370666504  (-0.36192816495895386)\n",
      "     | > loss_dur: 0.2263278067111969  (0.16462345918019614)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: -0.17949436604976654  (-0.19476037153175899)\n",
      "     | > log_mle: -0.34068000316619873  (-0.3588927132742746)\n",
      "     | > loss_dur: 0.1611856371164322  (0.16413234174251556)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: -0.19821177423000336  (-0.19519179686903954)\n",
      "     | > log_mle: -0.354366660118103  (-0.3583269566297531)\n",
      "     | > loss_dur: 0.15615488588809967  (0.16313515976071358)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: -0.19192209839820862  (-0.19482849703894722)\n",
      "     | > log_mle: -0.3671025037765503  (-0.3593020174238417)\n",
      "     | > loss_dur: 0.17518040537834167  (0.1644735203848945)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: -0.16876527667045593  (-0.1922221750020981)\n",
      "     | > log_mle: -0.35236942768096924  (-0.3586087584495544)\n",
      "     | > loss_dur: 0.1836041510105133  (0.16638658344745635)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: -0.20365796983242035  (-0.19326179271394556)\n",
      "     | > log_mle: -0.3696187734603882  (-0.3596096689050848)\n",
      "     | > loss_dur: 0.16596080362796783  (0.16634787619113922)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: -0.2096981257200241  (-0.19463148713111877)\n",
      "     | > log_mle: -0.3542689085006714  (-0.35916460553805035)\n",
      "     | > loss_dur: 0.14457078278064728  (0.16453311840693155)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: -0.22255343198776245  (-0.19677932904316828)\n",
      "     | > log_mle: -0.380324125289917  (-0.3607922609035785)\n",
      "     | > loss_dur: 0.15777069330215454  (0.16401293186041024)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: -0.19370438158512115  (-0.19655968993902206)\n",
      "     | > log_mle: -0.36599254608154297  (-0.36116370984486174)\n",
      "     | > loss_dur: 0.17228816449642181  (0.16460401990583964)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: -0.1941375732421875  (-0.19639821549256642)\n",
      "     | > log_mle: -0.3588442802429199  (-0.36100908120473224)\n",
      "     | > loss_dur: 0.16470670700073242  (0.16461086571216582)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: -0.19331194460391998  (-0.19620532356202602)\n",
      "     | > log_mle: -0.36405348777770996  (-0.36119935661554337)\n",
      "     | > loss_dur: 0.17074154317378998  (0.16499403305351734)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: audio amplitude out of range, auto clipped.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[91m 0.004420936107635498 \u001b[0m(+0.00015601515769958496)\n",
      "     | > avg_loss:\u001b[92m -0.19620532356202602 \u001b[0m(-0.0025967974215745926)\n",
      "     | > avg_log_mle:\u001b[92m -0.36119935661554337 \u001b[0m(-0.002877458930015564)\n",
      "     | > avg_loss_dur:\u001b[91m 0.16499403305351734 \u001b[0m(+0.0002806615084409714)\n",
      "\n",
      " > BEST MODEL : train/run-February-22-2025_10+59PM-fa84af3/best_model_58864.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 89/100\u001b[0m\n",
      " --> train/run-February-22-2025_10+59PM-fa84af3\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-23 06:40:09) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:40:16 -- STEP: 11/406 -- GLOBAL_STEP: 58875\u001b[0m\n",
      "     | > loss: -0.19856199622154236  (-0.19395092536102643)\n",
      "     | > log_mle: -0.32181215286254883  (-0.3291724811900746)\n",
      "     | > loss_dur: 0.12325016409158707  (0.13522155650637366)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(21.7581, device='cuda:0')  (tensor(42.7826, device='cuda:0'))\n",
      "     | > current_lr: 2.2250000000000002e-05 \n",
      "     | > step_time: 0.3353  (0.38714712316339667)\n",
      "     | > loader_time: 0.0041  (0.00589973276311701)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:40:30 -- STEP: 36/406 -- GLOBAL_STEP: 58900\u001b[0m\n",
      "     | > loss: -0.18621091544628143  (-0.18183690268132421)\n",
      "     | > log_mle: -0.32629692554473877  (-0.32812078131569755)\n",
      "     | > loss_dur: 0.14008601009845734  (0.14628387884133393)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(9.6417, device='cuda:0')  (tensor(32.9713, device='cuda:0'))\n",
      "     | > current_lr: 2.2250000000000002e-05 \n",
      "     | > step_time: 0.5249  (0.48565013541115654)\n",
      "     | > loader_time: 0.0063  (0.006769690248701308)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:40:45 -- STEP: 61/406 -- GLOBAL_STEP: 58925\u001b[0m\n",
      "     | > loss: -0.14684762060642242  (-0.1740010945034809)\n",
      "     | > log_mle: -0.3284580707550049  (-0.32717389161469507)\n",
      "     | > loss_dur: 0.18161045014858246  (0.15317279723335486)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(20.2826, device='cuda:0')  (tensor(34.1558, device='cuda:0'))\n",
      "     | > current_lr: 2.2250000000000002e-05 \n",
      "     | > step_time: 0.4917  (0.5299542380160975)\n",
      "     | > loader_time: 0.0047  (0.008622017063078333)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:41:01 -- STEP: 86/406 -- GLOBAL_STEP: 58950\u001b[0m\n",
      "     | > loss: -0.1557893306016922  (-0.17301676249088252)\n",
      "     | > log_mle: -0.329692006111145  (-0.32973154894141254)\n",
      "     | > loss_dur: 0.17390267550945282  (0.15671478653716492)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(27.4788, device='cuda:0')  (tensor(33.2042, device='cuda:0'))\n",
      "     | > current_lr: 2.2250000000000002e-05 \n",
      "     | > step_time: 0.6103  (0.5558640624201576)\n",
      "     | > loader_time: 0.0042  (0.009093902831853818)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:41:18 -- STEP: 111/406 -- GLOBAL_STEP: 58975\u001b[0m\n",
      "     | > loss: -0.18925048410892487  (-0.17237666047908173)\n",
      "     | > log_mle: -0.36396312713623047  (-0.3327807950543928)\n",
      "     | > loss_dur: 0.1747126430273056  (0.16040413464243353)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(37.2032, device='cuda:0')  (tensor(33.1871, device='cuda:0'))\n",
      "     | > current_lr: 2.2250000000000002e-05 \n",
      "     | > step_time: 0.5041  (0.583959480663678)\n",
      "     | > loader_time: 0.0114  (0.009083674834655211)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:41:35 -- STEP: 136/406 -- GLOBAL_STEP: 59000\u001b[0m\n",
      "     | > loss: -0.16314227879047394  (-0.17175302533980685)\n",
      "     | > log_mle: -0.3550906181335449  (-0.3349947990740047)\n",
      "     | > loss_dur: 0.19194833934307098  (0.16324177378898164)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(24.4275, device='cuda:0')  (tensor(33.8739, device='cuda:0'))\n",
      "     | > current_lr: 2.2250000000000002e-05 \n",
      "     | > step_time: 0.4029  (0.5958020564387829)\n",
      "     | > loader_time: 0.0083  (0.010171995443456313)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:41:53 -- STEP: 161/406 -- GLOBAL_STEP: 59025\u001b[0m\n",
      "     | > loss: -0.16161900758743286  (-0.17095367018110277)\n",
      "     | > log_mle: -0.34598708152770996  (-0.336630832334483)\n",
      "     | > loss_dur: 0.1843680739402771  (0.16567716219965717)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(31.4931, device='cuda:0')  (tensor(34.0722, device='cuda:0'))\n",
      "     | > current_lr: 2.2250000000000002e-05 \n",
      "     | > step_time: 0.6729  (0.6086928503853936)\n",
      "     | > loader_time: 0.0069  (0.01045508710493953)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:42:11 -- STEP: 186/406 -- GLOBAL_STEP: 59050\u001b[0m\n",
      "     | > loss: -0.17456969618797302  (-0.1711686252746533)\n",
      "     | > log_mle: -0.3492692708969116  (-0.33804433512431314)\n",
      "     | > loss_dur: 0.1746995747089386  (0.166875709889717)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(68.8460, device='cuda:0')  (tensor(34.0034, device='cuda:0'))\n",
      "     | > current_lr: 2.2250000000000002e-05 \n",
      "     | > step_time: 0.8143  (0.6248665496867187)\n",
      "     | > loader_time: 0.0071  (0.011113069390737883)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:42:30 -- STEP: 211/406 -- GLOBAL_STEP: 59075\u001b[0m\n",
      "     | > loss: -0.16666631400585175  (-0.17057113695483658)\n",
      "     | > log_mle: -0.3476642370223999  (-0.33896259617466484)\n",
      "     | > loss_dur: 0.18099792301654816  (0.1683914592551394)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(50.2936, device='cuda:0')  (tensor(36.1692, device='cuda:0'))\n",
      "     | > current_lr: 2.2250000000000002e-05 \n",
      "     | > step_time: 0.6216  (0.6358766759176387)\n",
      "     | > loader_time: 0.0066  (0.010933979992617929)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:42:48 -- STEP: 236/406 -- GLOBAL_STEP: 59100\u001b[0m\n",
      "     | > loss: -0.16249176859855652  (-0.17050923962714326)\n",
      "     | > log_mle: -0.33921635150909424  (-0.34030283810728673)\n",
      "     | > loss_dur: 0.17672458291053772  (0.16979359851171405)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(36.4463, device='cuda:0')  (tensor(36.2779, device='cuda:0'))\n",
      "     | > current_lr: 2.2250000000000002e-05 \n",
      "     | > step_time: 0.6782  (0.6446349681433983)\n",
      "     | > loader_time: 0.0069  (0.011335685091503596)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:43:07 -- STEP: 261/406 -- GLOBAL_STEP: 59125\u001b[0m\n",
      "     | > loss: -0.16943031549453735  (-0.17086469807387328)\n",
      "     | > log_mle: -0.35460734367370605  (-0.3417276883947437)\n",
      "     | > loss_dur: 0.1851770281791687  (0.170862990349417)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(65.9951, device='cuda:0')  (tensor(36.6256, device='cuda:0'))\n",
      "     | > current_lr: 2.2250000000000002e-05 \n",
      "     | > step_time: 0.9033  (0.6539777677177924)\n",
      "     | > loader_time: 0.0067  (0.011648271275662828)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:43:28 -- STEP: 286/406 -- GLOBAL_STEP: 59150\u001b[0m\n",
      "     | > loss: -0.16360628604888916  (-0.17091125296754453)\n",
      "     | > log_mle: -0.3502105474472046  (-0.34261445315567757)\n",
      "     | > loss_dur: 0.18660426139831543  (0.1717032002141842)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(70.3270, device='cuda:0')  (tensor(37.3595, device='cuda:0'))\n",
      "     | > current_lr: 2.2250000000000002e-05 \n",
      "     | > step_time: 0.8247  (0.6653257850166798)\n",
      "     | > loader_time: 0.0093  (0.012008060108531607)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:43:47 -- STEP: 311/406 -- GLOBAL_STEP: 59175\u001b[0m\n",
      "     | > loss: -0.1682768613100052  (-0.1707825319560013)\n",
      "     | > log_mle: -0.3462507724761963  (-0.3433356599409097)\n",
      "     | > loss_dur: 0.1779739111661911  (0.1725531280088654)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(36.1469, device='cuda:0')  (tensor(37.9213, device='cuda:0'))\n",
      "     | > current_lr: 2.2250000000000002e-05 \n",
      "     | > step_time: 0.7455  (0.6736254032785101)\n",
      "     | > loader_time: 0.017  (0.012306300773497949)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:44:07 -- STEP: 336/406 -- GLOBAL_STEP: 59200\u001b[0m\n",
      "     | > loss: -0.1786019504070282  (-0.1707452351582195)\n",
      "     | > log_mle: -0.35549676418304443  (-0.34406405261584694)\n",
      "     | > loss_dur: 0.17689481377601624  (0.17331881747980185)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(39.7361, device='cuda:0')  (tensor(37.9535, device='cuda:0'))\n",
      "     | > current_lr: 2.2250000000000002e-05 \n",
      "     | > step_time: 0.9202  (0.6807377388079957)\n",
      "     | > loader_time: 0.0106  (0.012402611828985671)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:44:28 -- STEP: 361/406 -- GLOBAL_STEP: 59225\u001b[0m\n",
      "     | > loss: -0.15722955763339996  (-0.17086233429796502)\n",
      "     | > log_mle: -0.35246026515960693  (-0.34493364455627273)\n",
      "     | > loss_dur: 0.19523070752620697  (0.17407131027894657)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(48.9870, device='cuda:0')  (tensor(38.1943, device='cuda:0'))\n",
      "     | > current_lr: 2.2250000000000002e-05 \n",
      "     | > step_time: 0.8209  (0.691202840646548)\n",
      "     | > loader_time: 0.023  (0.012403351448249292)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:44:49 -- STEP: 386/406 -- GLOBAL_STEP: 59250\u001b[0m\n",
      "     | > loss: -0.157023087143898  (-0.17085728103323944)\n",
      "     | > log_mle: -0.3538820743560791  (-0.34559563744253446)\n",
      "     | > loss_dur: 0.1968589872121811  (0.1747383564285972)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(28.3791, device='cuda:0')  (tensor(38.0672, device='cuda:0'))\n",
      "     | > current_lr: 2.2250000000000002e-05 \n",
      "     | > step_time: 1.055  (0.6981871294851744)\n",
      "     | > loader_time: 0.0284  (0.012666938218428066)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: -0.16341626644134521  (-0.16341626644134521)\n",
      "     | > log_mle: -0.33039891719818115  (-0.33039891719818115)\n",
      "     | > loss_dur: 0.16698265075683594  (0.16698265075683594)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: -0.19420532882213593  (-0.19420532882213593)\n",
      "     | > log_mle: -0.3752326965332031  (-0.3752326965332031)\n",
      "     | > loss_dur: 0.1810273677110672  (0.1810273677110672)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: -0.21652033925056458  (-0.20536283403635025)\n",
      "     | > log_mle: -0.3378652334213257  (-0.3565489649772644)\n",
      "     | > loss_dur: 0.12134489417076111  (0.15118613094091415)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: -0.20215195417404175  (-0.2042925407489141)\n",
      "     | > log_mle: -0.3459441661834717  (-0.3530140320460002)\n",
      "     | > loss_dur: 0.14379221200942993  (0.1487214912970861)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: -0.2186979055404663  (-0.20789388194680214)\n",
      "     | > log_mle: -0.3731718063354492  (-0.3580534756183624)\n",
      "     | > loss_dur: 0.1544739007949829  (0.1501595936715603)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: -0.2125570923089981  (-0.20882652401924134)\n",
      "     | > log_mle: -0.3718280792236328  (-0.3608083963394165)\n",
      "     | > loss_dur: 0.1592709869146347  (0.15198187232017518)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: -0.1640070229768753  (-0.20135660717884699)\n",
      "     | > log_mle: -0.38424670696258545  (-0.364714781443278)\n",
      "     | > loss_dur: 0.22023968398571014  (0.163358174264431)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: -0.18660219013690948  (-0.19924883331571305)\n",
      "     | > log_mle: -0.3429300785064697  (-0.36160268102373394)\n",
      "     | > loss_dur: 0.15632788836956024  (0.1623538477080209)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: -0.2057148963212967  (-0.20005709119141102)\n",
      "     | > log_mle: -0.35866832733154297  (-0.3612358868122101)\n",
      "     | > loss_dur: 0.15295343101024628  (0.16117879562079906)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: -0.19853177666664124  (-0.19988761179976994)\n",
      "     | > log_mle: -0.36965739727020264  (-0.36217161019643146)\n",
      "     | > loss_dur: 0.1711256206035614  (0.16228399839666155)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: -0.17075268924236298  (-0.19697411954402924)\n",
      "     | > log_mle: -0.3558793067932129  (-0.3615423798561096)\n",
      "     | > loss_dur: 0.18512661755084991  (0.16456826031208038)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: -0.20730112493038177  (-0.19791293821551584)\n",
      "     | > log_mle: -0.37283623218536377  (-0.36256909370422363)\n",
      "     | > loss_dur: 0.165535107254982  (0.1646561554887078)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: -0.21091283857822418  (-0.19899626324574152)\n",
      "     | > log_mle: -0.35748064517974854  (-0.362145056327184)\n",
      "     | > loss_dur: 0.14656780660152435  (0.1631487930814425)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: -0.21733148396015167  (-0.2004066648391577)\n",
      "     | > log_mle: -0.37960362434387207  (-0.3634880230976985)\n",
      "     | > loss_dur: 0.1622721403837204  (0.1630813582585408)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: -0.19917863607406616  (-0.200318948498794)\n",
      "     | > log_mle: -0.36923182010650635  (-0.36389829431261334)\n",
      "     | > loss_dur: 0.17005318403244019  (0.16357934581381933)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: -0.193063884973526  (-0.19983527759710948)\n",
      "     | > log_mle: -0.3612234592437744  (-0.36371997197469075)\n",
      "     | > loss_dur: 0.1681595742702484  (0.16388469437758127)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: -0.19688931107521057  (-0.1996511546894908)\n",
      "     | > log_mle: -0.36609697341918945  (-0.3638685345649719)\n",
      "     | > loss_dur: 0.16920766234397888  (0.16421737987548113)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: audio amplitude out of range, auto clipped.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[91m 0.0046539753675460815 \u001b[0m(+0.0002330392599105835)\n",
      "     | > avg_loss:\u001b[92m -0.1996511546894908 \u001b[0m(-0.0034458311274647713)\n",
      "     | > avg_log_mle:\u001b[92m -0.3638685345649719 \u001b[0m(-0.0026691779494285583)\n",
      "     | > avg_loss_dur:\u001b[92m 0.16421737987548113 \u001b[0m(-0.0007766531780362129)\n",
      "\n",
      " > BEST MODEL : train/run-February-22-2025_10+59PM-fa84af3/best_model_59270.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 90/100\u001b[0m\n",
      " --> train/run-February-22-2025_10+59PM-fa84af3\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-23 06:45:19) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:45:23 -- STEP: 5/406 -- GLOBAL_STEP: 59275\u001b[0m\n",
      "     | > loss: -0.17408619821071625  (-0.19262251257896423)\n",
      "     | > log_mle: -0.32415246963500977  (-0.3316798210144043)\n",
      "     | > loss_dur: 0.15006627142429352  (0.13905730843544006)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(32.7224, device='cuda:0')  (tensor(40.0314, device='cuda:0'))\n",
      "     | > current_lr: 2.25e-05 \n",
      "     | > step_time: 0.3689  (0.44974679946899415)\n",
      "     | > loader_time: 0.0119  (0.009690380096435547)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:45:36 -- STEP: 30/406 -- GLOBAL_STEP: 59300\u001b[0m\n",
      "     | > loss: -0.1757073998451233  (-0.18521047433217366)\n",
      "     | > log_mle: -0.3281508684158325  (-0.33008736769358316)\n",
      "     | > loss_dur: 0.15244346857070923  (0.1448768936097622)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(28.3745, device='cuda:0')  (tensor(31.7342, device='cuda:0'))\n",
      "     | > current_lr: 2.25e-05 \n",
      "     | > step_time: 0.3079  (0.5027002731959026)\n",
      "     | > loader_time: 0.006  (0.007778445879618326)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:45:51 -- STEP: 55/406 -- GLOBAL_STEP: 59325\u001b[0m\n",
      "     | > loss: -0.17429107427597046  (-0.17818392433903432)\n",
      "     | > log_mle: -0.3416450023651123  (-0.3295846462249756)\n",
      "     | > loss_dur: 0.16735392808914185  (0.15140072202140634)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(37.9305, device='cuda:0')  (tensor(32.0964, device='cuda:0'))\n",
      "     | > current_lr: 2.25e-05 \n",
      "     | > step_time: 0.8013  (0.5402666048570113)\n",
      "     | > loader_time: 0.0111  (0.008857675032182172)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:46:07 -- STEP: 80/406 -- GLOBAL_STEP: 59350\u001b[0m\n",
      "     | > loss: -0.15524092316627502  (-0.17587112318724393)\n",
      "     | > log_mle: -0.328411340713501  (-0.33106659650802617)\n",
      "     | > loss_dur: 0.17317041754722595  (0.15519547341391446)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(41.5123, device='cuda:0')  (tensor(31.4743, device='cuda:0'))\n",
      "     | > current_lr: 2.25e-05 \n",
      "     | > step_time: 0.365  (0.5637762874364854)\n",
      "     | > loader_time: 0.0098  (0.00877520740032196)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:46:23 -- STEP: 105/406 -- GLOBAL_STEP: 59375\u001b[0m\n",
      "     | > loss: -0.18180495500564575  (-0.17479354980446044)\n",
      "     | > log_mle: -0.3380897045135498  (-0.33374104840414887)\n",
      "     | > loss_dur: 0.15628474950790405  (0.15894749867064611)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(58.4461, device='cuda:0')  (tensor(31.2960, device='cuda:0'))\n",
      "     | > current_lr: 2.25e-05 \n",
      "     | > step_time: 0.6716  (0.5792737733750116)\n",
      "     | > loader_time: 0.0216  (0.009200277782621839)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:46:40 -- STEP: 130/406 -- GLOBAL_STEP: 59400\u001b[0m\n",
      "     | > loss: -0.16786915063858032  (-0.1736855855354896)\n",
      "     | > log_mle: -0.33261382579803467  (-0.3358359685310952)\n",
      "     | > loss_dur: 0.16474467515945435  (0.16215038305291762)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(21.8349, device='cuda:0')  (tensor(30.7834, device='cuda:0'))\n",
      "     | > current_lr: 2.25e-05 \n",
      "     | > step_time: 0.7432  (0.5966950434904834)\n",
      "     | > loader_time: 0.0213  (0.009578605798574594)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:46:58 -- STEP: 155/406 -- GLOBAL_STEP: 59425\u001b[0m\n",
      "     | > loss: -0.15089285373687744  (-0.1728390703278203)\n",
      "     | > log_mle: -0.3334277868270874  (-0.3374948901514855)\n",
      "     | > loss_dur: 0.18253493309020996  (0.16465581987173328)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(94.7868, device='cuda:0')  (tensor(34.6733, device='cuda:0'))\n",
      "     | > current_lr: 2.25e-05 \n",
      "     | > step_time: 0.5073  (0.6092732598704679)\n",
      "     | > loader_time: 0.0052  (0.009823436121786794)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:47:16 -- STEP: 180/406 -- GLOBAL_STEP: 59450\u001b[0m\n",
      "     | > loss: -0.17405565083026886  (-0.17248649423321089)\n",
      "     | > log_mle: -0.34823358058929443  (-0.33848998480372977)\n",
      "     | > loss_dur: 0.17417792975902557  (0.16600349061191083)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(30.3519, device='cuda:0')  (tensor(35.1321, device='cuda:0'))\n",
      "     | > current_lr: 2.25e-05 \n",
      "     | > step_time: 0.8012  (0.6216615716616317)\n",
      "     | > loader_time: 0.0082  (0.010012065039740668)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:47:34 -- STEP: 205/406 -- GLOBAL_STEP: 59475\u001b[0m\n",
      "     | > loss: -0.16280610859394073  (-0.17209075609358349)\n",
      "     | > log_mle: -0.35557568073272705  (-0.3397568225860597)\n",
      "     | > loss_dur: 0.19276957213878632  (0.1676660665288204)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(37.7623, device='cuda:0')  (tensor(35.7932, device='cuda:0'))\n",
      "     | > current_lr: 2.25e-05 \n",
      "     | > step_time: 0.6383  (0.6325113889647698)\n",
      "     | > loader_time: 0.0057  (0.010978524277849898)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:47:52 -- STEP: 230/406 -- GLOBAL_STEP: 59500\u001b[0m\n",
      "     | > loss: -0.17770490050315857  (-0.17247917295798015)\n",
      "     | > log_mle: -0.3522672653198242  (-0.3413029940231988)\n",
      "     | > loss_dur: 0.17456236481666565  (0.16882382109761238)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(48.5977, device='cuda:0')  (tensor(37.3452, device='cuda:0'))\n",
      "     | > current_lr: 2.25e-05 \n",
      "     | > step_time: 0.5933  (0.6406313315681793)\n",
      "     | > loader_time: 0.0193  (0.011212484732918119)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:48:11 -- STEP: 255/406 -- GLOBAL_STEP: 59525\u001b[0m\n",
      "     | > loss: -0.1645679622888565  (-0.17276725424271006)\n",
      "     | > log_mle: -0.34764254093170166  (-0.3427298106399238)\n",
      "     | > loss_dur: 0.18307457864284515  (0.16996255642643163)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(42.9993, device='cuda:0')  (tensor(38.0221, device='cuda:0'))\n",
      "     | > current_lr: 2.25e-05 \n",
      "     | > step_time: 0.6053  (0.6504372503243244)\n",
      "     | > loader_time: 0.0061  (0.011459033629473519)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:48:29 -- STEP: 280/406 -- GLOBAL_STEP: 59550\u001b[0m\n",
      "     | > loss: -0.16443227231502533  (-0.17281086774809024)\n",
      "     | > log_mle: -0.35950589179992676  (-0.34358912408351905)\n",
      "     | > loss_dur: 0.19507361948490143  (0.170778256362038)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(39.1772, device='cuda:0')  (tensor(38.2692, device='cuda:0'))\n",
      "     | > current_lr: 2.25e-05 \n",
      "     | > step_time: 0.9643  (0.6565015060561045)\n",
      "     | > loader_time: 0.0157  (0.011560342141560145)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:48:50 -- STEP: 305/406 -- GLOBAL_STEP: 59575\u001b[0m\n",
      "     | > loss: -0.17302586138248444  (-0.172838585933701)\n",
      "     | > log_mle: -0.35849761962890625  (-0.3445410153904899)\n",
      "     | > loss_dur: 0.18547175824642181  (0.17170242948121708)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(44.7970, device='cuda:0')  (tensor(38.8625, device='cuda:0'))\n",
      "     | > current_lr: 2.25e-05 \n",
      "     | > step_time: 0.7885  (0.6683114997676163)\n",
      "     | > loader_time: 0.0328  (0.0119596465689237)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:49:11 -- STEP: 330/406 -- GLOBAL_STEP: 59600\u001b[0m\n",
      "     | > loss: -0.16369181871414185  (-0.17279562760483133)\n",
      "     | > log_mle: -0.36252522468566895  (-0.34526797352415145)\n",
      "     | > loss_dur: 0.1988334059715271  (0.1724723459418976)\n",
      "     | > amp_scaler: 4096.0  (2054.2060606060604)\n",
      "     | > grad_norm: tensor(38.0016, device='cuda:0')  (tensor(39.1298, device='cuda:0'))\n",
      "     | > current_lr: 2.25e-05 \n",
      "     | > step_time: 0.6305  (0.6783554626233649)\n",
      "     | > loader_time: 0.0169  (0.012156677968574293)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:49:32 -- STEP: 355/406 -- GLOBAL_STEP: 59625\u001b[0m\n",
      "     | > loss: -0.17232634127140045  (-0.1727070442807506)\n",
      "     | > log_mle: -0.36194467544555664  (-0.3460307033968644)\n",
      "     | > loss_dur: 0.1896183341741562  (0.17332365913710135)\n",
      "     | > amp_scaler: 4096.0  (2197.9943661971824)\n",
      "     | > grad_norm: tensor(48.2095, device='cuda:0')  (tensor(39.0803, device='cuda:0'))\n",
      "     | > current_lr: 2.25e-05 \n",
      "     | > step_time: 0.554  (0.688460034383854)\n",
      "     | > loader_time: 0.0086  (0.012443622401062872)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:49:54 -- STEP: 380/406 -- GLOBAL_STEP: 59650\u001b[0m\n",
      "     | > loss: -0.16035449504852295  (-0.17276719090969936)\n",
      "     | > log_mle: -0.3514113426208496  (-0.3467084357613014)\n",
      "     | > loss_dur: 0.19105684757232666  (0.17394124487120863)\n",
      "     | > amp_scaler: 4096.0  (2322.8631578947357)\n",
      "     | > grad_norm: tensor(81.7502, device='cuda:0')  (tensor(39.2565, device='cuda:0'))\n",
      "     | > current_lr: 2.25e-05 \n",
      "     | > step_time: 1.0686  (0.6991055325457921)\n",
      "     | > loader_time: 0.0198  (0.012657080198589124)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:50:12 -- STEP: 405/406 -- GLOBAL_STEP: 59675\u001b[0m\n",
      "     | > loss: -0.17296023666858673  (-0.1729547493987613)\n",
      "     | > log_mle: -0.35835206508636475  (-0.34739661128432686)\n",
      "     | > loss_dur: 0.18539182841777802  (0.17444186190396185)\n",
      "     | > amp_scaler: 4096.0  (2432.3160493827154)\n",
      "     | > grad_norm: tensor(78.4783, device='cuda:0')  (tensor(39.6577, device='cuda:0'))\n",
      "     | > current_lr: 2.25e-05 \n",
      "     | > step_time: 0.3266  (0.6994909480766011)\n",
      "     | > loader_time: 0.0058  (0.013009071938785506)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: -0.1634920984506607  (-0.1634920984506607)\n",
      "     | > log_mle: -0.3308544158935547  (-0.3308544158935547)\n",
      "     | > loss_dur: 0.16736231744289398  (0.16736231744289398)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: -0.20510749518871307  (-0.20510749518871307)\n",
      "     | > log_mle: -0.37492644786834717  (-0.37492644786834717)\n",
      "     | > loss_dur: 0.1698189526796341  (0.1698189526796341)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: -0.2124900370836258  (-0.20879876613616943)\n",
      "     | > log_mle: -0.33920109272003174  (-0.35706377029418945)\n",
      "     | > loss_dur: 0.12671105563640594  (0.14826500415802002)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: -0.1917327642440796  (-0.20311009883880615)\n",
      "     | > log_mle: -0.34539926052093506  (-0.3531756003697713)\n",
      "     | > loss_dur: 0.15366649627685547  (0.15006550153096518)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: -0.21384358406066895  (-0.20579347014427185)\n",
      "     | > log_mle: -0.3718298673629761  (-0.3578391671180725)\n",
      "     | > loss_dur: 0.15798628330230713  (0.15204569697380066)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: -0.20770452916622162  (-0.20617568194866182)\n",
      "     | > log_mle: -0.37049150466918945  (-0.3603696346282959)\n",
      "     | > loss_dur: 0.16278697550296783  (0.1541939526796341)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: -0.158315509557724  (-0.19819898655017218)\n",
      "     | > log_mle: -0.3822667598724365  (-0.36401915550231934)\n",
      "     | > loss_dur: 0.22395125031471252  (0.16582016895214716)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: -0.18321511149406433  (-0.1960584329707282)\n",
      "     | > log_mle: -0.3422898054122925  (-0.3609149626323155)\n",
      "     | > loss_dur: 0.15907469391822815  (0.16485652966158731)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: -0.20168544352054596  (-0.1967618092894554)\n",
      "     | > log_mle: -0.3577843904495239  (-0.36052364110946655)\n",
      "     | > loss_dur: 0.15609894692897797  (0.16376183182001114)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: -0.18619230389595032  (-0.1955874198012882)\n",
      "     | > log_mle: -0.36885857582092285  (-0.361449744966295)\n",
      "     | > loss_dur: 0.18266627192497253  (0.16586232516500685)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: -0.16928504407405853  (-0.19295718222856523)\n",
      "     | > log_mle: -0.35495269298553467  (-0.360800039768219)\n",
      "     | > loss_dur: 0.18566764891147614  (0.16784285753965378)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: -0.2042548507452011  (-0.19398424300280484)\n",
      "     | > log_mle: -0.37209999561309814  (-0.36182730848138983)\n",
      "     | > loss_dur: 0.16784514486789703  (0.167843065478585)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: -0.21251368522644043  (-0.19552836318810782)\n",
      "     | > log_mle: -0.3572441339492798  (-0.3614453772703807)\n",
      "     | > loss_dur: 0.14473044872283936  (0.16591701408227286)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: -0.21795327961444855  (-0.19725335675936478)\n",
      "     | > log_mle: -0.3792985677719116  (-0.36281869961665225)\n",
      "     | > loss_dur: 0.16134528815746307  (0.16556534285728747)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: -0.19959431886672974  (-0.19742056833846228)\n",
      "     | > log_mle: -0.3681626319885254  (-0.3632004090717861)\n",
      "     | > loss_dur: 0.16856831312179565  (0.16577984073332377)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: -0.19280117750167847  (-0.19711260894934338)\n",
      "     | > log_mle: -0.3604789972305298  (-0.3630189816157023)\n",
      "     | > loss_dur: 0.16767781972885132  (0.16590637266635894)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: -0.1977911740541458  (-0.19715501926839352)\n",
      "     | > log_mle: -0.3659498691558838  (-0.36320216208696365)\n",
      "     | > loss_dur: 0.16815869510173798  (0.16604714281857014)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: audio amplitude out of range, auto clipped.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.003537014126777649 \u001b[0m(-0.0011169612407684326)\n",
      "     | > avg_loss:\u001b[91m -0.19715501926839352 \u001b[0m(+0.0024961354210972786)\n",
      "     | > avg_log_mle:\u001b[91m -0.36320216208696365 \u001b[0m(+0.0006663724780082703)\n",
      "     | > avg_loss_dur:\u001b[91m 0.16604714281857014 \u001b[0m(+0.0018297629430890083)\n",
      "\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 91/100\u001b[0m\n",
      " --> train/run-February-22-2025_10+59PM-fa84af3\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-23 06:50:28) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:50:42 -- STEP: 24/406 -- GLOBAL_STEP: 59700\u001b[0m\n",
      "     | > loss: -0.18695296347141266  (-0.19307338508466879)\n",
      "     | > log_mle: -0.3324861526489258  (-0.33325400948524475)\n",
      "     | > loss_dur: 0.14553318917751312  (0.1401806247110168)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(48.5414, device='cuda:0')  (tensor(33.9609, device='cuda:0'))\n",
      "     | > current_lr: 2.275e-05 \n",
      "     | > step_time: 0.7194  (0.48923184474309284)\n",
      "     | > loader_time: 0.0132  (0.007114768028259277)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:50:58 -- STEP: 49/406 -- GLOBAL_STEP: 59725\u001b[0m\n",
      "     | > loss: -0.17600448429584503  (-0.18293540058087326)\n",
      "     | > log_mle: -0.33220815658569336  (-0.3318737502000768)\n",
      "     | > loss_dur: 0.15620367228984833  (0.14893834977125636)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(26.8492, device='cuda:0')  (tensor(31.1810, device='cuda:0'))\n",
      "     | > current_lr: 2.275e-05 \n",
      "     | > step_time: 0.703  (0.5420387861680007)\n",
      "     | > loader_time: 0.0094  (0.00885403886133311)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:51:13 -- STEP: 74/406 -- GLOBAL_STEP: 59750\u001b[0m\n",
      "     | > loss: -0.17022112011909485  (-0.18042164517415535)\n",
      "     | > log_mle: -0.35728931427001953  (-0.33402377689206914)\n",
      "     | > loss_dur: 0.18706819415092468  (0.1536021318185974)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(40.3486, device='cuda:0')  (tensor(30.8180, device='cuda:0'))\n",
      "     | > current_lr: 2.275e-05 \n",
      "     | > step_time: 0.7309  (0.5646091345194222)\n",
      "     | > loader_time: 0.0063  (0.009517502140354466)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:51:30 -- STEP: 99/406 -- GLOBAL_STEP: 59775\u001b[0m\n",
      "     | > loss: -0.1731168031692505  (-0.17854043148984813)\n",
      "     | > log_mle: -0.33676445484161377  (-0.33608317616009953)\n",
      "     | > loss_dur: 0.16364765167236328  (0.1575427447455098)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(25.0392, device='cuda:0')  (tensor(32.6592, device='cuda:0'))\n",
      "     | > current_lr: 2.275e-05 \n",
      "     | > step_time: 0.6471  (0.5835765419584329)\n",
      "     | > loader_time: 0.0065  (0.010310919597895457)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:51:47 -- STEP: 124/406 -- GLOBAL_STEP: 59800\u001b[0m\n",
      "     | > loss: -0.16307401657104492  (-0.17803531704891112)\n",
      "     | > log_mle: -0.3486286401748657  (-0.338548582407736)\n",
      "     | > loss_dur: 0.1855546236038208  (0.1605132654189102)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(29.1328, device='cuda:0')  (tensor(33.0806, device='cuda:0'))\n",
      "     | > current_lr: 2.275e-05 \n",
      "     | > step_time: 0.7312  (0.6023475104762659)\n",
      "     | > loader_time: 0.0229  (0.010709524154663084)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:52:03 -- STEP: 149/406 -- GLOBAL_STEP: 59825\u001b[0m\n",
      "     | > loss: -0.18697382509708405  (-0.17718645650268403)\n",
      "     | > log_mle: -0.35867369174957275  (-0.340345739518236)\n",
      "     | > loss_dur: 0.1716998666524887  (0.16315928306555588)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(24.9301, device='cuda:0')  (tensor(32.6416, device='cuda:0'))\n",
      "     | > current_lr: 2.275e-05 \n",
      "     | > step_time: 0.6306  (0.6083740740014401)\n",
      "     | > loader_time: 0.0148  (0.010805275616229779)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:52:21 -- STEP: 174/406 -- GLOBAL_STEP: 59850\u001b[0m\n",
      "     | > loss: -0.17254896461963654  (-0.17572318968074077)\n",
      "     | > log_mle: -0.3430267572402954  (-0.34096470852007804)\n",
      "     | > loss_dur: 0.17047779262065887  (0.16524151888215677)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(33.8284, device='cuda:0')  (tensor(35.0788, device='cuda:0'))\n",
      "     | > current_lr: 2.275e-05 \n",
      "     | > step_time: 0.3732  (0.6186008165622582)\n",
      "     | > loader_time: 0.0056  (0.011204963442923009)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:52:38 -- STEP: 199/406 -- GLOBAL_STEP: 59875\u001b[0m\n",
      "     | > loss: -0.18180032074451447  (-0.1755503508164056)\n",
      "     | > log_mle: -0.34795260429382324  (-0.3421271638055542)\n",
      "     | > loss_dur: 0.16615228354930878  (0.1665768130265887)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(37.0497, device='cuda:0')  (tensor(35.3906, device='cuda:0'))\n",
      "     | > current_lr: 2.275e-05 \n",
      "     | > step_time: 0.5299  (0.626327682380101)\n",
      "     | > loader_time: 0.0079  (0.011350180036458535)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:52:58 -- STEP: 224/406 -- GLOBAL_STEP: 59900\u001b[0m\n",
      "     | > loss: -0.1831047683954239  (-0.17548811548788631)\n",
      "     | > log_mle: -0.34617316722869873  (-0.3432836750788347)\n",
      "     | > loss_dur: 0.16306839883327484  (0.16779555962420994)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(24.3666, device='cuda:0')  (tensor(35.8061, device='cuda:0'))\n",
      "     | > current_lr: 2.275e-05 \n",
      "     | > step_time: 1.0331  (0.6393785583121433)\n",
      "     | > loader_time: 0.0272  (0.011645814137799398)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:53:15 -- STEP: 249/406 -- GLOBAL_STEP: 59925\u001b[0m\n",
      "     | > loss: -0.16694146394729614  (-0.1751822705967838)\n",
      "     | > log_mle: -0.3433804512023926  (-0.3443055109805371)\n",
      "     | > loss_dur: 0.17643898725509644  (0.1691232404136753)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(34.8463, device='cuda:0')  (tensor(36.7464, device='cuda:0'))\n",
      "     | > current_lr: 2.275e-05 \n",
      "     | > step_time: 0.5043  (0.6439654549441661)\n",
      "     | > loader_time: 0.0122  (0.01198035358903877)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:53:35 -- STEP: 274/406 -- GLOBAL_STEP: 59950\u001b[0m\n",
      "     | > loss: -0.16940803825855255  (-0.17532362865052958)\n",
      "     | > log_mle: -0.3549504280090332  (-0.34527835576203614)\n",
      "     | > loss_dur: 0.18554238975048065  (0.1699547271386985)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(27.9668, device='cuda:0')  (tensor(36.1011, device='cuda:0'))\n",
      "     | > current_lr: 2.275e-05 \n",
      "     | > step_time: 0.4517  (0.6564553897746286)\n",
      "     | > loader_time: 0.0078  (0.012286366337407241)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:53:55 -- STEP: 299/406 -- GLOBAL_STEP: 59975\u001b[0m\n",
      "     | > loss: -0.1995120793581009  (-0.1746564113774827)\n",
      "     | > log_mle: -0.37842726707458496  (-0.34557374504497607)\n",
      "     | > loss_dur: 0.17891518771648407  (0.17091733369241185)\n",
      "     | > amp_scaler: 2048.0  (3945.3110367892978)\n",
      "     | > grad_norm: tensor(26.0847, device='cuda:0')  (tensor(37.4658, device='cuda:0'))\n",
      "     | > current_lr: 2.275e-05 \n",
      "     | > step_time: 0.985  (0.6643851991481206)\n",
      "     | > loader_time: 0.0291  (0.013055334123081982)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:54:15 -- STEP: 324/406 -- GLOBAL_STEP: 60000\u001b[0m\n",
      "     | > loss: -0.18167296051979065  (-0.17455469706544174)\n",
      "     | > log_mle: -0.35767531394958496  (-0.34628584576241755)\n",
      "     | > loss_dur: 0.1760023534297943  (0.17173114871997147)\n",
      "     | > amp_scaler: 2048.0  (3798.9135802469136)\n",
      "     | > grad_norm: tensor(89.8117, device='cuda:0')  (tensor(37.3072, device='cuda:0'))\n",
      "     | > current_lr: 2.275e-05 \n",
      "     | > step_time: 0.753  (0.6737005710601808)\n",
      "     | > loader_time: 0.0075  (0.013028202233491114)\n",
      "\n",
      "\n",
      " > CHECKPOINT : train/run-February-22-2025_10+59PM-fa84af3/checkpoint_60000.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: audio amplitude out of range, auto clipped.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:54:41 -- STEP: 349/406 -- GLOBAL_STEP: 60025\u001b[0m\n",
      "     | > loss: -0.15420502424240112  (-0.17427368897592438)\n",
      "     | > log_mle: -0.34699976444244385  (-0.3468902753212391)\n",
      "     | > loss_dur: 0.19279474020004272  (0.1726165863666629)\n",
      "     | > amp_scaler: 2048.0  (3673.489971346705)\n",
      "     | > grad_norm: tensor(43.5939, device='cuda:0')  (tensor(37.9899, device='cuda:0'))\n",
      "     | > current_lr: 2.275e-05 \n",
      "     | > step_time: 0.8944  (0.6835982102719281)\n",
      "     | > loader_time: 0.0148  (0.013005349560931618)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:55:03 -- STEP: 374/406 -- GLOBAL_STEP: 60050\u001b[0m\n",
      "     | > loss: -0.17287756502628326  (-0.1744540827000205)\n",
      "     | > log_mle: -0.34990692138671875  (-0.3476688294487205)\n",
      "     | > loss_dur: 0.17702935636043549  (0.17321474676862106)\n",
      "     | > amp_scaler: 2048.0  (3564.8342245989306)\n",
      "     | > grad_norm: tensor(46.0877, device='cuda:0')  (tensor(37.7929, device='cuda:0'))\n",
      "     | > current_lr: 2.275e-05 \n",
      "     | > step_time: 0.8017  (0.6945205225664024)\n",
      "     | > loader_time: 0.031  (0.013246285724129902)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:55:23 -- STEP: 399/406 -- GLOBAL_STEP: 60075\u001b[0m\n",
      "     | > loss: -0.17331577837467194  (-0.17457442956610134)\n",
      "     | > log_mle: -0.3592541217803955  (-0.3483759143896272)\n",
      "     | > loss_dur: 0.18593834340572357  (0.17380148484219868)\n",
      "     | > amp_scaler: 2048.0  (3469.7944862155387)\n",
      "     | > grad_norm: tensor(24.0957, device='cuda:0')  (tensor(38.5421, device='cuda:0'))\n",
      "     | > current_lr: 2.275e-05 \n",
      "     | > step_time: 0.5777  (0.7005251021612255)\n",
      "     | > loader_time: 0.0093  (0.013360245185985895)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: -0.1607699692249298  (-0.1607699692249298)\n",
      "     | > log_mle: -0.3281658887863159  (-0.3281658887863159)\n",
      "     | > loss_dur: 0.1673959195613861  (0.1673959195613861)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: -0.20391198992729187  (-0.20391198992729187)\n",
      "     | > log_mle: -0.3698008060455322  (-0.3698008060455322)\n",
      "     | > loss_dur: 0.16588881611824036  (0.16588881611824036)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: -0.20820268988609314  (-0.2060573399066925)\n",
      "     | > log_mle: -0.337002158164978  (-0.3534014821052551)\n",
      "     | > loss_dur: 0.1287994682788849  (0.14734414219856262)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: -0.19625425338745117  (-0.20278964440027872)\n",
      "     | > log_mle: -0.3403981924057007  (-0.3490670522054036)\n",
      "     | > loss_dur: 0.1441439390182495  (0.1462774078051249)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: -0.2056017369031906  (-0.2034926675260067)\n",
      "     | > log_mle: -0.3661363124847412  (-0.35333436727523804)\n",
      "     | > loss_dur: 0.1605345755815506  (0.14984169974923134)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: -0.20548368990421295  (-0.20389087200164796)\n",
      "     | > log_mle: -0.36295104026794434  (-0.3552577018737793)\n",
      "     | > loss_dur: 0.15746735036373138  (0.15136682987213135)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: -0.14476780593395233  (-0.194037027657032)\n",
      "     | > log_mle: -0.37170183658599854  (-0.3579983909924825)\n",
      "     | > loss_dur: 0.2269340306520462  (0.1639613633354505)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: -0.17769913375377655  (-0.1917030428137098)\n",
      "     | > log_mle: -0.33716249465942383  (-0.3550218343734741)\n",
      "     | > loss_dur: 0.15946336090564728  (0.1633187915597643)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: -0.19429603219032288  (-0.19202716648578644)\n",
      "     | > log_mle: -0.35178041458129883  (-0.3546166568994522)\n",
      "     | > loss_dur: 0.15748438239097595  (0.16258949041366577)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: -0.1894773244857788  (-0.1917438507080078)\n",
      "     | > log_mle: -0.36151909828186035  (-0.3553835948308309)\n",
      "     | > loss_dur: 0.17204177379608154  (0.1636397441228231)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: -0.1695430725812912  (-0.18952377289533615)\n",
      "     | > log_mle: -0.349251389503479  (-0.3547703742980957)\n",
      "     | > loss_dur: 0.1797083169221878  (0.16524660140275954)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: -0.2022860050201416  (-0.190683975815773)\n",
      "     | > log_mle: -0.3655890226364136  (-0.35575388778339734)\n",
      "     | > loss_dur: 0.16330301761627197  (0.16506991196762433)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: -0.20891641080379486  (-0.19220334539810816)\n",
      "     | > log_mle: -0.3518660068511963  (-0.3554298977057139)\n",
      "     | > loss_dur: 0.14294959604740143  (0.16322655230760574)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: -0.21590721607208252  (-0.19402672006533697)\n",
      "     | > log_mle: -0.37375879287719727  (-0.3568398127189049)\n",
      "     | > loss_dur: 0.15785157680511475  (0.16281309265356797)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: -0.1936808079481125  (-0.1940020120569638)\n",
      "     | > log_mle: -0.36187589168548584  (-0.3571995326450893)\n",
      "     | > loss_dur: 0.16819508373737335  (0.1631975205881255)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: -0.19886514544487  (-0.19432622094949087)\n",
      "     | > log_mle: -0.35469186305999756  (-0.35703235467274985)\n",
      "     | > loss_dur: 0.15582671761512756  (0.16270613372325898)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: -0.19977343082427979  (-0.19466667156666517)\n",
      "     | > log_mle: -0.358859658241272  (-0.35714656114578247)\n",
      "     | > loss_dur: 0.1590862274169922  (0.1624798895791173)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: audio amplitude out of range, auto clipped.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[91m 0.006068810820579529 \u001b[0m(+0.00253179669380188)\n",
      "     | > avg_loss:\u001b[91m -0.19466667156666517 \u001b[0m(+0.002488347701728344)\n",
      "     | > avg_log_mle:\u001b[91m -0.35714656114578247 \u001b[0m(+0.006055600941181183)\n",
      "     | > avg_loss_dur:\u001b[92m 0.1624798895791173 \u001b[0m(-0.003567253239452839)\n",
      "\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 92/100\u001b[0m\n",
      " --> train/run-February-22-2025_10+59PM-fa84af3\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-23 06:55:42) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:55:53 -- STEP: 18/406 -- GLOBAL_STEP: 60100\u001b[0m\n",
      "     | > loss: -0.1852129101753235  (-0.1959581118490961)\n",
      "     | > log_mle: -0.3258039951324463  (-0.33623164892196655)\n",
      "     | > loss_dur: 0.1405910849571228  (0.14027353665894932)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(19.0235, device='cuda:0')  (tensor(25.6767, device='cuda:0'))\n",
      "     | > current_lr: 2.3e-05 \n",
      "     | > step_time: 0.871  (0.45343661308288574)\n",
      "     | > loader_time: 0.0178  (0.008093661732143827)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:56:09 -- STEP: 43/406 -- GLOBAL_STEP: 60125\u001b[0m\n",
      "     | > loss: -0.1732444316148758  (-0.1836390862631243)\n",
      "     | > log_mle: -0.31957709789276123  (-0.331032769624577)\n",
      "     | > loss_dur: 0.14633266627788544  (0.14739368318818336)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(43.3638, device='cuda:0')  (tensor(33.3477, device='cuda:0'))\n",
      "     | > current_lr: 2.3e-05 \n",
      "     | > step_time: 1.1035  (0.5504666650018026)\n",
      "     | > loader_time: 0.0045  (0.008865500605383587)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:56:24 -- STEP: 68/406 -- GLOBAL_STEP: 60150\u001b[0m\n",
      "     | > loss: -0.1693524569272995  (-0.17952665094943607)\n",
      "     | > log_mle: -0.33672404289245605  (-0.3332553611082189)\n",
      "     | > loss_dur: 0.16737158596515656  (0.15372871004921546)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(44.0514, device='cuda:0')  (tensor(31.4918, device='cuda:0'))\n",
      "     | > current_lr: 2.3e-05 \n",
      "     | > step_time: 0.6503  (0.5746492357815013)\n",
      "     | > loader_time: 0.0054  (0.009584616212283866)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:56:41 -- STEP: 93/406 -- GLOBAL_STEP: 60175\u001b[0m\n",
      "     | > loss: -0.18163979053497314  (-0.1782620275212873)\n",
      "     | > log_mle: -0.35967934131622314  (-0.33566675134884405)\n",
      "     | > loss_dur: 0.17803955078125  (0.15740472374744316)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(26.3509, device='cuda:0')  (tensor(36.5692, device='cuda:0'))\n",
      "     | > current_lr: 2.3e-05 \n",
      "     | > step_time: 0.7685  (0.5916703234436691)\n",
      "     | > loader_time: 0.0157  (0.009492148635207965)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:56:57 -- STEP: 118/406 -- GLOBAL_STEP: 60200\u001b[0m\n",
      "     | > loss: -0.16998445987701416  (-0.17716194487224196)\n",
      "     | > log_mle: -0.35349559783935547  (-0.3377407991279989)\n",
      "     | > loss_dur: 0.1835111379623413  (0.16057885419261658)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(24.1098, device='cuda:0')  (tensor(34.4552, device='cuda:0'))\n",
      "     | > current_lr: 2.3e-05 \n",
      "     | > step_time: 0.4764  (0.5977759603726662)\n",
      "     | > loader_time: 0.0078  (0.009839536780017916)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:57:13 -- STEP: 143/406 -- GLOBAL_STEP: 60225\u001b[0m\n",
      "     | > loss: -0.18616534769535065  (-0.17638270494404376)\n",
      "     | > log_mle: -0.3547312021255493  (-0.33978396529084304)\n",
      "     | > loss_dur: 0.16856585443019867  (0.1634012602946975)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(39.6227, device='cuda:0')  (tensor(35.2164, device='cuda:0'))\n",
      "     | > current_lr: 2.3e-05 \n",
      "     | > step_time: 0.6495  (0.6082212158016391)\n",
      "     | > loader_time: 0.0048  (0.009799242019653319)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:57:32 -- STEP: 168/406 -- GLOBAL_STEP: 60250\u001b[0m\n",
      "     | > loss: -0.17708368599414825  (-0.17546591340076356)\n",
      "     | > log_mle: -0.33960843086242676  (-0.340818833027567)\n",
      "     | > loss_dur: 0.1625247448682785  (0.16535291958245493)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(22.0648, device='cuda:0')  (tensor(36.3636, device='cuda:0'))\n",
      "     | > current_lr: 2.3e-05 \n",
      "     | > step_time: 0.5389  (0.6269438777651104)\n",
      "     | > loader_time: 0.0062  (0.010109221651440573)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:57:50 -- STEP: 193/406 -- GLOBAL_STEP: 60275\u001b[0m\n",
      "     | > loss: -0.16883288323879242  (-0.17530467920970422)\n",
      "     | > log_mle: -0.3544398546218872  (-0.3420281175504693)\n",
      "     | > loss_dur: 0.1856069713830948  (0.1667234383021612)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(29.4983, device='cuda:0')  (tensor(36.1879, device='cuda:0'))\n",
      "     | > current_lr: 2.3e-05 \n",
      "     | > step_time: 0.7499  (0.6362261747449172)\n",
      "     | > loader_time: 0.0206  (0.01059659280925217)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:58:09 -- STEP: 218/406 -- GLOBAL_STEP: 60300\u001b[0m\n",
      "     | > loss: -0.17248064279556274  (-0.17474613338708878)\n",
      "     | > log_mle: -0.35369062423706055  (-0.3429637059159234)\n",
      "     | > loss_dur: 0.1812099814414978  (0.1682175724946578)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(29.6551, device='cuda:0')  (tensor(36.4020, device='cuda:0'))\n",
      "     | > current_lr: 2.3e-05 \n",
      "     | > step_time: 0.5643  (0.6467955396809707)\n",
      "     | > loader_time: 0.0082  (0.010843434465040854)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:58:28 -- STEP: 243/406 -- GLOBAL_STEP: 60325\u001b[0m\n",
      "     | > loss: -0.1761046051979065  (-0.17423993950027497)\n",
      "     | > log_mle: -0.36868059635162354  (-0.3438374525235022)\n",
      "     | > loss_dur: 0.19257599115371704  (0.16959751299256653)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(17.8047, device='cuda:0')  (tensor(37.1200, device='cuda:0'))\n",
      "     | > current_lr: 2.3e-05 \n",
      "     | > step_time: 0.74  (0.655872781580858)\n",
      "     | > loader_time: 0.0171  (0.011133536389825767)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:58:47 -- STEP: 268/406 -- GLOBAL_STEP: 60350\u001b[0m\n",
      "     | > loss: -0.1996370255947113  (-0.1744340172232087)\n",
      "     | > log_mle: -0.3695136308670044  (-0.3447241792038304)\n",
      "     | > loss_dur: 0.1698766052722931  (0.17029016195282123)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(35.4573, device='cuda:0')  (tensor(37.4073, device='cuda:0'))\n",
      "     | > current_lr: 2.3e-05 \n",
      "     | > step_time: 0.9139  (0.664952322618285)\n",
      "     | > loader_time: 0.0059  (0.011420080910867719)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:59:07 -- STEP: 293/406 -- GLOBAL_STEP: 60375\u001b[0m\n",
      "     | > loss: -0.18180406093597412  (-0.17450164177108543)\n",
      "     | > log_mle: -0.3587455749511719  (-0.3456005740898053)\n",
      "     | > loss_dur: 0.17694151401519775  (0.17109893229329137)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(94.1937, device='cuda:0')  (tensor(38.4030, device='cuda:0'))\n",
      "     | > current_lr: 2.3e-05 \n",
      "     | > step_time: 0.4716  (0.6736175948849308)\n",
      "     | > loader_time: 0.01  (0.011522638106102014)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:59:26 -- STEP: 318/406 -- GLOBAL_STEP: 60400\u001b[0m\n",
      "     | > loss: -0.16613230109214783  (-0.17467742516372184)\n",
      "     | > log_mle: -0.34673941135406494  (-0.3465651457414687)\n",
      "     | > loss_dur: 0.18060711026191711  (0.1718877205543173)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(45.1307, device='cuda:0')  (tensor(38.4423, device='cuda:0'))\n",
      "     | > current_lr: 2.3e-05 \n",
      "     | > step_time: 0.518  (0.6806462785732821)\n",
      "     | > loader_time: 0.0081  (0.011722899083071532)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 06:59:47 -- STEP: 343/406 -- GLOBAL_STEP: 60425\u001b[0m\n",
      "     | > loss: -0.1840161830186844  (-0.17478262066146028)\n",
      "     | > log_mle: -0.37225091457366943  (-0.3474475155766434)\n",
      "     | > loss_dur: 0.18823473155498505  (0.17266489489346137)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(36.3766, device='cuda:0')  (tensor(38.8723, device='cuda:0'))\n",
      "     | > current_lr: 2.3e-05 \n",
      "     | > step_time: 0.6179  (0.6902547953080161)\n",
      "     | > loader_time: 0.0201  (0.011974560623613805)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 07:00:09 -- STEP: 368/406 -- GLOBAL_STEP: 60450\u001b[0m\n",
      "     | > loss: -0.17128053307533264  (-0.1750683922158635)\n",
      "     | > log_mle: -0.354140043258667  (-0.34835322006888997)\n",
      "     | > loss_dur: 0.18285951018333435  (0.17328482783278043)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(44.1918, device='cuda:0')  (tensor(38.9483, device='cuda:0'))\n",
      "     | > current_lr: 2.3e-05 \n",
      "     | > step_time: 0.954  (0.7002848030432417)\n",
      "     | > loader_time: 0.0175  (0.012258578253828959)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 07:00:30 -- STEP: 393/406 -- GLOBAL_STEP: 60475\u001b[0m\n",
      "     | > loss: -0.18317125737667084  (-0.17517825873905163)\n",
      "     | > log_mle: -0.36503541469573975  (-0.3490117939980581)\n",
      "     | > loss_dur: 0.1818641573190689  (0.17383353524004833)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(35.0731, device='cuda:0')  (tensor(39.1655, device='cuda:0'))\n",
      "     | > current_lr: 2.3e-05 \n",
      "     | > step_time: 0.6126  (0.707878868088468)\n",
      "     | > loader_time: 0.0087  (0.012357282274551972)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: -0.16357183456420898  (-0.16357183456420898)\n",
      "     | > log_mle: -0.3331644535064697  (-0.3331644535064697)\n",
      "     | > loss_dur: 0.16959261894226074  (0.16959261894226074)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: -0.2098080813884735  (-0.2098080813884735)\n",
      "     | > log_mle: -0.3778458833694458  (-0.3778458833694458)\n",
      "     | > loss_dur: 0.1680378019809723  (0.1680378019809723)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: -0.2153358906507492  (-0.21257198601961136)\n",
      "     | > log_mle: -0.3423347473144531  (-0.36009031534194946)\n",
      "     | > loss_dur: 0.12699885666370392  (0.1475183293223381)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: -0.20608922839164734  (-0.21041106681029)\n",
      "     | > log_mle: -0.34884798526763916  (-0.356342871983846)\n",
      "     | > loss_dur: 0.14275875687599182  (0.145931805173556)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: -0.21932882070541382  (-0.21264050528407097)\n",
      "     | > log_mle: -0.3764456510543823  (-0.3613685667514801)\n",
      "     | > loss_dur: 0.1571168303489685  (0.14872806146740913)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: -0.21177533268928528  (-0.21246747076511383)\n",
      "     | > log_mle: -0.3762092590332031  (-0.3643367052078247)\n",
      "     | > loss_dur: 0.16443392634391785  (0.1518692344427109)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: -0.1589999496936798  (-0.20355621725320816)\n",
      "     | > log_mle: -0.3880804777145386  (-0.36829400062561035)\n",
      "     | > loss_dur: 0.22908052802085876  (0.1647377833724022)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: -0.18449483811855316  (-0.2008331630911146)\n",
      "     | > log_mle: -0.34609365463256836  (-0.36512252262660433)\n",
      "     | > loss_dur: 0.1615988165140152  (0.16428935953548976)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: -0.20638667047023773  (-0.20152735151350498)\n",
      "     | > log_mle: -0.36130189895629883  (-0.36464494466781616)\n",
      "     | > loss_dur: 0.1549152284860611  (0.16311759315431118)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: -0.19466370344161987  (-0.2007647239499622)\n",
      "     | > log_mle: -0.37316226959228516  (-0.36559131410386825)\n",
      "     | > loss_dur: 0.17849856615066528  (0.16482659015390608)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: -0.17612574994564056  (-0.19830082654953002)\n",
      "     | > log_mle: -0.3589017391204834  (-0.3649223566055298)\n",
      "     | > loss_dur: 0.18277598917484283  (0.16662153005599975)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: -0.21468320488929749  (-0.19979013367132706)\n",
      "     | > log_mle: -0.3760106563568115  (-0.3659303838556463)\n",
      "     | > loss_dur: 0.16132745146751404  (0.16614025018431924)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: -0.21982845664024353  (-0.20145999391873678)\n",
      "     | > log_mle: -0.36079883575439453  (-0.3655027548472087)\n",
      "     | > loss_dur: 0.140970379114151  (0.1640427609284719)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: -0.22246752679347992  (-0.2030759579860247)\n",
      "     | > log_mle: -0.3854442834854126  (-0.367036718588609)\n",
      "     | > loss_dur: 0.16297675669193268  (0.16396076060258424)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: -0.21258674561977386  (-0.20375529995986394)\n",
      "     | > log_mle: -0.3724609613418579  (-0.36742416449955534)\n",
      "     | > loss_dur: 0.15987421572208405  (0.16366886453969137)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: -0.20512327551841736  (-0.20384649833043417)\n",
      "     | > log_mle: -0.36486363410949707  (-0.36725346247355145)\n",
      "     | > loss_dur: 0.1597403585910797  (0.16340696414311726)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: -0.20287759602069855  (-0.2037859419360757)\n",
      "     | > log_mle: -0.3698384761810303  (-0.36741502583026886)\n",
      "     | > loss_dur: 0.16696088016033173  (0.16362908389419317)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: audio amplitude out of range, auto clipped.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.0036029964685440063 \u001b[0m(-0.0024658143520355225)\n",
      "     | > avg_loss:\u001b[92m -0.2037859419360757 \u001b[0m(-0.009119270369410515)\n",
      "     | > avg_log_mle:\u001b[92m -0.36741502583026886 \u001b[0m(-0.01026846468448639)\n",
      "     | > avg_loss_dur:\u001b[91m 0.16362908389419317 \u001b[0m(+0.0011491943150758743)\n",
      "\n",
      " > BEST MODEL : train/run-February-22-2025_10+59PM-fa84af3/best_model_60488.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 93/100\u001b[0m\n",
      " --> train/run-February-22-2025_10+59PM-fa84af3\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-23 07:00:54) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 07:01:01 -- STEP: 12/406 -- GLOBAL_STEP: 60500\u001b[0m\n",
      "     | > loss: -0.2035200148820877  (-0.20739859342575073)\n",
      "     | > log_mle: -0.3479008674621582  (-0.3386295934518178)\n",
      "     | > loss_dur: 0.1443808525800705  (0.13123100188871226)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(32.7145, device='cuda:0')  (tensor(35.6641, device='cuda:0'))\n",
      "     | > current_lr: 2.3250000000000003e-05 \n",
      "     | > step_time: 0.4019  (0.385325829188029)\n",
      "     | > loader_time: 0.0037  (0.00871815284093221)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 07:01:15 -- STEP: 37/406 -- GLOBAL_STEP: 60525\u001b[0m\n",
      "     | > loss: -0.17083550989627838  (-0.19219088796022774)\n",
      "     | > log_mle: -0.3286343812942505  (-0.3358155714498984)\n",
      "     | > loss_dur: 0.1577988713979721  (0.14362468409377174)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(32.6149, device='cuda:0')  (tensor(33.1621, device='cuda:0'))\n",
      "     | > current_lr: 2.3250000000000003e-05 \n",
      "     | > step_time: 0.2942  (0.497874066636369)\n",
      "     | > loader_time: 0.0064  (0.00994661047651961)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 07:01:30 -- STEP: 62/406 -- GLOBAL_STEP: 60550\u001b[0m\n",
      "     | > loss: -0.187547504901886  (-0.18513240328719538)\n",
      "     | > log_mle: -0.3335987329483032  (-0.33560951678983625)\n",
      "     | > loss_dur: 0.14605122804641724  (0.15047711386315285)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(44.4329, device='cuda:0')  (tensor(32.7839, device='cuda:0'))\n",
      "     | > current_lr: 2.3250000000000003e-05 \n",
      "     | > step_time: 0.5481  (0.5340184973132226)\n",
      "     | > loader_time: 0.0139  (0.009622243142897082)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 07:01:46 -- STEP: 87/406 -- GLOBAL_STEP: 60575\u001b[0m\n",
      "     | > loss: -0.190048485994339  (-0.1828858881503686)\n",
      "     | > log_mle: -0.36129307746887207  (-0.33745709232900345)\n",
      "     | > loss_dur: 0.17124459147453308  (0.1545712044355513)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(30.6335, device='cuda:0')  (tensor(32.8048, device='cuda:0'))\n",
      "     | > current_lr: 2.3250000000000003e-05 \n",
      "     | > step_time: 0.939  (0.5598540306091307)\n",
      "     | > loader_time: 0.0466  (0.009907955410836758)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 07:02:03 -- STEP: 112/406 -- GLOBAL_STEP: 60600\u001b[0m\n",
      "     | > loss: -0.1826871782541275  (-0.18140486188765084)\n",
      "     | > log_mle: -0.34874653816223145  (-0.33950637706688486)\n",
      "     | > loss_dur: 0.16605935990810394  (0.15810151537880301)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(31.1385, device='cuda:0')  (tensor(32.8054, device='cuda:0'))\n",
      "     | > current_lr: 2.3250000000000003e-05 \n",
      "     | > step_time: 0.4653  (0.5764120625598093)\n",
      "     | > loader_time: 0.006  (0.010607182979583742)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 07:02:20 -- STEP: 137/406 -- GLOBAL_STEP: 60625\u001b[0m\n",
      "     | > loss: -0.1642516702413559  (-0.18003515061670847)\n",
      "     | > log_mle: -0.3452688455581665  (-0.34122657340808515)\n",
      "     | > loss_dur: 0.1810171753168106  (0.161191422954528)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(53.9801, device='cuda:0')  (tensor(33.3863, device='cuda:0'))\n",
      "     | > current_lr: 2.3250000000000003e-05 \n",
      "     | > step_time: 0.7144  (0.5924919782763852)\n",
      "     | > loader_time: 0.0053  (0.011247168492226707)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 07:02:36 -- STEP: 162/406 -- GLOBAL_STEP: 60650\u001b[0m\n",
      "     | > loss: -0.17642778158187866  (-0.17847512460049297)\n",
      "     | > log_mle: -0.34912753105163574  (-0.34220193712799646)\n",
      "     | > loss_dur: 0.17269974946975708  (0.16372681266547726)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(38.3464, device='cuda:0')  (tensor(34.2980, device='cuda:0'))\n",
      "     | > current_lr: 2.3250000000000003e-05 \n",
      "     | > step_time: 0.4393  (0.6002796711745088)\n",
      "     | > loader_time: 0.0053  (0.011220778947995036)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 07:02:55 -- STEP: 187/406 -- GLOBAL_STEP: 60675\u001b[0m\n",
      "     | > loss: -0.1894572526216507  (-0.17870143239192154)\n",
      "     | > log_mle: -0.3564152717590332  (-0.34388896424502635)\n",
      "     | > loss_dur: 0.1669580191373825  (0.16518753197263278)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(36.1845, device='cuda:0')  (tensor(35.1582, device='cuda:0'))\n",
      "     | > current_lr: 2.3250000000000003e-05 \n",
      "     | > step_time: 0.6531  (0.6160794120421387)\n",
      "     | > loader_time: 0.0149  (0.01220189951320383)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 07:03:13 -- STEP: 212/406 -- GLOBAL_STEP: 60700\u001b[0m\n",
      "     | > loss: -0.17747639119625092  (-0.17847834267425094)\n",
      "     | > log_mle: -0.36147964000701904  (-0.34518786308900384)\n",
      "     | > loss_dur: 0.18400324881076813  (0.16670952052018567)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(134.0564, device='cuda:0')  (tensor(35.4371, device='cuda:0'))\n",
      "     | > current_lr: 2.3250000000000003e-05 \n",
      "     | > step_time: 0.8503  (0.6280371951607043)\n",
      "     | > loader_time: 0.0235  (0.01238539421333457)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 07:03:32 -- STEP: 237/406 -- GLOBAL_STEP: 60725\u001b[0m\n",
      "     | > loss: -0.18849505484104156  (-0.1784222473700842)\n",
      "     | > log_mle: -0.3735930919647217  (-0.3465007950987999)\n",
      "     | > loss_dur: 0.18509803712368011  (0.16807854782302684)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(36.7828, device='cuda:0')  (tensor(36.9469, device='cuda:0'))\n",
      "     | > current_lr: 2.3250000000000003e-05 \n",
      "     | > step_time: 0.722  (0.6388771523906214)\n",
      "     | > loader_time: 0.0069  (0.012529201145413556)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 07:03:51 -- STEP: 262/406 -- GLOBAL_STEP: 60750\u001b[0m\n",
      "     | > loss: -0.17533861100673676  (-0.17869347498844604)\n",
      "     | > log_mle: -0.33962273597717285  (-0.3475876773586712)\n",
      "     | > loss_dur: 0.1642841249704361  (0.16889420245553713)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(17.8516, device='cuda:0')  (tensor(37.3867, device='cuda:0'))\n",
      "     | > current_lr: 2.3250000000000003e-05 \n",
      "     | > step_time: 0.6791  (0.6499861333206414)\n",
      "     | > loader_time: 0.0159  (0.012563164907557366)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 07:04:12 -- STEP: 287/406 -- GLOBAL_STEP: 60775\u001b[0m\n",
      "     | > loss: -0.16304565966129303  (-0.17865681061553632)\n",
      "     | > log_mle: -0.35002875328063965  (-0.34848345073673387)\n",
      "     | > loss_dur: 0.18698309361934662  (0.16982664019907817)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(49.4894, device='cuda:0')  (tensor(37.8644, device='cuda:0'))\n",
      "     | > current_lr: 2.3250000000000003e-05 \n",
      "     | > step_time: 0.7376  (0.6621556448188813)\n",
      "     | > loader_time: 0.0186  (0.012594473071214632)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 07:04:31 -- STEP: 312/406 -- GLOBAL_STEP: 60800\u001b[0m\n",
      "     | > loss: -0.19439789652824402  (-0.17834750252465414)\n",
      "     | > log_mle: -0.3622504472732544  (-0.3490051489609941)\n",
      "     | > loss_dur: 0.16785255074501038  (0.17065764650798004)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(12.0241, device='cuda:0')  (tensor(38.5096, device='cuda:0'))\n",
      "     | > current_lr: 2.3250000000000003e-05 \n",
      "     | > step_time: 1.118  (0.6696844498316454)\n",
      "     | > loader_time: 0.0262  (0.012954338238789486)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 07:04:52 -- STEP: 337/406 -- GLOBAL_STEP: 60825\u001b[0m\n",
      "     | > loss: -0.17519813776016235  (-0.17775699606811973)\n",
      "     | > log_mle: -0.35379302501678467  (-0.3493405714940602)\n",
      "     | > loss_dur: 0.17859488725662231  (0.1715835754922661)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(38.4046, device='cuda:0')  (tensor(40.3657, device='cuda:0'))\n",
      "     | > current_lr: 2.3250000000000003e-05 \n",
      "     | > step_time: 0.8416  (0.6797755620599861)\n",
      "     | > loader_time: 0.0275  (0.013385370152640413)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 07:05:14 -- STEP: 362/406 -- GLOBAL_STEP: 60850\u001b[0m\n",
      "     | > loss: -0.1963985413312912  (-0.17775365035178248)\n",
      "     | > log_mle: -0.372051477432251  (-0.3501071495245836)\n",
      "     | > loss_dur: 0.17565293610095978  (0.1723534992345461)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(60.6811, device='cuda:0')  (tensor(40.8887, device='cuda:0'))\n",
      "     | > current_lr: 2.3250000000000003e-05 \n",
      "     | > step_time: 0.7454  (0.6925686070932214)\n",
      "     | > loader_time: 0.0358  (0.013907530689766395)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 07:05:37 -- STEP: 387/406 -- GLOBAL_STEP: 60875\u001b[0m\n",
      "     | > loss: -0.1858879178762436  (-0.1778900382284662)\n",
      "     | > log_mle: -0.3620035648345947  (-0.3508805387703949)\n",
      "     | > loss_dur: 0.17611564695835114  (0.17299050059968513)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(42.8446, device='cuda:0')  (tensor(41.0227, device='cuda:0'))\n",
      "     | > current_lr: 2.3250000000000003e-05 \n",
      "     | > step_time: 1.2268  (0.7051492470487455)\n",
      "     | > loader_time: 0.0101  (0.014034273704509095)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: -0.17160499095916748  (-0.17160499095916748)\n",
      "     | > log_mle: -0.3358032703399658  (-0.3358032703399658)\n",
      "     | > loss_dur: 0.16419827938079834  (0.16419827938079834)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: -0.21871212124824524  (-0.21871212124824524)\n",
      "     | > log_mle: -0.382443904876709  (-0.382443904876709)\n",
      "     | > loss_dur: 0.16373178362846375  (0.16373178362846375)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: -0.2176450937986374  (-0.21817860752344131)\n",
      "     | > log_mle: -0.34511494636535645  (-0.3637794256210327)\n",
      "     | > loss_dur: 0.12746985256671906  (0.1456008180975914)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: -0.21473394334316254  (-0.21703038613001505)\n",
      "     | > log_mle: -0.3533163070678711  (-0.3602917194366455)\n",
      "     | > loss_dur: 0.13858236372470856  (0.14326133330663046)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: -0.21969296038150787  (-0.21769602969288826)\n",
      "     | > log_mle: -0.380953311920166  (-0.36545711755752563)\n",
      "     | > loss_dur: 0.16126035153865814  (0.14776108786463737)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: -0.23560957610607147  (-0.2212787389755249)\n",
      "     | > log_mle: -0.3842533826828003  (-0.36921637058258056)\n",
      "     | > loss_dur: 0.14864380657672882  (0.14793763160705567)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: -0.17271044850349426  (-0.21318402389685312)\n",
      "     | > log_mle: -0.3974367380142212  (-0.3739197651545207)\n",
      "     | > loss_dur: 0.22472628951072693  (0.16073574125766754)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: -0.19491036236286163  (-0.21057350082056864)\n",
      "     | > log_mle: -0.35214877128601074  (-0.37080962317330496)\n",
      "     | > loss_dur: 0.1572384089231491  (0.16023612235273635)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: -0.20903457701206207  (-0.2103811353445053)\n",
      "     | > log_mle: -0.3664102554321289  (-0.37025970220565796)\n",
      "     | > loss_dur: 0.15737567842006683  (0.15987856686115265)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: -0.2093999683856964  (-0.21027211679352653)\n",
      "     | > log_mle: -0.37917160987854004  (-0.3712499141693115)\n",
      "     | > loss_dur: 0.16977164149284363  (0.160977797375785)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: -0.18500478565692902  (-0.20774538367986678)\n",
      "     | > log_mle: -0.364068865776062  (-0.3705318093299866)\n",
      "     | > loss_dur: 0.179064080119133  (0.16278642565011978)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: -0.21884466707706451  (-0.2087544094432484)\n",
      "     | > log_mle: -0.38163328170776367  (-0.37154103409160266)\n",
      "     | > loss_dur: 0.16278861463069916  (0.16278662464835428)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: -0.22236037254333496  (-0.20988823970158896)\n",
      "     | > log_mle: -0.36556923389434814  (-0.3710433840751648)\n",
      "     | > loss_dur: 0.14320886135101318  (0.16115514437357584)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: -0.23274053633213043  (-0.21164610867316908)\n",
      "     | > log_mle: -0.3915376663208008  (-0.3726198673248291)\n",
      "     | > loss_dur: 0.15879712998867035  (0.16097375865166003)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: -0.21336644887924194  (-0.21176899011645997)\n",
      "     | > log_mle: -0.377771258354187  (-0.3729878238269261)\n",
      "     | > loss_dur: 0.16440480947494507  (0.1612188337104661)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: -0.20997056365013123  (-0.21164909501870474)\n",
      "     | > log_mle: -0.36951375007629395  (-0.37275621891021726)\n",
      "     | > loss_dur: 0.15954318642616272  (0.16110712389151255)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: -0.20701682567596436  (-0.21135957818478346)\n",
      "     | > log_mle: -0.37579798698425293  (-0.3729463294148445)\n",
      "     | > loss_dur: 0.16878116130828857  (0.16158675123006105)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: audio amplitude out of range, auto clipped.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.0034188926219940186 \u001b[0m(-0.0001841038465499878)\n",
      "     | > avg_loss:\u001b[92m -0.21135957818478346 \u001b[0m(-0.007573636248707771)\n",
      "     | > avg_log_mle:\u001b[92m -0.3729463294148445 \u001b[0m(-0.005531303584575653)\n",
      "     | > avg_loss_dur:\u001b[92m 0.16158675123006105 \u001b[0m(-0.0020423326641321182)\n",
      "\n",
      " > BEST MODEL : train/run-February-22-2025_10+59PM-fa84af3/best_model_60894.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 94/100\u001b[0m\n",
      " --> train/run-February-22-2025_10+59PM-fa84af3\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-23 07:06:05) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 07:06:10 -- STEP: 6/406 -- GLOBAL_STEP: 60900\u001b[0m\n",
      "     | > loss: -0.21971388161182404  (-0.20475703477859497)\n",
      "     | > log_mle: -0.333926796913147  (-0.33558541536331177)\n",
      "     | > loss_dur: 0.11421291530132294  (0.1308283805847168)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(92.3885, device='cuda:0')  (tensor(36.6432, device='cuda:0'))\n",
      "     | > current_lr: 2.3500000000000002e-05 \n",
      "     | > step_time: 0.3023  (0.45880762736002606)\n",
      "     | > loader_time: 0.0045  (0.0049885908762613935)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 07:06:23 -- STEP: 31/406 -- GLOBAL_STEP: 60925\u001b[0m\n",
      "     | > loss: -0.17676375806331635  (-0.1925656362887352)\n",
      "     | > log_mle: -0.32509779930114746  (-0.33451609457692794)\n",
      "     | > loss_dur: 0.14833404123783112  (0.14195045852853405)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(26.6123, device='cuda:0')  (tensor(35.3995, device='cuda:0'))\n",
      "     | > current_lr: 2.3500000000000002e-05 \n",
      "     | > step_time: 0.4124  (0.49336861025902534)\n",
      "     | > loader_time: 0.0045  (0.007846893802765879)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 07:06:38 -- STEP: 56/406 -- GLOBAL_STEP: 60950\u001b[0m\n",
      "     | > loss: -0.19767403602600098  (-0.1863178781100682)\n",
      "     | > log_mle: -0.34221625328063965  (-0.3352921903133393)\n",
      "     | > loss_dur: 0.14454221725463867  (0.14897431233631706)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(25.2565, device='cuda:0')  (tensor(33.3982, device='cuda:0'))\n",
      "     | > current_lr: 2.3500000000000002e-05 \n",
      "     | > step_time: 0.6378  (0.5409999319485256)\n",
      "     | > loader_time: 0.004  (0.009036481380462646)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 07:06:54 -- STEP: 81/406 -- GLOBAL_STEP: 60975\u001b[0m\n",
      "     | > loss: -0.19084681570529938  (-0.18278663688235813)\n",
      "     | > log_mle: -0.3465402126312256  (-0.3365218595222191)\n",
      "     | > loss_dur: 0.1556933969259262  (0.1537352227318434)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(18.4855, device='cuda:0')  (tensor(34.4053, device='cuda:0'))\n",
      "     | > current_lr: 2.3500000000000002e-05 \n",
      "     | > step_time: 0.5897  (0.5650471434181118)\n",
      "     | > loader_time: 0.0148  (0.0106116047611943)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 07:07:11 -- STEP: 106/406 -- GLOBAL_STEP: 61000\u001b[0m\n",
      "     | > loss: -0.17833144962787628  (-0.18139794229898812)\n",
      "     | > log_mle: -0.33628547191619873  (-0.33887011712452164)\n",
      "     | > loss_dur: 0.15795402228832245  (0.15747217489582188)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(21.7376, device='cuda:0')  (tensor(32.6879, device='cuda:0'))\n",
      "     | > current_lr: 2.3500000000000002e-05 \n",
      "     | > step_time: 0.7744  (0.5879370064105629)\n",
      "     | > loader_time: 0.0069  (0.010812869611776101)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 07:07:28 -- STEP: 131/406 -- GLOBAL_STEP: 61025\u001b[0m\n",
      "     | > loss: -0.18748266994953156  (-0.17997011542320251)\n",
      "     | > log_mle: -0.3478926420211792  (-0.34050554901588975)\n",
      "     | > loss_dur: 0.16040997207164764  (0.1605354336495618)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(27.3435, device='cuda:0')  (tensor(34.4090, device='cuda:0'))\n",
      "     | > current_lr: 2.3500000000000002e-05 \n",
      "     | > step_time: 0.3899  (0.6006603386565931)\n",
      "     | > loader_time: 0.0045  (0.010901895188193287)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 07:07:45 -- STEP: 156/406 -- GLOBAL_STEP: 61050\u001b[0m\n",
      "     | > loss: -0.1767176240682602  (-0.1791705848314824)\n",
      "     | > log_mle: -0.36014795303344727  (-0.34242823185064863)\n",
      "     | > loss_dur: 0.18343032896518707  (0.16325764706692636)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(40.5000, device='cuda:0')  (tensor(35.9401, device='cuda:0'))\n",
      "     | > current_lr: 2.3500000000000002e-05 \n",
      "     | > step_time: 0.3778  (0.6141387300613599)\n",
      "     | > loader_time: 0.0052  (0.010799826719822027)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 07:08:03 -- STEP: 181/406 -- GLOBAL_STEP: 61075\u001b[0m\n",
      "     | > loss: -0.15501806139945984  (-0.17872923933669352)\n",
      "     | > log_mle: -0.34972643852233887  (-0.3435149759218838)\n",
      "     | > loss_dur: 0.19470837712287903  (0.1647857366263537)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(37.4502, device='cuda:0')  (tensor(37.4896, device='cuda:0'))\n",
      "     | > current_lr: 2.3500000000000002e-05 \n",
      "     | > step_time: 0.393  (0.6226589758751799)\n",
      "     | > loader_time: 0.0052  (0.011481522196564224)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 07:08:22 -- STEP: 206/406 -- GLOBAL_STEP: 61100\u001b[0m\n",
      "     | > loss: -0.1746317595243454  (-0.17838373331769003)\n",
      "     | > log_mle: -0.3503912687301636  (-0.344786141682597)\n",
      "     | > loss_dur: 0.17575950920581818  (0.16640240840107492)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(27.9024, device='cuda:0')  (tensor(37.4469, device='cuda:0'))\n",
      "     | > current_lr: 2.3500000000000002e-05 \n",
      "     | > step_time: 0.757  (0.6379826369794825)\n",
      "     | > loader_time: 0.0158  (0.011780979563888992)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 07:08:41 -- STEP: 231/406 -- GLOBAL_STEP: 61125\u001b[0m\n",
      "     | > loss: -0.16559049487113953  (-0.17848230879028126)\n",
      "     | > log_mle: -0.36599814891815186  (-0.3462858349729926)\n",
      "     | > loss_dur: 0.20040765404701233  (0.16780352621496497)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(52.9860, device='cuda:0')  (tensor(37.4726, device='cuda:0'))\n",
      "     | > current_lr: 2.3500000000000002e-05 \n",
      "     | > step_time: 0.6188  (0.6503986218274929)\n",
      "     | > loader_time: 0.0251  (0.01194322057616659)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 07:09:01 -- STEP: 256/406 -- GLOBAL_STEP: 61150\u001b[0m\n",
      "     | > loss: -0.17710518836975098  (-0.17859923216747123)\n",
      "     | > log_mle: -0.3593885898590088  (-0.34746257588267326)\n",
      "     | > loss_dur: 0.1822834014892578  (0.1688633437443059)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(62.6732, device='cuda:0')  (tensor(38.5065, device='cuda:0'))\n",
      "     | > current_lr: 2.3500000000000002e-05 \n",
      "     | > step_time: 0.4522  (0.65993978921324)\n",
      "     | > loader_time: 0.0074  (0.01237552613019943)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 07:09:20 -- STEP: 281/406 -- GLOBAL_STEP: 61175\u001b[0m\n",
      "     | > loss: -0.20352178812026978  (-0.1789592098829161)\n",
      "     | > log_mle: -0.36574292182922363  (-0.3484955550937041)\n",
      "     | > loss_dur: 0.16222113370895386  (0.1695363452373026)\n",
      "     | > amp_scaler: 2048.0  (2048.0)\n",
      "     | > grad_norm: tensor(50.5154, device='cuda:0')  (tensor(38.7958, device='cuda:0'))\n",
      "     | > current_lr: 2.3500000000000002e-05 \n",
      "     | > step_time: 0.8168  (0.6689320009374107)\n",
      "     | > loader_time: 0.0418  (0.012632450599263146)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 07:09:41 -- STEP: 306/406 -- GLOBAL_STEP: 61200\u001b[0m\n",
      "     | > loss: -0.15398988127708435  (-0.17862727936186817)\n",
      "     | > log_mle: -0.3448762893676758  (-0.3491443559235218)\n",
      "     | > loss_dur: 0.19088640809059143  (0.17051707658600188)\n",
      "     | > amp_scaler: 1024.0  (2027.921568627451)\n",
      "     | > grad_norm: tensor(63.2550, device='cuda:0')  (tensor(40.7731, device='cuda:0'))\n",
      "     | > current_lr: 2.3500000000000002e-05 \n",
      "     | > step_time: 0.6583  (0.6807453951804464)\n",
      "     | > loader_time: 0.0249  (0.012764430513568955)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 07:10:02 -- STEP: 331/406 -- GLOBAL_STEP: 61225\u001b[0m\n",
      "     | > loss: -0.16484925150871277  (-0.1785116490100445)\n",
      "     | > log_mle: -0.3559269905090332  (-0.34971825737967593)\n",
      "     | > loss_dur: 0.19107773900032043  (0.1712066083921407)\n",
      "     | > amp_scaler: 1024.0  (1952.0966767371601)\n",
      "     | > grad_norm: tensor(43.0683, device='cuda:0')  (tensor(40.7017, device='cuda:0'))\n",
      "     | > current_lr: 2.3500000000000002e-05 \n",
      "     | > step_time: 1.2133  (0.6924454416753298)\n",
      "     | > loader_time: 0.0294  (0.01293565067279735)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 07:10:24 -- STEP: 356/406 -- GLOBAL_STEP: 61250\u001b[0m\n",
      "     | > loss: -0.1863836795091629  (-0.1787053233619485)\n",
      "     | > log_mle: -0.37207531929016113  (-0.35068565171756094)\n",
      "     | > loss_dur: 0.18569163978099823  (0.17198032837654106)\n",
      "     | > amp_scaler: 1024.0  (1886.9213483146068)\n",
      "     | > grad_norm: tensor(31.1811, device='cuda:0')  (tensor(40.6490, device='cuda:0'))\n",
      "     | > current_lr: 2.3500000000000002e-05 \n",
      "     | > step_time: 0.6041  (0.7019344708892733)\n",
      "     | > loader_time: 0.0132  (0.012916257542170835)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 07:10:47 -- STEP: 381/406 -- GLOBAL_STEP: 61275\u001b[0m\n",
      "     | > loss: -0.16769947111606598  (-0.17902907772170576)\n",
      "     | > log_mle: -0.3512624502182007  (-0.3515475328200133)\n",
      "     | > loss_dur: 0.1835629791021347  (0.17251845511786265)\n",
      "     | > amp_scaler: 1024.0  (1830.2992125984251)\n",
      "     | > grad_norm: tensor(26.1239, device='cuda:0')  (tensor(40.5485, device='cuda:0'))\n",
      "     | > current_lr: 2.3500000000000002e-05 \n",
      "     | > step_time: 1.0263  (0.7151902910918383)\n",
      "     | > loader_time: 0.0086  (0.012974901149279176)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: -0.16693823039531708  (-0.16693823039531708)\n",
      "     | > log_mle: -0.3365485668182373  (-0.3365485668182373)\n",
      "     | > loss_dur: 0.16961033642292023  (0.16961033642292023)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: -0.21570828557014465  (-0.21570828557014465)\n",
      "     | > log_mle: -0.38253092765808105  (-0.38253092765808105)\n",
      "     | > loss_dur: 0.1668226420879364  (0.1668226420879364)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: -0.22254487872123718  (-0.21912658214569092)\n",
      "     | > log_mle: -0.3452308177947998  (-0.36388087272644043)\n",
      "     | > loss_dur: 0.12268593162298203  (0.1447542868554592)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: -0.20994499325752258  (-0.21606605251630148)\n",
      "     | > log_mle: -0.3531467914581299  (-0.3603028456370036)\n",
      "     | > loss_dur: 0.1432017982006073  (0.14423679063717523)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: -0.22524139285087585  (-0.21835988759994507)\n",
      "     | > log_mle: -0.3807793855667114  (-0.36542198061943054)\n",
      "     | > loss_dur: 0.15553799271583557  (0.14706209115684032)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: -0.2282591462135315  (-0.22033973932266235)\n",
      "     | > log_mle: -0.3823484182357788  (-0.3688072681427002)\n",
      "     | > loss_dur: 0.15408927202224731  (0.14846752732992172)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: -0.17401814460754395  (-0.2126194735368093)\n",
      "     | > log_mle: -0.39515209197998047  (-0.37319807211558026)\n",
      "     | > loss_dur: 0.22113394737243652  (0.16057859733700752)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: -0.19401444494724274  (-0.20996161230972835)\n",
      "     | > log_mle: -0.35121893882751465  (-0.37005819593157085)\n",
      "     | > loss_dur: 0.1572044938802719  (0.16009658255747386)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: -0.21133695542812347  (-0.21013353019952774)\n",
      "     | > log_mle: -0.3655756711959839  (-0.3694978803396225)\n",
      "     | > loss_dur: 0.1542387157678604  (0.15936434920877218)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: -0.2026141732931137  (-0.20929804609881508)\n",
      "     | > log_mle: -0.3783693313598633  (-0.37048359711964923)\n",
      "     | > loss_dur: 0.17575515806674957  (0.16118555019299188)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: -0.18309979140758514  (-0.20667822062969207)\n",
      "     | > log_mle: -0.3635423183441162  (-0.36978946924209594)\n",
      "     | > loss_dur: 0.18044252693653107  (0.16311124786734582)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: -0.2238570898771286  (-0.20823993601582266)\n",
      "     | > log_mle: -0.3809244632720947  (-0.3708017414266413)\n",
      "     | > loss_dur: 0.15706737339496613  (0.1625618047334931)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: -0.21909072995185852  (-0.20914416884382567)\n",
      "     | > log_mle: -0.3648937940597534  (-0.37030941247940063)\n",
      "     | > loss_dur: 0.1458030641078949  (0.16116524301469326)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: -0.2316499650478363  (-0.21087538393644187)\n",
      "     | > log_mle: -0.3903615474700928  (-0.3718518844017616)\n",
      "     | > loss_dur: 0.15871158242225647  (0.16097649989219812)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: -0.21120718121528625  (-0.2108990837420736)\n",
      "     | > log_mle: -0.3768075704574585  (-0.3722058619771685)\n",
      "     | > loss_dur: 0.16560038924217224  (0.16130677770291055)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: -0.20347878336906433  (-0.21040439705053965)\n",
      "     | > log_mle: -0.36868202686309814  (-0.37197093963623046)\n",
      "     | > loss_dur: 0.1652032434940338  (0.16156654208898544)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: -0.21108759939670563  (-0.21044709719717503)\n",
      "     | > log_mle: -0.37448906898498535  (-0.37212832272052765)\n",
      "     | > loss_dur: 0.16340146958827972  (0.16168122505769134)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: audio amplitude out of range, auto clipped.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[91m 0.004133179783821106 \u001b[0m(+0.0007142871618270874)\n",
      "     | > avg_loss:\u001b[91m -0.21044709719717503 \u001b[0m(+0.0009124809876084328)\n",
      "     | > avg_log_mle:\u001b[91m -0.37212832272052765 \u001b[0m(+0.000818006694316864)\n",
      "     | > avg_loss_dur:\u001b[91m 0.16168122505769134 \u001b[0m(+9.447382763028145e-05)\n",
      "\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 95/100\u001b[0m\n",
      " --> train/run-February-22-2025_10+59PM-fa84af3\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-23 07:11:20) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 07:11:23 -- STEP: 0/406 -- GLOBAL_STEP: 61300\u001b[0m\n",
      "     | > loss: -0.2112756073474884  (-0.2112756073474884)\n",
      "     | > log_mle: -0.3357229232788086  (-0.3357229232788086)\n",
      "     | > loss_dur: 0.1244473084807396  (0.1244473084807396)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(29.8428, device='cuda:0')  (tensor(29.8428, device='cuda:0'))\n",
      "     | > current_lr: 2.375e-05 \n",
      "     | > step_time: 1.2973  (1.2973182201385498)\n",
      "     | > loader_time: 0.9576  (0.9575793743133545)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 07:11:35 -- STEP: 25/406 -- GLOBAL_STEP: 61325\u001b[0m\n",
      "     | > loss: -0.18873217701911926  (-0.19695420384407045)\n",
      "     | > log_mle: -0.34298479557037354  (-0.33725804805755616)\n",
      "     | > loss_dur: 0.15425261855125427  (0.14030384451150893)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(19.7602, device='cuda:0')  (tensor(40.1835, device='cuda:0'))\n",
      "     | > current_lr: 2.375e-05 \n",
      "     | > step_time: 0.7214  (0.49240554809570314)\n",
      "     | > loader_time: 0.0048  (0.007725334167480467)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 07:11:51 -- STEP: 50/406 -- GLOBAL_STEP: 61350\u001b[0m\n",
      "     | > loss: -0.1875344216823578  (-0.18796174466609955)\n",
      "     | > log_mle: -0.36413586139678955  (-0.33614183664321895)\n",
      "     | > loss_dur: 0.17660143971443176  (0.14818009212613106)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(25.8878, device='cuda:0')  (tensor(37.3343, device='cuda:0'))\n",
      "     | > current_lr: 2.375e-05 \n",
      "     | > step_time: 0.4323  (0.5463534784317017)\n",
      "     | > loader_time: 0.0126  (0.008808417320251463)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 07:12:07 -- STEP: 75/406 -- GLOBAL_STEP: 61375\u001b[0m\n",
      "     | > loss: -0.18700051307678223  (-0.18576837937037152)\n",
      "     | > log_mle: -0.345928430557251  (-0.3379613542556762)\n",
      "     | > loss_dur: 0.15892791748046875  (0.15219297498464585)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(22.7574, device='cuda:0')  (tensor(34.8108, device='cuda:0'))\n",
      "     | > current_lr: 2.375e-05 \n",
      "     | > step_time: 0.8562  (0.5754969755808511)\n",
      "     | > loader_time: 0.0069  (0.009701054890950517)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 07:12:22 -- STEP: 100/406 -- GLOBAL_STEP: 61400\u001b[0m\n",
      "     | > loss: -0.1738361269235611  (-0.183281289935112)\n",
      "     | > log_mle: -0.34892749786376953  (-0.3396621966362)\n",
      "     | > loss_dur: 0.17509137094020844  (0.15638090677559371)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(41.0227, device='cuda:0')  (tensor(34.0646, device='cuda:0'))\n",
      "     | > current_lr: 2.375e-05 \n",
      "     | > step_time: 0.7194  (0.5817337203025817)\n",
      "     | > loader_time: 0.0089  (0.00974712610244751)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 07:12:39 -- STEP: 125/406 -- GLOBAL_STEP: 61425\u001b[0m\n",
      "     | > loss: -0.16572122275829315  (-0.182119655251503)\n",
      "     | > log_mle: -0.3571968078613281  (-0.3417137145996094)\n",
      "     | > loss_dur: 0.19147558510303497  (0.15959405940771096)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(55.3728, device='cuda:0')  (tensor(35.8595, device='cuda:0'))\n",
      "     | > current_lr: 2.375e-05 \n",
      "     | > step_time: 0.9979  (0.5989239234924315)\n",
      "     | > loader_time: 0.0188  (0.009641969680786133)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 07:12:56 -- STEP: 150/406 -- GLOBAL_STEP: 61450\u001b[0m\n",
      "     | > loss: -0.18277540802955627  (-0.18154623051484425)\n",
      "     | > log_mle: -0.3520088195800781  (-0.3435753639539083)\n",
      "     | > loss_dur: 0.16923341155052185  (0.16202913348873452)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(31.6324, device='cuda:0')  (tensor(36.5667, device='cuda:0'))\n",
      "     | > current_lr: 2.375e-05 \n",
      "     | > step_time: 0.7232  (0.6091380675633746)\n",
      "     | > loader_time: 0.0154  (0.009909865061442057)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 07:13:14 -- STEP: 175/406 -- GLOBAL_STEP: 61475\u001b[0m\n",
      "     | > loss: -0.1899978220462799  (-0.18119052103587557)\n",
      "     | > log_mle: -0.3574204444885254  (-0.34489409310477126)\n",
      "     | > loss_dur: 0.16742262244224548  (0.16370357211147024)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(63.9928, device='cuda:0')  (tensor(36.8641, device='cuda:0'))\n",
      "     | > current_lr: 2.375e-05 \n",
      "     | > step_time: 0.4511  (0.6220624024527414)\n",
      "     | > loader_time: 0.0089  (0.010104379653930665)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 07:13:32 -- STEP: 200/406 -- GLOBAL_STEP: 61500\u001b[0m\n",
      "     | > loss: -0.18282008171081543  (-0.18124701142311095)\n",
      "     | > log_mle: -0.35717904567718506  (-0.34643296658992784)\n",
      "     | > loss_dur: 0.17435896396636963  (0.1651859552040696)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(28.3236, device='cuda:0')  (tensor(36.4582, device='cuda:0'))\n",
      "     | > current_lr: 2.375e-05 \n",
      "     | > step_time: 0.6246  (0.6297155952453615)\n",
      "     | > loader_time: 0.0114  (0.010165731906890872)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 07:13:51 -- STEP: 225/406 -- GLOBAL_STEP: 61525\u001b[0m\n",
      "     | > loss: -0.18500076234340668  (-0.18117959486113655)\n",
      "     | > log_mle: -0.35982799530029297  (-0.3477759801016915)\n",
      "     | > loss_dur: 0.1748272329568863  (0.16659638527366846)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(25.1973, device='cuda:0')  (tensor(37.6672, device='cuda:0'))\n",
      "     | > current_lr: 2.375e-05 \n",
      "     | > step_time: 0.8408  (0.6438385295867922)\n",
      "     | > loader_time: 0.0195  (0.010823140674167212)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 07:14:10 -- STEP: 250/406 -- GLOBAL_STEP: 61550\u001b[0m\n",
      "     | > loss: -0.20334848761558533  (-0.1812597422003746)\n",
      "     | > log_mle: -0.3714590072631836  (-0.34898866987228405)\n",
      "     | > loss_dur: 0.16811051964759827  (0.16772892770171163)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(38.6824, device='cuda:0')  (tensor(38.1725, device='cuda:0'))\n",
      "     | > current_lr: 2.375e-05 \n",
      "     | > step_time: 0.7509  (0.6520788774490359)\n",
      "     | > loader_time: 0.0214  (0.011265285491943361)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 07:14:29 -- STEP: 275/406 -- GLOBAL_STEP: 61575\u001b[0m\n",
      "     | > loss: -0.17225611209869385  (-0.18157831880179318)\n",
      "     | > log_mle: -0.3550971746444702  (-0.35012144478884616)\n",
      "     | > loss_dur: 0.18284106254577637  (0.16854312601414595)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(54.9282, device='cuda:0')  (tensor(38.5566, device='cuda:0'))\n",
      "     | > current_lr: 2.375e-05 \n",
      "     | > step_time: 0.8003  (0.6604812587391249)\n",
      "     | > loader_time: 0.0223  (0.011691663915460762)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 07:14:49 -- STEP: 300/406 -- GLOBAL_STEP: 61600\u001b[0m\n",
      "     | > loss: -0.16716600954532623  (-0.18156666547060013)\n",
      "     | > log_mle: -0.34051811695098877  (-0.3508638274669647)\n",
      "     | > loss_dur: 0.17335210740566254  (0.16929716202119985)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(102.8108, device='cuda:0')  (tensor(39.6624, device='cuda:0'))\n",
      "     | > current_lr: 2.375e-05 \n",
      "     | > step_time: 0.6599  (0.6716396450996402)\n",
      "     | > loader_time: 0.0091  (0.012012691497802735)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 07:15:10 -- STEP: 325/406 -- GLOBAL_STEP: 61625\u001b[0m\n",
      "     | > loss: -0.17845797538757324  (-0.18158821376470416)\n",
      "     | > log_mle: -0.35236215591430664  (-0.3516359358567459)\n",
      "     | > loss_dur: 0.1739041805267334  (0.17004772211496638)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(29.5702, device='cuda:0')  (tensor(39.4366, device='cuda:0'))\n",
      "     | > current_lr: 2.375e-05 \n",
      "     | > step_time: 0.9616  (0.6805226003206695)\n",
      "     | > loader_time: 0.009  (0.012214609292837292)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 07:15:30 -- STEP: 350/406 -- GLOBAL_STEP: 61650\u001b[0m\n",
      "     | > loss: -0.18820658326148987  (-0.18154189510004862)\n",
      "     | > log_mle: -0.3667484521865845  (-0.352460220541273)\n",
      "     | > loss_dur: 0.1785418689250946  (0.17091832546251154)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(27.5605, device='cuda:0')  (tensor(39.6552, device='cuda:0'))\n",
      "     | > current_lr: 2.375e-05 \n",
      "     | > step_time: 0.694  (0.6887785891124184)\n",
      "     | > loader_time: 0.0085  (0.012478158814566482)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 07:15:52 -- STEP: 375/406 -- GLOBAL_STEP: 61675\u001b[0m\n",
      "     | > loss: -0.19775909185409546  (-0.18127229964733124)\n",
      "     | > log_mle: -0.3700758218765259  (-0.35294117450714124)\n",
      "     | > loss_dur: 0.17231673002243042  (0.17166887487967808)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(22.6129, device='cuda:0')  (tensor(40.5560, device='cuda:0'))\n",
      "     | > current_lr: 2.375e-05 \n",
      "     | > step_time: 0.9346  (0.6995445143381758)\n",
      "     | > loader_time: 0.0097  (0.012623022715250655)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 07:16:10 -- STEP: 400/406 -- GLOBAL_STEP: 61700\u001b[0m\n",
      "     | > loss: -0.1661810278892517  (-0.18103279128670693)\n",
      "     | > log_mle: -0.3588066101074219  (-0.35328148841857926)\n",
      "     | > loss_dur: 0.19262558221817017  (0.17224869715049862)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(46.9701, device='cuda:0')  (tensor(42.6411, device='cuda:0'))\n",
      "     | > current_lr: 2.375e-05 \n",
      "     | > step_time: 0.5762  (0.7009792417287829)\n",
      "     | > loader_time: 0.0055  (0.012534442543983464)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: -0.16825124621391296  (-0.16825124621391296)\n",
      "     | > log_mle: -0.3327920436859131  (-0.3327920436859131)\n",
      "     | > loss_dur: 0.16454079747200012  (0.16454079747200012)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: -0.20718041062355042  (-0.20718041062355042)\n",
      "     | > log_mle: -0.37686097621917725  (-0.37686097621917725)\n",
      "     | > loss_dur: 0.16968056559562683  (0.16968056559562683)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: -0.21902287006378174  (-0.21310164034366608)\n",
      "     | > log_mle: -0.34215080738067627  (-0.35950589179992676)\n",
      "     | > loss_dur: 0.12312792986631393  (0.14640424773097038)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: -0.2065209597349167  (-0.2109080801407496)\n",
      "     | > log_mle: -0.34829652309417725  (-0.35576943556467694)\n",
      "     | > loss_dur: 0.14177556335926056  (0.14486135294040045)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: -0.21569538116455078  (-0.2121049053966999)\n",
      "     | > log_mle: -0.37508833408355713  (-0.360599160194397)\n",
      "     | > loss_dur: 0.15939295291900635  (0.14849425293505192)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: -0.21265800297260284  (-0.2122155249118805)\n",
      "     | > log_mle: -0.37658703327178955  (-0.3637967348098755)\n",
      "     | > loss_dur: 0.1639290302991867  (0.15158120840787886)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: -0.16428248584270477  (-0.20422668506701788)\n",
      "     | > log_mle: -0.38931405544281006  (-0.36804962158203125)\n",
      "     | > loss_dur: 0.22503156960010529  (0.16382293527324995)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: -0.1866568922996521  (-0.2017167146716799)\n",
      "     | > log_mle: -0.34632885456085205  (-0.36494665486471994)\n",
      "     | > loss_dur: 0.15967196226119995  (0.16322993912867137)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: -0.20726656913757324  (-0.20241044647991657)\n",
      "     | > log_mle: -0.36032533645629883  (-0.3643689900636673)\n",
      "     | > loss_dur: 0.15305876731872559  (0.16195854265242815)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: -0.205730602145195  (-0.2027793526649475)\n",
      "     | > log_mle: -0.3737800121307373  (-0.36541465918223065)\n",
      "     | > loss_dur: 0.1680494099855423  (0.16263530568944085)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: -0.17207983136177063  (-0.19970940053462982)\n",
      "     | > log_mle: -0.3586918115615845  (-0.364742374420166)\n",
      "     | > loss_dur: 0.18661198019981384  (0.16503297314047813)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: -0.20785732567310333  (-0.20045012100176376)\n",
      "     | > log_mle: -0.3754938840866089  (-0.36571978438984265)\n",
      "     | > loss_dur: 0.16763655841350555  (0.16526966271075336)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: -0.21960344910621643  (-0.20204623167713484)\n",
      "     | > log_mle: -0.35989177227020264  (-0.365234116713206)\n",
      "     | > loss_dur: 0.1402883231639862  (0.16318788441518942)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: -0.22288484871387482  (-0.20364920221842253)\n",
      "     | > log_mle: -0.38516056537628174  (-0.3667669204565195)\n",
      "     | > loss_dur: 0.16227571666240692  (0.16311771766497538)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: -0.20908376574516296  (-0.20403738532747542)\n",
      "     | > log_mle: -0.37188446521759033  (-0.3671324593680246)\n",
      "     | > loss_dur: 0.16280069947242737  (0.1630950735083648)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: -0.20440997183322906  (-0.20406222442785898)\n",
      "     | > log_mle: -0.36418771743774414  (-0.3669361432393392)\n",
      "     | > loss_dur: 0.15977774560451508  (0.16287391831477482)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: -0.2061096429824829  (-0.20419018808752298)\n",
      "     | > log_mle: -0.3699982166290283  (-0.36712752282619476)\n",
      "     | > loss_dur: 0.1638885736465454  (0.1629373342730105)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: audio amplitude out of range, auto clipped.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.0034085065126419067 \u001b[0m(-0.0007246732711791992)\n",
      "     | > avg_loss:\u001b[91m -0.20419018808752298 \u001b[0m(+0.006256909109652042)\n",
      "     | > avg_log_mle:\u001b[91m -0.36712752282619476 \u001b[0m(+0.005000799894332886)\n",
      "     | > avg_loss_dur:\u001b[91m 0.1629373342730105 \u001b[0m(+0.0012561092153191566)\n",
      "\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 96/100\u001b[0m\n",
      " --> train/run-February-22-2025_10+59PM-fa84af3\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-23 07:16:28) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 07:16:39 -- STEP: 19/406 -- GLOBAL_STEP: 61725\u001b[0m\n",
      "     | > loss: -0.19080083072185516  (-0.19620829585351443)\n",
      "     | > log_mle: -0.323199987411499  (-0.3336028111608405)\n",
      "     | > loss_dur: 0.13239915668964386  (0.13739451530732608)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(8.1888, device='cuda:0')  (tensor(30.2034, device='cuda:0'))\n",
      "     | > current_lr: 2.4e-05 \n",
      "     | > step_time: 0.4284  (0.44176976304305227)\n",
      "     | > loader_time: 0.0036  (0.006231082113165604)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 07:16:55 -- STEP: 44/406 -- GLOBAL_STEP: 61750\u001b[0m\n",
      "     | > loss: -0.16779384016990662  (-0.1859355375848034)\n",
      "     | > log_mle: -0.3373532295227051  (-0.3311275948177685)\n",
      "     | > loss_dur: 0.16955938935279846  (0.14519205723296516)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(50.9101, device='cuda:0')  (tensor(29.0105, device='cuda:0'))\n",
      "     | > current_lr: 2.4e-05 \n",
      "     | > step_time: 0.769  (0.5364730195565657)\n",
      "     | > loader_time: 0.0086  (0.007543412121859464)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 07:17:10 -- STEP: 69/406 -- GLOBAL_STEP: 61775\u001b[0m\n",
      "     | > loss: -0.17693375051021576  (-0.18202367662519653)\n",
      "     | > log_mle: -0.3461735248565674  (-0.3337404503338579)\n",
      "     | > loss_dur: 0.16923977434635162  (0.15171677370866146)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(42.9674, device='cuda:0')  (tensor(30.6415, device='cuda:0'))\n",
      "     | > current_lr: 2.4e-05 \n",
      "     | > step_time: 0.4208  (0.5497104326883951)\n",
      "     | > loader_time: 0.0053  (0.008554043977156933)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 07:17:27 -- STEP: 94/406 -- GLOBAL_STEP: 61800\u001b[0m\n",
      "     | > loss: -0.17905473709106445  (-0.1813331920098751)\n",
      "     | > log_mle: -0.3444892168045044  (-0.3368034299383772)\n",
      "     | > loss_dur: 0.16543447971343994  (0.15547023792850215)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(28.5962, device='cuda:0')  (tensor(34.1859, device='cuda:0'))\n",
      "     | > current_lr: 2.4e-05 \n",
      "     | > step_time: 0.5906  (0.5831835447473731)\n",
      "     | > loader_time: 0.0063  (0.009820854410212094)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 07:17:43 -- STEP: 119/406 -- GLOBAL_STEP: 61825\u001b[0m\n",
      "     | > loss: -0.18799753487110138  (-0.18113253847891544)\n",
      "     | > log_mle: -0.36149680614471436  (-0.3397210575953251)\n",
      "     | > loss_dur: 0.17349927127361298  (0.1585885191164097)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(18.2296, device='cuda:0')  (tensor(32.8282, device='cuda:0'))\n",
      "     | > current_lr: 2.4e-05 \n",
      "     | > step_time: 0.6194  (0.5946484072869568)\n",
      "     | > loader_time: 0.0082  (0.010158404582688792)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 07:18:01 -- STEP: 144/406 -- GLOBAL_STEP: 61850\u001b[0m\n",
      "     | > loss: -0.17445410788059235  (-0.18052462891985974)\n",
      "     | > log_mle: -0.3508955240249634  (-0.342177152633667)\n",
      "     | > loss_dur: 0.17644141614437103  (0.16165252371380723)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(35.1554, device='cuda:0')  (tensor(34.2764, device='cuda:0'))\n",
      "     | > current_lr: 2.4e-05 \n",
      "     | > step_time: 0.7434  (0.6091011067231498)\n",
      "     | > loader_time: 0.005  (0.010684286554654442)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 07:18:18 -- STEP: 169/406 -- GLOBAL_STEP: 61875\u001b[0m\n",
      "     | > loss: -0.1814505010843277  (-0.1799724385935879)\n",
      "     | > log_mle: -0.35980498790740967  (-0.34387785302111373)\n",
      "     | > loss_dur: 0.17835448682308197  (0.1639054144275259)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(19.2817, device='cuda:0')  (tensor(34.7622, device='cuda:0'))\n",
      "     | > current_lr: 2.4e-05 \n",
      "     | > step_time: 0.5807  (0.615346304763704)\n",
      "     | > loader_time: 0.0046  (0.01146124100544044)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 07:18:35 -- STEP: 194/406 -- GLOBAL_STEP: 61900\u001b[0m\n",
      "     | > loss: -0.17899316549301147  (-0.18057586867170228)\n",
      "     | > log_mle: -0.3576626777648926  (-0.3457201018775861)\n",
      "     | > loss_dur: 0.1786695122718811  (0.16514423320588378)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(36.0404, device='cuda:0')  (tensor(36.0079, device='cuda:0'))\n",
      "     | > current_lr: 2.4e-05 \n",
      "     | > step_time: 0.7034  (0.6233784894353337)\n",
      "     | > loader_time: 0.0244  (0.011531413215951827)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 07:18:54 -- STEP: 219/406 -- GLOBAL_STEP: 61925\u001b[0m\n",
      "     | > loss: -0.19751620292663574  (-0.18060813939462508)\n",
      "     | > log_mle: -0.35905420780181885  (-0.34716317751636244)\n",
      "     | > loss_dur: 0.1615380048751831  (0.1665550381217373)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(26.1907, device='cuda:0')  (tensor(36.2042, device='cuda:0'))\n",
      "     | > current_lr: 2.4e-05 \n",
      "     | > step_time: 0.8326  (0.6338574712134931)\n",
      "     | > loader_time: 0.0085  (0.01157721319155062)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 07:19:13 -- STEP: 244/406 -- GLOBAL_STEP: 61950\u001b[0m\n",
      "     | > loss: -0.18805773556232452  (-0.18096039047250975)\n",
      "     | > log_mle: -0.3624563217163086  (-0.3488179528322376)\n",
      "     | > loss_dur: 0.17439858615398407  (0.1678575623597278)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(42.6434, device='cuda:0')  (tensor(36.1968, device='cuda:0'))\n",
      "     | > current_lr: 2.4e-05 \n",
      "     | > step_time: 0.7532  (0.6451780786279773)\n",
      "     | > loader_time: 0.0077  (0.012077983285559986)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 07:19:32 -- STEP: 269/406 -- GLOBAL_STEP: 61975\u001b[0m\n",
      "     | > loss: -0.17700502276420593  (-0.18093027750577176)\n",
      "     | > log_mle: -0.35498929023742676  (-0.34955516003321535)\n",
      "     | > loss_dur: 0.17798426747322083  (0.16862488252744356)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(61.3800, device='cuda:0')  (tensor(37.8263, device='cuda:0'))\n",
      "     | > current_lr: 2.4e-05 \n",
      "     | > step_time: 0.7882  (0.6555368696446755)\n",
      "     | > loader_time: 0.0088  (0.012237692411061117)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 07:19:52 -- STEP: 294/406 -- GLOBAL_STEP: 62000\u001b[0m\n",
      "     | > loss: -0.1808091402053833  (-0.1811904272660105)\n",
      "     | > log_mle: -0.3683347702026367  (-0.35063795410856907)\n",
      "     | > loss_dur: 0.18752562999725342  (0.16944752684255845)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(85.0475, device='cuda:0')  (tensor(38.5924, device='cuda:0'))\n",
      "     | > current_lr: 2.4e-05 \n",
      "     | > step_time: 0.6018  (0.6655732198637359)\n",
      "     | > loader_time: 0.0256  (0.012559940214870745)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 07:20:12 -- STEP: 319/406 -- GLOBAL_STEP: 62025\u001b[0m\n",
      "     | > loss: -0.17103590071201324  (-0.18147740043629662)\n",
      "     | > log_mle: -0.3619871139526367  (-0.35165389466061486)\n",
      "     | > loss_dur: 0.19095121324062347  (0.1701764942243182)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(30.7512, device='cuda:0')  (tensor(38.5636, device='cuda:0'))\n",
      "     | > current_lr: 2.4e-05 \n",
      "     | > step_time: 0.6684  (0.6748623803117805)\n",
      "     | > loader_time: 0.0159  (0.012797871353484251)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 07:20:33 -- STEP: 344/406 -- GLOBAL_STEP: 62050\u001b[0m\n",
      "     | > loss: -0.17700427770614624  (-0.18139529171897906)\n",
      "     | > log_mle: -0.3505690097808838  (-0.3523806032053259)\n",
      "     | > loss_dur: 0.17356473207473755  (0.17098531148634685)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(48.1956, device='cuda:0')  (tensor(39.1636, device='cuda:0'))\n",
      "     | > current_lr: 2.4e-05 \n",
      "     | > step_time: 0.6133  (0.6844696118388064)\n",
      "     | > loader_time: 0.013  (0.013012753669605704)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 07:20:54 -- STEP: 369/406 -- GLOBAL_STEP: 62075\u001b[0m\n",
      "     | > loss: -0.1865251362323761  (-0.18156669916822316)\n",
      "     | > log_mle: -0.36347687244415283  (-0.35322500696673287)\n",
      "     | > loss_dur: 0.17695173621177673  (0.17165830779850977)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(31.6755, device='cuda:0')  (tensor(39.8557, device='cuda:0'))\n",
      "     | > current_lr: 2.4e-05 \n",
      "     | > step_time: 0.9719  (0.6947072366388832)\n",
      "     | > loader_time: 0.0122  (0.013127272045063138)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 07:21:15 -- STEP: 394/406 -- GLOBAL_STEP: 62100\u001b[0m\n",
      "     | > loss: -0.1863691508769989  (-0.18171613988688737)\n",
      "     | > log_mle: -0.3647878170013428  (-0.353974218598477)\n",
      "     | > loss_dur: 0.17841866612434387  (0.1722580787115897)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(24.6138, device='cuda:0')  (tensor(39.8886, device='cuda:0'))\n",
      "     | > current_lr: 2.4e-05 \n",
      "     | > step_time: 0.5253  (0.7021978391608611)\n",
      "     | > loader_time: 0.0089  (0.013236517228450876)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: -0.17116153240203857  (-0.17116153240203857)\n",
      "     | > log_mle: -0.3390148878097534  (-0.3390148878097534)\n",
      "     | > loss_dur: 0.16785335540771484  (0.16785335540771484)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: -0.21623338758945465  (-0.21623338758945465)\n",
      "     | > log_mle: -0.38408422470092773  (-0.38408422470092773)\n",
      "     | > loss_dur: 0.16785083711147308  (0.16785083711147308)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: -0.22075876593589783  (-0.21849607676267624)\n",
      "     | > log_mle: -0.34776341915130615  (-0.36592382192611694)\n",
      "     | > loss_dur: 0.12700465321540833  (0.1474277451634407)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: -0.21004992723464966  (-0.2156806935866674)\n",
      "     | > log_mle: -0.3544917106628418  (-0.3621131181716919)\n",
      "     | > loss_dur: 0.14444178342819214  (0.1464324245850245)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: -0.22742429375648499  (-0.21861659362912178)\n",
      "     | > log_mle: -0.381247878074646  (-0.3668968081474304)\n",
      "     | > loss_dur: 0.153823584318161  (0.14828021451830864)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: -0.2271282821893692  (-0.22031893134117125)\n",
      "     | > log_mle: -0.3796640634536743  (-0.3694502592086792)\n",
      "     | > loss_dur: 0.15253578126430511  (0.14913132786750793)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: -0.172775536775589  (-0.21239503224690756)\n",
      "     | > log_mle: -0.3908778429031372  (-0.37302152315775555)\n",
      "     | > loss_dur: 0.21810230612754822  (0.160626490910848)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: -0.1908906251192093  (-0.2093229740858078)\n",
      "     | > log_mle: -0.3515441417694092  (-0.3699533258165632)\n",
      "     | > loss_dur: 0.1606535166501999  (0.1606303517307554)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: -0.2110661119222641  (-0.20954086631536484)\n",
      "     | > log_mle: -0.3673551082611084  (-0.36962854862213135)\n",
      "     | > loss_dur: 0.1562889963388443  (0.1600876823067665)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: -0.19753345847129822  (-0.20820670988824633)\n",
      "     | > log_mle: -0.3772745132446289  (-0.3704781002468533)\n",
      "     | > loss_dur: 0.1797410547733307  (0.16227139035860697)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: -0.1772764027118683  (-0.20511367917060852)\n",
      "     | > log_mle: -0.36338019371032715  (-0.3697683095932007)\n",
      "     | > loss_dur: 0.18610379099845886  (0.16465463042259215)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: -0.2168714702129364  (-0.2061825692653656)\n",
      "     | > log_mle: -0.38072478771209717  (-0.37076435305855493)\n",
      "     | > loss_dur: 0.16385331749916077  (0.1645817837931893)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: -0.2277822047472  (-0.2079825388888518)\n",
      "     | > log_mle: -0.3660120964050293  (-0.3703683316707611)\n",
      "     | > loss_dur: 0.13822989165782928  (0.16238579278190932)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: -0.23517422378063202  (-0.21007420695745027)\n",
      "     | > log_mle: -0.3888578414916992  (-0.37179060165698713)\n",
      "     | > loss_dur: 0.1536836177110672  (0.16171639469953683)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: -0.21622234582901  (-0.21051335973399027)\n",
      "     | > log_mle: -0.3769289255142212  (-0.3721576247896467)\n",
      "     | > loss_dur: 0.16070657968521118  (0.16164426505565643)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: -0.20954488217830658  (-0.21044879456361135)\n",
      "     | > log_mle: -0.3693428039550781  (-0.3719699700673421)\n",
      "     | > loss_dur: 0.15979792177677155  (0.16152117550373077)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: -0.20733609795570374  (-0.21025425102561712)\n",
      "     | > log_mle: -0.37398087978363037  (-0.37209565192461014)\n",
      "     | > loss_dur: 0.16664478182792664  (0.16184140089899302)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: audio amplitude out of range, auto clipped.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[91m 0.004503026604652405 \u001b[0m(+0.001094520092010498)\n",
      "     | > avg_loss:\u001b[92m -0.21025425102561712 \u001b[0m(-0.006064062938094139)\n",
      "     | > avg_log_mle:\u001b[92m -0.37209565192461014 \u001b[0m(-0.004968129098415375)\n",
      "     | > avg_loss_dur:\u001b[92m 0.16184140089899302 \u001b[0m(-0.001095933374017477)\n",
      "\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 97/100\u001b[0m\n",
      " --> train/run-February-22-2025_10+59PM-fa84af3\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-23 07:21:37) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 07:21:44 -- STEP: 13/406 -- GLOBAL_STEP: 62125\u001b[0m\n",
      "     | > loss: -0.18137867748737335  (-0.19979934508983904)\n",
      "     | > log_mle: -0.34130656719207764  (-0.33697417149176967)\n",
      "     | > loss_dur: 0.15992788970470428  (0.1371748264019306)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(19.2827, device='cuda:0')  (tensor(72.6781, device='cuda:0'))\n",
      "     | > current_lr: 2.425e-05 \n",
      "     | > step_time: 0.3643  (0.3703913872058575)\n",
      "     | > loader_time: 0.0057  (0.006899631940401518)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 07:21:59 -- STEP: 38/406 -- GLOBAL_STEP: 62150\u001b[0m\n",
      "     | > loss: -0.1863153874874115  (-0.19325023693473717)\n",
      "     | > log_mle: -0.3468809127807617  (-0.33786117403130783)\n",
      "     | > loss_dur: 0.16056552529335022  (0.14461093709657066)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(38.5323, device='cuda:0')  (tensor(42.3714, device='cuda:0'))\n",
      "     | > current_lr: 2.425e-05 \n",
      "     | > step_time: 0.4736  (0.5257813303094161)\n",
      "     | > loader_time: 0.005  (0.008680889480992368)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 07:22:15 -- STEP: 63/406 -- GLOBAL_STEP: 62175\u001b[0m\n",
      "     | > loss: -0.1729133129119873  (-0.18859349072925627)\n",
      "     | > log_mle: -0.34041523933410645  (-0.33909814887576634)\n",
      "     | > loss_dur: 0.16750192642211914  (0.15050465814651004)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(25.2408, device='cuda:0')  (tensor(37.7543, device='cuda:0'))\n",
      "     | > current_lr: 2.425e-05 \n",
      "     | > step_time: 0.6247  (0.5620527835119338)\n",
      "     | > loader_time: 0.0048  (0.009720514691065232)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 07:22:31 -- STEP: 88/406 -- GLOBAL_STEP: 62200\u001b[0m\n",
      "     | > loss: -0.17469234764575958  (-0.18801478669047353)\n",
      "     | > log_mle: -0.336692214012146  (-0.3418929482048209)\n",
      "     | > loss_dur: 0.1619998663663864  (0.15387816151434722)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(33.0868, device='cuda:0')  (tensor(37.0111, device='cuda:0'))\n",
      "     | > current_lr: 2.425e-05 \n",
      "     | > step_time: 0.4371  (0.5793720890175214)\n",
      "     | > loader_time: 0.0069  (0.010074274106459183)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 07:22:48 -- STEP: 113/406 -- GLOBAL_STEP: 62225\u001b[0m\n",
      "     | > loss: -0.1680126190185547  (-0.1864080289296344)\n",
      "     | > log_mle: -0.3418290615081787  (-0.344265341758728)\n",
      "     | > loss_dur: 0.17381644248962402  (0.1578573128290936)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(34.0401, device='cuda:0')  (tensor(37.0673, device='cuda:0'))\n",
      "     | > current_lr: 2.425e-05 \n",
      "     | > step_time: 0.7675  (0.5942564348203948)\n",
      "     | > loader_time: 0.0061  (0.010317910034044652)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 07:23:05 -- STEP: 138/406 -- GLOBAL_STEP: 62250\u001b[0m\n",
      "     | > loss: -0.1605396270751953  (-0.18450555367314292)\n",
      "     | > log_mle: -0.35570716857910156  (-0.3456791907116986)\n",
      "     | > loss_dur: 0.19516754150390625  (0.1611736370385557)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(37.6787, device='cuda:0')  (tensor(37.0154, device='cuda:0'))\n",
      "     | > current_lr: 2.425e-05 \n",
      "     | > step_time: 0.8895  (0.6052019250565683)\n",
      "     | > loader_time: 0.0072  (0.010473047477611595)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 07:23:22 -- STEP: 163/406 -- GLOBAL_STEP: 62275\u001b[0m\n",
      "     | > loss: -0.18161912262439728  (-0.18382616012008643)\n",
      "     | > log_mle: -0.369346022605896  (-0.34725549908503434)\n",
      "     | > loss_dur: 0.18772689998149872  (0.1634293389649479)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(31.4436, device='cuda:0')  (tensor(36.9226, device='cuda:0'))\n",
      "     | > current_lr: 2.425e-05 \n",
      "     | > step_time: 0.6029  (0.6173476207475725)\n",
      "     | > loader_time: 0.0247  (0.010589620087044366)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 07:23:40 -- STEP: 188/406 -- GLOBAL_STEP: 62300\u001b[0m\n",
      "     | > loss: -0.19261033833026886  (-0.18452164253338854)\n",
      "     | > log_mle: -0.3673877716064453  (-0.3489234726479713)\n",
      "     | > loss_dur: 0.17477743327617645  (0.1644018301145827)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(38.0198, device='cuda:0')  (tensor(37.4295, device='cuda:0'))\n",
      "     | > current_lr: 2.425e-05 \n",
      "     | > step_time: 0.7678  (0.6279490323776901)\n",
      "     | > loader_time: 0.0082  (0.011359591433342463)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 07:23:58 -- STEP: 213/406 -- GLOBAL_STEP: 62325\u001b[0m\n",
      "     | > loss: -0.18322034180164337  (-0.1844455855832973)\n",
      "     | > log_mle: -0.3651355504989624  (-0.3501935592839416)\n",
      "     | > loss_dur: 0.18191520869731903  (0.1657479737006442)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(71.9463, device='cuda:0')  (tensor(36.8099, device='cuda:0'))\n",
      "     | > current_lr: 2.425e-05 \n",
      "     | > step_time: 0.462  (0.6361898995341277)\n",
      "     | > loader_time: 0.0076  (0.011776925252636829)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 07:24:18 -- STEP: 238/406 -- GLOBAL_STEP: 62350\u001b[0m\n",
      "     | > loss: -0.1885462999343872  (-0.1840910214711638)\n",
      "     | > log_mle: -0.374147891998291  (-0.3513541777594751)\n",
      "     | > loss_dur: 0.1856015920639038  (0.1672631562883112)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(20.2607, device='cuda:0')  (tensor(38.1855, device='cuda:0'))\n",
      "     | > current_lr: 2.425e-05 \n",
      "     | > step_time: 1.1212  (0.6494851523086812)\n",
      "     | > loader_time: 0.0288  (0.01233154685557389)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 07:24:38 -- STEP: 263/406 -- GLOBAL_STEP: 62375\u001b[0m\n",
      "     | > loss: -0.19583120942115784  (-0.18423260000495403)\n",
      "     | > log_mle: -0.3715782165527344  (-0.35238378220184674)\n",
      "     | > loss_dur: 0.17574700713157654  (0.16815118219689265)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(25.1497, device='cuda:0')  (tensor(39.1569, device='cuda:0'))\n",
      "     | > current_lr: 2.425e-05 \n",
      "     | > step_time: 0.6005  (0.6620964922379184)\n",
      "     | > loader_time: 0.0123  (0.012234948887117911)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 07:24:58 -- STEP: 288/406 -- GLOBAL_STEP: 62400\u001b[0m\n",
      "     | > loss: -0.18573981523513794  (-0.1843489978152017)\n",
      "     | > log_mle: -0.35621190071105957  (-0.35334010422229767)\n",
      "     | > loss_dur: 0.17047208547592163  (0.16899110640709591)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(27.6360, device='cuda:0')  (tensor(39.4623, device='cuda:0'))\n",
      "     | > current_lr: 2.425e-05 \n",
      "     | > step_time: 0.6128  (0.6735811738504309)\n",
      "     | > loader_time: 0.008  (0.012379626433054604)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 07:25:18 -- STEP: 313/406 -- GLOBAL_STEP: 62425\u001b[0m\n",
      "     | > loss: -0.1858557164669037  (-0.18439618905131427)\n",
      "     | > log_mle: -0.358542799949646  (-0.35417738585426406)\n",
      "     | > loss_dur: 0.1726870834827423  (0.16978119680294965)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(23.9449, device='cuda:0')  (tensor(39.4789, device='cuda:0'))\n",
      "     | > current_lr: 2.425e-05 \n",
      "     | > step_time: 0.6314  (0.6815939178101177)\n",
      "     | > loader_time: 0.0118  (0.0126343413282888)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 07:25:39 -- STEP: 338/406 -- GLOBAL_STEP: 62450\u001b[0m\n",
      "     | > loss: -0.18400290608406067  (-0.1840432374435064)\n",
      "     | > log_mle: -0.3629523515701294  (-0.35476450666168047)\n",
      "     | > loss_dur: 0.17894944548606873  (0.17072126921817377)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(30.5791, device='cuda:0')  (tensor(39.2787, device='cuda:0'))\n",
      "     | > current_lr: 2.425e-05 \n",
      "     | > step_time: 0.5703  (0.6904804657196865)\n",
      "     | > loader_time: 0.0209  (0.012802561359292657)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 07:26:00 -- STEP: 363/406 -- GLOBAL_STEP: 62475\u001b[0m\n",
      "     | > loss: -0.19124771654605865  (-0.18408744583116754)\n",
      "     | > log_mle: -0.37141168117523193  (-0.35551889704607065)\n",
      "     | > loss_dur: 0.18016396462917328  (0.17143145121490314)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(40.2044, device='cuda:0')  (tensor(38.9458, device='cuda:0'))\n",
      "     | > current_lr: 2.425e-05 \n",
      "     | > step_time: 0.9117  (0.700065616076972)\n",
      "     | > loader_time: 0.0103  (0.013063567400635438)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 07:26:22 -- STEP: 388/406 -- GLOBAL_STEP: 62500\u001b[0m\n",
      "     | > loss: -0.17860044538974762  (-0.18396827689919282)\n",
      "     | > log_mle: -0.367282509803772  (-0.3559541991076517)\n",
      "     | > loss_dur: 0.18868206441402435  (0.17198592220845896)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(45.0891, device='cuda:0')  (tensor(39.5900, device='cuda:0'))\n",
      "     | > current_lr: 2.425e-05 \n",
      "     | > step_time: 0.985  (0.7094499911229644)\n",
      "     | > loader_time: 0.0121  (0.013234086872376118)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: -0.16896261274814606  (-0.16896261274814606)\n",
      "     | > log_mle: -0.33711540699005127  (-0.33711540699005127)\n",
      "     | > loss_dur: 0.1681527942419052  (0.1681527942419052)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: -0.21569769084453583  (-0.21569769084453583)\n",
      "     | > log_mle: -0.3797522783279419  (-0.3797522783279419)\n",
      "     | > loss_dur: 0.16405458748340607  (0.16405458748340607)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: -0.2256975620985031  (-0.22069762647151947)\n",
      "     | > log_mle: -0.34609532356262207  (-0.362923800945282)\n",
      "     | > loss_dur: 0.12039776146411896  (0.1422261744737625)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: -0.2140190750360489  (-0.21847144265969595)\n",
      "     | > log_mle: -0.34919488430023193  (-0.35834749539693195)\n",
      "     | > loss_dur: 0.13517580926418304  (0.13987605273723602)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: -0.21567128598690033  (-0.21777140349149704)\n",
      "     | > log_mle: -0.3757857084274292  (-0.3627070486545563)\n",
      "     | > loss_dur: 0.16011442244052887  (0.14493564516305923)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: -0.22014166414737701  (-0.21824545562267303)\n",
      "     | > log_mle: -0.37413156032562256  (-0.3649919509887695)\n",
      "     | > loss_dur: 0.15398989617824554  (0.1467464953660965)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: -0.169082373380661  (-0.2100516085823377)\n",
      "     | > log_mle: -0.38541626930236816  (-0.36839600404103595)\n",
      "     | > loss_dur: 0.21633389592170715  (0.15834439545869827)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: -0.19658662378787994  (-0.20812803932598659)\n",
      "     | > log_mle: -0.3472769260406494  (-0.3653789928981236)\n",
      "     | > loss_dur: 0.15069030225276947  (0.157250953572137)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: -0.20976515114307404  (-0.20833267830312252)\n",
      "     | > log_mle: -0.3630770444869995  (-0.3650912493467331)\n",
      "     | > loss_dur: 0.15331189334392548  (0.15675857104361057)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: -0.2109290212392807  (-0.20862116085158455)\n",
      "     | > log_mle: -0.37279295921325684  (-0.36594699488745797)\n",
      "     | > loss_dur: 0.16186393797397614  (0.1573258340358734)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: -0.18125246465206146  (-0.20588429123163224)\n",
      "     | > log_mle: -0.35984301567077637  (-0.3653365969657898)\n",
      "     | > loss_dur: 0.1785905510187149  (0.15945230573415756)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: -0.21818244457244873  (-0.20700230517170645)\n",
      "     | > log_mle: -0.3766622543334961  (-0.3663662021810358)\n",
      "     | > loss_dur: 0.15847980976104736  (0.15936389700932937)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: -0.2272675335407257  (-0.20869107420245805)\n",
      "     | > log_mle: -0.36273109912872314  (-0.36606327692667645)\n",
      "     | > loss_dur: 0.13546356558799744  (0.1573722027242184)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: -0.23068228363990784  (-0.2103827056976465)\n",
      "     | > log_mle: -0.38353800773620605  (-0.36740748698894793)\n",
      "     | > loss_dur: 0.15285572409629822  (0.15702478129130146)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: -0.2129209190607071  (-0.21056400665215083)\n",
      "     | > log_mle: -0.3728550672531128  (-0.3677965998649597)\n",
      "     | > loss_dur: 0.1599341481924057  (0.1572325932128089)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: -0.21071754395961761  (-0.2105742424726486)\n",
      "     | > log_mle: -0.3649348020553589  (-0.3676058133443197)\n",
      "     | > loss_dur: 0.15421725809574127  (0.15703157087167108)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: -0.20703212916851044  (-0.21035286039113998)\n",
      "     | > log_mle: -0.37107956409454346  (-0.36782292276620865)\n",
      "     | > loss_dur: 0.16404743492603302  (0.1574700623750687)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: audio amplitude out of range, auto clipped.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.003743469715118408 \u001b[0m(-0.0007595568895339966)\n",
      "     | > avg_loss:\u001b[92m -0.21035286039113998 \u001b[0m(-9.860936552286148e-05)\n",
      "     | > avg_log_mle:\u001b[91m -0.36782292276620865 \u001b[0m(+0.004272729158401489)\n",
      "     | > avg_loss_dur:\u001b[92m 0.1574700623750687 \u001b[0m(-0.004371338523924323)\n",
      "\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 98/100\u001b[0m\n",
      " --> train/run-February-22-2025_10+59PM-fa84af3\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-23 07:26:47) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 07:26:52 -- STEP: 7/406 -- GLOBAL_STEP: 62525\u001b[0m\n",
      "     | > loss: -0.20265570282936096  (-0.2127133309841156)\n",
      "     | > log_mle: -0.33571887016296387  (-0.3417069741657802)\n",
      "     | > loss_dur: 0.1330631673336029  (0.1289936431816646)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(43.1438, device='cuda:0')  (tensor(30.6528, device='cuda:0'))\n",
      "     | > current_lr: 2.45e-05 \n",
      "     | > step_time: 0.3984  (0.44710779190063477)\n",
      "     | > loader_time: 0.005  (0.006742783955165318)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 07:27:07 -- STEP: 32/406 -- GLOBAL_STEP: 62550\u001b[0m\n",
      "     | > loss: -0.18753571808338165  (-0.19992520660161972)\n",
      "     | > log_mle: -0.3422255516052246  (-0.3404442332684994)\n",
      "     | > loss_dur: 0.15468983352184296  (0.14051902666687965)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(62.2859, device='cuda:0')  (tensor(46.7546, device='cuda:0'))\n",
      "     | > current_lr: 2.45e-05 \n",
      "     | > step_time: 0.47  (0.5275614708662033)\n",
      "     | > loader_time: 0.0066  (0.007638007402420045)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 07:27:23 -- STEP: 57/406 -- GLOBAL_STEP: 62575\u001b[0m\n",
      "     | > loss: -0.17280013859272003  (-0.19200357010490016)\n",
      "     | > log_mle: -0.33152341842651367  (-0.33946055905860767)\n",
      "     | > loss_dur: 0.15872327983379364  (0.1474569889537075)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(17.1336, device='cuda:0')  (tensor(37.8621, device='cuda:0'))\n",
      "     | > current_lr: 2.45e-05 \n",
      "     | > step_time: 0.335  (0.5723466622202025)\n",
      "     | > loader_time: 0.0048  (0.00800455243963944)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 07:27:39 -- STEP: 82/406 -- GLOBAL_STEP: 62600\u001b[0m\n",
      "     | > loss: -0.1867646723985672  (-0.18996969156148957)\n",
      "     | > log_mle: -0.35246360301971436  (-0.34130796572057204)\n",
      "     | > loss_dur: 0.16569893062114716  (0.15133827415908258)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(35.5244, device='cuda:0')  (tensor(36.3149, device='cuda:0'))\n",
      "     | > current_lr: 2.45e-05 \n",
      "     | > step_time: 0.7157  (0.5890257707456265)\n",
      "     | > loader_time: 0.0051  (0.008403353574799325)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 07:27:54 -- STEP: 107/406 -- GLOBAL_STEP: 62625\u001b[0m\n",
      "     | > loss: -0.2029951810836792  (-0.18942885964273293)\n",
      "     | > log_mle: -0.36122024059295654  (-0.34447439920122364)\n",
      "     | > loss_dur: 0.15822505950927734  (0.1550455395584908)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(47.8506, device='cuda:0')  (tensor(36.3306, device='cuda:0'))\n",
      "     | > current_lr: 2.45e-05 \n",
      "     | > step_time: 0.4161  (0.591549445535535)\n",
      "     | > loader_time: 0.0048  (0.008756412523929197)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 07:28:11 -- STEP: 132/406 -- GLOBAL_STEP: 62650\u001b[0m\n",
      "     | > loss: -0.20295178890228271  (-0.1885310677867947)\n",
      "     | > log_mle: -0.3733999729156494  (-0.34684927264849336)\n",
      "     | > loss_dur: 0.1704481840133667  (0.15831820486169867)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(38.0226, device='cuda:0')  (tensor(36.7676, device='cuda:0'))\n",
      "     | > current_lr: 2.45e-05 \n",
      "     | > step_time: 0.8007  (0.6056392247026617)\n",
      "     | > loader_time: 0.0046  (0.009261344418381195)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 07:28:28 -- STEP: 157/406 -- GLOBAL_STEP: 62675\u001b[0m\n",
      "     | > loss: -0.17649583518505096  (-0.18708904030596385)\n",
      "     | > log_mle: -0.34607553482055664  (-0.34842374825933164)\n",
      "     | > loss_dur: 0.16957969963550568  (0.16133470795336802)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(26.9393, device='cuda:0')  (tensor(38.0376, device='cuda:0'))\n",
      "     | > current_lr: 2.45e-05 \n",
      "     | > step_time: 0.5465  (0.6154610594366766)\n",
      "     | > loader_time: 0.0078  (0.009671353990105302)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 07:28:46 -- STEP: 182/406 -- GLOBAL_STEP: 62700\u001b[0m\n",
      "     | > loss: -0.18933726847171783  (-0.1869227667595005)\n",
      "     | > log_mle: -0.3569352626800537  (-0.3497164360769502)\n",
      "     | > loss_dur: 0.16759799420833588  (0.16279366931744985)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(25.5696, device='cuda:0')  (tensor(39.1006, device='cuda:0'))\n",
      "     | > current_lr: 2.45e-05 \n",
      "     | > step_time: 0.5578  (0.6243331131044324)\n",
      "     | > loader_time: 0.016  (0.01032033595410022)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 07:29:04 -- STEP: 207/406 -- GLOBAL_STEP: 62725\u001b[0m\n",
      "     | > loss: -0.17344385385513306  (-0.1865375016766471)\n",
      "     | > log_mle: -0.35668134689331055  (-0.3509630500406459)\n",
      "     | > loss_dur: 0.1832374930381775  (0.1644255483639989)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(31.2577, device='cuda:0')  (tensor(39.3632, device='cuda:0'))\n",
      "     | > current_lr: 2.45e-05 \n",
      "     | > step_time: 1.219  (0.6343551937508698)\n",
      "     | > loader_time: 0.0057  (0.010670681506539315)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 07:29:22 -- STEP: 232/406 -- GLOBAL_STEP: 62750\u001b[0m\n",
      "     | > loss: -0.1896061897277832  (-0.18685817911193298)\n",
      "     | > log_mle: -0.36576974391937256  (-0.3526281313649539)\n",
      "     | > loss_dur: 0.17616355419158936  (0.16576995225302105)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(41.1370, device='cuda:0')  (tensor(39.8479, device='cuda:0'))\n",
      "     | > current_lr: 2.45e-05 \n",
      "     | > step_time: 0.4781  (0.642918089340473)\n",
      "     | > loader_time: 0.0088  (0.011188633483031703)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 07:29:41 -- STEP: 257/406 -- GLOBAL_STEP: 62775\u001b[0m\n",
      "     | > loss: -0.18874292075634003  (-0.18716692269312277)\n",
      "     | > log_mle: -0.36703062057495117  (-0.3539812755028098)\n",
      "     | > loss_dur: 0.17828769981861115  (0.16681435280968707)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(48.1467, device='cuda:0')  (tensor(40.5148, device='cuda:0'))\n",
      "     | > current_lr: 2.45e-05 \n",
      "     | > step_time: 0.7991  (0.6509033446182073)\n",
      "     | > loader_time: 0.0102  (0.011440346677015729)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 07:30:00 -- STEP: 282/406 -- GLOBAL_STEP: 62800\u001b[0m\n",
      "     | > loss: -0.18956661224365234  (-0.1873426807793321)\n",
      "     | > log_mle: -0.3774341344833374  (-0.35502108614495453)\n",
      "     | > loss_dur: 0.18786752223968506  (0.16767840536562265)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(48.5734, device='cuda:0')  (tensor(39.9665, device='cuda:0'))\n",
      "     | > current_lr: 2.45e-05 \n",
      "     | > step_time: 0.8745  (0.6602525465877341)\n",
      "     | > loader_time: 0.0122  (0.01155062685621546)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 07:30:20 -- STEP: 307/406 -- GLOBAL_STEP: 62825\u001b[0m\n",
      "     | > loss: -0.1873549073934555  (-0.18720117488008378)\n",
      "     | > log_mle: -0.36158978939056396  (-0.35583693002644884)\n",
      "     | > loss_dur: 0.17423488199710846  (0.16863575514636525)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(35.8775, device='cuda:0')  (tensor(40.3719, device='cuda:0'))\n",
      "     | > current_lr: 2.45e-05 \n",
      "     | > step_time: 1.0406  (0.6680304491558756)\n",
      "     | > loader_time: 0.0142  (0.011798860195793624)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 07:30:40 -- STEP: 332/406 -- GLOBAL_STEP: 62850\u001b[0m\n",
      "     | > loss: -0.1791117787361145  (-0.1870326092803335)\n",
      "     | > log_mle: -0.35573911666870117  (-0.3564292903406075)\n",
      "     | > loss_dur: 0.17662733793258667  (0.16939668106027397)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(22.2475, device='cuda:0')  (tensor(40.1772, device='cuda:0'))\n",
      "     | > current_lr: 2.45e-05 \n",
      "     | > step_time: 0.6879  (0.6769822814378389)\n",
      "     | > loader_time: 0.0084  (0.012126574315220476)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 07:31:00 -- STEP: 357/406 -- GLOBAL_STEP: 62875\u001b[0m\n",
      "     | > loss: -0.17856469750404358  (-0.1869537282724675)\n",
      "     | > log_mle: -0.3622915744781494  (-0.3571856539456451)\n",
      "     | > loss_dur: 0.18372687697410583  (0.17023192567317763)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(43.7142, device='cuda:0')  (tensor(41.0525, device='cuda:0'))\n",
      "     | > current_lr: 2.45e-05 \n",
      "     | > step_time: 0.7777  (0.6851483780462863)\n",
      "     | > loader_time: 0.0068  (0.012275818015347007)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 07:31:22 -- STEP: 382/406 -- GLOBAL_STEP: 62900\u001b[0m\n",
      "     | > loss: -0.16230174899101257  (-0.1870521039004726)\n",
      "     | > log_mle: -0.35475409030914307  (-0.3578919178528312)\n",
      "     | > loss_dur: 0.1924523413181305  (0.17083981395235867)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(43.0735, device='cuda:0')  (tensor(41.4558, device='cuda:0'))\n",
      "     | > current_lr: 2.45e-05 \n",
      "     | > step_time: 0.6938  (0.6943745556926222)\n",
      "     | > loader_time: 0.009  (0.012509282970927772)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: -0.17868877947330475  (-0.17868877947330475)\n",
      "     | > log_mle: -0.34117400646209717  (-0.34117400646209717)\n",
      "     | > loss_dur: 0.16248522698879242  (0.16248522698879242)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: -0.22699899971485138  (-0.22699899971485138)\n",
      "     | > log_mle: -0.38789546489715576  (-0.38789546489715576)\n",
      "     | > loss_dur: 0.16089646518230438  (0.16089646518230438)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: -0.2232915461063385  (-0.22514527291059494)\n",
      "     | > log_mle: -0.35073232650756836  (-0.36931389570236206)\n",
      "     | > loss_dur: 0.12744078040122986  (0.14416862279176712)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: -0.21942201256752014  (-0.22323751946290335)\n",
      "     | > log_mle: -0.35849618911743164  (-0.36570799350738525)\n",
      "     | > loss_dur: 0.1390741765499115  (0.1424704740444819)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: -0.2328893393278122  (-0.22565047442913055)\n",
      "     | > log_mle: -0.3859691619873047  (-0.3707732856273651)\n",
      "     | > loss_dur: 0.1530798226594925  (0.14512281119823456)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: -0.23364050686359406  (-0.22724848091602326)\n",
      "     | > log_mle: -0.3890986442565918  (-0.37443835735321046)\n",
      "     | > loss_dur: 0.15545813739299774  (0.1471898764371872)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: -0.18160855770111084  (-0.21964182704687119)\n",
      "     | > log_mle: -0.4019176959991455  (-0.37901824712753296)\n",
      "     | > loss_dur: 0.22030913829803467  (0.15937642008066177)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: -0.19772441685199738  (-0.2165107684476035)\n",
      "     | > log_mle: -0.3564894199371338  (-0.3757998432431902)\n",
      "     | > loss_dur: 0.1587650030851364  (0.1592890747955867)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: -0.21846403181552887  (-0.21675492636859417)\n",
      "     | > log_mle: -0.3713386058807373  (-0.3752421885728836)\n",
      "     | > loss_dur: 0.15287457406520844  (0.15848726220428944)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: -0.21850213408470154  (-0.21694906055927277)\n",
      "     | > log_mle: -0.3847237825393677  (-0.37629569901360405)\n",
      "     | > loss_dur: 0.16622164845466614  (0.15934663845433128)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: -0.19198672473430634  (-0.21445282697677612)\n",
      "     | > log_mle: -0.36889123916625977  (-0.3755552530288696)\n",
      "     | > loss_dur: 0.17690451443195343  (0.16110242605209352)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: -0.2233155220746994  (-0.21525852653113278)\n",
      "     | > log_mle: -0.38687872886657715  (-0.37658465992320667)\n",
      "     | > loss_dur: 0.16356320679187775  (0.16132613339207388)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: -0.2317681908607483  (-0.21663433189193407)\n",
      "     | > log_mle: -0.37093639373779297  (-0.3761139710744222)\n",
      "     | > loss_dur: 0.13916820287704468  (0.15947963918248811)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: -0.2431662380695343  (-0.21867524775174949)\n",
      "     | > log_mle: -0.39598512649536133  (-0.3776425214914175)\n",
      "     | > loss_dur: 0.15281888842582703  (0.15896727373966804)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: -0.22694267332553864  (-0.21926577814987727)\n",
      "     | > log_mle: -0.38260841369628906  (-0.37799722807747976)\n",
      "     | > loss_dur: 0.15566574037075043  (0.1587314499276025)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: -0.2157144993543625  (-0.21902902623017628)\n",
      "     | > log_mle: -0.37457168102264404  (-0.37776885827382406)\n",
      "     | > loss_dur: 0.15885718166828156  (0.15873983204364778)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: -0.2128562331199646  (-0.21864322666078806)\n",
      "     | > log_mle: -0.38086414337158203  (-0.37796231359243393)\n",
      "     | > loss_dur: 0.16800791025161743  (0.15931908693164587)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: audio amplitude out of range, auto clipped.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[91m 0.004013121128082275 \u001b[0m(+0.0002696514129638672)\n",
      "     | > avg_loss:\u001b[92m -0.21864322666078806 \u001b[0m(-0.008290366269648075)\n",
      "     | > avg_log_mle:\u001b[92m -0.37796231359243393 \u001b[0m(-0.01013939082622528)\n",
      "     | > avg_loss_dur:\u001b[91m 0.15931908693164587 \u001b[0m(+0.001849024556577178)\n",
      "\n",
      " > BEST MODEL : train/run-February-22-2025_10+59PM-fa84af3/best_model_62924.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 99/100\u001b[0m\n",
      " --> train/run-February-22-2025_10+59PM-fa84af3\n",
      "\n",
      "\u001b[1m > TRAINING (2025-02-23 07:31:54) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 07:31:57 -- STEP: 1/406 -- GLOBAL_STEP: 62925\u001b[0m\n",
      "     | > loss: -0.22806298732757568  (-0.22806298732757568)\n",
      "     | > log_mle: -0.3431999683380127  (-0.3431999683380127)\n",
      "     | > loss_dur: 0.11513698101043701  (0.11513698101043701)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(39.6526, device='cuda:0')  (tensor(39.6526, device='cuda:0'))\n",
      "     | > current_lr: 2.475e-05 \n",
      "     | > step_time: 0.4753  (0.47525715827941895)\n",
      "     | > loader_time: 0.0355  (0.03551912307739258)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 07:32:09 -- STEP: 26/406 -- GLOBAL_STEP: 62950\u001b[0m\n",
      "     | > loss: -0.19858068227767944  (-0.1996596765059691)\n",
      "     | > log_mle: -0.335965633392334  (-0.3389465625469501)\n",
      "     | > loss_dur: 0.13738495111465454  (0.139286886040981)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(17.1701, device='cuda:0')  (tensor(42.6380, device='cuda:0'))\n",
      "     | > current_lr: 2.475e-05 \n",
      "     | > step_time: 0.408  (0.4767279074742244)\n",
      "     | > loader_time: 0.0046  (0.009815711241502028)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 07:32:25 -- STEP: 51/406 -- GLOBAL_STEP: 62975\u001b[0m\n",
      "     | > loss: -0.19783508777618408  (-0.19064544199728498)\n",
      "     | > log_mle: -0.3553500175476074  (-0.3382120553184958)\n",
      "     | > loss_dur: 0.15751492977142334  (0.14756661332121085)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(17.4328, device='cuda:0')  (tensor(34.5586, device='cuda:0'))\n",
      "     | > current_lr: 2.475e-05 \n",
      "     | > step_time: 0.6644  (0.5508239409502816)\n",
      "     | > loader_time: 0.0066  (0.011557406070185643)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 07:32:42 -- STEP: 76/406 -- GLOBAL_STEP: 63000\u001b[0m\n",
      "     | > loss: -0.18915390968322754  (-0.18950121849775317)\n",
      "     | > log_mle: -0.34151506423950195  (-0.34114562210283783)\n",
      "     | > loss_dur: 0.15236115455627441  (0.15164440360508466)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(45.7054, device='cuda:0')  (tensor(35.2278, device='cuda:0'))\n",
      "     | > current_lr: 2.475e-05 \n",
      "     | > step_time: 0.4523  (0.5802420126764397)\n",
      "     | > loader_time: 0.0085  (0.010806918144226078)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 07:32:58 -- STEP: 101/406 -- GLOBAL_STEP: 63025\u001b[0m\n",
      "     | > loss: -0.16180582344532013  (-0.18790519945692316)\n",
      "     | > log_mle: -0.3445223569869995  (-0.3436696647417427)\n",
      "     | > loss_dur: 0.18271653354167938  (0.1557644652848196)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(31.8463, device='cuda:0')  (tensor(33.8353, device='cuda:0'))\n",
      "     | > current_lr: 2.475e-05 \n",
      "     | > step_time: 0.3444  (0.5959576899462407)\n",
      "     | > loader_time: 0.0078  (0.010937244585244968)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 07:33:15 -- STEP: 126/406 -- GLOBAL_STEP: 63050\u001b[0m\n",
      "     | > loss: -0.18288102746009827  (-0.1874277158862069)\n",
      "     | > log_mle: -0.3539224863052368  (-0.34610196238472346)\n",
      "     | > loss_dur: 0.17104145884513855  (0.15867424649851658)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(43.5669, device='cuda:0')  (tensor(36.5255, device='cuda:0'))\n",
      "     | > current_lr: 2.475e-05 \n",
      "     | > step_time: 0.6609  (0.6089327600267197)\n",
      "     | > loader_time: 0.0224  (0.010759393374125166)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 07:33:31 -- STEP: 151/406 -- GLOBAL_STEP: 63075\u001b[0m\n",
      "     | > loss: -0.15962401032447815  (-0.18717617674773893)\n",
      "     | > log_mle: -0.3478670120239258  (-0.3484446307681255)\n",
      "     | > loss_dur: 0.18824300169944763  (0.16126845402038645)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(117.3617, device='cuda:0')  (tensor(37.1990, device='cuda:0'))\n",
      "     | > current_lr: 2.475e-05 \n",
      "     | > step_time: 0.9597  (0.613820649140718)\n",
      "     | > loader_time: 0.0164  (0.011107861600964277)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 07:33:49 -- STEP: 176/406 -- GLOBAL_STEP: 63100\u001b[0m\n",
      "     | > loss: -0.18535764515399933  (-0.18663069292564288)\n",
      "     | > log_mle: -0.3560001850128174  (-0.3497197208079424)\n",
      "     | > loss_dur: 0.17064253985881805  (0.1630890278822995)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(45.5300, device='cuda:0')  (tensor(36.8857, device='cuda:0'))\n",
      "     | > current_lr: 2.475e-05 \n",
      "     | > step_time: 0.5536  (0.6261192492463376)\n",
      "     | > loader_time: 0.0154  (0.011364893479780718)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 07:34:08 -- STEP: 201/406 -- GLOBAL_STEP: 63125\u001b[0m\n",
      "     | > loss: -0.1958639919757843  (-0.1871560984731314)\n",
      "     | > log_mle: -0.35321366786956787  (-0.3513939267960353)\n",
      "     | > loss_dur: 0.15734967589378357  (0.16423782832290396)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(42.9723, device='cuda:0')  (tensor(37.0489, device='cuda:0'))\n",
      "     | > current_lr: 2.475e-05 \n",
      "     | > step_time: 0.8218  (0.6384523733338319)\n",
      "     | > loader_time: 0.0074  (0.011780879983854532)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 07:34:27 -- STEP: 226/406 -- GLOBAL_STEP: 63150\u001b[0m\n",
      "     | > loss: -0.18656355142593384  (-0.187298414453996)\n",
      "     | > log_mle: -0.369388222694397  (-0.35293940474501745)\n",
      "     | > loss_dur: 0.18282467126846313  (0.1656409902910215)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(59.1038, device='cuda:0')  (tensor(37.7473, device='cuda:0'))\n",
      "     | > current_lr: 2.475e-05 \n",
      "     | > step_time: 0.7631  (0.6490490288861035)\n",
      "     | > loader_time: 0.0056  (0.012037997752164317)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 07:34:46 -- STEP: 251/406 -- GLOBAL_STEP: 63175\u001b[0m\n",
      "     | > loss: -0.19062767922878265  (-0.18752080819521294)\n",
      "     | > log_mle: -0.363672137260437  (-0.3542201039325668)\n",
      "     | > loss_dur: 0.17304445803165436  (0.16669929573735387)\n",
      "     | > amp_scaler: 1024.0  (1024.0)\n",
      "     | > grad_norm: tensor(50.3330, device='cuda:0')  (tensor(38.2038, device='cuda:0'))\n",
      "     | > current_lr: 2.475e-05 \n",
      "     | > step_time: 0.4412  (0.6595527593833046)\n",
      "     | > loader_time: 0.007  (0.01206285260113112)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 07:35:04 -- STEP: 276/406 -- GLOBAL_STEP: 63200\u001b[0m\n",
      "     | > loss: -0.17217446863651276  (-0.187575552828502)\n",
      "     | > log_mle: -0.3603132963180542  (-0.35513025824574446)\n",
      "     | > loss_dur: 0.18813882768154144  (0.16755470541724254)\n",
      "     | > amp_scaler: 2048.0  (1046.2608695652173)\n",
      "     | > grad_norm: tensor(31.6289, device='cuda:0')  (tensor(37.9834, device='cuda:0'))\n",
      "     | > current_lr: 2.475e-05 \n",
      "     | > step_time: 0.7765  (0.6641295612722208)\n",
      "     | > loader_time: 0.0059  (0.011901205000670058)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 07:35:24 -- STEP: 301/406 -- GLOBAL_STEP: 63225\u001b[0m\n",
      "     | > loss: -0.1991187036037445  (-0.1876267348215034)\n",
      "     | > log_mle: -0.3834545612335205  (-0.35597831664291324)\n",
      "     | > loss_dur: 0.184335857629776  (0.16835158182140988)\n",
      "     | > amp_scaler: 2048.0  (1129.4617940199332)\n",
      "     | > grad_norm: tensor(93.4604, device='cuda:0')  (tensor(37.6931, device='cuda:0'))\n",
      "     | > current_lr: 2.475e-05 \n",
      "     | > step_time: 0.9323  (0.673571364824162)\n",
      "     | > loader_time: 0.0069  (0.012475385222324102)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 07:35:45 -- STEP: 326/406 -- GLOBAL_STEP: 63250\u001b[0m\n",
      "     | > loss: -0.18316248059272766  (-0.1875472745738147)\n",
      "     | > log_mle: -0.3561636209487915  (-0.3566391029240895)\n",
      "     | > loss_dur: 0.17300114035606384  (0.1690918283502748)\n",
      "     | > amp_scaler: 2048.0  (1199.9018404907974)\n",
      "     | > grad_norm: tensor(56.5800, device='cuda:0')  (tensor(38.4037, device='cuda:0'))\n",
      "     | > current_lr: 2.475e-05 \n",
      "     | > step_time: 0.706  (0.6835386796963)\n",
      "     | > loader_time: 0.0105  (0.01279423353862177)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 07:36:06 -- STEP: 351/406 -- GLOBAL_STEP: 63275\u001b[0m\n",
      "     | > loss: -0.15737509727478027  (-0.18721924310396207)\n",
      "     | > log_mle: -0.3586611747741699  (-0.35721998744540745)\n",
      "     | > loss_dur: 0.20128607749938965  (0.1700007443414455)\n",
      "     | > amp_scaler: 2048.0  (1260.3076923076922)\n",
      "     | > grad_norm: tensor(19.5786, device='cuda:0')  (tensor(38.8739, device='cuda:0'))\n",
      "     | > current_lr: 2.475e-05 \n",
      "     | > step_time: 0.7427  (0.692267184923178)\n",
      "     | > loader_time: 0.0093  (0.01298112679071236)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 07:36:27 -- STEP: 376/406 -- GLOBAL_STEP: 63300\u001b[0m\n",
      "     | > loss: -0.19056934118270874  (-0.187406775719942)\n",
      "     | > log_mle: -0.37157297134399414  (-0.3579651519973228)\n",
      "     | > loss_dur: 0.1810036301612854  (0.1705583762773808)\n",
      "     | > amp_scaler: 2048.0  (1312.6808510638296)\n",
      "     | > grad_norm: tensor(20.5065, device='cuda:0')  (tensor(39.4012, device='cuda:0'))\n",
      "     | > current_lr: 2.475e-05 \n",
      "     | > step_time: 0.5677  (0.7003669028586536)\n",
      "     | > loader_time: 0.0098  (0.012987450082251363)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-02-23 07:36:47 -- STEP: 401/406 -- GLOBAL_STEP: 63325\u001b[0m\n",
      "     | > loss: -0.19905684888362885  (-0.18761324406859292)\n",
      "     | > log_mle: -0.3723376989364624  (-0.35867102098583886)\n",
      "     | > loss_dur: 0.17328085005283356  (0.1710577769172459)\n",
      "     | > amp_scaler: 2048.0  (1358.5236907730675)\n",
      "     | > grad_norm: tensor(54.5164, device='cuda:0')  (tensor(40.3410, device='cuda:0'))\n",
      "     | > current_lr: 2.475e-05 \n",
      "     | > step_time: 0.6059  (0.7064106220616373)\n",
      "     | > loader_time: 0.0077  (0.013136120508436547)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\u001b[1m   --> STEP: 0\u001b[0m\n",
      "     | > loss: -0.1814359575510025  (-0.1814359575510025)\n",
      "     | > log_mle: -0.3435838222503662  (-0.3435838222503662)\n",
      "     | > loss_dur: 0.1621478646993637  (0.1621478646993637)\n",
      "\n",
      "\u001b[1m   --> STEP: 1\u001b[0m\n",
      "     | > loss: -0.233316570520401  (-0.233316570520401)\n",
      "     | > log_mle: -0.391304612159729  (-0.391304612159729)\n",
      "     | > loss_dur: 0.157988041639328  (0.157988041639328)\n",
      "\n",
      "\u001b[1m   --> STEP: 2\u001b[0m\n",
      "     | > loss: -0.23117363452911377  (-0.23224510252475739)\n",
      "     | > log_mle: -0.3537766933441162  (-0.3725406527519226)\n",
      "     | > loss_dur: 0.12260305881500244  (0.14029555022716522)\n",
      "\n",
      "\u001b[1m   --> STEP: 3\u001b[0m\n",
      "     | > loss: -0.22473300993442535  (-0.22974107166131338)\n",
      "     | > log_mle: -0.3617837429046631  (-0.36895501613616943)\n",
      "     | > loss_dur: 0.13705073297023773  (0.13921394447485605)\n",
      "\n",
      "\u001b[1m   --> STEP: 4\u001b[0m\n",
      "     | > loss: -0.23509478569030762  (-0.23107950016856194)\n",
      "     | > log_mle: -0.3896583318710327  (-0.37413084506988525)\n",
      "     | > loss_dur: 0.1545635461807251  (0.14305134490132332)\n",
      "\n",
      "\u001b[1m   --> STEP: 5\u001b[0m\n",
      "     | > loss: -0.23746800422668457  (-0.23235720098018647)\n",
      "     | > log_mle: -0.39312684535980225  (-0.37793004512786865)\n",
      "     | > loss_dur: 0.15565884113311768  (0.14557284414768218)\n",
      "\n",
      "\u001b[1m   --> STEP: 6\u001b[0m\n",
      "     | > loss: -0.183052659034729  (-0.22413977732261023)\n",
      "     | > log_mle: -0.4067293405532837  (-0.3827299276987712)\n",
      "     | > loss_dur: 0.2236766815185547  (0.15859015037616095)\n",
      "\n",
      "\u001b[1m   --> STEP: 7\u001b[0m\n",
      "     | > loss: -0.20575585961341858  (-0.22151350336415426)\n",
      "     | > log_mle: -0.3597712516784668  (-0.3794501168387277)\n",
      "     | > loss_dur: 0.15401539206504822  (0.1579366134745734)\n",
      "\n",
      "\u001b[1m   --> STEP: 8\u001b[0m\n",
      "     | > loss: -0.22318485379219055  (-0.2217224221676588)\n",
      "     | > log_mle: -0.37466323375701904  (-0.3788517564535141)\n",
      "     | > loss_dur: 0.1514783799648285  (0.1571293342858553)\n",
      "\n",
      "\u001b[1m   --> STEP: 9\u001b[0m\n",
      "     | > loss: -0.22203606367111206  (-0.22175727122359806)\n",
      "     | > log_mle: -0.38857877254486084  (-0.3799325360192193)\n",
      "     | > loss_dur: 0.16654270887374878  (0.15817526479562125)\n",
      "\n",
      "\u001b[1m   --> STEP: 10\u001b[0m\n",
      "     | > loss: -0.19221064448356628  (-0.21880260854959488)\n",
      "     | > log_mle: -0.37263381481170654  (-0.379202663898468)\n",
      "     | > loss_dur: 0.18042317032814026  (0.16040005534887314)\n",
      "\n",
      "\u001b[1m   --> STEP: 11\u001b[0m\n",
      "     | > loss: -0.2275751829147339  (-0.21960011531006207)\n",
      "     | > log_mle: -0.3906458616256714  (-0.38024295460094104)\n",
      "     | > loss_dur: 0.1630706787109375  (0.160642839290879)\n",
      "\n",
      "\u001b[1m   --> STEP: 12\u001b[0m\n",
      "     | > loss: -0.23755355179309845  (-0.22109623501698175)\n",
      "     | > log_mle: -0.3741891384124756  (-0.3797384699185689)\n",
      "     | > loss_dur: 0.13663558661937714  (0.15864223490158716)\n",
      "\n",
      "\u001b[1m   --> STEP: 13\u001b[0m\n",
      "     | > loss: -0.24707403779029846  (-0.22309452753800613)\n",
      "     | > log_mle: -0.400376558303833  (-0.38132601517897385)\n",
      "     | > loss_dur: 0.15330252051353455  (0.15823148764096773)\n",
      "\n",
      "\u001b[1m   --> STEP: 14\u001b[0m\n",
      "     | > loss: -0.2300257533788681  (-0.22358961509806768)\n",
      "     | > log_mle: -0.3865540027618408  (-0.38169944286346436)\n",
      "     | > loss_dur: 0.15652824938297272  (0.15810982776539667)\n",
      "\n",
      "\u001b[1m   --> STEP: 15\u001b[0m\n",
      "     | > loss: -0.22154715657234192  (-0.22345345119635265)\n",
      "     | > log_mle: -0.3781994581222534  (-0.3814661105473836)\n",
      "     | > loss_dur: 0.1566523015499115  (0.15801265935103098)\n",
      "\n",
      "\u001b[1m   --> STEP: 16\u001b[0m\n",
      "     | > loss: -0.22212889790534973  (-0.22337066661566496)\n",
      "     | > log_mle: -0.3846251964569092  (-0.381663553416729)\n",
      "     | > loss_dur: 0.16249629855155945  (0.15829288680106401)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: audio amplitude out of range, auto clipped.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.0034129321575164795 \u001b[0m(-0.0006001889705657959)\n",
      "     | > avg_loss:\u001b[92m -0.22337066661566496 \u001b[0m(-0.0047274399548769)\n",
      "     | > avg_log_mle:\u001b[92m -0.381663553416729 \u001b[0m(-0.003701239824295044)\n",
      "     | > avg_loss_dur:\u001b[92m 0.15829288680106401 \u001b[0m(-0.0010262001305818558)\n",
      "\n",
      " > BEST MODEL : train/run-February-22-2025_10+59PM-fa84af3/best_model_63330.pth\n"
     ]
    }
   ],
   "source": [
    "trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
